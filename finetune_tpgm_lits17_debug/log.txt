[17:54:35.288] Namespace(root_path='./datasets/lits17/train_npz', dataset='lits17', list_dir='./lists/lits17', num_classes=3, model_num_classes=9, output_dir='./finetune_tpgm_lits17_debug', max_iterations=10000, max_epochs=20, batch_size=16, n_gpu=1, deterministic=1, base_lr=0.0001, img_size=224, seed=1234, cfg='configs/finetune.yaml', pretrained_path='./finetune_tpgm_kits23_debug/finetuned_final.pth', data_fraction=0.2, freeze_layers=0, opts=None, zip=False, cache_mode='part', resume=None, accumulation_steps=None, use_checkpoint=False, amp_opt_level='O1', tag=None, eval=False, throughput=False, tpgm_norm_mode='l2', tpgm_lr=0.01, tpgm_iters=100, tpgm_exclude=[], tpgm_frequency=2, tpgm_start_epoch=10, disable_tpgm=False, gpu_id=1)
[17:54:35.293] Training lits17 with 3 classes
[17:54:35.293] Using 2968/14843 samples for finetuning
[17:54:35.293] Using 50/14843 samples for TPGM
[17:54:35.293] TPGM enabled: True
[17:54:46.478] 186 iterations per epoch
[17:55:00.502] Epoch 0, Iter 10: loss=0.3005, ce=0.0812, dice=0.4467, grad_norm=0.617134
[17:55:02.711] Epoch 0, Iter 20: loss=0.1568, ce=0.0476, dice=0.2296, grad_norm=1.909101
[17:55:04.943] Epoch 0, Iter 30: loss=0.2279, ce=0.0169, dice=0.3686, grad_norm=0.290755
[17:55:07.154] Epoch 0, Iter 40: loss=0.1029, ce=0.0162, dice=0.1607, grad_norm=1.126135
[17:55:09.384] Epoch 0, Iter 50: loss=0.2482, ce=0.0194, dice=0.4008, grad_norm=0.223036
[17:55:11.570] Epoch 0, Iter 60: loss=0.1846, ce=0.0057, dice=0.3040, grad_norm=1.208879
[17:55:13.766] Epoch 0, Iter 70: loss=0.2380, ce=0.0267, dice=0.3789, grad_norm=0.243705
[17:55:15.948] Epoch 0, Iter 80: loss=0.1975, ce=0.0149, dice=0.3192, grad_norm=0.830518
[17:55:18.143] Epoch 0, Iter 90: loss=0.0949, ce=0.0056, dice=0.1545, grad_norm=1.384770
[17:55:20.330] Epoch 0, Iter 100: loss=0.2272, ce=0.0181, dice=0.3665, grad_norm=0.391445
[17:55:22.518] Epoch 0, Iter 110: loss=0.0486, ce=0.0165, dice=0.0701, grad_norm=0.931266
[17:55:24.720] Epoch 0, Iter 120: loss=0.0755, ce=0.0093, dice=0.1196, grad_norm=1.364743
[17:55:26.917] Epoch 0, Iter 130: loss=0.0776, ce=0.0057, dice=0.1256, grad_norm=0.193375
[17:55:29.125] Epoch 0, Iter 140: loss=0.2138, ce=0.0052, dice=0.3529, grad_norm=0.087870
[17:55:31.342] Epoch 0, Iter 150: loss=0.0706, ce=0.0093, dice=0.1115, grad_norm=1.512717
[17:55:33.536] Epoch 0, Iter 160: loss=0.2164, ce=0.0084, dice=0.3550, grad_norm=0.238587
[17:55:35.759] Epoch 0, Iter 170: loss=0.1522, ce=0.0147, dice=0.2439, grad_norm=2.152237
[17:55:37.960] Epoch 0, Iter 180: loss=0.2153, ce=0.0066, dice=0.3544, grad_norm=0.328766
[17:55:39.889] Epoch 0: Avg Loss=0.1752, CE=0.0206, Dice=0.2783
[17:55:51.803] Epoch 1, Iter 190: loss=0.2075, ce=0.0100, dice=0.3391, grad_norm=0.436053
[17:55:54.036] Epoch 1, Iter 200: loss=0.0520, ce=0.0059, dice=0.0828, grad_norm=1.168899
[17:55:56.244] Epoch 1, Iter 210: loss=0.1781, ce=0.0021, dice=0.2955, grad_norm=1.405706
[17:55:58.428] Epoch 1, Iter 220: loss=0.0638, ce=0.0041, dice=0.1036, grad_norm=0.963348
[17:56:00.630] Epoch 1, Iter 230: loss=0.2136, ce=0.0114, dice=0.3485, grad_norm=0.113993
[17:56:02.836] Epoch 1, Iter 240: loss=0.2067, ce=0.0042, dice=0.3416, grad_norm=0.040923
[17:56:05.067] Epoch 1, Iter 250: loss=0.2083, ce=0.0035, dice=0.3447, grad_norm=0.035897
[17:56:07.273] Epoch 1, Iter 260: loss=0.2132, ce=0.0051, dice=0.3519, grad_norm=0.037948
[17:56:09.513] Epoch 1, Iter 270: loss=0.0582, ce=0.0036, dice=0.0946, grad_norm=0.515972
[17:56:11.748] Epoch 1, Iter 280: loss=0.2075, ce=0.0037, dice=0.3433, grad_norm=0.198503
[17:56:13.954] Epoch 1, Iter 290: loss=0.0530, ce=0.0105, dice=0.0813, grad_norm=0.951695
[17:56:16.152] Epoch 1, Iter 300: loss=0.0726, ce=0.0021, dice=0.1196, grad_norm=1.679480
[17:56:18.361] Epoch 1, Iter 310: loss=0.2092, ce=0.0070, dice=0.3440, grad_norm=0.043406
[17:56:20.559] Epoch 1, Iter 320: loss=0.0392, ce=0.0159, dice=0.0547, grad_norm=0.325617
[17:56:22.760] Epoch 1, Iter 330: loss=0.2120, ce=0.0082, dice=0.3479, grad_norm=0.138852
[17:56:24.956] Epoch 1, Iter 340: loss=0.0370, ce=0.0101, dice=0.0549, grad_norm=0.272520
[17:56:27.155] Epoch 1, Iter 350: loss=0.1106, ce=0.0107, dice=0.1773, grad_norm=1.112820
[17:56:29.361] Epoch 1, Iter 360: loss=0.1926, ce=0.0050, dice=0.3177, grad_norm=0.874021
[17:56:31.569] Epoch 1, Iter 370: loss=0.0671, ce=0.0098, dice=0.1054, grad_norm=0.693195
[17:56:32.627] Epoch 1: Avg Loss=0.1188, CE=0.0075, Dice=0.1931
[17:56:46.285] Epoch 2, Iter 380: loss=0.1008, ce=0.0052, dice=0.1644, grad_norm=0.286959
[17:56:48.532] Epoch 2, Iter 390: loss=0.4007, ce=0.0017, dice=0.6667, grad_norm=0.039779
[17:56:50.782] Epoch 2, Iter 400: loss=0.1053, ce=0.0084, dice=0.1698, grad_norm=2.071921
[17:56:53.134] Epoch 2, Iter 410: loss=0.1922, ce=0.0026, dice=0.3186, grad_norm=1.900773
[17:56:55.386] Epoch 2, Iter 420: loss=0.0445, ce=0.0136, dice=0.0651, grad_norm=0.540342
[17:56:57.631] Epoch 2, Iter 430: loss=0.0493, ce=0.0101, dice=0.0754, grad_norm=0.402827
[17:56:59.863] Epoch 2, Iter 440: loss=0.2124, ce=0.0127, dice=0.3455, grad_norm=0.175331
[17:57:02.115] Epoch 2, Iter 450: loss=0.0488, ce=0.0056, dice=0.0776, grad_norm=1.156874
[17:57:04.364] Epoch 2, Iter 460: loss=0.2140, ce=0.0083, dice=0.3512, grad_norm=0.240494
[17:57:06.615] Epoch 2, Iter 470: loss=0.1725, ce=0.0049, dice=0.2843, grad_norm=2.308557
[17:57:08.830] Epoch 2, Iter 480: loss=0.2038, ce=0.0084, dice=0.3341, grad_norm=0.354460
[17:57:11.071] Epoch 2, Iter 490: loss=0.0495, ce=0.0105, dice=0.0754, grad_norm=0.983882
[17:57:13.314] Epoch 2, Iter 500: loss=0.2642, ce=0.0026, dice=0.4385, grad_norm=0.347099
[17:57:15.535] Epoch 2, Iter 510: loss=0.0730, ce=0.0037, dice=0.1192, grad_norm=0.622765
[17:57:17.765] Epoch 2, Iter 520: loss=0.1070, ce=0.0028, dice=0.1764, grad_norm=0.936374
[17:57:19.999] Epoch 2, Iter 530: loss=0.0277, ce=0.0024, dice=0.0446, grad_norm=0.192629
[17:57:22.211] Epoch 2, Iter 540: loss=0.2106, ce=0.0019, dice=0.3497, grad_norm=0.116737
[17:57:24.470] Epoch 2, Iter 550: loss=0.0290, ce=0.0030, dice=0.0463, grad_norm=0.370744
[17:57:26.787] Epoch 2: Avg Loss=0.1065, CE=0.0066, Dice=0.1731
[17:57:38.725] Epoch 3, Iter 560: loss=0.0908, ce=0.0079, dice=0.1460, grad_norm=1.099594
[17:57:40.934] Epoch 3, Iter 570: loss=0.2346, ce=0.0075, dice=0.3860, grad_norm=0.502329
[17:57:43.120] Epoch 3, Iter 580: loss=0.0359, ce=0.0110, dice=0.0525, grad_norm=0.699033
[17:57:45.320] Epoch 3, Iter 590: loss=0.2145, ce=0.0045, dice=0.3545, grad_norm=0.082570
[17:57:47.513] Epoch 3, Iter 600: loss=0.0470, ce=0.0081, dice=0.0729, grad_norm=0.461558
[17:57:49.722] Epoch 3, Iter 610: loss=0.0693, ce=0.0056, dice=0.1118, grad_norm=0.447671
[17:57:51.911] Epoch 3, Iter 620: loss=0.0581, ce=0.0039, dice=0.0942, grad_norm=0.797828
[17:57:54.119] Epoch 3, Iter 630: loss=0.0408, ce=0.0074, dice=0.0630, grad_norm=0.284586
[17:57:56.330] Epoch 3, Iter 640: loss=0.0555, ce=0.0076, dice=0.0875, grad_norm=0.400376
[17:57:58.540] Epoch 3, Iter 650: loss=0.2106, ce=0.0058, dice=0.3471, grad_norm=0.042468
[17:58:00.745] Epoch 3, Iter 660: loss=0.0406, ce=0.0043, dice=0.0648, grad_norm=0.321524
[17:58:02.942] Epoch 3, Iter 670: loss=0.0321, ce=0.0059, dice=0.0496, grad_norm=0.200890
[17:58:05.144] Epoch 3, Iter 680: loss=0.1865, ce=0.0063, dice=0.3066, grad_norm=1.200767
[17:58:07.351] Epoch 3, Iter 690: loss=0.0417, ce=0.0115, dice=0.0618, grad_norm=0.550549
[17:58:09.543] Epoch 3, Iter 700: loss=0.1963, ce=0.0017, dice=0.3260, grad_norm=0.645657
[17:58:11.754] Epoch 3, Iter 710: loss=0.0199, ce=0.0047, dice=0.0300, grad_norm=0.121800
[17:58:13.947] Epoch 3, Iter 720: loss=0.0458, ce=0.0070, dice=0.0717, grad_norm=0.264226
[17:58:16.173] Epoch 3, Iter 730: loss=0.0299, ce=0.0058, dice=0.0460, grad_norm=0.216514
[17:58:18.379] Epoch 3, Iter 740: loss=0.0271, ce=0.0092, dice=0.0391, grad_norm=0.340316
[17:58:19.841] Epoch 3: Avg Loss=0.1013, CE=0.0061, Dice=0.1647
[17:58:32.383] Epoch 4, Iter 750: loss=0.2100, ce=0.0033, dice=0.3479, grad_norm=0.196557
[17:58:34.578] Epoch 4, Iter 760: loss=0.1540, ce=0.0051, dice=0.2532, grad_norm=4.817671
[17:58:36.820] Epoch 4, Iter 770: loss=0.2065, ce=0.0029, dice=0.3423, grad_norm=0.042024
[17:58:39.025] Epoch 4, Iter 780: loss=0.2096, ce=0.0004, dice=0.3491, grad_norm=0.095067
[17:58:41.218] Epoch 4, Iter 790: loss=0.2062, ce=0.0025, dice=0.3421, grad_norm=0.110370
[17:58:43.414] Epoch 4, Iter 800: loss=0.0346, ce=0.0052, dice=0.0542, grad_norm=0.464155
[17:58:45.605] Epoch 4, Iter 810: loss=0.0211, ce=0.0041, dice=0.0324, grad_norm=0.204564
[17:58:47.801] Epoch 4, Iter 820: loss=0.0243, ce=0.0023, dice=0.0390, grad_norm=0.258559
[17:58:50.001] Epoch 4, Iter 830: loss=0.0441, ce=0.0072, dice=0.0687, grad_norm=0.321551
[17:58:52.210] Epoch 4, Iter 840: loss=0.0352, ce=0.0058, dice=0.0548, grad_norm=0.336934
[17:58:54.412] Epoch 4, Iter 850: loss=0.0453, ce=0.0056, dice=0.0717, grad_norm=0.243172
[17:58:56.608] Epoch 4, Iter 860: loss=0.0252, ce=0.0036, dice=0.0397, grad_norm=0.205624
[17:58:58.833] Epoch 4, Iter 870: loss=0.2119, ce=0.0028, dice=0.3513, grad_norm=0.069412
[17:59:01.022] Epoch 4, Iter 880: loss=0.0447, ce=0.0039, dice=0.0719, grad_norm=2.160301
[17:59:03.215] Epoch 4, Iter 890: loss=0.0338, ce=0.0049, dice=0.0530, grad_norm=0.235221
[17:59:05.416] Epoch 4, Iter 900: loss=0.0349, ce=0.0069, dice=0.0536, grad_norm=0.146001
[17:59:07.619] Epoch 4, Iter 910: loss=0.2072, ce=0.0033, dice=0.3431, grad_norm=0.027315
[17:59:09.837] Epoch 4, Iter 920: loss=0.2250, ce=0.0086, dice=0.3693, grad_norm=0.192697
[17:59:11.966] Epoch 4, Iter 930: loss=0.2313, ce=0.0084, dice=0.3798, grad_norm=0.509827
[17:59:12.592] Epoch 4: Avg Loss=0.1042, CE=0.0062, Dice=0.1694
[17:59:25.656] Epoch 5, Iter 940: loss=0.0329, ce=0.0060, dice=0.0508, grad_norm=0.129245
[17:59:27.867] Epoch 5, Iter 950: loss=0.2051, ce=0.0023, dice=0.3403, grad_norm=0.039916
[17:59:30.064] Epoch 5, Iter 960: loss=0.1270, ce=0.0051, dice=0.2083, grad_norm=2.407407
[17:59:32.264] Epoch 5, Iter 970: loss=0.0925, ce=0.0036, dice=0.1518, grad_norm=4.460757
[17:59:34.468] Epoch 5, Iter 980: loss=0.1100, ce=0.0053, dice=0.1798, grad_norm=1.049773
[17:59:36.681] Epoch 5, Iter 990: loss=0.2076, ce=0.0011, dice=0.3453, grad_norm=0.107268
[17:59:38.877] Epoch 5, Iter 1000: loss=0.0369, ce=0.0075, dice=0.0566, grad_norm=0.235826
[17:59:41.082] Epoch 5, Iter 1010: loss=0.0507, ce=0.0096, dice=0.0781, grad_norm=0.503556
[17:59:43.291] Epoch 5, Iter 1020: loss=0.2096, ce=0.0005, dice=0.3491, grad_norm=0.025166
[17:59:45.491] Epoch 5, Iter 1030: loss=0.0317, ce=0.0123, dice=0.0446, grad_norm=0.435431
[17:59:47.713] Epoch 5, Iter 1040: loss=0.0570, ce=0.0093, dice=0.0888, grad_norm=0.283395
[17:59:49.930] Epoch 5, Iter 1050: loss=0.0414, ce=0.0088, dice=0.0632, grad_norm=0.199237
[17:59:52.116] Epoch 5, Iter 1060: loss=0.0513, ce=0.0044, dice=0.0825, grad_norm=0.289864
[17:59:54.314] Epoch 5, Iter 1070: loss=0.0485, ce=0.0049, dice=0.0775, grad_norm=0.703317
[17:59:56.510] Epoch 5, Iter 1080: loss=0.0309, ce=0.0053, dice=0.0480, grad_norm=0.087799
[17:59:58.724] Epoch 5, Iter 1090: loss=0.0321, ce=0.0062, dice=0.0493, grad_norm=0.360432
[18:00:00.922] Epoch 5, Iter 1100: loss=0.1192, ce=0.0044, dice=0.1957, grad_norm=1.553059
[18:00:03.121] Epoch 5, Iter 1110: loss=0.1151, ce=0.0076, dice=0.1868, grad_norm=0.727358
[18:00:04.975] Epoch 5: Avg Loss=0.0931, CE=0.0055, Dice=0.1515
[18:00:16.712] Epoch 6, Iter 1120: loss=0.2131, ce=0.0045, dice=0.3522, grad_norm=0.114947
[18:00:18.913] Epoch 6, Iter 1130: loss=0.0741, ce=0.0080, dice=0.1182, grad_norm=1.295841
[18:00:21.121] Epoch 6, Iter 1140: loss=0.0464, ce=0.0071, dice=0.0726, grad_norm=0.422902
[18:00:23.328] Epoch 6, Iter 1150: loss=0.1823, ce=0.0038, dice=0.3012, grad_norm=3.237750
[18:00:25.514] Epoch 6, Iter 1160: loss=0.0686, ce=0.0037, dice=0.1118, grad_norm=1.198218
[18:00:27.715] Epoch 6, Iter 1170: loss=0.0263, ce=0.0091, dice=0.0378, grad_norm=0.151275
[18:00:29.915] Epoch 6, Iter 1180: loss=0.2072, ce=0.0041, dice=0.3426, grad_norm=0.024194
[18:00:32.127] Epoch 6, Iter 1190: loss=0.0481, ce=0.0015, dice=0.0792, grad_norm=1.148878
[18:00:34.323] Epoch 6, Iter 1200: loss=0.2098, ce=0.0047, dice=0.3466, grad_norm=0.063942
[18:00:36.529] Epoch 6, Iter 1210: loss=0.0532, ce=0.0010, dice=0.0880, grad_norm=0.571936
[18:00:38.716] Epoch 6, Iter 1220: loss=0.0773, ce=0.0091, dice=0.1227, grad_norm=0.212687
[18:00:40.919] Epoch 6, Iter 1230: loss=0.0724, ce=0.0038, dice=0.1181, grad_norm=0.552819
[18:00:43.121] Epoch 6, Iter 1240: loss=0.2094, ce=0.0029, dice=0.3471, grad_norm=0.102917
[18:00:45.319] Epoch 6, Iter 1250: loss=0.0356, ce=0.0148, dice=0.0496, grad_norm=0.195440
[18:00:47.506] Epoch 6, Iter 1260: loss=0.0447, ce=0.0053, dice=0.0710, grad_norm=0.325086
[18:00:49.710] Epoch 6, Iter 1270: loss=0.0387, ce=0.0049, dice=0.0612, grad_norm=0.498589
[18:00:51.911] Epoch 6, Iter 1280: loss=0.0371, ce=0.0053, dice=0.0582, grad_norm=0.266953
[18:00:54.113] Epoch 6, Iter 1290: loss=0.0604, ce=0.0039, dice=0.0981, grad_norm=1.194495
[18:00:56.323] Epoch 6, Iter 1300: loss=0.2065, ce=0.0014, dice=0.3433, grad_norm=0.072227
[18:00:57.326] Epoch 6: Avg Loss=0.0919, CE=0.0052, Dice=0.1497
[18:01:09.975] Epoch 7, Iter 1310: loss=0.0462, ce=0.0066, dice=0.0726, grad_norm=0.527856
[18:01:12.172] Epoch 7, Iter 1320: loss=0.0555, ce=0.0046, dice=0.0894, grad_norm=0.570930
[18:01:14.386] Epoch 7, Iter 1330: loss=0.2043, ce=0.0031, dice=0.3385, grad_norm=0.142617
[18:01:16.568] Epoch 7, Iter 1340: loss=0.2075, ce=0.0036, dice=0.3434, grad_norm=0.053694
[18:01:18.779] Epoch 7, Iter 1350: loss=0.0315, ce=0.0063, dice=0.0483, grad_norm=0.167647
[18:01:20.981] Epoch 7, Iter 1360: loss=0.0568, ce=0.0052, dice=0.0912, grad_norm=0.663083
[18:01:23.202] Epoch 7, Iter 1370: loss=0.2082, ce=0.0021, dice=0.3456, grad_norm=0.062501
[18:01:25.428] Epoch 7, Iter 1380: loss=0.0291, ce=0.0051, dice=0.0450, grad_norm=0.420264
[18:01:27.633] Epoch 7, Iter 1390: loss=0.1953, ce=0.0052, dice=0.3220, grad_norm=0.804907
[18:01:29.835] Epoch 7, Iter 1400: loss=0.0249, ce=0.0024, dice=0.0400, grad_norm=0.139612
[18:01:32.059] Epoch 7, Iter 1410: loss=0.2056, ce=0.0035, dice=0.3404, grad_norm=0.041415
[18:01:34.246] Epoch 7, Iter 1420: loss=0.0932, ce=0.0033, dice=0.1532, grad_norm=2.191186
[18:01:36.462] Epoch 7, Iter 1430: loss=0.0338, ce=0.0022, dice=0.0549, grad_norm=0.582152
[18:01:38.654] Epoch 7, Iter 1440: loss=0.0270, ce=0.0023, dice=0.0435, grad_norm=1.120593
[18:01:40.880] Epoch 7, Iter 1450: loss=0.0222, ce=0.0032, dice=0.0349, grad_norm=0.413641
[18:01:43.075] Epoch 7, Iter 1460: loss=0.2082, ce=0.0052, dice=0.3435, grad_norm=0.039564
[18:01:45.269] Epoch 7, Iter 1470: loss=0.2096, ce=0.0037, dice=0.3468, grad_norm=0.483673
[18:01:47.461] Epoch 7, Iter 1480: loss=0.0360, ce=0.0040, dice=0.0573, grad_norm=0.273420
[18:01:49.755] Epoch 7: Avg Loss=0.0827, CE=0.0048, Dice=0.1347
[18:02:01.054] Epoch 8, Iter 1490: loss=0.0591, ce=0.0031, dice=0.0965, grad_norm=0.298502
[18:02:03.256] Epoch 8, Iter 1500: loss=0.0393, ce=0.0055, dice=0.0619, grad_norm=0.242120
[18:02:05.467] Epoch 8, Iter 1510: loss=0.0293, ce=0.0047, dice=0.0458, grad_norm=0.186962
[18:02:07.659] Epoch 8, Iter 1520: loss=0.0239, ce=0.0029, dice=0.0378, grad_norm=0.261311
[18:02:09.874] Epoch 8, Iter 1530: loss=0.0433, ce=0.0067, dice=0.0677, grad_norm=0.185584
[18:02:12.060] Epoch 8, Iter 1540: loss=0.0300, ce=0.0057, dice=0.0462, grad_norm=0.140199
[18:02:14.271] Epoch 8, Iter 1550: loss=0.0214, ce=0.0056, dice=0.0319, grad_norm=0.144580
[18:02:16.467] Epoch 8, Iter 1560: loss=0.0446, ce=0.0045, dice=0.0713, grad_norm=0.268682
[18:02:18.678] Epoch 8, Iter 1570: loss=0.0759, ce=0.0047, dice=0.1234, grad_norm=0.512396
[18:02:20.875] Epoch 8, Iter 1580: loss=0.0391, ce=0.0038, dice=0.0626, grad_norm=1.236944
[18:02:23.095] Epoch 8, Iter 1590: loss=0.0308, ce=0.0044, dice=0.0484, grad_norm=0.271223
[18:02:25.293] Epoch 8, Iter 1600: loss=0.0191, ce=0.0041, dice=0.0291, grad_norm=0.069299
[18:02:27.506] Epoch 8, Iter 1610: loss=0.0624, ce=0.0050, dice=0.1006, grad_norm=1.242530
[18:02:29.795] Epoch 8, Iter 1620: loss=0.0722, ce=0.0055, dice=0.1167, grad_norm=1.003083
[18:02:31.998] Epoch 8, Iter 1630: loss=0.0367, ce=0.0059, dice=0.0572, grad_norm=0.222606
[18:02:34.192] Epoch 8, Iter 1640: loss=0.0795, ce=0.0064, dice=0.1282, grad_norm=0.737617
[18:02:36.394] Epoch 8, Iter 1650: loss=0.0391, ce=0.0027, dice=0.0634, grad_norm=0.417321
[18:02:38.590] Epoch 8, Iter 1660: loss=0.1230, ce=0.0019, dice=0.2037, grad_norm=3.030693
[18:02:40.792] Epoch 8, Iter 1670: loss=0.2086, ce=0.0040, dice=0.3451, grad_norm=0.078788
[18:02:42.214] Epoch 8: Avg Loss=0.0834, CE=0.0047, Dice=0.1359
[18:02:54.509] Epoch 9, Iter 1680: loss=0.0156, ce=0.0032, dice=0.0238, grad_norm=0.114930
[18:02:56.704] Epoch 9, Iter 1690: loss=0.0572, ce=0.0038, dice=0.0927, grad_norm=0.772029
[18:02:58.899] Epoch 9, Iter 1700: loss=0.0312, ce=0.0045, dice=0.0490, grad_norm=0.466822
[18:03:01.093] Epoch 9, Iter 1710: loss=0.0189, ce=0.0019, dice=0.0302, grad_norm=0.103732
[18:03:03.284] Epoch 9, Iter 1720: loss=0.0402, ce=0.0032, dice=0.0649, grad_norm=0.853314
[18:03:05.494] Epoch 9, Iter 1730: loss=0.0289, ce=0.0067, dice=0.0436, grad_norm=0.227276
[18:03:07.689] Epoch 9, Iter 1740: loss=0.0693, ce=0.0056, dice=0.1117, grad_norm=0.800960
[18:03:09.882] Epoch 9, Iter 1750: loss=0.0283, ce=0.0102, dice=0.0403, grad_norm=0.103336
[18:03:12.076] Epoch 9, Iter 1760: loss=0.0233, ce=0.0014, dice=0.0379, grad_norm=0.145741
[18:03:14.289] Epoch 9, Iter 1770: loss=0.0236, ce=0.0055, dice=0.0357, grad_norm=0.110156
[18:03:16.490] Epoch 9, Iter 1780: loss=0.0323, ce=0.0042, dice=0.0510, grad_norm=0.304038
[18:03:18.709] Epoch 9, Iter 1790: loss=0.0744, ce=0.0090, dice=0.1180, grad_norm=0.430769
[18:03:20.908] Epoch 9, Iter 1800: loss=0.0337, ce=0.0056, dice=0.0524, grad_norm=0.182188
[18:03:23.117] Epoch 9, Iter 1810: loss=0.0321, ce=0.0020, dice=0.0522, grad_norm=0.319805
[18:03:25.342] Epoch 9, Iter 1820: loss=0.0769, ce=0.0052, dice=0.1247, grad_norm=0.612894
[18:03:27.570] Epoch 9, Iter 1830: loss=0.0160, ce=0.0051, dice=0.0233, grad_norm=0.124381
[18:03:29.771] Epoch 9, Iter 1840: loss=0.2063, ce=0.0003, dice=0.3436, grad_norm=0.028920
[18:03:31.971] Epoch 9, Iter 1850: loss=0.2074, ce=0.0031, dice=0.3437, grad_norm=0.060148
[18:03:34.082] Epoch 9, Iter 1860: loss=0.1081, ce=0.0034, dice=0.1779, grad_norm=3.014793
[18:03:34.702] Epoch 9: Avg Loss=0.0860, CE=0.0047, Dice=0.1403
[18:03:34.792] save model to ./finetune_tpgm_lits17_debug\finetuned_lits17_epoch_9.pth
[18:03:47.959] Epoch 10, Iter 1870: loss=0.1299, ce=0.0052, dice=0.2131, grad_norm=1.242058
[18:03:50.154] Epoch 10, Iter 1880: loss=0.0513, ce=0.0026, dice=0.0838, grad_norm=0.981052
[18:03:52.355] Epoch 10, Iter 1890: loss=0.1346, ce=0.0025, dice=0.2227, grad_norm=0.414981
[18:03:54.560] Epoch 10, Iter 1900: loss=0.2041, ce=0.0027, dice=0.3383, grad_norm=0.143395
[18:03:56.760] Epoch 10, Iter 1910: loss=0.0518, ce=0.0052, dice=0.0828, grad_norm=0.316593
[18:03:58.958] Epoch 10, Iter 1920: loss=0.0401, ce=0.0076, dice=0.0618, grad_norm=0.413504
[18:04:01.162] Epoch 10, Iter 1930: loss=0.2072, ce=0.0021, dice=0.3440, grad_norm=0.051107
[18:04:03.362] Epoch 10, Iter 1940: loss=0.0367, ce=0.0054, dice=0.0576, grad_norm=0.268337
[18:04:05.584] Epoch 10, Iter 1950: loss=0.0270, ce=0.0037, dice=0.0426, grad_norm=0.188619
[18:04:07.780] Epoch 10, Iter 1960: loss=0.0329, ce=0.0032, dice=0.0528, grad_norm=0.117583
[18:04:09.994] Epoch 10, Iter 1970: loss=0.2054, ce=0.0026, dice=0.3406, grad_norm=0.164979
[18:04:12.199] Epoch 10, Iter 1980: loss=0.0252, ce=0.0058, dice=0.0380, grad_norm=0.090562
[18:04:14.413] Epoch 10, Iter 1990: loss=0.0247, ce=0.0052, dice=0.0376, grad_norm=0.235644
[18:04:16.609] Epoch 10, Iter 2000: loss=0.1489, ce=0.0023, dice=0.2466, grad_norm=1.980671
[18:04:18.817] Epoch 10, Iter 2010: loss=0.2479, ce=0.0036, dice=0.4108, grad_norm=0.267805
[18:04:21.019] Epoch 10, Iter 2020: loss=0.2041, ce=0.0017, dice=0.3391, grad_norm=0.029269
[18:04:23.219] Epoch 10, Iter 2030: loss=0.0608, ce=0.0066, dice=0.0969, grad_norm=0.546771
[18:04:25.412] Epoch 10, Iter 2040: loss=0.0428, ce=0.0067, dice=0.0669, grad_norm=0.152227
[18:04:27.278] Epoch 10: Avg Loss=0.0886, CE=0.0045, Dice=0.1447
[18:04:39.048] Epoch 11, Iter 2050: loss=0.2077, ce=0.0038, dice=0.3436, grad_norm=0.032599
[18:04:41.240] Epoch 11, Iter 2060: loss=0.0257, ce=0.0032, dice=0.0407, grad_norm=0.658334
[18:04:43.436] Epoch 11, Iter 2070: loss=0.0509, ce=0.0017, dice=0.0837, grad_norm=0.314340
[18:04:45.631] Epoch 11, Iter 2080: loss=0.0506, ce=0.0027, dice=0.0825, grad_norm=1.128548
[18:04:47.838] Epoch 11, Iter 2090: loss=0.0387, ce=0.0038, dice=0.0620, grad_norm=0.242051
[18:04:50.039] Epoch 11, Iter 2100: loss=0.0376, ce=0.0043, dice=0.0598, grad_norm=0.391970
[18:04:52.250] Epoch 11, Iter 2110: loss=0.2029, ce=0.0003, dice=0.3380, grad_norm=0.029051
[18:04:54.452] Epoch 11, Iter 2120: loss=0.0327, ce=0.0026, dice=0.0528, grad_norm=0.468067
[18:04:56.669] Epoch 11, Iter 2130: loss=0.0205, ce=0.0014, dice=0.0333, grad_norm=0.133489
[18:04:58.860] Epoch 11, Iter 2140: loss=0.0663, ce=0.0052, dice=0.1070, grad_norm=1.564391
[18:05:01.067] Epoch 11, Iter 2150: loss=0.0241, ce=0.0046, dice=0.0371, grad_norm=0.191071
[18:05:03.265] Epoch 11, Iter 2160: loss=0.2065, ce=0.0024, dice=0.3425, grad_norm=0.066956
[18:05:05.481] Epoch 11, Iter 2170: loss=0.2106, ce=0.0034, dice=0.3487, grad_norm=0.103083
[18:05:07.675] Epoch 11, Iter 2180: loss=0.2085, ce=0.0038, dice=0.3450, grad_norm=0.043446
[18:05:09.881] Epoch 11, Iter 2190: loss=0.0214, ce=0.0053, dice=0.0322, grad_norm=0.078137
[18:05:12.077] Epoch 11, Iter 2200: loss=0.0554, ce=0.0063, dice=0.0881, grad_norm=0.239359
[18:05:14.283] Epoch 11, Iter 2210: loss=0.0290, ce=0.0047, dice=0.0451, grad_norm=0.148348
[18:05:16.488] Epoch 11, Iter 2220: loss=0.0587, ce=0.0012, dice=0.0971, grad_norm=1.256118
[18:05:18.682] Epoch 11, Iter 2230: loss=0.0218, ce=0.0026, dice=0.0347, grad_norm=0.392303
[18:05:19.654] Epoch 11: Avg Loss=0.0839, CE=0.0042, Dice=0.1371
[18:10:40.993] Epoch 12, Iter 2240: loss=0.0328, ce=0.0028, dice=0.0529, grad_norm=0.194587
[18:10:43.182] Epoch 12, Iter 2250: loss=0.0359, ce=0.0048, dice=0.0566, grad_norm=0.445784
[18:10:45.362] Epoch 12, Iter 2260: loss=0.0857, ce=0.0045, dice=0.1399, grad_norm=0.989638
[18:10:47.553] Epoch 12, Iter 2270: loss=0.0168, ce=0.0050, dice=0.0247, grad_norm=0.122360
[18:10:49.724] Epoch 12, Iter 2280: loss=0.0593, ce=0.0027, dice=0.0971, grad_norm=1.243427
[18:10:51.918] Epoch 12, Iter 2290: loss=0.0485, ce=0.0015, dice=0.0798, grad_norm=0.481433
[18:10:54.102] Epoch 12, Iter 2300: loss=0.0365, ce=0.0111, dice=0.0535, grad_norm=0.329281
[18:10:56.294] Epoch 12, Iter 2310: loss=0.2048, ce=0.0011, dice=0.3407, grad_norm=0.034023
[18:10:58.492] Epoch 12, Iter 2320: loss=0.0635, ce=0.0015, dice=0.1048, grad_norm=0.789376
[18:11:00.687] Epoch 12, Iter 2330: loss=0.0404, ce=0.0027, dice=0.0655, grad_norm=0.328363
[18:11:02.879] Epoch 12, Iter 2340: loss=0.0366, ce=0.0026, dice=0.0592, grad_norm=0.458226
[18:11:05.063] Epoch 12, Iter 2350: loss=0.0946, ce=0.0042, dice=0.1548, grad_norm=1.099012
[18:11:07.252] Epoch 12, Iter 2360: loss=0.0252, ce=0.0030, dice=0.0399, grad_norm=0.129356
[18:11:09.445] Epoch 12, Iter 2370: loss=0.2070, ce=0.0024, dice=0.3434, grad_norm=0.067811
[18:11:11.627] Epoch 12, Iter 2380: loss=0.0507, ce=0.0024, dice=0.0829, grad_norm=0.820951
[18:11:13.814] Epoch 12, Iter 2390: loss=0.0217, ce=0.0028, dice=0.0343, grad_norm=0.107808
[18:11:15.997] Epoch 12, Iter 2400: loss=0.0477, ce=0.0111, dice=0.0721, grad_norm=0.485419
[18:11:18.206] Epoch 12, Iter 2410: loss=0.0235, ce=0.0060, dice=0.0351, grad_norm=0.098059
[18:11:20.530] Epoch 12: Avg Loss=0.0812, CE=0.0043, Dice=0.1324
[18:11:32.279] Epoch 13, Iter 2420: loss=0.0401, ce=0.0016, dice=0.0657, grad_norm=0.217458
[18:11:34.479] Epoch 13, Iter 2430: loss=0.0514, ce=0.0077, dice=0.0806, grad_norm=0.367453
[18:11:36.660] Epoch 13, Iter 2440: loss=0.0503, ce=0.0039, dice=0.0813, grad_norm=0.603937
[18:11:38.854] Epoch 13, Iter 2450: loss=0.0586, ce=0.0053, dice=0.0942, grad_norm=0.982873
[18:11:41.035] Epoch 13, Iter 2460: loss=0.0220, ce=0.0047, dice=0.0335, grad_norm=0.113375
[18:11:43.229] Epoch 13, Iter 2470: loss=0.0399, ce=0.0032, dice=0.0644, grad_norm=0.690097
[18:11:45.426] Epoch 13, Iter 2480: loss=0.0225, ce=0.0026, dice=0.0359, grad_norm=0.138701
[18:11:47.619] Epoch 13, Iter 2490: loss=0.2182, ce=0.0054, dice=0.3601, grad_norm=0.139148
[18:11:49.814] Epoch 13, Iter 2500: loss=0.0327, ce=0.0078, dice=0.0493, grad_norm=0.151531
[18:11:52.006] Epoch 13, Iter 2510: loss=0.0272, ce=0.0043, dice=0.0425, grad_norm=0.203888
[18:11:54.196] Epoch 13, Iter 2520: loss=0.0209, ce=0.0089, dice=0.0289, grad_norm=0.083047
[18:11:56.391] Epoch 13, Iter 2530: loss=0.0308, ce=0.0107, dice=0.0441, grad_norm=0.153365
[18:11:58.571] Epoch 13, Iter 2540: loss=0.0170, ce=0.0045, dice=0.0253, grad_norm=0.154462
[18:12:00.769] Epoch 13, Iter 2550: loss=0.0248, ce=0.0056, dice=0.0376, grad_norm=0.115925
[18:12:02.963] Epoch 13, Iter 2560: loss=0.0260, ce=0.0017, dice=0.0421, grad_norm=0.338009
[18:12:05.158] Epoch 13, Iter 2570: loss=0.0448, ce=0.0060, dice=0.0706, grad_norm=0.383488
[18:12:07.354] Epoch 13, Iter 2580: loss=0.0154, ce=0.0035, dice=0.0233, grad_norm=0.081751
[18:12:09.546] Epoch 13, Iter 2590: loss=0.0581, ce=0.0063, dice=0.0926, grad_norm=0.660774
[18:12:11.736] Epoch 13, Iter 2600: loss=0.0379, ce=0.0052, dice=0.0597, grad_norm=0.413602
[18:12:13.194] Epoch 13: Avg Loss=0.0770, CE=0.0041, Dice=0.1255
[18:17:45.625] Epoch 14, Iter 2610: loss=0.2049, ce=0.0028, dice=0.3396, grad_norm=0.015190
[18:17:47.801] Epoch 14, Iter 2620: loss=0.2131, ce=0.0005, dice=0.3549, grad_norm=0.125425
[18:17:49.990] Epoch 14, Iter 2630: loss=0.0482, ce=0.0069, dice=0.0757, grad_norm=0.526922
[18:17:52.171] Epoch 14, Iter 2640: loss=0.2074, ce=0.0018, dice=0.3445, grad_norm=0.101967
[18:17:54.374] Epoch 14, Iter 2650: loss=0.0559, ce=0.0012, dice=0.0923, grad_norm=0.452020
[18:17:56.543] Epoch 14, Iter 2660: loss=0.2057, ce=0.0020, dice=0.3415, grad_norm=0.055052
[18:17:58.728] Epoch 14, Iter 2670: loss=0.0297, ce=0.0035, dice=0.0471, grad_norm=0.148579
[18:18:00.914] Epoch 14, Iter 2680: loss=0.0632, ce=0.0089, dice=0.0994, grad_norm=1.332551
[18:18:03.115] Epoch 14, Iter 2690: loss=0.0712, ce=0.0030, dice=0.1166, grad_norm=0.760331
[18:18:05.305] Epoch 14, Iter 2700: loss=0.2029, ce=0.0009, dice=0.3376, grad_norm=0.017259
[18:18:07.493] Epoch 14, Iter 2710: loss=0.0184, ce=0.0063, dice=0.0265, grad_norm=0.097710
[18:18:09.688] Epoch 14, Iter 2720: loss=0.2097, ce=0.0046, dice=0.3465, grad_norm=0.057494
[18:18:11.882] Epoch 14, Iter 2730: loss=0.0249, ce=0.0060, dice=0.0374, grad_norm=0.132393
[18:18:14.077] Epoch 14, Iter 2740: loss=0.0244, ce=0.0035, dice=0.0384, grad_norm=0.091004
[18:18:16.271] Epoch 14, Iter 2750: loss=0.0556, ce=0.0061, dice=0.0886, grad_norm=0.229208
[18:18:18.464] Epoch 14, Iter 2760: loss=0.0310, ce=0.0049, dice=0.0484, grad_norm=0.230382
[18:18:20.666] Epoch 14, Iter 2770: loss=0.2104, ce=0.0022, dice=0.3493, grad_norm=0.089282
[18:18:22.859] Epoch 14, Iter 2780: loss=0.0256, ce=0.0037, dice=0.0402, grad_norm=0.146065
[18:18:24.964] Epoch 14, Iter 2790: loss=0.0226, ce=0.0012, dice=0.0369, grad_norm=0.317295
[18:18:25.617] Epoch 14: Avg Loss=0.0815, CE=0.0040, Dice=0.1331
[18:18:38.896] Epoch 15, Iter 2800: loss=0.0228, ce=0.0056, dice=0.0343, grad_norm=0.186522
[18:18:41.098] Epoch 15, Iter 2810: loss=0.0265, ce=0.0053, dice=0.0407, grad_norm=0.115388
[18:18:43.289] Epoch 15, Iter 2820: loss=0.2069, ce=0.0055, dice=0.3412, grad_norm=0.028029
[18:18:45.488] Epoch 15, Iter 2830: loss=0.0177, ce=0.0052, dice=0.0260, grad_norm=0.125338
[18:18:47.678] Epoch 15, Iter 2840: loss=0.2069, ce=0.0040, dice=0.3422, grad_norm=0.033629
[18:18:49.889] Epoch 15, Iter 2850: loss=0.0373, ce=0.0071, dice=0.0574, grad_norm=0.272502
[18:18:52.074] Epoch 15, Iter 2860: loss=0.0202, ce=0.0038, dice=0.0312, grad_norm=0.109961
[18:18:54.284] Epoch 15, Iter 2870: loss=0.0353, ce=0.0040, dice=0.0562, grad_norm=0.230118
[18:18:56.468] Epoch 15, Iter 2880: loss=0.2049, ce=0.0021, dice=0.3401, grad_norm=0.061477
[18:18:58.665] Epoch 15, Iter 2890: loss=0.0319, ce=0.0038, dice=0.0507, grad_norm=0.297148
[18:19:00.852] Epoch 15, Iter 2900: loss=0.0979, ce=0.0034, dice=0.1609, grad_norm=0.358328
[18:19:03.047] Epoch 15, Iter 2910: loss=0.2015, ce=0.0035, dice=0.3335, grad_norm=0.232340
[18:19:05.241] Epoch 15, Iter 2920: loss=0.0277, ce=0.0040, dice=0.0435, grad_norm=0.186158
[18:19:07.441] Epoch 15, Iter 2930: loss=0.0297, ce=0.0044, dice=0.0466, grad_norm=0.251489
[18:19:09.625] Epoch 15, Iter 2940: loss=0.0488, ce=0.0032, dice=0.0793, grad_norm=0.405396
[18:19:11.821] Epoch 15, Iter 2950: loss=0.0191, ce=0.0053, dice=0.0282, grad_norm=0.136479
[18:19:14.016] Epoch 15, Iter 2960: loss=0.0469, ce=0.0039, dice=0.0756, grad_norm=0.315742
[18:19:16.207] Epoch 15, Iter 2970: loss=0.0345, ce=0.0037, dice=0.0550, grad_norm=0.273926
[18:19:18.077] Epoch 15: Avg Loss=0.0761, CE=0.0040, Dice=0.1241
[18:24:50.469] Epoch 16, Iter 2980: loss=0.0581, ce=0.0015, dice=0.0958, grad_norm=1.257729
[18:24:52.672] Epoch 16, Iter 2990: loss=0.0507, ce=0.0082, dice=0.0790, grad_norm=0.599197
[18:24:54.848] Epoch 16, Iter 3000: loss=0.0420, ce=0.0062, dice=0.0658, grad_norm=0.610567
[18:24:57.041] Epoch 16, Iter 3010: loss=0.0698, ce=0.0015, dice=0.1154, grad_norm=1.015643
[18:24:59.236] Epoch 16, Iter 3020: loss=0.0497, ce=0.0023, dice=0.0813, grad_norm=0.296216
[18:25:01.417] Epoch 16, Iter 3030: loss=0.0723, ce=0.0044, dice=0.1175, grad_norm=0.686701
[18:25:03.602] Epoch 16, Iter 3040: loss=0.0371, ce=0.0060, dice=0.0579, grad_norm=0.300899
[18:25:05.800] Epoch 16, Iter 3050: loss=0.0439, ce=0.0024, dice=0.0715, grad_norm=0.531820
[18:25:07.991] Epoch 16, Iter 3060: loss=0.2085, ce=0.0012, dice=0.3467, grad_norm=0.287860
[18:25:10.195] Epoch 16, Iter 3070: loss=0.0326, ce=0.0009, dice=0.0538, grad_norm=0.268331
[18:25:12.403] Epoch 16, Iter 3080: loss=0.2055, ce=0.0022, dice=0.3410, grad_norm=0.027714
[18:25:14.601] Epoch 16, Iter 3090: loss=0.2049, ce=0.0019, dice=0.3402, grad_norm=0.040711
[18:25:16.786] Epoch 16, Iter 3100: loss=0.0340, ce=0.0029, dice=0.0547, grad_norm=0.379470
[18:25:18.976] Epoch 16, Iter 3110: loss=0.0282, ce=0.0030, dice=0.0450, grad_norm=0.175025
[18:25:21.176] Epoch 16, Iter 3120: loss=0.0743, ce=0.0019, dice=0.1227, grad_norm=0.614861
[18:25:23.388] Epoch 16, Iter 3130: loss=0.0623, ce=0.0068, dice=0.0993, grad_norm=1.589380
[18:25:25.604] Epoch 16, Iter 3140: loss=0.2035, ce=0.0013, dice=0.3383, grad_norm=0.026987
[18:25:27.796] Epoch 16, Iter 3150: loss=0.0269, ce=0.0028, dice=0.0430, grad_norm=0.450261
[18:25:29.974] Epoch 16, Iter 3160: loss=0.2082, ce=0.0052, dice=0.3435, grad_norm=0.120287
[18:25:31.001] Epoch 16: Avg Loss=0.0772, CE=0.0039, Dice=0.1260
[18:25:43.930] Epoch 17, Iter 3170: loss=0.0134, ce=0.0020, dice=0.0210, grad_norm=0.084126
[18:25:46.113] Epoch 17, Iter 3180: loss=0.1309, ce=0.0024, dice=0.2165, grad_norm=2.938723
[18:25:48.308] Epoch 17, Iter 3190: loss=0.2045, ce=0.0016, dice=0.3397, grad_norm=0.083702
[18:25:50.492] Epoch 17, Iter 3200: loss=0.0379, ce=0.0074, dice=0.0582, grad_norm=0.215397
[18:25:52.700] Epoch 17, Iter 3210: loss=0.0472, ce=0.0061, dice=0.0747, grad_norm=0.227567
[18:25:54.886] Epoch 17, Iter 3220: loss=0.0207, ce=0.0062, dice=0.0303, grad_norm=0.084758
[18:25:57.086] Epoch 17, Iter 3230: loss=0.2055, ce=0.0009, dice=0.3419, grad_norm=0.033779
[18:25:59.276] Epoch 17, Iter 3240: loss=0.0692, ce=0.0047, dice=0.1121, grad_norm=0.366611
[18:26:01.478] Epoch 17, Iter 3250: loss=0.0450, ce=0.0013, dice=0.0741, grad_norm=0.415939
[18:26:03.673] Epoch 17, Iter 3260: loss=0.0202, ce=0.0021, dice=0.0323, grad_norm=0.173528
[18:26:05.869] Epoch 17, Iter 3270: loss=0.0175, ce=0.0046, dice=0.0262, grad_norm=0.090104
[18:26:08.061] Epoch 17, Iter 3280: loss=0.0507, ce=0.0061, dice=0.0805, grad_norm=0.225513
[18:26:10.255] Epoch 17, Iter 3290: loss=0.1546, ce=0.0036, dice=0.2552, grad_norm=3.077440
[18:26:12.441] Epoch 17, Iter 3300: loss=0.0352, ce=0.0027, dice=0.0568, grad_norm=0.240050
[18:26:14.636] Epoch 17, Iter 3310: loss=0.2072, ce=0.0046, dice=0.3423, grad_norm=0.064061
[18:26:16.836] Epoch 17, Iter 3320: loss=0.2399, ce=0.0023, dice=0.3983, grad_norm=0.451668
[18:26:19.039] Epoch 17, Iter 3330: loss=0.0312, ce=0.0026, dice=0.0504, grad_norm=0.677455
[18:26:21.220] Epoch 17, Iter 3340: loss=0.2032, ce=0.0007, dice=0.3382, grad_norm=0.128517
[18:26:23.563] Epoch 17: Avg Loss=0.0852, CE=0.0039, Dice=0.1394
[18:31:55.489] Epoch 18, Iter 3350: loss=0.0322, ce=0.0024, dice=0.0521, grad_norm=0.186291
[18:31:57.672] Epoch 18, Iter 3360: loss=0.2090, ce=0.0037, dice=0.3458, grad_norm=0.036855
[18:31:59.869] Epoch 18, Iter 3370: loss=0.0211, ce=0.0057, dice=0.0314, grad_norm=0.119968
[18:32:02.051] Epoch 18, Iter 3380: loss=0.0190, ce=0.0027, dice=0.0298, grad_norm=0.190958
[18:32:04.240] Epoch 18, Iter 3390: loss=0.1186, ce=0.0070, dice=0.1930, grad_norm=2.604098
[18:32:06.428] Epoch 18, Iter 3400: loss=0.0176, ce=0.0031, dice=0.0272, grad_norm=0.172217
[18:32:08.618] Epoch 18, Iter 3410: loss=0.0385, ce=0.0016, dice=0.0631, grad_norm=0.368154
[18:32:10.800] Epoch 18, Iter 3420: loss=0.0556, ce=0.0049, dice=0.0895, grad_norm=0.963496
[18:32:12.988] Epoch 18, Iter 3430: loss=0.0533, ce=0.0043, dice=0.0859, grad_norm=0.311413
[18:32:15.177] Epoch 18, Iter 3440: loss=0.0986, ce=0.0028, dice=0.1626, grad_norm=2.263028
[18:32:17.371] Epoch 18, Iter 3450: loss=0.2064, ce=0.0038, dice=0.3414, grad_norm=0.015592
[18:32:19.557] Epoch 18, Iter 3460: loss=0.0448, ce=0.0042, dice=0.0718, grad_norm=0.780756
[18:32:21.758] Epoch 18, Iter 3470: loss=0.2069, ce=0.0027, dice=0.3429, grad_norm=0.031393
[18:32:23.949] Epoch 18, Iter 3480: loss=0.2054, ce=0.0026, dice=0.3406, grad_norm=0.020693
[18:32:26.132] Epoch 18, Iter 3490: loss=0.0929, ce=0.0053, dice=0.1514, grad_norm=1.202537
[18:32:28.332] Epoch 18, Iter 3500: loss=0.2078, ce=0.0029, dice=0.3443, grad_norm=0.061763
[18:32:30.520] Epoch 18, Iter 3510: loss=0.0934, ce=0.0038, dice=0.1532, grad_norm=3.615779
[18:32:32.712] Epoch 18, Iter 3520: loss=0.2046, ce=0.0026, dice=0.3393, grad_norm=0.239459
[18:32:34.915] Epoch 18, Iter 3530: loss=0.2063, ce=0.0030, dice=0.3419, grad_norm=0.054077
[18:32:36.372] Epoch 18: Avg Loss=0.0814, CE=0.0039, Dice=0.1331
[18:32:48.763] Epoch 19, Iter 3540: loss=0.0176, ce=0.0037, dice=0.0269, grad_norm=0.080178
[18:32:50.955] Epoch 19, Iter 3550: loss=0.0454, ce=0.0030, dice=0.0736, grad_norm=0.438661
[18:32:53.135] Epoch 19, Iter 3560: loss=0.0269, ce=0.0035, dice=0.0426, grad_norm=0.206579
[18:32:55.331] Epoch 19, Iter 3570: loss=0.0261, ce=0.0031, dice=0.0415, grad_norm=0.142490
[18:32:57.524] Epoch 19, Iter 3580: loss=0.2093, ce=0.0029, dice=0.3469, grad_norm=0.070841
[18:32:59.720] Epoch 19, Iter 3590: loss=0.0651, ce=0.0058, dice=0.1046, grad_norm=0.762777
[18:33:01.920] Epoch 19, Iter 3600: loss=0.0162, ce=0.0056, dice=0.0232, grad_norm=0.068982
[18:33:04.112] Epoch 19, Iter 3610: loss=0.0375, ce=0.0017, dice=0.0614, grad_norm=0.332120
[18:33:06.305] Epoch 19, Iter 3620: loss=0.0286, ce=0.0023, dice=0.0462, grad_norm=0.240325
[18:33:08.493] Epoch 19, Iter 3630: loss=0.0355, ce=0.0046, dice=0.0560, grad_norm=0.305694
[18:33:10.683] Epoch 19, Iter 3640: loss=0.0340, ce=0.0055, dice=0.0530, grad_norm=0.390190
[18:33:12.893] Epoch 19, Iter 3650: loss=0.2059, ce=0.0014, dice=0.3423, grad_norm=0.065939
[18:33:15.080] Epoch 19, Iter 3660: loss=0.0769, ce=0.0061, dice=0.1241, grad_norm=0.722069
[18:33:17.280] Epoch 19, Iter 3670: loss=0.2076, ce=0.0046, dice=0.3429, grad_norm=0.026192
[18:33:19.471] Epoch 19, Iter 3680: loss=0.2054, ce=0.0032, dice=0.3403, grad_norm=0.020094
[18:33:21.667] Epoch 19, Iter 3690: loss=0.1784, ce=0.0049, dice=0.2941, grad_norm=2.459893
[18:33:23.870] Epoch 19, Iter 3700: loss=0.0665, ce=0.0040, dice=0.1082, grad_norm=0.516772
[18:33:26.082] Epoch 19, Iter 3710: loss=0.0213, ce=0.0023, dice=0.0340, grad_norm=0.229245
[18:33:28.183] Epoch 19, Iter 3720: loss=0.1508, ce=0.0042, dice=0.2485, grad_norm=4.784774
[18:33:28.861] Epoch 19: Avg Loss=0.0789, CE=0.0038, Dice=0.1289
[18:38:48.981] save model to ./finetune_tpgm_lits17_debug\finetuned_lits17_epoch_19.pth
[18:38:49.152] save final model to ./finetune_tpgm_lits17_debug\finetuned_lits17_final.pth
[18:43:42.493] Namespace(root_path='./datasets/lits17/train_npz', dataset='lits17', list_dir='./lists/lits17', num_classes=3, model_num_classes=9, output_dir='./finetune_tpgm_lits17_debug', max_iterations=10000, max_epochs=20, batch_size=16, n_gpu=1, deterministic=1, base_lr=0.0001, img_size=224, seed=1234, cfg='configs/finetune.yaml', pretrained_path='./finetune_tpgm_kits23_debug/finetuned_final.pth', data_fraction=0.5, freeze_layers=0, opts=None, zip=False, cache_mode='part', resume=None, accumulation_steps=None, use_checkpoint=False, amp_opt_level='O1', tag=None, eval=False, throughput=False, tpgm_norm_mode='l2', tpgm_lr=0.01, tpgm_iters=100, tpgm_exclude=[], tpgm_frequency=2, tpgm_start_epoch=10, disable_tpgm=False, gpu_id=1)
[18:43:42.497] Training lits17 with 3 classes
[18:43:42.497] Using 7421/14843 samples for finetuning
[18:43:42.497] Using 50/14843 samples for TPGM
[18:43:42.497] TPGM enabled: True
[18:43:52.727] 464 iterations per epoch
[18:44:05.815] Epoch 0, Iter 10: loss=0.2334, ce=0.0520, dice=0.3543, grad_norm=2.736708
[18:44:08.029] Epoch 0, Iter 20: loss=0.2429, ce=0.0470, dice=0.3735, grad_norm=0.986395
[18:44:10.274] Epoch 0, Iter 30: loss=0.2400, ce=0.0060, dice=0.3960, grad_norm=0.461873
[18:44:12.500] Epoch 0, Iter 40: loss=0.2181, ce=0.0092, dice=0.3573, grad_norm=0.463286
[18:44:14.771] Epoch 0, Iter 50: loss=0.1329, ce=0.0211, dice=0.2074, grad_norm=1.768781
[18:44:17.018] Epoch 0, Iter 60: loss=0.1198, ce=0.0170, dice=0.1884, grad_norm=1.261196
[18:44:19.281] Epoch 0, Iter 70: loss=0.2376, ce=0.0061, dice=0.3919, grad_norm=0.411425
[18:44:21.547] Epoch 0, Iter 80: loss=0.2261, ce=0.0095, dice=0.3705, grad_norm=0.342986
[18:44:23.835] Epoch 0, Iter 90: loss=0.0525, ce=0.0132, dice=0.0786, grad_norm=0.387486
[18:44:26.126] Epoch 0, Iter 100: loss=0.2118, ce=0.0039, dice=0.3504, grad_norm=0.362814
[18:44:28.409] Epoch 0, Iter 110: loss=0.1235, ce=0.0128, dice=0.1973, grad_norm=1.230760
[18:44:30.664] Epoch 0, Iter 120: loss=0.2358, ce=0.0055, dice=0.3894, grad_norm=0.619535
[18:44:32.934] Epoch 0, Iter 130: loss=0.0745, ce=0.0089, dice=0.1182, grad_norm=0.683450
[18:44:35.164] Epoch 0, Iter 140: loss=0.0556, ce=0.0124, dice=0.0843, grad_norm=0.397680
[18:44:37.409] Epoch 0, Iter 150: loss=0.1860, ce=0.0116, dice=0.3023, grad_norm=1.484328
[18:44:39.639] Epoch 0, Iter 160: loss=0.2111, ce=0.0060, dice=0.3479, grad_norm=0.051226
[18:44:41.877] Epoch 0, Iter 170: loss=0.1960, ce=0.0061, dice=0.3226, grad_norm=0.536939
[18:44:44.117] Epoch 0, Iter 180: loss=0.2285, ce=0.0063, dice=0.3766, grad_norm=0.284823
[18:44:46.374] Epoch 0, Iter 190: loss=0.2112, ce=0.0035, dice=0.3496, grad_norm=0.065379
[18:44:48.617] Epoch 0, Iter 200: loss=0.2082, ce=0.0092, dice=0.3409, grad_norm=0.510022
[18:44:50.854] Epoch 0, Iter 210: loss=0.0423, ce=0.0203, dice=0.0569, grad_norm=0.181490
[18:44:53.086] Epoch 0, Iter 220: loss=0.1985, ce=0.0131, dice=0.3221, grad_norm=2.409653
[18:44:55.331] Epoch 0, Iter 230: loss=0.0644, ce=0.0039, dice=0.1048, grad_norm=0.892866
[18:44:57.583] Epoch 0, Iter 240: loss=0.0962, ce=0.0065, dice=0.1560, grad_norm=0.754200
[18:44:59.826] Epoch 0, Iter 250: loss=0.0900, ce=0.0062, dice=0.1458, grad_norm=1.745845
[18:45:02.059] Epoch 0, Iter 260: loss=0.3484, ce=0.0049, dice=0.5774, grad_norm=2.043534
[18:45:04.309] Epoch 0, Iter 270: loss=0.0409, ce=0.0126, dice=0.0597, grad_norm=0.296284
[18:45:06.545] Epoch 0, Iter 280: loss=0.1843, ce=0.0036, dice=0.3048, grad_norm=1.570655
[18:45:08.785] Epoch 0, Iter 290: loss=0.2213, ce=0.0095, dice=0.3625, grad_norm=0.284929
[18:45:11.016] Epoch 0, Iter 300: loss=0.0296, ce=0.0118, dice=0.0415, grad_norm=0.482700
[18:45:13.256] Epoch 0, Iter 310: loss=0.2141, ce=0.0067, dice=0.3523, grad_norm=0.196961
[18:45:15.483] Epoch 0, Iter 320: loss=0.0775, ce=0.0044, dice=0.1262, grad_norm=0.220557
[18:45:17.763] Epoch 0, Iter 330: loss=0.0376, ce=0.0065, dice=0.0584, grad_norm=0.553226
[18:45:20.038] Epoch 0, Iter 340: loss=0.0419, ce=0.0034, dice=0.0676, grad_norm=0.652378
[18:45:22.359] Epoch 0, Iter 350: loss=0.1510, ce=0.0037, dice=0.2492, grad_norm=4.544630
[18:45:24.657] Epoch 0, Iter 360: loss=0.0777, ce=0.0012, dice=0.1288, grad_norm=2.065064
[18:45:26.954] Epoch 0, Iter 370: loss=0.1087, ce=0.0081, dice=0.1758, grad_norm=1.266428
[18:45:29.233] Epoch 0, Iter 380: loss=0.0799, ce=0.0052, dice=0.1297, grad_norm=1.137220
[18:45:31.496] Epoch 0, Iter 390: loss=0.0505, ce=0.0103, dice=0.0773, grad_norm=0.502511
[18:45:33.742] Epoch 0, Iter 400: loss=0.0741, ce=0.0090, dice=0.1175, grad_norm=0.837976
[18:45:36.083] Epoch 0, Iter 410: loss=0.0310, ce=0.0128, dice=0.0432, grad_norm=0.144771
[18:45:38.350] Epoch 0, Iter 420: loss=0.0832, ce=0.0088, dice=0.1328, grad_norm=2.273830
[18:45:40.666] Epoch 0, Iter 430: loss=0.1083, ce=0.0052, dice=0.1770, grad_norm=1.414290
[18:45:42.964] Epoch 0, Iter 440: loss=0.0352, ce=0.0063, dice=0.0545, grad_norm=0.459717
[18:45:45.253] Epoch 0, Iter 450: loss=0.2054, ce=0.0022, dice=0.3408, grad_norm=0.049016
[18:45:47.525] Epoch 0, Iter 460: loss=0.0214, ce=0.0050, dice=0.0323, grad_norm=0.265176
[18:45:49.046] Epoch 0: Avg Loss=0.1345, CE=0.0132, Dice=0.2154
[18:46:01.748] Epoch 1, Iter 470: loss=0.0340, ce=0.0009, dice=0.0560, grad_norm=0.198925
[18:46:03.972] Epoch 1, Iter 480: loss=0.0686, ce=0.0066, dice=0.1099, grad_norm=0.531557
[18:46:06.251] Epoch 1, Iter 490: loss=0.2065, ce=0.0006, dice=0.3438, grad_norm=0.121506
[18:46:08.503] Epoch 1, Iter 500: loss=0.2045, ce=0.0011, dice=0.3401, grad_norm=0.079893
[18:46:10.764] Epoch 1, Iter 510: loss=0.2306, ce=0.0128, dice=0.3758, grad_norm=0.492150
[18:46:13.025] Epoch 1, Iter 520: loss=0.1540, ce=0.0142, dice=0.2472, grad_norm=0.966536
[18:46:15.277] Epoch 1, Iter 530: loss=0.0496, ce=0.0016, dice=0.0815, grad_norm=0.433415
[18:46:17.539] Epoch 1, Iter 540: loss=0.4006, ce=0.0015, dice=0.6667, grad_norm=0.056265
[18:46:19.832] Epoch 1, Iter 550: loss=0.0304, ce=0.0082, dice=0.0451, grad_norm=0.190124
[18:46:22.108] Epoch 1, Iter 560: loss=0.0293, ce=0.0059, dice=0.0448, grad_norm=0.156664
[18:46:24.397] Epoch 1, Iter 570: loss=0.1953, ce=0.0060, dice=0.3216, grad_norm=0.911185
[18:46:26.644] Epoch 1, Iter 580: loss=0.0633, ce=0.0024, dice=0.1038, grad_norm=0.617625
[18:46:28.917] Epoch 1, Iter 590: loss=0.0461, ce=0.0063, dice=0.0727, grad_norm=0.432208
[18:46:31.208] Epoch 1, Iter 600: loss=0.2138, ce=0.0027, dice=0.3545, grad_norm=0.095676
[18:46:33.528] Epoch 1, Iter 610: loss=0.0293, ce=0.0043, dice=0.0460, grad_norm=0.254609
[18:46:35.818] Epoch 1, Iter 620: loss=0.0162, ce=0.0019, dice=0.0258, grad_norm=0.127426
[18:46:38.125] Epoch 1, Iter 630: loss=0.1146, ce=0.0055, dice=0.1874, grad_norm=0.718808
[18:46:40.414] Epoch 1, Iter 640: loss=0.0738, ce=0.0025, dice=0.1214, grad_norm=1.309753
[18:46:42.741] Epoch 1, Iter 650: loss=0.0636, ce=0.0087, dice=0.1001, grad_norm=0.694444
[18:46:45.058] Epoch 1, Iter 660: loss=0.0297, ce=0.0087, dice=0.0437, grad_norm=0.121184
[18:46:47.363] Epoch 1, Iter 670: loss=0.2122, ce=0.0044, dice=0.3507, grad_norm=0.254942
[18:46:49.629] Epoch 1, Iter 680: loss=0.0770, ce=0.0056, dice=0.1245, grad_norm=0.766125
[18:46:51.925] Epoch 1, Iter 690: loss=0.2099, ce=0.0035, dice=0.3475, grad_norm=0.307426
[18:46:54.208] Epoch 1, Iter 700: loss=0.0389, ce=0.0130, dice=0.0562, grad_norm=0.347134
[18:46:56.497] Epoch 1, Iter 710: loss=0.1197, ce=0.0055, dice=0.1959, grad_norm=5.565363
[18:46:58.782] Epoch 1, Iter 720: loss=0.1189, ce=0.0075, dice=0.1933, grad_norm=1.300040
[18:47:01.083] Epoch 1, Iter 730: loss=0.2542, ce=0.0143, dice=0.4142, grad_norm=0.819278
[18:47:03.372] Epoch 1, Iter 740: loss=0.2116, ce=0.0044, dice=0.3497, grad_norm=0.070270
[18:47:05.651] Epoch 1, Iter 750: loss=0.2099, ce=0.0044, dice=0.3469, grad_norm=0.046730
[18:47:07.933] Epoch 1, Iter 760: loss=0.0581, ce=0.0124, dice=0.0886, grad_norm=0.511180
[18:47:10.224] Epoch 1, Iter 770: loss=0.2145, ce=0.0098, dice=0.3511, grad_norm=0.112260
[18:47:12.490] Epoch 1, Iter 780: loss=0.2780, ce=0.0006, dice=0.4630, grad_norm=4.661915
[18:47:14.753] Epoch 1, Iter 790: loss=0.0479, ce=0.0060, dice=0.0759, grad_norm=0.197248
[18:47:17.001] Epoch 1, Iter 800: loss=0.1000, ce=0.0095, dice=0.1604, grad_norm=2.551639
[18:47:19.266] Epoch 1, Iter 810: loss=0.2016, ce=0.0026, dice=0.3343, grad_norm=0.422941
[18:47:21.536] Epoch 1, Iter 820: loss=0.0257, ce=0.0076, dice=0.0378, grad_norm=0.188581
[18:47:23.811] Epoch 1, Iter 830: loss=0.0298, ce=0.0042, dice=0.0469, grad_norm=0.273596
[18:47:26.080] Epoch 1, Iter 840: loss=0.0346, ce=0.0044, dice=0.0548, grad_norm=0.486576
[18:47:28.363] Epoch 1, Iter 850: loss=0.0655, ce=0.0080, dice=0.1038, grad_norm=0.624741
[18:47:30.643] Epoch 1, Iter 860: loss=0.2058, ce=0.0029, dice=0.3411, grad_norm=0.046858
[18:47:32.915] Epoch 1, Iter 870: loss=0.2049, ce=0.0060, dice=0.3375, grad_norm=0.249951
[18:47:35.181] Epoch 1, Iter 880: loss=0.0238, ce=0.0052, dice=0.0363, grad_norm=0.205747
[18:47:37.447] Epoch 1, Iter 890: loss=0.2049, ce=0.0021, dice=0.3402, grad_norm=0.042621
[18:47:39.704] Epoch 1, Iter 900: loss=0.0389, ce=0.0020, dice=0.0635, grad_norm=0.268382
[18:47:41.982] Epoch 1, Iter 910: loss=0.0318, ce=0.0115, dice=0.0454, grad_norm=0.101333
[18:47:44.235] Epoch 1, Iter 920: loss=0.0843, ce=0.0050, dice=0.1372, grad_norm=0.904019
[18:47:46.595] Epoch 1: Avg Loss=0.0978, CE=0.0062, Dice=0.1589
[18:47:57.194] Epoch 2, Iter 930: loss=0.0505, ce=0.0108, dice=0.0770, grad_norm=0.636714
[18:47:59.415] Epoch 2, Iter 940: loss=0.2064, ce=0.0025, dice=0.3423, grad_norm=0.021893
[18:48:01.665] Epoch 2, Iter 950: loss=0.0300, ce=0.0040, dice=0.0473, grad_norm=0.398868
[18:48:03.891] Epoch 2, Iter 960: loss=0.0647, ce=0.0090, dice=0.1018, grad_norm=0.935629
[18:48:06.157] Epoch 2, Iter 970: loss=0.0713, ce=0.0031, dice=0.1167, grad_norm=0.683762
[18:48:08.400] Epoch 2, Iter 980: loss=0.0643, ce=0.0057, dice=0.1034, grad_norm=0.419951
[18:48:10.642] Epoch 2, Iter 990: loss=0.2110, ce=0.0081, dice=0.3462, grad_norm=0.021844
[18:48:12.860] Epoch 2, Iter 1000: loss=0.0230, ce=0.0070, dice=0.0337, grad_norm=0.137092
[18:48:15.116] Epoch 2, Iter 1010: loss=0.0411, ce=0.0053, dice=0.0650, grad_norm=0.324531
[18:48:17.345] Epoch 2, Iter 1020: loss=0.0430, ce=0.0039, dice=0.0692, grad_norm=0.262900
[18:48:19.589] Epoch 2, Iter 1030: loss=0.0967, ce=0.0100, dice=0.1545, grad_norm=1.433449
[18:48:21.839] Epoch 2, Iter 1040: loss=0.2074, ce=0.0025, dice=0.3440, grad_norm=0.037015
[18:48:24.109] Epoch 2, Iter 1050: loss=0.0505, ce=0.0037, dice=0.0817, grad_norm=0.761971
[18:48:26.326] Epoch 2, Iter 1060: loss=0.2055, ce=0.0024, dice=0.3408, grad_norm=0.111181
[18:48:28.589] Epoch 2, Iter 1070: loss=0.0442, ce=0.0045, dice=0.0706, grad_norm=0.285877
[18:48:30.826] Epoch 2, Iter 1080: loss=0.0457, ce=0.0064, dice=0.0720, grad_norm=0.372213
[18:48:33.107] Epoch 2, Iter 1090: loss=0.0302, ce=0.0051, dice=0.0469, grad_norm=0.325672
[18:48:35.357] Epoch 2, Iter 1100: loss=0.0207, ce=0.0033, dice=0.0324, grad_norm=0.177419
[18:48:37.614] Epoch 2, Iter 1110: loss=0.2127, ce=0.0039, dice=0.3519, grad_norm=0.244821
[18:48:39.864] Epoch 2, Iter 1120: loss=0.2172, ce=0.0077, dice=0.3568, grad_norm=0.208385
[18:48:42.119] Epoch 2, Iter 1130: loss=0.0453, ce=0.0043, dice=0.0727, grad_norm=0.244089
[18:48:44.351] Epoch 2, Iter 1140: loss=0.0452, ce=0.0055, dice=0.0717, grad_norm=0.330068
[18:48:46.603] Epoch 2, Iter 1150: loss=0.0417, ce=0.0049, dice=0.0663, grad_norm=0.245333
[18:48:48.841] Epoch 2, Iter 1160: loss=0.0613, ce=0.0019, dice=0.1010, grad_norm=0.644249
[18:48:51.118] Epoch 2, Iter 1170: loss=0.1121, ce=0.0071, dice=0.1822, grad_norm=3.015415
[18:48:53.395] Epoch 2, Iter 1180: loss=0.0321, ce=0.0041, dice=0.0507, grad_norm=0.156773
[18:48:55.665] Epoch 2, Iter 1190: loss=0.0253, ce=0.0064, dice=0.0378, grad_norm=0.097639
[18:48:57.913] Epoch 2, Iter 1200: loss=0.0266, ce=0.0030, dice=0.0422, grad_norm=0.095868
[18:49:00.177] Epoch 2, Iter 1210: loss=0.2091, ce=0.0069, dice=0.3439, grad_norm=0.065664
[18:49:02.441] Epoch 2, Iter 1220: loss=0.1421, ce=0.0048, dice=0.2336, grad_norm=1.163081
[18:49:04.694] Epoch 2, Iter 1230: loss=0.0617, ce=0.0068, dice=0.0983, grad_norm=1.172216
[18:49:06.936] Epoch 2, Iter 1240: loss=0.0341, ce=0.0055, dice=0.0532, grad_norm=0.388800
[18:49:09.182] Epoch 2, Iter 1250: loss=0.0544, ce=0.0089, dice=0.0847, grad_norm=0.737641
[18:49:11.418] Epoch 2, Iter 1260: loss=0.1974, ce=0.0056, dice=0.3253, grad_norm=0.742264
[18:49:13.673] Epoch 2, Iter 1270: loss=0.0257, ce=0.0029, dice=0.0409, grad_norm=0.378732
[18:49:15.919] Epoch 2, Iter 1280: loss=0.1712, ce=0.0050, dice=0.2820, grad_norm=2.555576
[18:49:18.182] Epoch 2, Iter 1290: loss=0.2201, ce=0.0043, dice=0.3640, grad_norm=0.478851
[18:49:20.434] Epoch 2, Iter 1300: loss=0.0190, ce=0.0039, dice=0.0291, grad_norm=0.092561
[18:49:22.699] Epoch 2, Iter 1310: loss=0.2117, ce=0.0078, dice=0.3476, grad_norm=0.051939
[18:49:24.955] Epoch 2, Iter 1320: loss=0.0634, ce=0.0131, dice=0.0969, grad_norm=1.571819
[18:49:27.198] Epoch 2, Iter 1330: loss=0.0308, ce=0.0051, dice=0.0480, grad_norm=0.576032
[18:49:29.448] Epoch 2, Iter 1340: loss=0.0299, ce=0.0010, dice=0.0492, grad_norm=0.435660
[18:49:31.712] Epoch 2, Iter 1350: loss=0.0265, ce=0.0078, dice=0.0390, grad_norm=0.259333
[18:49:33.953] Epoch 2, Iter 1360: loss=0.0741, ce=0.0063, dice=0.1194, grad_norm=1.048506
[18:49:36.210] Epoch 2, Iter 1370: loss=0.0369, ce=0.0057, dice=0.0576, grad_norm=0.463315
[18:49:38.441] Epoch 2, Iter 1380: loss=0.0534, ce=0.0089, dice=0.0832, grad_norm=0.454648
[18:49:40.655] Epoch 2, Iter 1390: loss=0.0302, ce=0.0114, dice=0.0427, grad_norm=0.100429
[18:49:41.699] Epoch 2: Avg Loss=0.0881, CE=0.0054, Dice=0.1433
[18:49:53.681] Epoch 3, Iter 1400: loss=0.1212, ce=0.0080, dice=0.1967, grad_norm=1.975917
[18:49:55.933] Epoch 3, Iter 1410: loss=0.2074, ce=0.0038, dice=0.3432, grad_norm=0.032891
[18:49:58.174] Epoch 3, Iter 1420: loss=0.0409, ce=0.0050, dice=0.0649, grad_norm=1.134386
[18:50:00.428] Epoch 3, Iter 1430: loss=0.2051, ce=0.0003, dice=0.3416, grad_norm=0.039367
[18:50:02.716] Epoch 3, Iter 1440: loss=0.0719, ce=0.0022, dice=0.1183, grad_norm=0.548229
[18:50:05.006] Epoch 3, Iter 1450: loss=0.1848, ce=0.0118, dice=0.3001, grad_norm=0.999290
[18:50:07.287] Epoch 3, Iter 1460: loss=0.0422, ce=0.0074, dice=0.0653, grad_norm=0.887601
[18:50:09.574] Epoch 3, Iter 1470: loss=0.2070, ce=0.0055, dice=0.3414, grad_norm=0.029854
[18:50:11.844] Epoch 3, Iter 1480: loss=0.0310, ce=0.0064, dice=0.0474, grad_norm=0.173562
[18:50:14.134] Epoch 3, Iter 1490: loss=0.0644, ce=0.0052, dice=0.1038, grad_norm=0.579567
[18:50:16.410] Epoch 3, Iter 1500: loss=0.2071, ce=0.0018, dice=0.3439, grad_norm=0.035438
[18:50:18.662] Epoch 3, Iter 1510: loss=0.0280, ce=0.0042, dice=0.0439, grad_norm=0.149300
[18:50:20.862] Epoch 3, Iter 1520: loss=0.0388, ce=0.0068, dice=0.0601, grad_norm=0.225655
[18:50:23.045] Epoch 3, Iter 1530: loss=0.0500, ce=0.0028, dice=0.0816, grad_norm=0.548782
[18:50:25.216] Epoch 3, Iter 1540: loss=0.0569, ce=0.0063, dice=0.0907, grad_norm=1.363726
[18:50:27.455] Epoch 3, Iter 1550: loss=0.2025, ce=0.0007, dice=0.3370, grad_norm=0.114947
[18:50:29.692] Epoch 3, Iter 1560: loss=0.2106, ce=0.0024, dice=0.3494, grad_norm=0.112485
[18:50:31.944] Epoch 3, Iter 1570: loss=0.0273, ce=0.0015, dice=0.0446, grad_norm=0.457893
[18:50:34.162] Epoch 3, Iter 1580: loss=0.1982, ce=0.0051, dice=0.3270, grad_norm=1.177593
[18:50:36.404] Epoch 3, Iter 1590: loss=0.2102, ce=0.0079, dice=0.3452, grad_norm=0.040153
[18:50:38.645] Epoch 3, Iter 1600: loss=0.2103, ce=0.0063, dice=0.3462, grad_norm=0.042325
[18:50:40.883] Epoch 3, Iter 1610: loss=0.0289, ce=0.0024, dice=0.0465, grad_norm=0.285477
[18:50:43.113] Epoch 3, Iter 1620: loss=0.0536, ce=0.0048, dice=0.0862, grad_norm=0.417452
[18:50:45.350] Epoch 3, Iter 1630: loss=0.2077, ce=0.0022, dice=0.3447, grad_norm=0.084523
[18:50:47.663] Epoch 3, Iter 1640: loss=0.0609, ce=0.0061, dice=0.0975, grad_norm=0.681533
[18:50:49.929] Epoch 3, Iter 1650: loss=0.0169, ce=0.0043, dice=0.0254, grad_norm=0.128223
[18:50:52.200] Epoch 3, Iter 1660: loss=0.2076, ce=0.0054, dice=0.3425, grad_norm=0.071277
[18:50:54.486] Epoch 3, Iter 1670: loss=0.0230, ce=0.0037, dice=0.0358, grad_norm=0.112460
[18:50:56.731] Epoch 3, Iter 1680: loss=0.0260, ce=0.0045, dice=0.0403, grad_norm=0.237744
[18:50:58.978] Epoch 3, Iter 1690: loss=0.0342, ce=0.0047, dice=0.0539, grad_norm=0.200907
[18:51:01.222] Epoch 3, Iter 1700: loss=0.0468, ce=0.0071, dice=0.0733, grad_norm=0.250774
[18:51:03.500] Epoch 3, Iter 1710: loss=0.2009, ce=0.0034, dice=0.3326, grad_norm=0.559228
[18:51:05.739] Epoch 3, Iter 1720: loss=0.2219, ce=0.0117, dice=0.3620, grad_norm=0.142781
[18:51:07.990] Epoch 3, Iter 1730: loss=0.0268, ce=0.0058, dice=0.0408, grad_norm=0.118106
[18:51:10.220] Epoch 3, Iter 1740: loss=0.0673, ce=0.0047, dice=0.1090, grad_norm=0.829791
[18:51:12.459] Epoch 3, Iter 1750: loss=0.0446, ce=0.0084, dice=0.0686, grad_norm=0.518916
[18:51:14.729] Epoch 3, Iter 1760: loss=0.0767, ce=0.0049, dice=0.1246, grad_norm=0.722686
[18:51:16.983] Epoch 3, Iter 1770: loss=0.0346, ce=0.0065, dice=0.0534, grad_norm=0.162604
[18:51:19.216] Epoch 3, Iter 1780: loss=0.0409, ce=0.0024, dice=0.0666, grad_norm=0.272740
[18:51:21.469] Epoch 3, Iter 1790: loss=0.0339, ce=0.0027, dice=0.0547, grad_norm=0.546581
[18:51:23.735] Epoch 3, Iter 1800: loss=0.1262, ce=0.0056, dice=0.2066, grad_norm=3.586628
[18:51:26.020] Epoch 3, Iter 1810: loss=0.0976, ce=0.0059, dice=0.1588, grad_norm=6.685893
[18:51:28.273] Epoch 3, Iter 1820: loss=0.0411, ce=0.0059, dice=0.0646, grad_norm=0.600732
[18:51:30.535] Epoch 3, Iter 1830: loss=0.1855, ce=0.0030, dice=0.3072, grad_norm=1.557147
[18:51:32.819] Epoch 3, Iter 1840: loss=0.0406, ce=0.0044, dice=0.0648, grad_norm=0.243898
[18:51:35.068] Epoch 3, Iter 1850: loss=0.2033, ce=0.0017, dice=0.3378, grad_norm=0.059846
[18:51:37.072] Epoch 3: Avg Loss=0.0896, CE=0.0051, Dice=0.1459
[18:51:48.574] Epoch 4, Iter 1860: loss=0.0113, ce=0.0031, dice=0.0167, grad_norm=0.057346
[18:51:50.874] Epoch 4, Iter 1870: loss=0.0567, ce=0.0052, dice=0.0910, grad_norm=1.534628
[18:51:53.200] Epoch 4, Iter 1880: loss=0.2083, ce=0.0048, dice=0.3440, grad_norm=0.038075
[18:51:55.476] Epoch 4, Iter 1890: loss=0.0241, ce=0.0076, dice=0.0352, grad_norm=0.239807
[18:51:57.752] Epoch 4, Iter 1900: loss=0.0465, ce=0.0061, dice=0.0735, grad_norm=0.280554
[18:52:00.012] Epoch 4, Iter 1910: loss=0.1831, ce=0.0040, dice=0.3025, grad_norm=0.699336
[18:52:02.275] Epoch 4, Iter 1920: loss=0.0300, ce=0.0049, dice=0.0468, grad_norm=0.251229
[18:52:04.545] Epoch 4, Iter 1930: loss=0.0692, ce=0.0042, dice=0.1126, grad_norm=1.383468
[18:52:06.818] Epoch 4, Iter 1940: loss=0.0390, ce=0.0044, dice=0.0621, grad_norm=0.170077
[18:52:09.064] Epoch 4, Iter 1950: loss=0.0222, ce=0.0070, dice=0.0323, grad_norm=0.161561
[18:52:11.316] Epoch 4, Iter 1960: loss=0.0448, ce=0.0036, dice=0.0722, grad_norm=0.327256
[18:52:13.580] Epoch 4, Iter 1970: loss=0.0274, ce=0.0035, dice=0.0434, grad_norm=0.144558
[18:52:15.827] Epoch 4, Iter 1980: loss=0.0263, ce=0.0026, dice=0.0421, grad_norm=0.176140
[18:52:18.089] Epoch 4, Iter 1990: loss=0.0437, ce=0.0025, dice=0.0712, grad_norm=0.649016
[18:52:20.383] Epoch 4, Iter 2000: loss=0.0360, ce=0.0020, dice=0.0587, grad_norm=0.295098
[18:52:22.695] Epoch 4, Iter 2010: loss=0.0530, ce=0.0026, dice=0.0866, grad_norm=0.192689
[18:52:24.923] Epoch 4, Iter 2020: loss=0.2072, ce=0.0031, dice=0.3433, grad_norm=0.149193
[18:52:27.185] Epoch 4, Iter 2030: loss=0.1216, ce=0.0028, dice=0.2008, grad_norm=0.898459
[18:52:29.431] Epoch 4, Iter 2040: loss=0.0244, ce=0.0042, dice=0.0378, grad_norm=0.321281
[18:52:31.684] Epoch 4, Iter 2050: loss=0.0391, ce=0.0047, dice=0.0621, grad_norm=0.670337
[18:52:33.914] Epoch 4, Iter 2060: loss=0.0518, ce=0.0062, dice=0.0822, grad_norm=0.395729
[18:52:36.172] Epoch 4, Iter 2070: loss=0.0684, ce=0.0082, dice=0.1085, grad_norm=0.279734
[18:52:38.417] Epoch 4, Iter 2080: loss=0.0293, ce=0.0068, dice=0.0443, grad_norm=0.201032
[18:52:40.652] Epoch 4, Iter 2090: loss=0.2070, ce=0.0057, dice=0.3412, grad_norm=0.102265
[18:52:42.914] Epoch 4, Iter 2100: loss=0.0280, ce=0.0063, dice=0.0424, grad_norm=0.103364
[18:52:45.171] Epoch 4, Iter 2110: loss=0.0298, ce=0.0025, dice=0.0480, grad_norm=1.152909
[18:52:47.477] Epoch 4, Iter 2120: loss=0.0451, ce=0.0029, dice=0.0732, grad_norm=0.408205
[18:52:49.771] Epoch 4, Iter 2130: loss=0.0537, ce=0.0040, dice=0.0868, grad_norm=0.393833
[18:52:52.005] Epoch 4, Iter 2140: loss=0.1748, ce=0.0049, dice=0.2881, grad_norm=2.527936
[18:52:54.279] Epoch 4, Iter 2150: loss=0.0874, ce=0.0052, dice=0.1421, grad_norm=2.863272
[18:52:56.531] Epoch 4, Iter 2160: loss=0.0435, ce=0.0050, dice=0.0692, grad_norm=0.320174
[18:52:58.828] Epoch 4, Iter 2170: loss=0.0296, ce=0.0029, dice=0.0474, grad_norm=0.481345
[18:53:01.069] Epoch 4, Iter 2180: loss=0.2236, ce=0.0011, dice=0.3720, grad_norm=0.649799
[18:53:03.362] Epoch 4, Iter 2190: loss=0.0335, ce=0.0044, dice=0.0530, grad_norm=0.233395
[18:53:05.631] Epoch 4, Iter 2200: loss=0.0332, ce=0.0052, dice=0.0518, grad_norm=0.467693
[18:53:07.894] Epoch 4, Iter 2210: loss=0.0311, ce=0.0103, dice=0.0450, grad_norm=0.154723
[18:53:10.140] Epoch 4, Iter 2220: loss=0.0738, ce=0.0048, dice=0.1198, grad_norm=2.247955
[18:53:12.389] Epoch 4, Iter 2230: loss=0.0218, ce=0.0047, dice=0.0332, grad_norm=0.183773
[18:53:14.632] Epoch 4, Iter 2240: loss=0.0359, ce=0.0023, dice=0.0582, grad_norm=0.272949
[18:53:16.901] Epoch 4, Iter 2250: loss=0.2076, ce=0.0052, dice=0.3425, grad_norm=0.054892
[18:53:19.175] Epoch 4, Iter 2260: loss=0.2023, ce=0.0024, dice=0.3355, grad_norm=4.053595
[18:53:21.429] Epoch 4, Iter 2270: loss=0.0485, ce=0.0042, dice=0.0781, grad_norm=0.328439
[18:53:23.692] Epoch 4, Iter 2280: loss=0.0171, ce=0.0033, dice=0.0262, grad_norm=0.250265
[18:53:25.929] Epoch 4, Iter 2290: loss=0.2153, ce=0.0138, dice=0.3496, grad_norm=3.919493
[18:53:28.176] Epoch 4, Iter 2300: loss=0.0709, ce=0.0082, dice=0.1126, grad_norm=0.443148
[18:53:30.497] Epoch 4, Iter 2310: loss=0.0232, ce=0.0065, dice=0.0343, grad_norm=0.103253
[18:53:32.707] Epoch 4, Iter 2320: loss=0.0187, ce=0.0005, dice=0.0307, grad_norm=1.346788
[18:53:33.384] Epoch 4: Avg Loss=0.0863, CE=0.0049, Dice=0.1405
[18:53:45.870] Epoch 5, Iter 2330: loss=0.2078, ce=0.0033, dice=0.3441, grad_norm=0.103686
[18:53:48.106] Epoch 5, Iter 2340: loss=0.0339, ce=0.0011, dice=0.0557, grad_norm=3.334557
[18:53:50.346] Epoch 5, Iter 2350: loss=0.0403, ce=0.0084, dice=0.0616, grad_norm=0.479059
[18:53:52.601] Epoch 5, Iter 2360: loss=0.0776, ce=0.0036, dice=0.1270, grad_norm=0.642646
[18:53:54.876] Epoch 5, Iter 2370: loss=0.1560, ce=0.0071, dice=0.2552, grad_norm=16.029383
[18:53:57.146] Epoch 5, Iter 2380: loss=0.1275, ce=0.0058, dice=0.2086, grad_norm=4.101568
[18:53:59.392] Epoch 5, Iter 2390: loss=0.0264, ce=0.0065, dice=0.0396, grad_norm=0.291199
[18:54:01.624] Epoch 5, Iter 2400: loss=0.2089, ce=0.0045, dice=0.3452, grad_norm=0.105514
[18:54:03.887] Epoch 5, Iter 2410: loss=0.0464, ce=0.0112, dice=0.0699, grad_norm=0.187368
[18:54:06.146] Epoch 5, Iter 2420: loss=0.0108, ce=0.0059, dice=0.0141, grad_norm=0.141409
[18:54:08.413] Epoch 5, Iter 2430: loss=0.0570, ce=0.0129, dice=0.0864, grad_norm=0.563044
[18:54:10.664] Epoch 5, Iter 2440: loss=0.0354, ce=0.0061, dice=0.0550, grad_norm=0.194308
[18:54:12.932] Epoch 5, Iter 2450: loss=0.0658, ce=0.0060, dice=0.1057, grad_norm=2.041800
[18:54:15.172] Epoch 5, Iter 2460: loss=0.0581, ce=0.0049, dice=0.0936, grad_norm=0.860625
[18:54:17.407] Epoch 5, Iter 2470: loss=0.0429, ce=0.0046, dice=0.0684, grad_norm=0.746922
[18:54:19.650] Epoch 5, Iter 2480: loss=0.0789, ce=0.0050, dice=0.1282, grad_norm=0.423989
[18:54:21.912] Epoch 5, Iter 2490: loss=0.1419, ce=0.0021, dice=0.2351, grad_norm=14.743636
[18:54:24.183] Epoch 5, Iter 2500: loss=0.1002, ce=0.0067, dice=0.1626, grad_norm=1.075168
[18:54:26.431] Epoch 5, Iter 2510: loss=0.0423, ce=0.0090, dice=0.0645, grad_norm=0.310494
[18:54:28.671] Epoch 5, Iter 2520: loss=0.0250, ce=0.0030, dice=0.0396, grad_norm=0.129888
[18:54:30.926] Epoch 5, Iter 2530: loss=0.0457, ce=0.0069, dice=0.0715, grad_norm=0.801086
[18:54:33.144] Epoch 5, Iter 2540: loss=0.0299, ce=0.0091, dice=0.0438, grad_norm=0.997583
[18:54:35.401] Epoch 5, Iter 2550: loss=0.0242, ce=0.0046, dice=0.0373, grad_norm=0.225313
[18:54:37.663] Epoch 5, Iter 2560: loss=0.0545, ce=0.0071, dice=0.0861, grad_norm=0.808418
[18:54:39.931] Epoch 5, Iter 2570: loss=0.0691, ce=0.0086, dice=0.1095, grad_norm=0.397804
[18:54:42.162] Epoch 5, Iter 2580: loss=0.0454, ce=0.0031, dice=0.0736, grad_norm=0.377205
[18:54:44.429] Epoch 5, Iter 2590: loss=0.0328, ce=0.0038, dice=0.0521, grad_norm=0.229156
[18:54:46.666] Epoch 5, Iter 2600: loss=0.0213, ce=0.0080, dice=0.0301, grad_norm=0.163609
[18:54:48.927] Epoch 5, Iter 2610: loss=0.0294, ce=0.0072, dice=0.0442, grad_norm=0.370179
[18:54:51.168] Epoch 5, Iter 2620: loss=0.0266, ce=0.0045, dice=0.0414, grad_norm=0.181029
[18:54:53.423] Epoch 5, Iter 2630: loss=0.0272, ce=0.0057, dice=0.0416, grad_norm=0.494121
[18:54:55.671] Epoch 5, Iter 2640: loss=0.0214, ce=0.0006, dice=0.0353, grad_norm=0.280264
[18:54:57.913] Epoch 5, Iter 2650: loss=0.2039, ce=0.0023, dice=0.3383, grad_norm=0.190635
[18:55:00.161] Epoch 5, Iter 2660: loss=0.0409, ce=0.0048, dice=0.0649, grad_norm=0.373270
[18:55:02.434] Epoch 5, Iter 2670: loss=0.0282, ce=0.0040, dice=0.0443, grad_norm=0.086280
[18:55:04.701] Epoch 5, Iter 2680: loss=0.0376, ce=0.0065, dice=0.0584, grad_norm=0.236165
[18:55:06.942] Epoch 5, Iter 2690: loss=0.0831, ce=0.0068, dice=0.1339, grad_norm=3.808196
[18:55:09.199] Epoch 5, Iter 2700: loss=0.2086, ce=0.0055, dice=0.3440, grad_norm=0.041951
[18:55:11.462] Epoch 5, Iter 2710: loss=0.0582, ce=0.0058, dice=0.0931, grad_norm=0.248569
[18:55:13.721] Epoch 5, Iter 2720: loss=0.0380, ce=0.0035, dice=0.0610, grad_norm=0.383274
[18:55:16.001] Epoch 5, Iter 2730: loss=0.0896, ce=0.0031, dice=0.1473, grad_norm=1.608173
[18:55:18.223] Epoch 5, Iter 2740: loss=0.0424, ce=0.0028, dice=0.0687, grad_norm=0.289822
[18:55:20.492] Epoch 5, Iter 2750: loss=0.0233, ce=0.0051, dice=0.0355, grad_norm=0.122536
[18:55:22.732] Epoch 5, Iter 2760: loss=0.1637, ce=0.0051, dice=0.2694, grad_norm=2.057936
[18:55:24.991] Epoch 5, Iter 2770: loss=0.0111, ce=0.0003, dice=0.0183, grad_norm=0.098475
[18:55:27.243] Epoch 5, Iter 2780: loss=0.0327, ce=0.0058, dice=0.0507, grad_norm=0.377489
[18:55:28.728] Epoch 5: Avg Loss=0.0710, CE=0.0050, Dice=0.1149
[18:55:40.152] Epoch 6, Iter 2790: loss=0.1705, ce=0.0042, dice=0.2814, grad_norm=7.506724
[18:55:42.366] Epoch 6, Iter 2800: loss=0.0335, ce=0.0040, dice=0.0531, grad_norm=0.097092
[18:55:44.622] Epoch 6, Iter 2810: loss=0.0280, ce=0.0093, dice=0.0405, grad_norm=0.093263
[18:55:46.853] Epoch 6, Iter 2820: loss=0.0271, ce=0.0085, dice=0.0395, grad_norm=0.257121
[18:55:49.074] Epoch 6, Iter 2830: loss=0.0566, ce=0.0028, dice=0.0925, grad_norm=3.005277
[18:55:51.313] Epoch 6, Iter 2840: loss=0.0468, ce=0.0036, dice=0.0756, grad_norm=0.155227
[18:55:53.585] Epoch 6, Iter 2850: loss=0.0725, ce=0.0010, dice=0.1201, grad_norm=0.874573
[18:55:55.901] Epoch 6, Iter 2860: loss=0.0275, ce=0.0118, dice=0.0380, grad_norm=0.187317
[18:55:58.133] Epoch 6, Iter 2870: loss=0.0348, ce=0.0032, dice=0.0559, grad_norm=0.200638
[18:56:00.378] Epoch 6, Iter 2880: loss=0.0372, ce=0.0049, dice=0.0587, grad_norm=0.213808
[18:56:02.632] Epoch 6, Iter 2890: loss=0.0543, ce=0.0063, dice=0.0863, grad_norm=0.270943
[18:56:04.894] Epoch 6, Iter 2900: loss=0.1238, ce=0.0092, dice=0.2003, grad_norm=0.319191
[18:56:07.132] Epoch 6, Iter 2910: loss=0.0567, ce=0.0070, dice=0.0899, grad_norm=0.468417
[18:56:09.369] Epoch 6, Iter 2920: loss=0.0485, ce=0.0065, dice=0.0765, grad_norm=0.694935
[18:56:11.634] Epoch 6, Iter 2930: loss=0.0163, ce=0.0040, dice=0.0246, grad_norm=0.268082
[18:56:13.879] Epoch 6, Iter 2940: loss=0.0195, ce=0.0096, dice=0.0261, grad_norm=0.057716
[18:56:16.156] Epoch 6, Iter 2950: loss=0.0492, ce=0.0066, dice=0.0776, grad_norm=0.264533
[18:56:18.392] Epoch 6, Iter 2960: loss=0.2077, ce=0.0052, dice=0.3427, grad_norm=0.165982
[18:56:20.643] Epoch 6, Iter 2970: loss=0.0390, ce=0.0030, dice=0.0630, grad_norm=0.327322
[18:56:22.892] Epoch 6, Iter 2980: loss=0.0283, ce=0.0107, dice=0.0400, grad_norm=0.136524
[18:56:25.147] Epoch 6, Iter 2990: loss=0.0208, ce=0.0019, dice=0.0335, grad_norm=0.206788
[18:56:27.386] Epoch 6, Iter 3000: loss=0.0533, ce=0.0030, dice=0.0868, grad_norm=0.510655
[18:56:29.643] Epoch 6, Iter 3010: loss=0.0518, ce=0.0025, dice=0.0847, grad_norm=0.700836
[18:56:31.886] Epoch 6, Iter 3020: loss=0.0230, ce=0.0047, dice=0.0352, grad_norm=0.238232
[18:56:34.120] Epoch 6, Iter 3030: loss=0.0159, ce=0.0032, dice=0.0244, grad_norm=0.101071
[18:56:36.361] Epoch 6, Iter 3040: loss=0.0708, ce=0.0044, dice=0.1151, grad_norm=0.548283
[18:56:38.596] Epoch 6, Iter 3050: loss=0.0476, ce=0.0048, dice=0.0761, grad_norm=0.363849
[18:56:40.840] Epoch 6, Iter 3060: loss=0.0424, ce=0.0038, dice=0.0681, grad_norm=0.419237
[18:56:43.057] Epoch 6, Iter 3070: loss=0.0117, ce=0.0021, dice=0.0181, grad_norm=0.401772
[18:56:45.320] Epoch 6, Iter 3080: loss=0.1876, ce=0.0038, dice=0.3101, grad_norm=17.504525
[18:56:47.597] Epoch 6, Iter 3090: loss=0.1702, ce=0.0223, dice=0.2689, grad_norm=1.397232
[18:56:49.904] Epoch 6, Iter 3100: loss=0.0867, ce=0.0032, dice=0.1424, grad_norm=0.513127
[18:56:52.162] Epoch 6, Iter 3110: loss=0.0505, ce=0.0133, dice=0.0753, grad_norm=1.097752
[18:56:54.417] Epoch 6, Iter 3120: loss=0.0082, ce=0.0031, dice=0.0116, grad_norm=0.250405
[18:56:56.675] Epoch 6, Iter 3130: loss=0.2063, ce=0.0030, dice=0.3418, grad_norm=0.036686
[18:56:58.932] Epoch 6, Iter 3140: loss=0.0231, ce=0.0073, dice=0.0336, grad_norm=0.203880
[18:57:01.195] Epoch 6, Iter 3150: loss=0.0068, ce=0.0025, dice=0.0097, grad_norm=0.060151
[18:57:03.452] Epoch 6, Iter 3160: loss=0.0329, ce=0.0062, dice=0.0506, grad_norm=0.199355
[18:57:05.715] Epoch 6, Iter 3170: loss=0.0325, ce=0.0058, dice=0.0502, grad_norm=0.125381
[18:57:07.983] Epoch 6, Iter 3180: loss=0.0496, ce=0.0040, dice=0.0799, grad_norm=0.165673
[18:57:10.261] Epoch 6, Iter 3190: loss=0.0077, ce=0.0035, dice=0.0105, grad_norm=0.065658
[18:57:12.521] Epoch 6, Iter 3200: loss=0.0773, ce=0.0020, dice=0.1275, grad_norm=0.443741
[18:57:14.832] Epoch 6, Iter 3210: loss=0.0204, ce=0.0075, dice=0.0291, grad_norm=0.299417
[18:57:17.112] Epoch 6, Iter 3220: loss=0.0073, ce=0.0018, dice=0.0109, grad_norm=0.051644
[18:57:19.378] Epoch 6, Iter 3230: loss=0.0503, ce=0.0033, dice=0.0816, grad_norm=0.548101
[18:57:21.655] Epoch 6, Iter 3240: loss=0.2052, ce=0.0019, dice=0.3407, grad_norm=0.199973
[18:57:24.047] Epoch 6: Avg Loss=0.0662, CE=0.0048, Dice=0.1072
[18:57:34.432] Epoch 7, Iter 3250: loss=0.0262, ce=0.0040, dice=0.0411, grad_norm=1.718088
[18:57:36.642] Epoch 7, Iter 3260: loss=0.0687, ce=0.0042, dice=0.1117, grad_norm=0.426108
[18:57:38.892] Epoch 7, Iter 3270: loss=0.0413, ce=0.0072, dice=0.0640, grad_norm=0.243970
[18:57:41.118] Epoch 7, Iter 3280: loss=0.0498, ce=0.0019, dice=0.0817, grad_norm=3.015869
[18:57:43.377] Epoch 7, Iter 3290: loss=0.0558, ce=0.0064, dice=0.0888, grad_norm=0.309044
[18:57:45.632] Epoch 7, Iter 3300: loss=0.0234, ce=0.0042, dice=0.0363, grad_norm=0.175893
[18:57:47.902] Epoch 7, Iter 3310: loss=0.0042, ce=0.0003, dice=0.0069, grad_norm=0.086922
[18:57:50.160] Epoch 7, Iter 3320: loss=0.0485, ce=0.0025, dice=0.0792, grad_norm=0.248681
[18:57:52.461] Epoch 7, Iter 3330: loss=0.0706, ce=0.0055, dice=0.1140, grad_norm=0.905908
[18:57:54.722] Epoch 7, Iter 3340: loss=0.2068, ce=0.0034, dice=0.3424, grad_norm=0.050615
[18:57:56.992] Epoch 7, Iter 3350: loss=0.0146, ce=0.0040, dice=0.0216, grad_norm=0.061095
[18:57:59.253] Epoch 7, Iter 3360: loss=0.0093, ce=0.0026, dice=0.0138, grad_norm=0.045204
[18:58:01.510] Epoch 7, Iter 3370: loss=0.0278, ce=0.0020, dice=0.0449, grad_norm=0.272007
[18:58:03.784] Epoch 7, Iter 3380: loss=0.0601, ce=0.0060, dice=0.0962, grad_norm=0.963049
[18:58:06.052] Epoch 7, Iter 3390: loss=0.0219, ce=0.0038, dice=0.0341, grad_norm=0.083666
[18:58:08.310] Epoch 7, Iter 3400: loss=0.0175, ce=0.0037, dice=0.0268, grad_norm=0.162640
[18:58:10.557] Epoch 7, Iter 3410: loss=0.0301, ce=0.0048, dice=0.0470, grad_norm=0.469578
[18:58:12.824] Epoch 7, Iter 3420: loss=0.0432, ce=0.0009, dice=0.0715, grad_norm=10.915977
[18:58:15.096] Epoch 7, Iter 3430: loss=0.2058, ce=0.0030, dice=0.3410, grad_norm=0.039657
[18:58:17.346] Epoch 7, Iter 3440: loss=0.0304, ce=0.0025, dice=0.0490, grad_norm=0.121179
[18:58:19.596] Epoch 7, Iter 3450: loss=0.0378, ce=0.0035, dice=0.0606, grad_norm=0.461595
[18:58:21.848] Epoch 7, Iter 3460: loss=0.0358, ce=0.0054, dice=0.0561, grad_norm=1.388410
[18:58:24.107] Epoch 7, Iter 3470: loss=0.0490, ce=0.0025, dice=0.0799, grad_norm=0.477815
[18:58:26.399] Epoch 7, Iter 3480: loss=0.0257, ce=0.0033, dice=0.0406, grad_norm=0.223397
[18:58:28.649] Epoch 7, Iter 3490: loss=0.0209, ce=0.0049, dice=0.0315, grad_norm=0.109617
[18:58:30.870] Epoch 7, Iter 3500: loss=0.2057, ce=0.0024, dice=0.3412, grad_norm=0.027720
[18:58:33.117] Epoch 7, Iter 3510: loss=0.2039, ce=0.0013, dice=0.3389, grad_norm=0.017810
[18:58:35.351] Epoch 7, Iter 3520: loss=0.0174, ce=0.0026, dice=0.0273, grad_norm=0.084400
[18:58:37.614] Epoch 7, Iter 3530: loss=0.0019, ce=0.0003, dice=0.0030, grad_norm=0.010440
[18:58:39.867] Epoch 7, Iter 3540: loss=0.2074, ce=0.0034, dice=0.3434, grad_norm=0.042470
[18:58:42.104] Epoch 7, Iter 3550: loss=0.0195, ce=0.0010, dice=0.0318, grad_norm=0.309087
[18:58:44.350] Epoch 7, Iter 3560: loss=0.2097, ce=0.0097, dice=0.3430, grad_norm=0.051832
[18:58:46.615] Epoch 7, Iter 3570: loss=0.0272, ce=0.0053, dice=0.0419, grad_norm=0.124981
[18:58:48.876] Epoch 7, Iter 3580: loss=0.0473, ce=0.0023, dice=0.0774, grad_norm=0.959195
[18:58:51.158] Epoch 7, Iter 3590: loss=0.0339, ce=0.0045, dice=0.0534, grad_norm=0.219493
[18:58:53.427] Epoch 7, Iter 3600: loss=0.0207, ce=0.0008, dice=0.0339, grad_norm=4.999980
[18:58:55.688] Epoch 7, Iter 3610: loss=0.0400, ce=0.0022, dice=0.0653, grad_norm=0.119649
[18:58:57.915] Epoch 7, Iter 3620: loss=0.1898, ce=0.0015, dice=0.3154, grad_norm=4.215888
[18:59:00.156] Epoch 7, Iter 3630: loss=0.0282, ce=0.0039, dice=0.0444, grad_norm=0.206356
[18:59:02.410] Epoch 7, Iter 3640: loss=0.0067, ce=0.0033, dice=0.0089, grad_norm=0.370510
[18:59:04.672] Epoch 7, Iter 3650: loss=0.2080, ce=0.0022, dice=0.3451, grad_norm=0.028675
[18:59:06.930] Epoch 7, Iter 3660: loss=0.0151, ce=0.0017, dice=0.0240, grad_norm=0.175844
[18:59:09.208] Epoch 7, Iter 3670: loss=0.2086, ce=0.0030, dice=0.3457, grad_norm=0.079403
[18:59:11.463] Epoch 7, Iter 3680: loss=0.0401, ce=0.0045, dice=0.0639, grad_norm=0.329636
[18:59:13.719] Epoch 7, Iter 3690: loss=0.0224, ce=0.0023, dice=0.0358, grad_norm=0.096029
[18:59:15.965] Epoch 7, Iter 3700: loss=0.0063, ce=0.0009, dice=0.0099, grad_norm=0.041444
[18:59:18.200] Epoch 7, Iter 3710: loss=0.0410, ce=0.0047, dice=0.0651, grad_norm=0.703774
[18:59:19.256] Epoch 7: Avg Loss=0.0598, CE=0.0043, Dice=0.0968
[18:59:31.305] Epoch 8, Iter 3720: loss=0.0336, ce=0.0043, dice=0.0530, grad_norm=0.139086
[18:59:33.562] Epoch 8, Iter 3730: loss=0.0431, ce=0.0008, dice=0.0713, grad_norm=0.404186
[18:59:35.823] Epoch 8, Iter 3740: loss=0.0417, ce=0.0022, dice=0.0681, grad_norm=0.329112
[18:59:38.069] Epoch 8, Iter 3750: loss=0.0906, ce=0.0046, dice=0.1479, grad_norm=0.350463
[18:59:40.337] Epoch 8, Iter 3760: loss=0.0238, ce=0.0074, dice=0.0347, grad_norm=0.073370
[18:59:42.603] Epoch 8, Iter 3770: loss=0.0348, ce=0.0050, dice=0.0546, grad_norm=0.322800
[18:59:44.879] Epoch 8, Iter 3780: loss=0.0372, ce=0.0041, dice=0.0593, grad_norm=0.198817
[18:59:47.186] Epoch 8, Iter 3790: loss=0.0483, ce=0.0068, dice=0.0759, grad_norm=0.329648
[18:59:49.433] Epoch 8, Iter 3800: loss=0.0260, ce=0.0027, dice=0.0416, grad_norm=0.306138
[18:59:51.701] Epoch 8, Iter 3810: loss=0.0039, ce=0.0007, dice=0.0060, grad_norm=0.039938
[18:59:53.941] Epoch 8, Iter 3820: loss=0.0454, ce=0.0012, dice=0.0749, grad_norm=0.466037
[18:59:56.204] Epoch 8, Iter 3830: loss=0.0354, ce=0.0060, dice=0.0550, grad_norm=0.224381
[18:59:58.463] Epoch 8, Iter 3840: loss=0.2104, ce=0.0063, dice=0.3465, grad_norm=0.190595
[19:00:00.713] Epoch 8, Iter 3850: loss=0.0184, ce=0.0028, dice=0.0288, grad_norm=0.096871
[19:00:02.953] Epoch 8, Iter 3860: loss=0.0403, ce=0.0061, dice=0.0632, grad_norm=0.527145
[19:00:05.212] Epoch 8, Iter 3870: loss=0.0225, ce=0.0075, dice=0.0325, grad_norm=0.097688
[19:00:07.451] Epoch 8, Iter 3880: loss=0.0305, ce=0.0021, dice=0.0494, grad_norm=0.151556
[19:00:09.705] Epoch 8, Iter 3890: loss=0.0058, ce=0.0017, dice=0.0086, grad_norm=0.238961
[19:00:11.947] Epoch 8, Iter 3900: loss=0.0231, ce=0.0019, dice=0.0373, grad_norm=0.253752
[19:00:14.257] Epoch 8, Iter 3910: loss=0.0509, ce=0.0068, dice=0.0802, grad_norm=0.180489
[19:00:16.497] Epoch 8, Iter 3920: loss=0.0086, ce=0.0020, dice=0.0131, grad_norm=1.003949
[19:00:18.753] Epoch 8, Iter 3930: loss=0.0205, ce=0.0021, dice=0.0327, grad_norm=9.979618
[19:00:20.999] Epoch 8, Iter 3940: loss=0.0260, ce=0.0053, dice=0.0397, grad_norm=0.455401
[19:00:23.256] Epoch 8, Iter 3950: loss=0.1074, ce=0.0039, dice=0.1763, grad_norm=0.281242
[19:00:25.523] Epoch 8, Iter 3960: loss=0.0244, ce=0.0019, dice=0.0395, grad_norm=0.185427
[19:00:27.798] Epoch 8, Iter 3970: loss=0.0520, ce=0.0096, dice=0.0803, grad_norm=0.147469
[19:00:30.045] Epoch 8, Iter 3980: loss=0.0065, ce=0.0004, dice=0.0106, grad_norm=0.090254
[19:00:32.305] Epoch 8, Iter 3990: loss=0.0258, ce=0.0088, dice=0.0371, grad_norm=0.114339
[19:00:34.565] Epoch 8, Iter 4000: loss=0.0416, ce=0.0040, dice=0.0667, grad_norm=0.273232
[19:00:36.845] Epoch 8, Iter 4010: loss=0.0267, ce=0.0022, dice=0.0430, grad_norm=0.185113
[19:00:39.117] Epoch 8, Iter 4020: loss=0.2076, ce=0.0026, dice=0.3443, grad_norm=0.028256
[19:00:41.368] Epoch 8, Iter 4030: loss=0.0162, ce=0.0031, dice=0.0249, grad_norm=0.070780
[19:00:43.595] Epoch 8, Iter 4040: loss=0.0207, ce=0.0039, dice=0.0319, grad_norm=0.113638
[19:00:45.847] Epoch 8, Iter 4050: loss=0.0329, ce=0.0035, dice=0.0525, grad_norm=0.295335
[19:00:48.100] Epoch 8, Iter 4060: loss=0.0236, ce=0.0049, dice=0.0361, grad_norm=0.169645
[19:00:50.350] Epoch 8, Iter 4070: loss=0.0476, ce=0.0045, dice=0.0764, grad_norm=0.145179
[19:00:52.590] Epoch 8, Iter 4080: loss=0.1071, ce=0.0010, dice=0.1779, grad_norm=3.394890
[19:00:54.928] Epoch 8, Iter 4090: loss=0.0270, ce=0.0028, dice=0.0431, grad_norm=0.160027
[19:00:57.182] Epoch 8, Iter 4100: loss=0.0185, ce=0.0040, dice=0.0282, grad_norm=0.292209
[19:00:59.418] Epoch 8, Iter 4110: loss=0.0464, ce=0.0047, dice=0.0743, grad_norm=0.362776
[19:01:01.667] Epoch 8, Iter 4120: loss=0.0187, ce=0.0061, dice=0.0272, grad_norm=0.082198
[19:01:03.891] Epoch 8, Iter 4130: loss=0.0248, ce=0.0016, dice=0.0402, grad_norm=0.368306
[19:01:06.138] Epoch 8, Iter 4140: loss=0.0269, ce=0.0102, dice=0.0381, grad_norm=0.067456
[19:01:08.398] Epoch 8, Iter 4150: loss=0.0430, ce=0.0026, dice=0.0699, grad_norm=1.881629
[19:01:10.637] Epoch 8, Iter 4160: loss=0.0549, ce=0.0030, dice=0.0895, grad_norm=0.359807
[19:01:12.882] Epoch 8, Iter 4170: loss=0.0218, ce=0.0070, dice=0.0316, grad_norm=0.072138
[19:01:14.802] Epoch 8: Avg Loss=0.0534, CE=0.0043, Dice=0.0861
[19:01:25.784] Epoch 9, Iter 4180: loss=0.0443, ce=0.0119, dice=0.0658, grad_norm=0.253375
[19:01:28.007] Epoch 9, Iter 4190: loss=0.0550, ce=0.0043, dice=0.0887, grad_norm=0.989486
[19:01:30.220] Epoch 9, Iter 4200: loss=0.0241, ce=0.0043, dice=0.0373, grad_norm=0.082875
[19:01:32.470] Epoch 9, Iter 4210: loss=0.0194, ce=0.0056, dice=0.0286, grad_norm=0.137375
[19:01:34.705] Epoch 9, Iter 4220: loss=0.0627, ce=0.0042, dice=0.1017, grad_norm=0.474500
[19:01:36.937] Epoch 9, Iter 4230: loss=0.0162, ce=0.0020, dice=0.0257, grad_norm=0.154873
[19:01:39.159] Epoch 9, Iter 4240: loss=0.0248, ce=0.0052, dice=0.0379, grad_norm=0.155052
[19:01:41.384] Epoch 9, Iter 4250: loss=0.0460, ce=0.0059, dice=0.0727, grad_norm=0.367962
[19:01:43.609] Epoch 9, Iter 4260: loss=0.0461, ce=0.0044, dice=0.0739, grad_norm=0.147929
[19:01:45.818] Epoch 9, Iter 4270: loss=0.0332, ce=0.0040, dice=0.0527, grad_norm=0.251210
[19:01:48.043] Epoch 9, Iter 4280: loss=0.0233, ce=0.0034, dice=0.0365, grad_norm=0.139825
[19:01:50.294] Epoch 9, Iter 4290: loss=0.0137, ce=0.0024, dice=0.0212, grad_norm=0.130355
[19:01:52.527] Epoch 9, Iter 4300: loss=0.0236, ce=0.0083, dice=0.0338, grad_norm=0.081516
[19:01:54.772] Epoch 9, Iter 4310: loss=0.0246, ce=0.0056, dice=0.0372, grad_norm=0.154393
[19:01:57.005] Epoch 9, Iter 4320: loss=0.0391, ce=0.0007, dice=0.0647, grad_norm=2.268540
[19:01:59.224] Epoch 9, Iter 4330: loss=0.0346, ce=0.0044, dice=0.0548, grad_norm=0.211591
[19:02:01.448] Epoch 9, Iter 4340: loss=0.2039, ce=0.0043, dice=0.3369, grad_norm=1.187458
[19:02:03.696] Epoch 9, Iter 4350: loss=0.0623, ce=0.0022, dice=0.1023, grad_norm=0.336063
[19:02:05.917] Epoch 9, Iter 4360: loss=0.0260, ce=0.0067, dice=0.0388, grad_norm=0.114450
[19:02:08.153] Epoch 9, Iter 4370: loss=0.0204, ce=0.0061, dice=0.0299, grad_norm=0.120942
[19:02:10.356] Epoch 9, Iter 4380: loss=0.0277, ce=0.0072, dice=0.0413, grad_norm=0.136214
[19:02:12.594] Epoch 9, Iter 4390: loss=0.0514, ce=0.0036, dice=0.0832, grad_norm=0.362473
[19:02:14.826] Epoch 9, Iter 4400: loss=0.0190, ce=0.0027, dice=0.0299, grad_norm=0.162519
[19:02:17.074] Epoch 9, Iter 4410: loss=0.0533, ce=0.0047, dice=0.0856, grad_norm=0.349535
[19:02:19.310] Epoch 9, Iter 4420: loss=0.0801, ce=0.0031, dice=0.1315, grad_norm=3.265312
[19:02:21.548] Epoch 9, Iter 4430: loss=0.0261, ce=0.0056, dice=0.0398, grad_norm=0.159709
[19:02:23.757] Epoch 9, Iter 4440: loss=0.0287, ce=0.0073, dice=0.0430, grad_norm=0.133986
[19:02:25.998] Epoch 9, Iter 4450: loss=0.0502, ce=0.0037, dice=0.0811, grad_norm=0.179226
[19:02:28.221] Epoch 9, Iter 4460: loss=0.0142, ce=0.0045, dice=0.0207, grad_norm=0.051948
[19:02:30.445] Epoch 9, Iter 4470: loss=0.0422, ce=0.0027, dice=0.0685, grad_norm=0.248234
[19:02:32.681] Epoch 9, Iter 4480: loss=0.0606, ce=0.0025, dice=0.0993, grad_norm=0.239820
[19:02:34.926] Epoch 9, Iter 4490: loss=0.0271, ce=0.0041, dice=0.0423, grad_norm=0.130296
[19:02:37.180] Epoch 9, Iter 4500: loss=0.0223, ce=0.0036, dice=0.0347, grad_norm=0.117722
[19:02:39.408] Epoch 9, Iter 4510: loss=0.0256, ce=0.0036, dice=0.0402, grad_norm=0.129646
[19:02:41.640] Epoch 9, Iter 4520: loss=0.0060, ce=0.0026, dice=0.0083, grad_norm=0.049383
[19:02:43.916] Epoch 9, Iter 4530: loss=0.0348, ce=0.0221, dice=0.0433, grad_norm=0.329695
[19:02:46.245] Epoch 9, Iter 4540: loss=0.0773, ce=0.0026, dice=0.1272, grad_norm=0.135406
[19:02:48.564] Epoch 9, Iter 4550: loss=0.0328, ce=0.0087, dice=0.0488, grad_norm=0.208215
[19:02:50.839] Epoch 9, Iter 4560: loss=0.0082, ce=0.0018, dice=0.0124, grad_norm=0.249329
[19:02:53.129] Epoch 9, Iter 4570: loss=0.0480, ce=0.0036, dice=0.0777, grad_norm=0.914333
[19:02:55.433] Epoch 9, Iter 4580: loss=0.0816, ce=0.0055, dice=0.1324, grad_norm=1.242386
[19:02:57.715] Epoch 9, Iter 4590: loss=0.0511, ce=0.0024, dice=0.0835, grad_norm=0.782525
[19:02:59.974] Epoch 9, Iter 4600: loss=0.2011, ce=0.0069, dice=0.3305, grad_norm=1.167243
[19:03:02.229] Epoch 9, Iter 4610: loss=0.0268, ce=0.0057, dice=0.0409, grad_norm=0.178369
[19:03:04.499] Epoch 9, Iter 4620: loss=0.0091, ce=0.0024, dice=0.0135, grad_norm=0.065398
[19:03:06.749] Epoch 9, Iter 4630: loss=0.0230, ce=0.0018, dice=0.0371, grad_norm=0.318028
[19:03:08.927] Epoch 9, Iter 4640: loss=0.0194, ce=0.0035, dice=0.0301, grad_norm=0.120152
[19:03:09.580] Epoch 9: Avg Loss=0.0574, CE=0.0042, Dice=0.0929
[19:03:09.680] save model to ./finetune_tpgm_lits17_debug\finetuned_lits17_epoch_9.pth
[19:03:22.460] Epoch 10, Iter 4650: loss=0.0422, ce=0.0033, dice=0.0681, grad_norm=0.263784
[19:03:24.694] Epoch 10, Iter 4660: loss=0.2076, ce=0.0064, dice=0.3417, grad_norm=0.044379
[19:03:26.916] Epoch 10, Iter 4670: loss=0.0348, ce=0.0052, dice=0.0545, grad_norm=0.306217
[19:03:29.156] Epoch 10, Iter 4680: loss=0.0469, ce=0.0038, dice=0.0756, grad_norm=0.226890
[19:03:31.399] Epoch 10, Iter 4690: loss=0.0072, ce=0.0029, dice=0.0100, grad_norm=0.041831
[19:03:33.624] Epoch 10, Iter 4700: loss=0.0189, ce=0.0042, dice=0.0287, grad_norm=0.202184
[19:03:35.867] Epoch 10, Iter 4710: loss=0.0339, ce=0.0033, dice=0.0543, grad_norm=0.365438
[19:03:38.097] Epoch 10, Iter 4720: loss=0.0574, ce=0.0026, dice=0.0939, grad_norm=0.311078
[19:03:40.336] Epoch 10, Iter 4730: loss=0.0496, ce=0.0025, dice=0.0810, grad_norm=0.228237
[19:03:42.557] Epoch 10, Iter 4740: loss=0.0252, ce=0.0037, dice=0.0395, grad_norm=0.541933
[19:03:44.797] Epoch 10, Iter 4750: loss=0.0461, ce=0.0064, dice=0.0725, grad_norm=0.205162
[19:03:47.019] Epoch 10, Iter 4760: loss=0.2056, ce=0.0023, dice=0.3411, grad_norm=1.731085
[19:03:49.266] Epoch 10, Iter 4770: loss=0.2076, ce=0.0055, dice=0.3423, grad_norm=0.399379
[19:03:51.482] Epoch 10, Iter 4780: loss=0.0235, ce=0.0041, dice=0.0364, grad_norm=0.420299
[19:03:53.722] Epoch 10, Iter 4790: loss=0.0485, ce=0.0034, dice=0.0785, grad_norm=0.722709
[19:03:55.965] Epoch 10, Iter 4800: loss=0.0624, ce=0.0064, dice=0.0998, grad_norm=0.488062
[19:03:58.211] Epoch 10, Iter 4810: loss=0.0602, ce=0.0064, dice=0.0960, grad_norm=0.725979
[19:04:00.446] Epoch 10, Iter 4820: loss=0.0269, ce=0.0029, dice=0.0428, grad_norm=0.306494
[19:04:02.705] Epoch 10, Iter 4830: loss=0.0075, ce=0.0035, dice=0.0102, grad_norm=0.036595
[19:04:04.929] Epoch 10, Iter 4840: loss=0.0459, ce=0.0042, dice=0.0738, grad_norm=0.514050
[19:04:07.148] Epoch 10, Iter 4850: loss=0.0534, ce=0.0032, dice=0.0870, grad_norm=0.406945
[19:04:09.387] Epoch 10, Iter 4860: loss=0.0535, ce=0.0046, dice=0.0860, grad_norm=0.790758
[19:04:11.612] Epoch 10, Iter 4870: loss=0.0328, ce=0.0047, dice=0.0515, grad_norm=0.183071
[19:04:13.848] Epoch 10, Iter 4880: loss=0.0252, ce=0.0027, dice=0.0402, grad_norm=0.148625
[19:04:16.073] Epoch 10, Iter 4890: loss=0.0073, ce=0.0022, dice=0.0107, grad_norm=0.051979
[19:04:18.310] Epoch 10, Iter 4900: loss=0.0088, ce=0.0039, dice=0.0121, grad_norm=0.053173
[19:04:20.560] Epoch 10, Iter 4910: loss=0.0512, ce=0.0089, dice=0.0794, grad_norm=0.299883
[19:04:22.787] Epoch 10, Iter 4920: loss=0.0254, ce=0.0043, dice=0.0394, grad_norm=0.176516
[19:04:25.020] Epoch 10, Iter 4930: loss=0.0071, ce=0.0047, dice=0.0087, grad_norm=0.053180
[19:04:27.236] Epoch 10, Iter 4940: loss=0.0418, ce=0.0005, dice=0.0694, grad_norm=0.456562
[19:04:29.461] Epoch 10, Iter 4950: loss=0.0279, ce=0.0095, dice=0.0402, grad_norm=0.055105
[19:04:31.694] Epoch 10, Iter 4960: loss=0.0376, ce=0.0058, dice=0.0587, grad_norm=0.438929
[19:04:33.958] Epoch 10, Iter 4970: loss=0.1814, ce=0.0056, dice=0.2987, grad_norm=9.947533
[19:04:36.194] Epoch 10, Iter 4980: loss=0.0185, ce=0.0039, dice=0.0282, grad_norm=0.084043
[19:04:38.453] Epoch 10, Iter 4990: loss=0.0212, ce=0.0012, dice=0.0346, grad_norm=0.162737
[19:04:40.731] Epoch 10, Iter 5000: loss=0.0259, ce=0.0030, dice=0.0413, grad_norm=0.200536
[19:04:42.994] Epoch 10, Iter 5010: loss=0.0229, ce=0.0071, dice=0.0335, grad_norm=0.237442
[19:04:45.223] Epoch 10, Iter 5020: loss=0.0540, ce=0.0017, dice=0.0888, grad_norm=0.448327
[19:04:47.462] Epoch 10, Iter 5030: loss=0.0282, ce=0.0065, dice=0.0426, grad_norm=0.198931
[19:04:49.732] Epoch 10, Iter 5040: loss=0.0176, ce=0.0020, dice=0.0280, grad_norm=0.089716
[19:04:51.995] Epoch 10, Iter 5050: loss=0.0679, ce=0.0063, dice=0.1089, grad_norm=0.901490
[19:04:54.233] Epoch 10, Iter 5060: loss=0.0366, ce=0.0033, dice=0.0588, grad_norm=0.172356
[19:04:56.469] Epoch 10, Iter 5070: loss=0.0361, ce=0.0007, dice=0.0597, grad_norm=0.666251
[19:04:58.705] Epoch 10, Iter 5080: loss=0.0419, ce=0.0026, dice=0.0681, grad_norm=0.279662
[19:05:00.963] Epoch 10, Iter 5090: loss=0.0768, ce=0.0026, dice=0.1262, grad_norm=1.327158
[19:05:03.171] Epoch 10, Iter 5100: loss=0.0303, ce=0.0050, dice=0.0472, grad_norm=0.185405
[19:05:04.646] Epoch 10: Avg Loss=0.0481, CE=0.0040, Dice=0.0775
[19:05:16.342] Epoch 11, Iter 5110: loss=0.0078, ce=0.0051, dice=0.0096, grad_norm=0.041668
[19:05:18.498] Epoch 11, Iter 5120: loss=0.0035, ce=0.0009, dice=0.0052, grad_norm=0.014460
[19:05:20.675] Epoch 11, Iter 5130: loss=0.0060, ce=0.0031, dice=0.0080, grad_norm=0.024323
[19:05:22.844] Epoch 11, Iter 5140: loss=0.1335, ce=0.0031, dice=0.2204, grad_norm=10.830405
[19:05:25.029] Epoch 11, Iter 5150: loss=0.0471, ce=0.0108, dice=0.0714, grad_norm=0.435237
[19:05:27.191] Epoch 11, Iter 5160: loss=0.0135, ce=0.0009, dice=0.0219, grad_norm=2.866393
[19:05:29.366] Epoch 11, Iter 5170: loss=0.0323, ce=0.0031, dice=0.0517, grad_norm=0.160785
[19:05:31.528] Epoch 11, Iter 5180: loss=0.0625, ce=0.0040, dice=0.1014, grad_norm=0.619304
[19:05:33.703] Epoch 11, Iter 5190: loss=0.0422, ce=0.0037, dice=0.0679, grad_norm=0.364185
[19:05:35.865] Epoch 11, Iter 5200: loss=0.0304, ce=0.0099, dice=0.0440, grad_norm=0.254588
[19:05:38.044] Epoch 11, Iter 5210: loss=0.0318, ce=0.0030, dice=0.0510, grad_norm=0.247855
[19:05:40.208] Epoch 11, Iter 5220: loss=0.0510, ce=0.0043, dice=0.0822, grad_norm=0.467588
[19:05:42.393] Epoch 11, Iter 5230: loss=0.0359, ce=0.0080, dice=0.0545, grad_norm=0.089026
[19:05:44.568] Epoch 11, Iter 5240: loss=0.0180, ce=0.0054, dice=0.0264, grad_norm=0.097955
[19:05:46.749] Epoch 11, Iter 5250: loss=0.0541, ce=0.0014, dice=0.0893, grad_norm=0.602753
[19:05:48.917] Epoch 11, Iter 5260: loss=0.0045, ce=0.0013, dice=0.0067, grad_norm=0.034539
[19:05:51.103] Epoch 11, Iter 5270: loss=0.0368, ce=0.0038, dice=0.0587, grad_norm=0.160820
[19:05:53.271] Epoch 11, Iter 5280: loss=0.0220, ce=0.0038, dice=0.0342, grad_norm=0.140964
[19:05:55.449] Epoch 11, Iter 5290: loss=0.0178, ce=0.0039, dice=0.0271, grad_norm=0.182577
[19:05:57.617] Epoch 11, Iter 5300: loss=0.0330, ce=0.0037, dice=0.0525, grad_norm=0.300367
[19:05:59.881] Epoch 11, Iter 5310: loss=0.0309, ce=0.0039, dice=0.0489, grad_norm=0.133842
[19:06:02.101] Epoch 11, Iter 5320: loss=0.0108, ce=0.0039, dice=0.0154, grad_norm=0.046734
[19:06:04.295] Epoch 11, Iter 5330: loss=0.0165, ce=0.0027, dice=0.0257, grad_norm=0.094174
[19:06:06.467] Epoch 11, Iter 5340: loss=0.1931, ce=0.0030, dice=0.3198, grad_norm=0.570842
[19:06:08.644] Epoch 11, Iter 5350: loss=0.2071, ce=0.0060, dice=0.3411, grad_norm=0.024967
[19:06:10.826] Epoch 11, Iter 5360: loss=0.0295, ce=0.0067, dice=0.0447, grad_norm=0.227715
[19:06:13.008] Epoch 11, Iter 5370: loss=0.2059, ce=0.0032, dice=0.3410, grad_norm=0.036724
[19:06:15.199] Epoch 11, Iter 5380: loss=0.0267, ce=0.0043, dice=0.0417, grad_norm=0.244862
[19:06:17.382] Epoch 11, Iter 5390: loss=0.1488, ce=0.0028, dice=0.2461, grad_norm=1.194342
[19:06:19.549] Epoch 11, Iter 5400: loss=0.0203, ce=0.0030, dice=0.0317, grad_norm=0.201337
[19:06:21.731] Epoch 11, Iter 5410: loss=0.0574, ce=0.0040, dice=0.0930, grad_norm=1.079897
[19:06:23.898] Epoch 11, Iter 5420: loss=0.0239, ce=0.0009, dice=0.0392, grad_norm=0.256279
[19:06:26.080] Epoch 11, Iter 5430: loss=0.0329, ce=0.0087, dice=0.0491, grad_norm=0.160542
[19:06:28.253] Epoch 11, Iter 5440: loss=0.0353, ce=0.0040, dice=0.0562, grad_norm=0.256180
[19:06:30.431] Epoch 11, Iter 5450: loss=0.0541, ce=0.0069, dice=0.0856, grad_norm=0.758826
[19:06:32.617] Epoch 11, Iter 5460: loss=0.2081, ce=0.0042, dice=0.3440, grad_norm=0.056431
[19:06:34.810] Epoch 11, Iter 5470: loss=0.0245, ce=0.0024, dice=0.0392, grad_norm=0.216338
[19:06:36.981] Epoch 11, Iter 5480: loss=0.0344, ce=0.0028, dice=0.0554, grad_norm=0.204351
[19:06:39.169] Epoch 11, Iter 5490: loss=0.0160, ce=0.0019, dice=0.0253, grad_norm=0.171193
[19:06:41.340] Epoch 11, Iter 5500: loss=0.0157, ce=0.0030, dice=0.0242, grad_norm=0.138317
[19:06:43.532] Epoch 11, Iter 5510: loss=0.0187, ce=0.0035, dice=0.0289, grad_norm=0.057243
[19:06:45.709] Epoch 11, Iter 5520: loss=0.0189, ce=0.0043, dice=0.0287, grad_norm=0.088145
[19:06:47.893] Epoch 11, Iter 5530: loss=0.1164, ce=0.0027, dice=0.1921, grad_norm=0.666065
[19:06:50.070] Epoch 11, Iter 5540: loss=0.0148, ce=0.0053, dice=0.0211, grad_norm=0.070818
[19:06:52.258] Epoch 11, Iter 5550: loss=0.0096, ce=0.0035, dice=0.0137, grad_norm=0.067038
[19:06:54.434] Epoch 11, Iter 5560: loss=0.0932, ce=0.0029, dice=0.1534, grad_norm=0.872688
[19:06:56.738] Epoch 11: Avg Loss=0.0484, CE=0.0039, Dice=0.0781
[19:11:50.549] Epoch 12, Iter 5570: loss=0.0288, ce=0.0049, dice=0.0446, grad_norm=0.274937
[19:11:52.680] Epoch 12, Iter 5580: loss=0.0506, ce=0.0045, dice=0.0814, grad_norm=0.801208
[19:11:54.838] Epoch 12, Iter 5590: loss=0.2067, ce=0.0029, dice=0.3426, grad_norm=0.023683
[19:11:56.968] Epoch 12, Iter 5600: loss=0.2090, ce=0.0022, dice=0.3468, grad_norm=0.073311
[19:11:59.107] Epoch 12, Iter 5610: loss=0.1709, ce=0.0037, dice=0.2824, grad_norm=17.290654
[19:12:01.241] Epoch 12, Iter 5620: loss=0.0059, ce=0.0034, dice=0.0075, grad_norm=0.024557
[19:12:03.388] Epoch 12, Iter 5630: loss=0.0156, ce=0.0041, dice=0.0233, grad_norm=0.096065
[19:12:05.527] Epoch 12, Iter 5640: loss=0.0161, ce=0.0024, dice=0.0253, grad_norm=0.210264
[19:12:07.677] Epoch 12, Iter 5650: loss=0.0104, ce=0.0048, dice=0.0141, grad_norm=0.068568
[19:12:09.813] Epoch 12, Iter 5660: loss=0.0904, ce=0.0015, dice=0.1496, grad_norm=0.307727
[19:12:11.966] Epoch 12, Iter 5670: loss=0.0756, ce=0.0037, dice=0.1235, grad_norm=1.343832
[19:12:14.109] Epoch 12, Iter 5680: loss=0.0475, ce=0.0111, dice=0.0718, grad_norm=0.313173
[19:12:16.274] Epoch 12, Iter 5690: loss=0.2060, ce=0.0029, dice=0.3414, grad_norm=0.032996
[19:12:18.425] Epoch 12, Iter 5700: loss=0.2056, ce=0.0012, dice=0.3419, grad_norm=0.025476
[19:12:20.573] Epoch 12, Iter 5710: loss=0.1240, ce=0.0062, dice=0.2025, grad_norm=2.617201
[19:12:22.715] Epoch 12, Iter 5720: loss=0.0233, ce=0.0055, dice=0.0352, grad_norm=0.255279
[19:12:24.864] Epoch 12, Iter 5730: loss=0.0240, ce=0.0046, dice=0.0370, grad_norm=0.151406
[19:12:27.016] Epoch 12, Iter 5740: loss=0.0173, ce=0.0032, dice=0.0268, grad_norm=0.091329
[19:12:29.209] Epoch 12, Iter 5750: loss=0.0222, ce=0.0037, dice=0.0346, grad_norm=0.126618
[19:12:31.368] Epoch 12, Iter 5760: loss=0.0146, ce=0.0038, dice=0.0218, grad_norm=0.068697
[19:12:33.537] Epoch 12, Iter 5770: loss=0.0232, ce=0.0074, dice=0.0336, grad_norm=0.066962
[19:12:35.716] Epoch 12, Iter 5780: loss=0.0344, ce=0.0035, dice=0.0549, grad_norm=0.163246
[19:12:37.888] Epoch 12, Iter 5790: loss=0.2050, ce=0.0044, dice=0.3386, grad_norm=0.500356
[19:12:40.057] Epoch 12, Iter 5800: loss=0.0346, ce=0.0043, dice=0.0547, grad_norm=0.174455
[19:12:42.228] Epoch 12, Iter 5810: loss=0.0413, ce=0.0065, dice=0.0644, grad_norm=0.634117
[19:12:44.387] Epoch 12, Iter 5820: loss=0.0215, ce=0.0027, dice=0.0341, grad_norm=0.122293
[19:12:46.559] Epoch 12, Iter 5830: loss=0.0046, ce=0.0030, dice=0.0056, grad_norm=0.023679
[19:12:48.730] Epoch 12, Iter 5840: loss=0.0392, ce=0.0042, dice=0.0625, grad_norm=0.295790
[19:12:50.897] Epoch 12, Iter 5850: loss=0.0205, ce=0.0058, dice=0.0303, grad_norm=0.075018
[19:12:53.058] Epoch 12, Iter 5860: loss=0.0333, ce=0.0067, dice=0.0510, grad_norm=0.273950
[19:12:55.247] Epoch 12, Iter 5870: loss=0.0456, ce=0.0018, dice=0.0748, grad_norm=0.455315
[19:12:57.416] Epoch 12, Iter 5880: loss=0.0205, ce=0.0038, dice=0.0316, grad_norm=1.018626
[19:12:59.587] Epoch 12, Iter 5890: loss=0.0184, ce=0.0072, dice=0.0259, grad_norm=0.098543
[19:13:01.761] Epoch 12, Iter 5900: loss=0.0195, ce=0.0045, dice=0.0295, grad_norm=0.060176
[19:13:03.935] Epoch 12, Iter 5910: loss=0.0137, ce=0.0045, dice=0.0199, grad_norm=2.864286
[19:13:06.099] Epoch 12, Iter 5920: loss=0.0530, ce=0.0033, dice=0.0861, grad_norm=0.599225
[19:13:08.291] Epoch 12, Iter 5930: loss=0.0227, ce=0.0062, dice=0.0337, grad_norm=0.138829
[19:13:10.455] Epoch 12, Iter 5940: loss=0.0038, ce=0.0005, dice=0.0061, grad_norm=0.018431
[19:13:12.647] Epoch 12, Iter 5950: loss=0.0118, ce=0.0093, dice=0.0135, grad_norm=0.537718
[19:13:14.820] Epoch 12, Iter 5960: loss=0.0157, ce=0.0026, dice=0.0245, grad_norm=0.179544
[19:13:17.011] Epoch 12, Iter 5970: loss=0.0524, ce=0.0016, dice=0.0863, grad_norm=0.677333
[19:13:19.166] Epoch 12, Iter 5980: loss=0.0171, ce=0.0020, dice=0.0272, grad_norm=0.196398
[19:13:21.325] Epoch 12, Iter 5990: loss=0.0499, ce=0.0035, dice=0.0808, grad_norm=0.523347
[19:13:23.483] Epoch 12, Iter 6000: loss=0.0177, ce=0.0046, dice=0.0264, grad_norm=0.084709
[19:13:25.709] Epoch 12, Iter 6010: loss=0.0448, ce=0.0028, dice=0.0729, grad_norm=0.285531
[19:13:27.901] Epoch 12, Iter 6020: loss=0.2118, ce=0.0032, dice=0.3509, grad_norm=0.055556
[19:13:30.084] Epoch 12, Iter 6030: loss=0.0277, ce=0.0019, dice=0.0449, grad_norm=0.106431
[19:13:31.108] Epoch 12: Avg Loss=0.0467, CE=0.0038, Dice=0.0752
[19:13:43.229] Epoch 13, Iter 6040: loss=0.0197, ce=0.0035, dice=0.0305, grad_norm=0.161666
[19:13:45.406] Epoch 13, Iter 6050: loss=0.2098, ce=0.0053, dice=0.3461, grad_norm=0.114589
[19:13:47.568] Epoch 13, Iter 6060: loss=0.0285, ce=0.0025, dice=0.0459, grad_norm=0.124788
[19:13:49.756] Epoch 13, Iter 6070: loss=0.2037, ce=0.0020, dice=0.3382, grad_norm=0.151593
[19:13:51.914] Epoch 13, Iter 6080: loss=0.0618, ce=0.0044, dice=0.1000, grad_norm=1.591766
[19:13:54.091] Epoch 13, Iter 6090: loss=0.0064, ce=0.0018, dice=0.0094, grad_norm=0.083192
[19:13:56.256] Epoch 13, Iter 6100: loss=0.0231, ce=0.0024, dice=0.0369, grad_norm=0.183490
[19:13:58.443] Epoch 13, Iter 6110: loss=0.0339, ce=0.0052, dice=0.0530, grad_norm=0.299269
[19:14:00.652] Epoch 13, Iter 6120: loss=0.0644, ce=0.0046, dice=0.1043, grad_norm=0.366069
[19:14:02.847] Epoch 13, Iter 6130: loss=0.0202, ce=0.0087, dice=0.0278, grad_norm=0.120399
[19:14:05.046] Epoch 13, Iter 6140: loss=0.0396, ce=0.0050, dice=0.0626, grad_norm=0.171050
[19:14:07.233] Epoch 13, Iter 6150: loss=0.0270, ce=0.0034, dice=0.0427, grad_norm=0.110073
[19:14:09.419] Epoch 13, Iter 6160: loss=0.0302, ce=0.0065, dice=0.0460, grad_norm=0.073895
[19:14:11.610] Epoch 13, Iter 6170: loss=0.0226, ce=0.0023, dice=0.0361, grad_norm=0.140207
[19:14:13.844] Epoch 13, Iter 6180: loss=0.0469, ce=0.0070, dice=0.0736, grad_norm=0.362548
[19:14:16.182] Epoch 13, Iter 6190: loss=0.0231, ce=0.0009, dice=0.0379, grad_norm=0.180846
[19:14:18.365] Epoch 13, Iter 6200: loss=0.0280, ce=0.0041, dice=0.0439, grad_norm=0.227762
[19:14:20.556] Epoch 13, Iter 6210: loss=0.0192, ce=0.0062, dice=0.0279, grad_norm=0.085833
[19:14:22.736] Epoch 13, Iter 6220: loss=0.1221, ce=0.0070, dice=0.1987, grad_norm=5.613773
[19:14:24.914] Epoch 13, Iter 6230: loss=0.0171, ce=0.0054, dice=0.0248, grad_norm=0.078072
[19:14:27.083] Epoch 13, Iter 6240: loss=0.0218, ce=0.0036, dice=0.0339, grad_norm=0.093189
[19:14:29.260] Epoch 13, Iter 6250: loss=0.0423, ce=0.0032, dice=0.0683, grad_norm=0.446675
[19:14:31.468] Epoch 13, Iter 6260: loss=0.0362, ce=0.0041, dice=0.0576, grad_norm=0.198023
[19:14:33.669] Epoch 13, Iter 6270: loss=0.0725, ce=0.0045, dice=0.1178, grad_norm=0.503844
[19:14:35.840] Epoch 13, Iter 6280: loss=0.0224, ce=0.0054, dice=0.0337, grad_norm=0.117385
[19:14:38.011] Epoch 13, Iter 6290: loss=0.0242, ce=0.0053, dice=0.0368, grad_norm=0.148250
[19:14:40.181] Epoch 13, Iter 6300: loss=0.0077, ce=0.0019, dice=0.0115, grad_norm=0.079936
[19:14:42.369] Epoch 13, Iter 6310: loss=0.0485, ce=0.0040, dice=0.0781, grad_norm=0.191206
[19:14:44.543] Epoch 13, Iter 6320: loss=0.0216, ce=0.0045, dice=0.0331, grad_norm=0.106004
[19:14:46.731] Epoch 13, Iter 6330: loss=0.0221, ce=0.0056, dice=0.0331, grad_norm=0.081773
[19:14:48.900] Epoch 13, Iter 6340: loss=0.0237, ce=0.0052, dice=0.0361, grad_norm=0.133523
[19:14:51.086] Epoch 13, Iter 6350: loss=0.0283, ce=0.0035, dice=0.0448, grad_norm=0.125838
[19:14:53.265] Epoch 13, Iter 6360: loss=0.0360, ce=0.0025, dice=0.0584, grad_norm=0.239448
[19:14:55.457] Epoch 13, Iter 6370: loss=0.0795, ce=0.0030, dice=0.1304, grad_norm=0.345262
[19:14:57.626] Epoch 13, Iter 6380: loss=0.0060, ce=0.0043, dice=0.0072, grad_norm=0.022688
[19:14:59.805] Epoch 13, Iter 6390: loss=0.0293, ce=0.0021, dice=0.0474, grad_norm=0.177871
[19:15:01.991] Epoch 13, Iter 6400: loss=0.0251, ce=0.0054, dice=0.0382, grad_norm=0.124344
[19:15:04.171] Epoch 13, Iter 6410: loss=0.0074, ce=0.0076, dice=0.0073, grad_norm=0.026373
[19:15:06.342] Epoch 13, Iter 6420: loss=0.2095, ce=0.0036, dice=0.3467, grad_norm=0.165535
[19:15:08.529] Epoch 13, Iter 6430: loss=0.0703, ce=0.0030, dice=0.1151, grad_norm=0.744210
[19:15:10.704] Epoch 13, Iter 6440: loss=0.0209, ce=0.0019, dice=0.0336, grad_norm=0.138809
[19:15:12.898] Epoch 13, Iter 6450: loss=0.0944, ce=0.0054, dice=0.1538, grad_norm=1.345324
[19:15:15.071] Epoch 13, Iter 6460: loss=0.0054, ce=0.0024, dice=0.0074, grad_norm=0.022213
[19:15:17.263] Epoch 13, Iter 6470: loss=0.0074, ce=0.0025, dice=0.0106, grad_norm=0.048640
[19:15:19.434] Epoch 13, Iter 6480: loss=0.0276, ce=0.0116, dice=0.0383, grad_norm=0.166477
[19:15:21.617] Epoch 13, Iter 6490: loss=0.0396, ce=0.0045, dice=0.0630, grad_norm=0.144996
[19:15:23.537] Epoch 13: Avg Loss=0.0456, CE=0.0038, Dice=0.0734
[19:20:35.225] Epoch 14, Iter 6500: loss=0.0223, ce=0.0059, dice=0.0333, grad_norm=0.118420
[19:20:37.407] Epoch 14, Iter 6510: loss=0.0179, ce=0.0047, dice=0.0267, grad_norm=0.077625
[19:20:39.561] Epoch 14, Iter 6520: loss=0.0067, ce=0.0026, dice=0.0095, grad_norm=0.085847
[19:20:41.746] Epoch 14, Iter 6530: loss=0.1069, ce=0.0038, dice=0.1755, grad_norm=0.280681
[19:20:43.908] Epoch 14, Iter 6540: loss=0.0183, ce=0.0035, dice=0.0281, grad_norm=0.104824
[19:20:46.078] Epoch 14, Iter 6550: loss=0.0143, ce=0.0027, dice=0.0220, grad_norm=0.098100
[19:20:48.232] Epoch 14, Iter 6560: loss=0.0159, ce=0.0074, dice=0.0215, grad_norm=0.057732
[19:20:50.401] Epoch 14, Iter 6570: loss=0.0340, ce=0.0030, dice=0.0548, grad_norm=0.253460
[19:20:52.555] Epoch 14, Iter 6580: loss=0.0259, ce=0.0040, dice=0.0406, grad_norm=0.085379
[19:20:54.723] Epoch 14, Iter 6590: loss=0.0557, ce=0.0041, dice=0.0901, grad_norm=0.590376
[19:20:56.899] Epoch 14, Iter 6600: loss=0.0391, ce=0.0025, dice=0.0636, grad_norm=0.702547
[19:20:59.082] Epoch 14, Iter 6610: loss=0.0248, ce=0.0045, dice=0.0383, grad_norm=0.120979
[19:21:01.253] Epoch 14, Iter 6620: loss=0.0060, ce=0.0045, dice=0.0071, grad_norm=0.061367
[19:21:03.424] Epoch 14, Iter 6630: loss=0.0901, ce=0.0058, dice=0.1463, grad_norm=2.969078
[19:21:05.589] Epoch 14, Iter 6640: loss=0.0272, ce=0.0041, dice=0.0426, grad_norm=0.191565
[19:21:07.763] Epoch 14, Iter 6650: loss=0.0159, ce=0.0047, dice=0.0234, grad_norm=0.062833
[19:21:09.933] Epoch 14, Iter 6660: loss=0.0166, ce=0.0037, dice=0.0251, grad_norm=0.081613
[19:21:12.119] Epoch 14, Iter 6670: loss=0.0157, ce=0.0011, dice=0.0253, grad_norm=0.163399
[19:21:14.285] Epoch 14, Iter 6680: loss=0.0727, ce=0.0062, dice=0.1170, grad_norm=1.125570
[19:21:16.467] Epoch 14, Iter 6690: loss=0.0207, ce=0.0033, dice=0.0323, grad_norm=0.069501
[19:21:18.634] Epoch 14, Iter 6700: loss=0.1567, ce=0.0036, dice=0.2588, grad_norm=1.356020
[19:21:20.813] Epoch 14, Iter 6710: loss=0.1736, ce=0.0050, dice=0.2859, grad_norm=3.020500
[19:21:22.977] Epoch 14, Iter 6720: loss=0.2054, ce=0.0014, dice=0.3413, grad_norm=0.037549
[19:21:25.200] Epoch 14, Iter 6730: loss=0.0195, ce=0.0056, dice=0.0288, grad_norm=0.125879
[19:21:27.386] Epoch 14, Iter 6740: loss=0.0298, ce=0.0017, dice=0.0485, grad_norm=0.214331
[19:21:29.566] Epoch 14, Iter 6750: loss=0.0668, ce=0.0043, dice=0.1084, grad_norm=0.761172
[19:21:31.737] Epoch 14, Iter 6760: loss=0.0182, ce=0.0012, dice=0.0295, grad_norm=0.135902
[19:21:33.936] Epoch 14, Iter 6770: loss=0.0277, ce=0.0062, dice=0.0420, grad_norm=0.314595
[19:21:36.099] Epoch 14, Iter 6780: loss=0.0871, ce=0.0025, dice=0.1435, grad_norm=1.020073
[19:21:38.286] Epoch 14, Iter 6790: loss=0.0241, ce=0.0018, dice=0.0390, grad_norm=0.132905
[19:21:40.467] Epoch 14, Iter 6800: loss=0.0220, ce=0.0036, dice=0.0344, grad_norm=0.202192
[19:21:42.655] Epoch 14, Iter 6810: loss=0.0056, ce=0.0025, dice=0.0077, grad_norm=0.015266
[19:21:44.819] Epoch 14, Iter 6820: loss=0.0182, ce=0.0061, dice=0.0263, grad_norm=0.098642
[19:21:47.007] Epoch 14, Iter 6830: loss=0.0561, ce=0.0086, dice=0.0877, grad_norm=0.378048
[19:21:49.181] Epoch 14, Iter 6840: loss=0.0324, ce=0.0117, dice=0.0462, grad_norm=0.119792
[19:21:51.363] Epoch 14, Iter 6850: loss=0.0337, ce=0.0046, dice=0.0531, grad_norm=0.123073
[19:21:53.536] Epoch 14, Iter 6860: loss=0.0077, ce=0.0045, dice=0.0098, grad_norm=0.134483
[19:21:55.719] Epoch 14, Iter 6870: loss=0.0258, ce=0.0056, dice=0.0393, grad_norm=0.130087
[19:21:57.983] Epoch 14, Iter 6880: loss=0.0210, ce=0.0046, dice=0.0319, grad_norm=0.064143
[19:22:00.157] Epoch 14, Iter 6890: loss=0.0663, ce=0.0015, dice=0.1096, grad_norm=0.517377
[19:22:02.327] Epoch 14, Iter 6900: loss=0.0179, ce=0.0023, dice=0.0283, grad_norm=0.205912
[19:22:04.509] Epoch 14, Iter 6910: loss=0.0314, ce=0.0076, dice=0.0472, grad_norm=0.093803
[19:22:06.676] Epoch 14, Iter 6920: loss=0.0476, ce=0.0041, dice=0.0766, grad_norm=23.623929
[19:22:08.863] Epoch 14, Iter 6930: loss=0.0473, ce=0.0033, dice=0.0767, grad_norm=0.556654
[19:22:11.032] Epoch 14, Iter 6940: loss=0.0331, ce=0.0034, dice=0.0530, grad_norm=0.121955
[19:22:13.223] Epoch 14, Iter 6950: loss=0.0272, ce=0.0060, dice=0.0414, grad_norm=0.153147
[19:22:15.364] Epoch 14, Iter 6960: loss=0.0465, ce=0.0021, dice=0.0761, grad_norm=0.353434
[19:22:15.976] Epoch 14: Avg Loss=0.0479, CE=0.0037, Dice=0.0774
[19:22:28.687] Epoch 15, Iter 6970: loss=0.1369, ce=0.0096, dice=0.2218, grad_norm=0.132755
[19:22:30.851] Epoch 15, Iter 6980: loss=0.0550, ce=0.0014, dice=0.0906, grad_norm=1.164780
[19:22:33.039] Epoch 15, Iter 6990: loss=0.2093, ce=0.0059, dice=0.3448, grad_norm=0.135442
[19:22:35.221] Epoch 15, Iter 7000: loss=0.0854, ce=0.0051, dice=0.1389, grad_norm=0.465059
[19:22:37.399] Epoch 15, Iter 7010: loss=0.0264, ce=0.0049, dice=0.0407, grad_norm=0.183346
[19:22:39.566] Epoch 15, Iter 7020: loss=0.0180, ce=0.0008, dice=0.0295, grad_norm=0.085404
[19:22:41.733] Epoch 15, Iter 7030: loss=0.0070, ce=0.0035, dice=0.0093, grad_norm=0.083506
[19:22:43.901] Epoch 15, Iter 7040: loss=0.0294, ce=0.0034, dice=0.0468, grad_norm=0.224183
[19:22:46.085] Epoch 15, Iter 7050: loss=0.0376, ce=0.0016, dice=0.0616, grad_norm=0.525474
[19:22:48.249] Epoch 15, Iter 7060: loss=0.0229, ce=0.0051, dice=0.0348, grad_norm=0.151250
[19:22:50.443] Epoch 15, Iter 7070: loss=0.0269, ce=0.0067, dice=0.0404, grad_norm=0.347408
[19:22:52.614] Epoch 15, Iter 7080: loss=0.0036, ce=0.0008, dice=0.0055, grad_norm=0.036250
[19:22:54.789] Epoch 15, Iter 7090: loss=0.0349, ce=0.0047, dice=0.0550, grad_norm=0.244109
[19:22:56.958] Epoch 15, Iter 7100: loss=0.0437, ce=0.0045, dice=0.0697, grad_norm=0.298931
[19:22:59.142] Epoch 15, Iter 7110: loss=0.0274, ce=0.0049, dice=0.0425, grad_norm=0.183363
[19:23:01.327] Epoch 15, Iter 7120: loss=0.0317, ce=0.0033, dice=0.0506, grad_norm=0.237584
[19:23:03.517] Epoch 15, Iter 7130: loss=0.0129, ce=0.0031, dice=0.0194, grad_norm=0.074145
[19:23:05.690] Epoch 15, Iter 7140: loss=0.0442, ce=0.0029, dice=0.0717, grad_norm=0.449810
[19:23:07.875] Epoch 15, Iter 7150: loss=0.0522, ce=0.0024, dice=0.0854, grad_norm=0.518137
[19:23:10.051] Epoch 15, Iter 7160: loss=0.0481, ce=0.0035, dice=0.0779, grad_norm=0.177421
[19:23:12.234] Epoch 15, Iter 7170: loss=0.0217, ce=0.0031, dice=0.0341, grad_norm=0.163937
[19:23:14.404] Epoch 15, Iter 7180: loss=0.0606, ce=0.0057, dice=0.0973, grad_norm=0.710549
[19:23:16.609] Epoch 15, Iter 7190: loss=0.0142, ce=0.0021, dice=0.0222, grad_norm=0.100711
[19:23:18.786] Epoch 15, Iter 7200: loss=0.0303, ce=0.0057, dice=0.0466, grad_norm=0.147646
[19:23:20.972] Epoch 15, Iter 7210: loss=0.2079, ce=0.0045, dice=0.3436, grad_norm=0.055051
[19:23:23.143] Epoch 15, Iter 7220: loss=0.0331, ce=0.0085, dice=0.0495, grad_norm=0.111636
[19:23:25.338] Epoch 15, Iter 7230: loss=0.0478, ce=0.0060, dice=0.0757, grad_norm=0.364888
[19:23:27.521] Epoch 15, Iter 7240: loss=0.0226, ce=0.0066, dice=0.0332, grad_norm=0.114362
[19:23:29.716] Epoch 15, Iter 7250: loss=0.0171, ce=0.0028, dice=0.0266, grad_norm=0.088869
[19:23:31.916] Epoch 15, Iter 7260: loss=0.0187, ce=0.0022, dice=0.0298, grad_norm=0.184046
[19:23:34.122] Epoch 15, Iter 7270: loss=0.0161, ce=0.0055, dice=0.0233, grad_norm=0.094039
[19:23:36.298] Epoch 15, Iter 7280: loss=0.0399, ce=0.0026, dice=0.0647, grad_norm=0.317645
[19:23:38.486] Epoch 15, Iter 7290: loss=0.1785, ce=0.0016, dice=0.2965, grad_norm=2.427850
[19:23:40.665] Epoch 15, Iter 7300: loss=0.0184, ce=0.0035, dice=0.0283, grad_norm=0.113779
[19:23:42.851] Epoch 15, Iter 7310: loss=0.0271, ce=0.0058, dice=0.0413, grad_norm=0.235989
[19:23:45.032] Epoch 15, Iter 7320: loss=0.0952, ce=0.0045, dice=0.1557, grad_norm=0.511844
[19:23:47.228] Epoch 15, Iter 7330: loss=0.0322, ce=0.0035, dice=0.0514, grad_norm=0.096475
[19:23:49.406] Epoch 15, Iter 7340: loss=0.0350, ce=0.0031, dice=0.0563, grad_norm=0.145309
[19:23:51.595] Epoch 15, Iter 7350: loss=0.0211, ce=0.0061, dice=0.0311, grad_norm=0.246639
[19:23:53.783] Epoch 15, Iter 7360: loss=0.0214, ce=0.0062, dice=0.0316, grad_norm=0.065952
[19:23:55.979] Epoch 15, Iter 7370: loss=0.0324, ce=0.0027, dice=0.0522, grad_norm=0.136671
[19:23:58.169] Epoch 15, Iter 7380: loss=0.0220, ce=0.0048, dice=0.0335, grad_norm=0.099411
[19:24:00.364] Epoch 15, Iter 7390: loss=0.0134, ce=0.0033, dice=0.0201, grad_norm=0.085900
[19:24:02.560] Epoch 15, Iter 7400: loss=0.0054, ce=0.0021, dice=0.0076, grad_norm=0.016966
[19:24:04.752] Epoch 15, Iter 7410: loss=0.0538, ce=0.0035, dice=0.0873, grad_norm=1.690419
[19:24:06.935] Epoch 15, Iter 7420: loss=0.0681, ce=0.0003, dice=0.1133, grad_norm=0.710556
[19:24:08.385] Epoch 15: Avg Loss=0.0427, CE=0.0037, Dice=0.0687
[19:29:18.886] Epoch 16, Iter 7430: loss=0.0242, ce=0.0041, dice=0.0376, grad_norm=0.175226
[19:29:21.030] Epoch 16, Iter 7440: loss=0.2071, ce=0.0042, dice=0.3423, grad_norm=0.026535
[19:29:23.193] Epoch 16, Iter 7450: loss=0.0715, ce=0.0044, dice=0.1162, grad_norm=1.112628
[19:29:25.358] Epoch 16, Iter 7460: loss=0.0561, ce=0.0048, dice=0.0902, grad_norm=0.654266
[19:29:27.547] Epoch 16, Iter 7470: loss=0.2002, ce=0.0010, dice=0.3331, grad_norm=2.621024
[19:29:29.704] Epoch 16, Iter 7480: loss=0.2055, ce=0.0030, dice=0.3406, grad_norm=0.035978
[19:29:31.878] Epoch 16, Iter 7490: loss=0.0243, ce=0.0021, dice=0.0391, grad_norm=0.267679
[19:29:34.037] Epoch 16, Iter 7500: loss=0.0229, ce=0.0007, dice=0.0377, grad_norm=0.172491
[19:29:36.210] Epoch 16, Iter 7510: loss=0.2062, ce=0.0023, dice=0.3422, grad_norm=0.265212
[19:29:38.372] Epoch 16, Iter 7520: loss=0.0560, ce=0.0044, dice=0.0904, grad_norm=0.632499
[19:29:40.554] Epoch 16, Iter 7530: loss=0.0241, ce=0.0049, dice=0.0370, grad_norm=0.149691
[19:29:42.725] Epoch 16, Iter 7540: loss=0.0353, ce=0.0055, dice=0.0552, grad_norm=0.257605
[19:29:44.898] Epoch 16, Iter 7550: loss=0.0235, ce=0.0047, dice=0.0360, grad_norm=0.102088
[19:29:47.063] Epoch 16, Iter 7560: loss=0.0733, ce=0.0045, dice=0.1191, grad_norm=0.440665
[19:29:49.243] Epoch 16, Iter 7570: loss=0.0165, ce=0.0041, dice=0.0249, grad_norm=0.059177
[19:29:51.409] Epoch 16, Iter 7580: loss=0.0133, ce=0.0043, dice=0.0193, grad_norm=0.038353
[19:29:53.586] Epoch 16, Iter 7590: loss=0.0182, ce=0.0010, dice=0.0297, grad_norm=0.119076
[19:29:55.755] Epoch 16, Iter 7600: loss=0.0153, ce=0.0022, dice=0.0240, grad_norm=0.098210
[19:29:57.954] Epoch 16, Iter 7610: loss=0.0286, ce=0.0044, dice=0.0448, grad_norm=0.380387
[19:30:00.139] Epoch 16, Iter 7620: loss=0.0243, ce=0.0023, dice=0.0390, grad_norm=0.119473
[19:30:02.306] Epoch 16, Iter 7630: loss=0.1112, ce=0.0067, dice=0.1809, grad_norm=1.220844
[19:30:04.472] Epoch 16, Iter 7640: loss=0.0056, ce=0.0035, dice=0.0069, grad_norm=0.347245
[19:30:06.642] Epoch 16, Iter 7650: loss=0.0204, ce=0.0042, dice=0.0313, grad_norm=0.134517
[19:30:08.814] Epoch 16, Iter 7660: loss=0.0715, ce=0.0015, dice=0.1181, grad_norm=0.618418
[19:30:11.001] Epoch 16, Iter 7670: loss=0.0158, ce=0.0022, dice=0.0248, grad_norm=0.064710
[19:30:13.171] Epoch 16, Iter 7680: loss=0.0494, ce=0.0021, dice=0.0810, grad_norm=1.218326
[19:30:15.342] Epoch 16, Iter 7690: loss=0.1892, ce=0.0038, dice=0.3127, grad_norm=0.463768
[19:30:17.494] Epoch 16, Iter 7700: loss=0.0217, ce=0.0044, dice=0.0332, grad_norm=0.112216
[19:30:19.673] Epoch 16, Iter 7710: loss=0.0686, ce=0.0050, dice=0.1111, grad_norm=1.116462
[19:30:21.838] Epoch 16, Iter 7720: loss=0.0256, ce=0.0070, dice=0.0380, grad_norm=0.188504
[19:30:24.036] Epoch 16, Iter 7730: loss=0.0201, ce=0.0043, dice=0.0306, grad_norm=0.075971
[19:30:26.200] Epoch 16, Iter 7740: loss=0.0377, ce=0.0030, dice=0.0608, grad_norm=0.241722
[19:30:28.384] Epoch 16, Iter 7750: loss=0.0174, ce=0.0064, dice=0.0248, grad_norm=0.056456
[19:30:30.552] Epoch 16, Iter 7760: loss=0.0214, ce=0.0055, dice=0.0320, grad_norm=0.150356
[19:30:32.734] Epoch 16, Iter 7770: loss=0.0613, ce=0.0061, dice=0.0981, grad_norm=2.241759
[19:30:34.902] Epoch 16, Iter 7780: loss=0.0141, ce=0.0010, dice=0.0229, grad_norm=0.074900
[19:30:37.097] Epoch 16, Iter 7790: loss=0.0052, ce=0.0010, dice=0.0080, grad_norm=0.057733
[19:30:39.277] Epoch 16, Iter 7800: loss=0.0064, ce=0.0018, dice=0.0095, grad_norm=0.028621
[19:30:41.457] Epoch 16, Iter 7810: loss=0.1076, ce=0.0040, dice=0.1766, grad_norm=0.168063
[19:30:43.625] Epoch 16, Iter 7820: loss=0.0325, ce=0.0013, dice=0.0532, grad_norm=0.172012
[19:30:45.801] Epoch 16, Iter 7830: loss=0.0158, ce=0.0036, dice=0.0240, grad_norm=0.061395
[19:30:47.965] Epoch 16, Iter 7840: loss=0.1972, ce=0.0024, dice=0.3271, grad_norm=5.561767
[19:30:50.150] Epoch 16, Iter 7850: loss=0.0199, ce=0.0043, dice=0.0303, grad_norm=0.177811
[19:30:52.342] Epoch 16, Iter 7860: loss=0.0312, ce=0.0080, dice=0.0467, grad_norm=0.139073
[19:30:54.631] Epoch 16, Iter 7870: loss=0.0380, ce=0.0049, dice=0.0601, grad_norm=0.125964
[19:30:56.832] Epoch 16, Iter 7880: loss=0.0260, ce=0.0072, dice=0.0386, grad_norm=0.149950
[19:30:59.210] Epoch 16: Avg Loss=0.0445, CE=0.0036, Dice=0.0717
[19:31:10.391] Epoch 17, Iter 7890: loss=0.0330, ce=0.0030, dice=0.0530, grad_norm=0.209007
[19:31:12.582] Epoch 17, Iter 7900: loss=0.0344, ce=0.0069, dice=0.0527, grad_norm=0.157913
[19:31:14.754] Epoch 17, Iter 7910: loss=0.0225, ce=0.0030, dice=0.0356, grad_norm=0.065328
[19:31:16.931] Epoch 17, Iter 7920: loss=0.0305, ce=0.0049, dice=0.0477, grad_norm=0.120196
[19:31:19.125] Epoch 17, Iter 7930: loss=0.0327, ce=0.0028, dice=0.0525, grad_norm=0.113749
[19:31:21.301] Epoch 17, Iter 7940: loss=0.0117, ce=0.0043, dice=0.0166, grad_norm=0.157742
[19:31:23.493] Epoch 17, Iter 7950: loss=0.0581, ce=0.0073, dice=0.0919, grad_norm=0.190987
[19:31:25.675] Epoch 17, Iter 7960: loss=0.0532, ce=0.0026, dice=0.0869, grad_norm=0.389198
[19:31:27.854] Epoch 17, Iter 7970: loss=0.0192, ce=0.0040, dice=0.0292, grad_norm=0.119531
[19:31:30.024] Epoch 17, Iter 7980: loss=0.0113, ce=0.0029, dice=0.0168, grad_norm=2.717004
[19:31:32.218] Epoch 17, Iter 7990: loss=0.0317, ce=0.0109, dice=0.0456, grad_norm=0.199286
[19:31:34.397] Epoch 17, Iter 8000: loss=0.2077, ce=0.0055, dice=0.3425, grad_norm=0.016864
[19:31:36.589] Epoch 17, Iter 8010: loss=0.0089, ce=0.0019, dice=0.0135, grad_norm=0.177861
[19:31:38.758] Epoch 17, Iter 8020: loss=0.0176, ce=0.0041, dice=0.0265, grad_norm=0.129057
[19:31:40.939] Epoch 17, Iter 8030: loss=0.0178, ce=0.0028, dice=0.0278, grad_norm=0.086447
[19:31:43.108] Epoch 17, Iter 8040: loss=0.0189, ce=0.0019, dice=0.0303, grad_norm=0.100628
[19:31:45.292] Epoch 17, Iter 8050: loss=0.0902, ce=0.0007, dice=0.1500, grad_norm=0.530586
[19:31:47.465] Epoch 17, Iter 8060: loss=0.0410, ce=0.0021, dice=0.0669, grad_norm=0.215158
[19:31:49.676] Epoch 17, Iter 8070: loss=0.0340, ce=0.0024, dice=0.0550, grad_norm=0.361361
[19:31:51.861] Epoch 17, Iter 8080: loss=0.0412, ce=0.0028, dice=0.0667, grad_norm=0.255738
[19:31:54.045] Epoch 17, Iter 8090: loss=0.0439, ce=0.0048, dice=0.0700, grad_norm=0.221246
[19:31:56.221] Epoch 17, Iter 8100: loss=0.0055, ce=0.0033, dice=0.0070, grad_norm=0.043590
[19:31:58.411] Epoch 17, Iter 8110: loss=0.0274, ce=0.0078, dice=0.0405, grad_norm=0.174847
[19:32:00.617] Epoch 17, Iter 8120: loss=0.2065, ce=0.0043, dice=0.3414, grad_norm=0.027262
[19:32:02.818] Epoch 17, Iter 8130: loss=0.0438, ce=0.0034, dice=0.0707, grad_norm=0.718298
[19:32:04.992] Epoch 17, Iter 8140: loss=0.0289, ce=0.0022, dice=0.0466, grad_norm=0.291964
[19:32:07.185] Epoch 17, Iter 8150: loss=0.0302, ce=0.0015, dice=0.0493, grad_norm=0.604743
[19:32:09.362] Epoch 17, Iter 8160: loss=0.0484, ce=0.0025, dice=0.0790, grad_norm=0.278660
[19:32:11.561] Epoch 17, Iter 8170: loss=0.0335, ce=0.0018, dice=0.0547, grad_norm=0.182113
[19:32:13.741] Epoch 17, Iter 8180: loss=0.2060, ce=0.0021, dice=0.3420, grad_norm=0.034415
[19:32:15.924] Epoch 17, Iter 8190: loss=0.0228, ce=0.0086, dice=0.0322, grad_norm=0.089095
[19:32:18.120] Epoch 17, Iter 8200: loss=0.0585, ce=0.0067, dice=0.0930, grad_norm=0.246889
[19:32:20.317] Epoch 17, Iter 8210: loss=0.0187, ce=0.0027, dice=0.0293, grad_norm=0.090180
[19:32:22.495] Epoch 17, Iter 8220: loss=0.0035, ce=0.0006, dice=0.0054, grad_norm=0.038004
[19:32:24.679] Epoch 17, Iter 8230: loss=0.0248, ce=0.0072, dice=0.0366, grad_norm=0.069166
[19:32:26.860] Epoch 17, Iter 8240: loss=0.0479, ce=0.0021, dice=0.0785, grad_norm=1.154110
[19:32:29.057] Epoch 17, Iter 8250: loss=0.0054, ce=0.0019, dice=0.0078, grad_norm=0.025251
[19:32:31.246] Epoch 17, Iter 8260: loss=0.0260, ce=0.0036, dice=0.0410, grad_norm=0.296255
[19:32:33.439] Epoch 17, Iter 8270: loss=0.0202, ce=0.0046, dice=0.0306, grad_norm=0.068328
[19:32:35.615] Epoch 17, Iter 8280: loss=0.0791, ce=0.0023, dice=0.1303, grad_norm=1.438878
[19:32:37.793] Epoch 17, Iter 8290: loss=0.0641, ce=0.0030, dice=0.1048, grad_norm=0.539398
[19:32:39.963] Epoch 17, Iter 8300: loss=0.0456, ce=0.0031, dice=0.0739, grad_norm=0.389467
[19:32:42.161] Epoch 17, Iter 8310: loss=0.0284, ce=0.0064, dice=0.0431, grad_norm=0.081050
[19:32:44.368] Epoch 17, Iter 8320: loss=0.0328, ce=0.0046, dice=0.0515, grad_norm=0.153729
[19:32:46.553] Epoch 17, Iter 8330: loss=0.0236, ce=0.0035, dice=0.0371, grad_norm=0.204728
[19:32:48.731] Epoch 17, Iter 8340: loss=0.0255, ce=0.0049, dice=0.0391, grad_norm=0.239706
[19:32:50.918] Epoch 17, Iter 8350: loss=0.0218, ce=0.0040, dice=0.0337, grad_norm=0.076073
[19:32:51.913] Epoch 17: Avg Loss=0.0409, CE=0.0035, Dice=0.0657
[19:38:01.957] Epoch 18, Iter 8360: loss=0.0214, ce=0.0030, dice=0.0337, grad_norm=0.079086
[19:38:04.120] Epoch 18, Iter 8370: loss=0.0148, ce=0.0061, dice=0.0205, grad_norm=0.071477
[19:38:06.280] Epoch 18, Iter 8380: loss=0.0056, ce=0.0036, dice=0.0070, grad_norm=0.022323
[19:38:08.449] Epoch 18, Iter 8390: loss=0.0646, ce=0.0057, dice=0.1039, grad_norm=0.372078
[19:38:10.599] Epoch 18, Iter 8400: loss=0.0154, ce=0.0041, dice=0.0230, grad_norm=0.120428
[19:38:12.761] Epoch 18, Iter 8410: loss=0.0070, ce=0.0034, dice=0.0094, grad_norm=0.050774
[19:38:14.933] Epoch 18, Iter 8420: loss=0.0063, ce=0.0020, dice=0.0092, grad_norm=0.074073
[19:38:17.129] Epoch 18, Iter 8430: loss=0.0268, ce=0.0025, dice=0.0430, grad_norm=0.158698
[19:38:19.286] Epoch 18, Iter 8440: loss=0.0272, ce=0.0009, dice=0.0447, grad_norm=0.840949
[19:38:21.455] Epoch 18, Iter 8450: loss=0.0205, ce=0.0068, dice=0.0296, grad_norm=0.081550
[19:38:23.615] Epoch 18, Iter 8460: loss=0.0418, ce=0.0019, dice=0.0685, grad_norm=3.557825
[19:38:25.808] Epoch 18, Iter 8470: loss=0.0052, ce=0.0010, dice=0.0080, grad_norm=0.057266
[19:38:27.979] Epoch 18, Iter 8480: loss=0.0147, ce=0.0035, dice=0.0221, grad_norm=0.077176
[19:38:30.163] Epoch 18, Iter 8490: loss=0.0370, ce=0.0010, dice=0.0610, grad_norm=0.322651
[19:38:32.324] Epoch 18, Iter 8500: loss=0.0368, ce=0.0023, dice=0.0597, grad_norm=0.203904
[19:38:34.493] Epoch 18, Iter 8510: loss=0.0293, ce=0.0018, dice=0.0477, grad_norm=0.196467
[19:38:36.652] Epoch 18, Iter 8520: loss=0.0434, ce=0.0044, dice=0.0693, grad_norm=0.444938
[19:38:38.821] Epoch 18, Iter 8530: loss=0.0199, ce=0.0047, dice=0.0300, grad_norm=0.058992
[19:38:40.983] Epoch 18, Iter 8540: loss=0.2050, ce=0.0019, dice=0.3403, grad_norm=0.040942
[19:38:43.164] Epoch 18, Iter 8550: loss=0.0037, ce=0.0009, dice=0.0056, grad_norm=0.015819
[19:38:45.345] Epoch 18, Iter 8560: loss=0.0231, ce=0.0070, dice=0.0339, grad_norm=0.092440
[19:38:47.524] Epoch 18, Iter 8570: loss=0.1845, ce=0.0029, dice=0.3055, grad_norm=4.309223
[19:38:49.687] Epoch 18, Iter 8580: loss=0.0242, ce=0.0035, dice=0.0380, grad_norm=0.128155
[19:38:51.862] Epoch 18, Iter 8590: loss=0.0194, ce=0.0032, dice=0.0302, grad_norm=0.132950
[19:38:54.031] Epoch 18, Iter 8600: loss=0.0175, ce=0.0049, dice=0.0259, grad_norm=0.103059
[19:38:56.212] Epoch 18, Iter 8610: loss=0.0258, ce=0.0027, dice=0.0412, grad_norm=0.107778
[19:38:58.396] Epoch 18, Iter 8620: loss=0.0437, ce=0.0064, dice=0.0686, grad_norm=0.200424
[19:39:00.587] Epoch 18, Iter 8630: loss=0.0720, ce=0.0084, dice=0.1143, grad_norm=1.113124
[19:39:02.757] Epoch 18, Iter 8640: loss=0.0191, ce=0.0034, dice=0.0296, grad_norm=0.219113
[19:39:04.935] Epoch 18, Iter 8650: loss=0.1020, ce=0.0040, dice=0.1673, grad_norm=0.386280
[19:39:07.103] Epoch 18, Iter 8660: loss=0.0046, ce=0.0015, dice=0.0067, grad_norm=0.024272
[19:39:09.282] Epoch 18, Iter 8670: loss=0.0040, ce=0.0008, dice=0.0061, grad_norm=0.043029
[19:39:11.451] Epoch 18, Iter 8680: loss=0.0057, ce=0.0034, dice=0.0073, grad_norm=0.019674
[19:39:13.643] Epoch 18, Iter 8690: loss=0.2090, ce=0.0065, dice=0.3439, grad_norm=0.042023
[19:39:15.818] Epoch 18, Iter 8700: loss=0.0217, ce=0.0022, dice=0.0347, grad_norm=0.218404
[19:39:17.992] Epoch 18, Iter 8710: loss=0.0333, ce=0.0031, dice=0.0534, grad_norm=0.192062
[19:39:20.160] Epoch 18, Iter 8720: loss=0.0193, ce=0.0076, dice=0.0272, grad_norm=0.066843
[19:39:22.359] Epoch 18, Iter 8730: loss=0.0460, ce=0.0017, dice=0.0756, grad_norm=0.392349
[19:39:24.551] Epoch 18, Iter 8740: loss=0.0136, ce=0.0022, dice=0.0211, grad_norm=0.087083
[19:39:26.746] Epoch 18, Iter 8750: loss=0.0417, ce=0.0035, dice=0.0671, grad_norm=0.189291
[19:39:28.910] Epoch 18, Iter 8760: loss=0.0343, ce=0.0057, dice=0.0533, grad_norm=0.263816
[19:39:31.094] Epoch 18, Iter 8770: loss=0.0209, ce=0.0041, dice=0.0320, grad_norm=0.139007
[19:39:33.258] Epoch 18, Iter 8780: loss=0.0249, ce=0.0081, dice=0.0361, grad_norm=0.094542
[19:39:35.435] Epoch 18, Iter 8790: loss=0.2047, ce=0.0025, dice=0.3395, grad_norm=0.020364
[19:39:37.607] Epoch 18, Iter 8800: loss=0.0146, ce=0.0035, dice=0.0221, grad_norm=0.080072
[19:39:39.799] Epoch 18, Iter 8810: loss=0.0206, ce=0.0040, dice=0.0316, grad_norm=0.455799
[19:39:41.661] Epoch 18: Avg Loss=0.0407, CE=0.0035, Dice=0.0655
[19:39:52.865] Epoch 19, Iter 8820: loss=0.2041, ce=0.0018, dice=0.3390, grad_norm=0.021494
[19:39:55.055] Epoch 19, Iter 8830: loss=0.0232, ce=0.0030, dice=0.0367, grad_norm=0.072573
[19:39:57.234] Epoch 19, Iter 8840: loss=0.0276, ce=0.0022, dice=0.0445, grad_norm=0.225883
[19:39:59.415] Epoch 19, Iter 8850: loss=0.1016, ce=0.0041, dice=0.1667, grad_norm=0.707425
[19:40:01.579] Epoch 19, Iter 8860: loss=0.0134, ce=0.0045, dice=0.0194, grad_norm=0.092730
[19:40:03.780] Epoch 19, Iter 8870: loss=0.0154, ce=0.0029, dice=0.0237, grad_norm=0.104875
[19:40:05.964] Epoch 19, Iter 8880: loss=0.1982, ce=0.0031, dice=0.3283, grad_norm=1.142139
[19:40:08.150] Epoch 19, Iter 8890: loss=0.0116, ce=0.0021, dice=0.0180, grad_norm=0.121699
[19:40:10.320] Epoch 19, Iter 8900: loss=0.0209, ce=0.0047, dice=0.0317, grad_norm=0.102304
[19:40:12.498] Epoch 19, Iter 8910: loss=0.0098, ce=0.0002, dice=0.0162, grad_norm=0.128306
[19:40:14.666] Epoch 19, Iter 8920: loss=0.0211, ce=0.0089, dice=0.0293, grad_norm=0.062155
[19:40:16.855] Epoch 19, Iter 8930: loss=0.2052, ce=0.0035, dice=0.3396, grad_norm=0.028031
[19:40:19.044] Epoch 19, Iter 8940: loss=0.0450, ce=0.0026, dice=0.0732, grad_norm=0.312707
[19:40:21.226] Epoch 19, Iter 8950: loss=0.0433, ce=0.0010, dice=0.0715, grad_norm=0.513094
[19:40:23.395] Epoch 19, Iter 8960: loss=0.0429, ce=0.0020, dice=0.0701, grad_norm=0.277911
[19:40:25.571] Epoch 19, Iter 8970: loss=0.2041, ce=0.0019, dice=0.3389, grad_norm=0.011998
[19:40:27.741] Epoch 19, Iter 8980: loss=0.0074, ce=0.0036, dice=0.0099, grad_norm=0.055662
[19:40:29.939] Epoch 19, Iter 8990: loss=0.0039, ce=0.0010, dice=0.0058, grad_norm=0.020734
[19:40:32.116] Epoch 19, Iter 9000: loss=0.0069, ce=0.0027, dice=0.0096, grad_norm=0.029999
[19:40:34.301] Epoch 19, Iter 9010: loss=0.0141, ce=0.0015, dice=0.0225, grad_norm=0.100726
[19:40:36.482] Epoch 19, Iter 9020: loss=0.0208, ce=0.0019, dice=0.0333, grad_norm=0.104616
[19:40:38.660] Epoch 19, Iter 9030: loss=0.0061, ce=0.0012, dice=0.0093, grad_norm=0.027348
[19:40:40.831] Epoch 19, Iter 9040: loss=0.0072, ce=0.0015, dice=0.0110, grad_norm=1.342132
[19:40:43.014] Epoch 19, Iter 9050: loss=0.0172, ce=0.0024, dice=0.0271, grad_norm=0.075096
[19:40:45.274] Epoch 19, Iter 9060: loss=0.0606, ce=0.0021, dice=0.0995, grad_norm=0.797600
[19:40:47.467] Epoch 19, Iter 9070: loss=0.0189, ce=0.0030, dice=0.0295, grad_norm=0.182501
[19:40:49.641] Epoch 19, Iter 9080: loss=0.0178, ce=0.0037, dice=0.0272, grad_norm=0.112915
[19:40:51.824] Epoch 19, Iter 9090: loss=0.0258, ce=0.0033, dice=0.0408, grad_norm=0.166650
[19:40:53.994] Epoch 19, Iter 9100: loss=0.0357, ce=0.0051, dice=0.0562, grad_norm=0.139642
[19:40:56.178] Epoch 19, Iter 9110: loss=0.2001, ce=0.0049, dice=0.3302, grad_norm=1.518088
[19:40:58.363] Epoch 19, Iter 9120: loss=0.0128, ce=0.0062, dice=0.0172, grad_norm=0.081474
[19:41:00.558] Epoch 19, Iter 9130: loss=0.0439, ce=0.0030, dice=0.0712, grad_norm=0.313349
[19:41:02.732] Epoch 19, Iter 9140: loss=0.0324, ce=0.0056, dice=0.0503, grad_norm=0.156187
[19:41:04.918] Epoch 19, Iter 9150: loss=0.0475, ce=0.0022, dice=0.0776, grad_norm=0.452675
[19:41:07.088] Epoch 19, Iter 9160: loss=0.0392, ce=0.0031, dice=0.0633, grad_norm=0.232973
[19:41:09.269] Epoch 19, Iter 9170: loss=0.0171, ce=0.0049, dice=0.0252, grad_norm=0.081488
[19:41:11.453] Epoch 19, Iter 9180: loss=0.0272, ce=0.0032, dice=0.0432, grad_norm=0.227961
[19:41:13.654] Epoch 19, Iter 9190: loss=0.0213, ce=0.0030, dice=0.0335, grad_norm=0.096521
[19:41:15.851] Epoch 19, Iter 9200: loss=0.0230, ce=0.0049, dice=0.0352, grad_norm=0.092639
[19:41:18.051] Epoch 19, Iter 9210: loss=0.0135, ce=0.0065, dice=0.0183, grad_norm=0.046016
[19:41:20.225] Epoch 19, Iter 9220: loss=0.0101, ce=0.0032, dice=0.0148, grad_norm=0.090797
[19:41:22.408] Epoch 19, Iter 9230: loss=0.0435, ce=0.0013, dice=0.0716, grad_norm=0.258366
[19:41:24.588] Epoch 19, Iter 9240: loss=0.0372, ce=0.0055, dice=0.0583, grad_norm=0.282328
[19:41:26.767] Epoch 19, Iter 9250: loss=0.0510, ce=0.0027, dice=0.0831, grad_norm=0.498599
[19:41:28.946] Epoch 19, Iter 9260: loss=0.0206, ce=0.0051, dice=0.0309, grad_norm=0.086703
[19:41:31.142] Epoch 19, Iter 9270: loss=0.0062, ce=0.0027, dice=0.0085, grad_norm=0.058575
[19:41:33.285] Epoch 19, Iter 9280: loss=0.0066, ce=0.0017, dice=0.0099, grad_norm=0.076757
[19:41:33.898] Epoch 19: Avg Loss=0.0415, CE=0.0035, Dice=0.0667
[19:46:32.499] save model to ./finetune_tpgm_lits17_debug\finetuned_lits17_epoch_19.pth
[19:46:32.672] save final model to ./finetune_tpgm_lits17_debug\finetuned_lits17_final.pth
