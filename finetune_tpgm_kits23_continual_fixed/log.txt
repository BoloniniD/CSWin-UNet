[17:12:00.284] Namespace(root_path='./datasets/kits23/train_npz', dataset='kits23', list_dir='./lists/kits23', num_classes=4, model_num_classes=9, output_dir='./finetune_tpgm_kits23_continual_fixed', max_iterations=10000, max_epochs=50, batch_size=32, n_gpu=1, deterministic=1, base_lr=0.001, img_size=224, seed=1234, cfg='configs/finetune.yaml', pretrained_path='./pretrain/epoch_149.pth', data_fraction=0.3, freeze_layers=0, opts=None, zip=False, cache_mode='part', resume=None, accumulation_steps=None, use_checkpoint=False, amp_opt_level='O1', tag=None, eval=False, throughput=False, tpgm_norm_mode='l2', tpgm_lr=0.01, tpgm_iters=300, tpgm_exclude=[], tpgm_frequency=3, gpu_id=0)
[17:12:00.316] Using 27137/95221 samples for finetuning
[17:12:00.316] Using 1429/95221 samples for TPGM
[17:12:00.316] Model has 9 total classes, training on 4 classes
[17:12:00.316] TPGM will run every 3 epochs
[17:12:15.776] Namespace(root_path='./datasets/kits23/train_npz', dataset='kits23', list_dir='./lists/kits23', num_classes=4, model_num_classes=9, output_dir='./finetune_tpgm_kits23_continual_fixed', max_iterations=10000, max_epochs=50, batch_size=32, n_gpu=1, deterministic=1, base_lr=0.001, img_size=224, seed=1234, cfg='configs/finetune.yaml', pretrained_path='./pretrain/epoch_149.pth', data_fraction=0.3, freeze_layers=0, opts=None, zip=False, cache_mode='part', resume=None, accumulation_steps=None, use_checkpoint=False, amp_opt_level='O1', tag=None, eval=False, throughput=False, tpgm_norm_mode='l2', tpgm_lr=0.01, tpgm_iters=300, tpgm_exclude=[], tpgm_frequency=3, gpu_id=1)
[17:12:15.803] Using 27137/95221 samples for finetuning
[17:12:15.803] Using 1429/95221 samples for TPGM
[17:12:15.803] Model has 9 total classes, training on 4 classes
[17:12:15.803] TPGM will run every 3 epochs
[17:12:26.212] 849 iterations per epoch. 42450 max iterations 
[17:12:41.671] iteration 10 : loss : 0.454834, loss_ce: 0.062264
[17:12:45.706] iteration 20 : loss : 0.441612, loss_ce: 0.035067
[17:12:49.771] iteration 30 : loss : 0.439590, loss_ce: 0.070523
[17:12:53.809] iteration 40 : loss : 0.295951, loss_ce: 0.043768
[17:12:57.863] iteration 50 : loss : 0.440533, loss_ce: 0.040352
[17:13:01.918] iteration 60 : loss : 0.434180, loss_ce: 0.046719
[17:13:05.980] iteration 70 : loss : 0.444475, loss_ce: 0.060068
[17:13:10.036] iteration 80 : loss : 0.433517, loss_ce: 0.059961
[17:13:14.105] iteration 90 : loss : 0.425320, loss_ce: 0.049951
[17:13:18.164] iteration 100 : loss : 0.405538, loss_ce: 0.026535
[17:13:22.228] iteration 110 : loss : 0.449732, loss_ce: 0.015524
[17:13:26.282] iteration 120 : loss : 0.473499, loss_ce: 0.127309
[17:13:30.355] iteration 130 : loss : 0.440914, loss_ce: 0.089035
[17:13:34.413] iteration 140 : loss : 0.436214, loss_ce: 0.039661
[17:13:38.488] iteration 150 : loss : 0.429076, loss_ce: 0.044918
[17:13:42.545] iteration 160 : loss : 0.403512, loss_ce: 0.049586
[17:13:46.619] iteration 170 : loss : 0.258357, loss_ce: 0.020572
[17:13:50.690] iteration 180 : loss : 0.376077, loss_ce: 0.048405
[17:13:54.768] iteration 190 : loss : 0.384334, loss_ce: 0.039312
[17:13:58.838] iteration 200 : loss : 0.369499, loss_ce: 0.055598
[17:14:02.914] iteration 210 : loss : 0.339818, loss_ce: 0.016494
[17:14:06.982] iteration 220 : loss : 0.363460, loss_ce: 0.024666
[17:14:11.068] iteration 230 : loss : 0.342400, loss_ce: 0.026743
[17:14:15.134] iteration 240 : loss : 0.375280, loss_ce: 0.028018
[17:14:19.207] iteration 250 : loss : 0.356893, loss_ce: 0.041605
[17:14:23.269] iteration 260 : loss : 0.349700, loss_ce: 0.030640
[17:14:27.351] iteration 270 : loss : 0.310216, loss_ce: 0.029886
[17:14:50.347] Namespace(root_path='./datasets/kits23/train_npz', dataset='kits23', list_dir='./lists/kits23', num_classes=4, model_num_classes=9, output_dir='./finetune_tpgm_kits23_continual_fixed', max_iterations=10000, max_epochs=50, batch_size=48, n_gpu=1, deterministic=1, base_lr=0.001, img_size=224, seed=1234, cfg='configs/finetune.yaml', pretrained_path='./pretrain/epoch_149.pth', data_fraction=0.3, freeze_layers=0, opts=None, zip=False, cache_mode='part', resume=None, accumulation_steps=None, use_checkpoint=False, amp_opt_level='O1', tag=None, eval=False, throughput=False, tpgm_norm_mode='l2', tpgm_lr=0.01, tpgm_iters=300, tpgm_exclude=[], tpgm_frequency=3, gpu_id=1)
[17:14:50.374] Using 27137/95221 samples for finetuning
[17:14:50.375] Using 1429/95221 samples for TPGM
[17:14:50.375] Model has 9 total classes, training on 4 classes
[17:14:50.375] TPGM will run every 3 epochs
[17:15:00.808] 566 iterations per epoch. 28300 max iterations 
[17:15:18.161] iteration 10 : loss : 0.457689, loss_ce: 0.036288
[17:15:24.497] iteration 20 : loss : 0.471845, loss_ce: 0.067832
[17:15:30.859] iteration 30 : loss : 0.464304, loss_ce: 0.070392
[17:15:37.204] iteration 40 : loss : 0.450783, loss_ce: 0.060436
[17:15:43.561] iteration 50 : loss : 0.448893, loss_ce: 0.077408
[17:15:49.915] iteration 60 : loss : 0.433418, loss_ce: 0.056140
[17:15:56.282] iteration 70 : loss : 0.428019, loss_ce: 0.057940
[17:16:02.637] iteration 80 : loss : 0.441485, loss_ce: 0.064634
[17:16:09.006] iteration 90 : loss : 0.439481, loss_ce: 0.062471
[17:16:15.361] iteration 100 : loss : 0.441264, loss_ce: 0.049371
[17:16:21.727] iteration 110 : loss : 0.436466, loss_ce: 0.051456
[17:16:28.086] iteration 120 : loss : 0.439157, loss_ce: 0.088843
[17:16:34.457] iteration 130 : loss : 0.439515, loss_ce: 0.041068
[17:16:40.822] iteration 140 : loss : 0.426417, loss_ce: 0.041297
[17:16:47.198] iteration 150 : loss : 0.419804, loss_ce: 0.056198
[17:16:53.568] iteration 160 : loss : 0.408618, loss_ce: 0.039707
[17:16:59.944] iteration 170 : loss : 0.414235, loss_ce: 0.047077
[17:17:06.313] iteration 180 : loss : 0.393052, loss_ce: 0.044303
[17:17:12.700] iteration 190 : loss : 0.405347, loss_ce: 0.025368
[17:17:19.077] iteration 200 : loss : 0.390673, loss_ce: 0.035000
[17:17:25.459] iteration 210 : loss : 0.385506, loss_ce: 0.046891
[17:17:31.851] iteration 220 : loss : 0.364734, loss_ce: 0.026795
[17:17:38.248] iteration 230 : loss : 0.231446, loss_ce: 0.061563
[17:17:44.632] iteration 240 : loss : 0.316372, loss_ce: 0.020869
[17:17:51.031] iteration 250 : loss : 0.395556, loss_ce: 0.024844
[17:17:57.415] iteration 260 : loss : 0.201438, loss_ce: 0.049726
[17:18:03.808] iteration 270 : loss : 0.423390, loss_ce: 0.044733
[17:18:10.191] iteration 280 : loss : 0.389654, loss_ce: 0.014348
[17:18:16.585] iteration 290 : loss : 0.397172, loss_ce: 0.055052
[17:18:22.965] iteration 300 : loss : 0.401465, loss_ce: 0.026049
[17:18:29.363] iteration 310 : loss : 0.385012, loss_ce: 0.046124
[17:18:35.751] iteration 320 : loss : 0.354223, loss_ce: 0.029471
[17:18:42.149] iteration 330 : loss : 0.365267, loss_ce: 0.035374
[17:18:48.534] iteration 340 : loss : 0.358264, loss_ce: 0.028600
[17:18:54.933] iteration 350 : loss : 0.348949, loss_ce: 0.019310
[17:19:01.322] iteration 360 : loss : 0.315493, loss_ce: 0.029291
[17:19:07.721] iteration 370 : loss : 0.339259, loss_ce: 0.031664
[17:19:14.110] iteration 380 : loss : 0.330050, loss_ce: 0.023464
[17:19:20.511] iteration 390 : loss : 0.326950, loss_ce: 0.015782
[17:19:26.903] iteration 400 : loss : 0.202521, loss_ce: 0.026113
[17:19:33.306] iteration 410 : loss : 0.318571, loss_ce: 0.028305
[17:19:39.695] iteration 420 : loss : 0.273121, loss_ce: 0.018677
[17:19:46.098] iteration 430 : loss : 0.337518, loss_ce: 0.031892
[17:19:52.490] iteration 440 : loss : 0.291907, loss_ce: 0.010288
[17:19:58.890] iteration 450 : loss : 0.304965, loss_ce: 0.027120
[17:20:05.285] iteration 460 : loss : 0.330009, loss_ce: 0.029014
[17:20:11.683] iteration 470 : loss : 0.268112, loss_ce: 0.036251
[17:20:18.075] iteration 480 : loss : 0.360061, loss_ce: 0.041925
[17:20:24.474] iteration 490 : loss : 0.346896, loss_ce: 0.012321
[17:20:30.866] iteration 500 : loss : 0.261338, loss_ce: 0.032412
[17:20:37.271] iteration 510 : loss : 0.313733, loss_ce: 0.023408
[17:20:43.670] iteration 520 : loss : 0.294093, loss_ce: 0.019057
[17:20:50.071] iteration 530 : loss : 0.244893, loss_ce: 0.015308
[17:20:56.468] iteration 540 : loss : 0.274649, loss_ce: 0.017978
[17:21:02.873] iteration 550 : loss : 0.311356, loss_ce: 0.054810
[17:21:09.264] iteration 560 : loss : 0.277860, loss_ce: 0.014016
[17:21:13.343] Epoch 0: Average loss: 0.3669
[17:21:26.657] iteration 570 : loss : 0.328794, loss_ce: 0.012446
[17:21:33.029] iteration 580 : loss : 0.340263, loss_ce: 0.020658
[17:21:39.416] iteration 590 : loss : 0.191645, loss_ce: 0.015250
[17:21:45.790] iteration 600 : loss : 0.321142, loss_ce: 0.045184
[17:21:52.178] iteration 610 : loss : 0.223319, loss_ce: 0.013915
[17:21:58.561] iteration 620 : loss : 0.333684, loss_ce: 0.029408
[17:22:04.952] iteration 630 : loss : 0.301634, loss_ce: 0.024340
[17:22:11.341] iteration 640 : loss : 0.150164, loss_ce: 0.011110
[17:22:17.737] iteration 650 : loss : 0.188907, loss_ce: 0.047636
[17:22:24.123] iteration 660 : loss : 0.245312, loss_ce: 0.024054
[17:22:30.521] iteration 670 : loss : 0.335897, loss_ce: 0.018544
[17:22:36.906] iteration 680 : loss : 0.322329, loss_ce: 0.011741
[17:22:43.316] iteration 690 : loss : 0.244563, loss_ce: 0.016843
[17:22:49.703] iteration 700 : loss : 0.211465, loss_ce: 0.014877
[17:22:56.107] iteration 710 : loss : 0.324411, loss_ce: 0.023356
[17:23:02.497] iteration 720 : loss : 0.308291, loss_ce: 0.020141
[17:23:08.900] iteration 730 : loss : 0.321897, loss_ce: 0.007452
[17:23:15.290] iteration 740 : loss : 0.292932, loss_ce: 0.010891
[17:23:21.692] iteration 750 : loss : 0.267586, loss_ce: 0.022420
[17:23:28.087] iteration 760 : loss : 0.107537, loss_ce: 0.007505
[17:23:34.492] iteration 770 : loss : 0.290843, loss_ce: 0.022824
[17:23:40.888] iteration 780 : loss : 0.290484, loss_ce: 0.015991
[17:23:47.289] iteration 790 : loss : 0.258066, loss_ce: 0.017514
[17:23:53.681] iteration 800 : loss : 0.308822, loss_ce: 0.028130
[17:24:00.083] iteration 810 : loss : 0.260403, loss_ce: 0.010509
[17:24:06.474] iteration 820 : loss : 0.298483, loss_ce: 0.025984
[17:24:12.874] iteration 830 : loss : 0.239673, loss_ce: 0.007722
[17:24:19.267] iteration 840 : loss : 0.244646, loss_ce: 0.027832
[17:24:25.670] iteration 850 : loss : 0.270188, loss_ce: 0.020345
[17:24:32.066] iteration 860 : loss : 0.288671, loss_ce: 0.006287
[17:24:38.473] iteration 870 : loss : 0.255305, loss_ce: 0.010449
[17:24:44.873] iteration 880 : loss : 0.243776, loss_ce: 0.013702
[17:24:51.274] iteration 890 : loss : 0.218026, loss_ce: 0.016083
[17:24:57.668] iteration 900 : loss : 0.080058, loss_ce: 0.009386
[17:25:04.073] iteration 910 : loss : 0.290964, loss_ce: 0.015476
[17:25:10.467] iteration 920 : loss : 0.262595, loss_ce: 0.013581
[17:25:16.875] iteration 930 : loss : 0.231752, loss_ce: 0.013444
[17:25:23.276] iteration 940 : loss : 0.226949, loss_ce: 0.012094
[17:25:29.681] iteration 950 : loss : 0.219709, loss_ce: 0.007873
[17:25:36.081] iteration 960 : loss : 0.220657, loss_ce: 0.012083
[17:25:42.497] iteration 970 : loss : 0.168168, loss_ce: 0.012250
[17:25:48.890] iteration 980 : loss : 0.257075, loss_ce: 0.014756
[17:25:55.294] iteration 990 : loss : 0.221485, loss_ce: 0.018927
[17:26:01.691] iteration 1000 : loss : 0.236346, loss_ce: 0.019233
[17:26:08.109] iteration 1010 : loss : 0.275354, loss_ce: 0.025529
[17:26:14.504] iteration 1020 : loss : 0.216874, loss_ce: 0.011864
[17:26:20.907] iteration 1030 : loss : 0.234888, loss_ce: 0.010645
[17:26:27.301] iteration 1040 : loss : 0.285688, loss_ce: 0.012453
[17:26:33.715] iteration 1050 : loss : 0.271637, loss_ce: 0.019079
[17:26:40.111] iteration 1060 : loss : 0.200411, loss_ce: 0.009144
[17:26:46.517] iteration 1070 : loss : 0.344392, loss_ce: 0.037243
[17:26:52.914] iteration 1080 : loss : 0.253900, loss_ce: 0.025726
[17:26:59.326] iteration 1090 : loss : 0.234240, loss_ce: 0.010527
[17:27:05.725] iteration 1100 : loss : 0.252628, loss_ce: 0.031002
[17:27:12.135] iteration 1110 : loss : 0.234957, loss_ce: 0.010432
[17:27:18.530] iteration 1120 : loss : 0.258850, loss_ce: 0.015798
[17:27:24.935] iteration 1130 : loss : 0.223986, loss_ce: 0.007548
[17:27:26.507] Epoch 1: Average loss: 0.2596
[17:27:43.086] iteration 1140 : loss : 0.261480, loss_ce: 0.031246
[17:27:49.471] iteration 1150 : loss : 0.187006, loss_ce: 0.011166
[17:27:55.851] iteration 1160 : loss : 0.326438, loss_ce: 0.017321
[17:28:02.243] iteration 1170 : loss : 0.227544, loss_ce: 0.016190
[17:28:08.624] iteration 1180 : loss : 0.068320, loss_ce: 0.010144
[17:28:15.016] iteration 1190 : loss : 0.274037, loss_ce: 0.059255
[17:28:21.403] iteration 1200 : loss : 0.133484, loss_ce: 0.039478
[17:28:27.801] iteration 1210 : loss : 0.251571, loss_ce: 0.015228
[17:28:34.186] iteration 1220 : loss : 0.288212, loss_ce: 0.014337
[17:28:40.584] iteration 1230 : loss : 0.264576, loss_ce: 0.026332
[17:28:46.965] iteration 1240 : loss : 0.239925, loss_ce: 0.024079
[17:28:53.362] iteration 1250 : loss : 0.229972, loss_ce: 0.012005
[17:28:59.750] iteration 1260 : loss : 0.320451, loss_ce: 0.007739
[17:29:06.150] iteration 1270 : loss : 0.227700, loss_ce: 0.013977
[17:29:12.541] iteration 1280 : loss : 0.292008, loss_ce: 0.010029
[17:29:18.937] iteration 1290 : loss : 0.225889, loss_ce: 0.006917
[17:29:25.328] iteration 1300 : loss : 0.192292, loss_ce: 0.010871
[17:29:31.730] iteration 1310 : loss : 0.215118, loss_ce: 0.015910
[17:29:38.122] iteration 1320 : loss : 0.274712, loss_ce: 0.022403
[17:29:44.525] iteration 1330 : loss : 0.301223, loss_ce: 0.020860
[17:29:50.920] iteration 1340 : loss : 0.263675, loss_ce: 0.020140
[17:29:57.326] iteration 1350 : loss : 0.186371, loss_ce: 0.005588
[17:30:03.725] iteration 1360 : loss : 0.083391, loss_ce: 0.016590
[17:30:10.133] iteration 1370 : loss : 0.255070, loss_ce: 0.019533
[17:30:16.535] iteration 1380 : loss : 0.243812, loss_ce: 0.028482
[17:30:22.944] iteration 1390 : loss : 0.292971, loss_ce: 0.007052
[17:30:29.339] iteration 1400 : loss : 0.282826, loss_ce: 0.013071
[17:30:35.746] iteration 1410 : loss : 0.217523, loss_ce: 0.012176
[17:30:42.146] iteration 1420 : loss : 0.218861, loss_ce: 0.014391
[17:30:48.556] iteration 1430 : loss : 0.333433, loss_ce: 0.019234
[17:30:54.952] iteration 1440 : loss : 0.276252, loss_ce: 0.012174
[17:31:01.359] iteration 1450 : loss : 0.300951, loss_ce: 0.039145
[17:31:07.759] iteration 1460 : loss : 0.283947, loss_ce: 0.013364
[17:31:14.168] iteration 1470 : loss : 0.314516, loss_ce: 0.004368
[17:31:20.570] iteration 1480 : loss : 0.043081, loss_ce: 0.004847
[17:31:26.979] iteration 1490 : loss : 0.359662, loss_ce: 0.038172
[17:31:33.376] iteration 1500 : loss : 0.274596, loss_ce: 0.034400
[17:31:39.791] iteration 1510 : loss : 0.250153, loss_ce: 0.023587
[17:31:46.192] iteration 1520 : loss : 0.248344, loss_ce: 0.005684
[17:31:52.611] iteration 1530 : loss : 0.286482, loss_ce: 0.022757
[17:31:59.006] iteration 1540 : loss : 0.215783, loss_ce: 0.008704
[17:32:05.419] iteration 1550 : loss : 0.221870, loss_ce: 0.011869
[17:32:11.816] iteration 1560 : loss : 0.259352, loss_ce: 0.014410
[17:32:18.223] iteration 1570 : loss : 0.300950, loss_ce: 0.007211
[17:32:24.622] iteration 1580 : loss : 0.201508, loss_ce: 0.013901
[17:32:31.032] iteration 1590 : loss : 0.228459, loss_ce: 0.014478
[17:32:37.434] iteration 1600 : loss : 0.185268, loss_ce: 0.006905
[17:32:43.851] iteration 1610 : loss : 0.242107, loss_ce: 0.013282
[17:32:50.251] iteration 1620 : loss : 0.228398, loss_ce: 0.011677
[17:32:56.663] iteration 1630 : loss : 0.260943, loss_ce: 0.005626
[17:33:03.064] iteration 1640 : loss : 0.066718, loss_ce: 0.008486
[17:33:09.476] iteration 1650 : loss : 0.300632, loss_ce: 0.010828
[17:33:15.886] iteration 1660 : loss : 0.235579, loss_ce: 0.020105
[17:33:22.296] iteration 1670 : loss : 0.354800, loss_ce: 0.015092
[17:33:28.694] iteration 1680 : loss : 0.066897, loss_ce: 0.007884
[17:33:35.114] iteration 1690 : loss : 0.306338, loss_ce: 0.010215
[17:33:40.483] Epoch 2: Average loss: 0.2418
[17:39:16.262] iteration 1700 : loss : 0.287856, loss_ce: 0.007954
[17:39:22.623] iteration 1710 : loss : 0.318061, loss_ce: 0.006924
[17:39:28.980] iteration 1720 : loss : 0.326624, loss_ce: 0.011235
[17:39:35.348] iteration 1730 : loss : 0.257461, loss_ce: 0.020219
[17:39:41.705] iteration 1740 : loss : 0.278309, loss_ce: 0.014280
[17:39:48.078] iteration 1750 : loss : 0.082665, loss_ce: 0.009817
[17:39:54.443] iteration 1760 : loss : 0.262061, loss_ce: 0.005535
[17:40:00.821] iteration 1770 : loss : 0.241131, loss_ce: 0.008351
[17:40:07.192] iteration 1780 : loss : 0.256778, loss_ce: 0.014102
[17:40:13.576] iteration 1790 : loss : 0.224842, loss_ce: 0.012268
[17:40:19.947] iteration 1800 : loss : 0.070077, loss_ce: 0.014951
[17:40:26.331] iteration 1810 : loss : 0.221410, loss_ce: 0.009823
[17:40:32.705] iteration 1820 : loss : 0.228820, loss_ce: 0.009270
[17:40:39.089] iteration 1830 : loss : 0.232266, loss_ce: 0.012376
[17:40:45.464] iteration 1840 : loss : 0.261746, loss_ce: 0.012211
[17:40:51.846] iteration 1850 : loss : 0.345349, loss_ce: 0.026106
[17:40:58.223] iteration 1860 : loss : 0.260026, loss_ce: 0.019561
[17:41:04.610] iteration 1870 : loss : 0.199980, loss_ce: 0.011321
[17:41:10.989] iteration 1880 : loss : 0.243357, loss_ce: 0.023423
[17:41:17.384] iteration 1890 : loss : 0.211762, loss_ce: 0.011457
[17:41:23.772] iteration 1900 : loss : 0.271249, loss_ce: 0.030735
[17:41:30.165] iteration 1910 : loss : 0.307240, loss_ce: 0.034611
[17:41:36.549] iteration 1920 : loss : 0.200617, loss_ce: 0.008441
[17:41:42.944] iteration 1930 : loss : 0.314641, loss_ce: 0.011350
[17:41:49.331] iteration 1940 : loss : 0.225809, loss_ce: 0.021092
[17:41:55.728] iteration 1950 : loss : 0.254427, loss_ce: 0.009818
[17:42:02.115] iteration 1960 : loss : 0.231539, loss_ce: 0.015091
[17:42:08.509] iteration 1970 : loss : 0.215563, loss_ce: 0.015787
[17:42:14.892] iteration 1980 : loss : 0.277546, loss_ce: 0.015453
[17:42:21.288] iteration 1990 : loss : 0.225421, loss_ce: 0.011592
[17:42:27.678] iteration 2000 : loss : 0.232062, loss_ce: 0.009913
[17:42:34.077] iteration 2010 : loss : 0.226724, loss_ce: 0.009321
[17:42:40.469] iteration 2020 : loss : 0.275332, loss_ce: 0.009655
[17:42:46.866] iteration 2030 : loss : 0.307325, loss_ce: 0.005470
[17:42:53.256] iteration 2040 : loss : 0.238393, loss_ce: 0.021245
[17:42:59.659] iteration 2050 : loss : 0.196661, loss_ce: 0.007333
[17:43:06.058] iteration 2060 : loss : 0.248599, loss_ce: 0.016897
[17:43:12.459] iteration 2070 : loss : 0.251488, loss_ce: 0.009745
[17:43:18.851] iteration 2080 : loss : 0.290977, loss_ce: 0.006513
[17:43:25.253] iteration 2090 : loss : 0.316440, loss_ce: 0.018796
[17:43:31.646] iteration 2100 : loss : 0.200149, loss_ce: 0.011864
[17:43:38.047] iteration 2110 : loss : 0.233001, loss_ce: 0.011506
[17:43:44.441] iteration 2120 : loss : 0.266484, loss_ce: 0.013919
[17:43:50.849] iteration 2130 : loss : 0.047136, loss_ce: 0.008181
[17:43:57.248] iteration 2140 : loss : 0.302601, loss_ce: 0.028631
[17:44:03.654] iteration 2150 : loss : 0.323014, loss_ce: 0.011831
[17:44:10.045] iteration 2160 : loss : 0.228939, loss_ce: 0.032952
[17:44:16.452] iteration 2170 : loss : 0.193993, loss_ce: 0.007320
[17:44:22.854] iteration 2180 : loss : 0.259614, loss_ce: 0.010758
[17:44:29.262] iteration 2190 : loss : 0.251309, loss_ce: 0.016690
[17:44:35.661] iteration 2200 : loss : 0.283618, loss_ce: 0.018537
[17:44:42.066] iteration 2210 : loss : 0.231932, loss_ce: 0.018922
[17:44:48.463] iteration 2220 : loss : 0.214791, loss_ce: 0.012704
[17:44:54.868] iteration 2230 : loss : 0.313605, loss_ce: 0.006550
[17:45:01.264] iteration 2240 : loss : 0.222242, loss_ce: 0.016132
[17:45:07.669] iteration 2250 : loss : 0.252960, loss_ce: 0.011305
[17:45:14.065] iteration 2260 : loss : 0.222933, loss_ce: 0.022354
[17:45:16.868] Epoch 3: Average loss: 0.2350
[17:45:32.105] iteration 2270 : loss : 0.207928, loss_ce: 0.010491
[17:45:38.484] iteration 2280 : loss : 0.267809, loss_ce: 0.015207
[17:45:44.874] iteration 2290 : loss : 0.309643, loss_ce: 0.002975
[17:45:51.255] iteration 2300 : loss : 0.300244, loss_ce: 0.010074
[17:45:57.650] iteration 2310 : loss : 0.107280, loss_ce: 0.006500
[17:46:04.034] iteration 2320 : loss : 0.249767, loss_ce: 0.013055
[17:46:10.434] iteration 2330 : loss : 0.216727, loss_ce: 0.012849
[17:46:16.822] iteration 2340 : loss : 0.301090, loss_ce: 0.028817
[17:46:23.218] iteration 2350 : loss : 0.277841, loss_ce: 0.010741
[17:46:29.603] iteration 2360 : loss : 0.228001, loss_ce: 0.017095
[17:46:36.004] iteration 2370 : loss : 0.126785, loss_ce: 0.007602
[17:46:42.392] iteration 2380 : loss : 0.257343, loss_ce: 0.017752
[17:46:48.794] iteration 2390 : loss : 0.228834, loss_ce: 0.016942
[17:46:55.183] iteration 2400 : loss : 0.202997, loss_ce: 0.012345
[17:47:01.588] iteration 2410 : loss : 0.196945, loss_ce: 0.011127
[17:47:07.980] iteration 2420 : loss : 0.212988, loss_ce: 0.019251
[17:47:14.387] iteration 2430 : loss : 0.235811, loss_ce: 0.027552
[17:47:20.777] iteration 2440 : loss : 0.209785, loss_ce: 0.014269
[17:47:27.184] iteration 2450 : loss : 0.202010, loss_ce: 0.011602
[17:47:33.582] iteration 2460 : loss : 0.250049, loss_ce: 0.010153
[17:47:39.999] iteration 2470 : loss : 0.221147, loss_ce: 0.011797
[17:47:46.397] iteration 2480 : loss : 0.211450, loss_ce: 0.011152
[17:47:52.801] iteration 2490 : loss : 0.213871, loss_ce: 0.011503
[17:47:59.201] iteration 2500 : loss : 0.189723, loss_ce: 0.010255
[17:48:05.610] iteration 2510 : loss : 0.324901, loss_ce: 0.009329
[17:48:12.008] iteration 2520 : loss : 0.225828, loss_ce: 0.016871
[17:48:18.417] iteration 2530 : loss : 0.302327, loss_ce: 0.019796
[17:48:24.817] iteration 2540 : loss : 0.221416, loss_ce: 0.010992
[17:48:31.226] iteration 2550 : loss : 0.369917, loss_ce: 0.050607
[17:48:37.630] iteration 2560 : loss : 0.266762, loss_ce: 0.014926
[17:48:44.040] iteration 2570 : loss : 0.238433, loss_ce: 0.015156
[17:48:50.438] iteration 2580 : loss : 0.219900, loss_ce: 0.012797
[17:48:56.852] iteration 2590 : loss : 0.283500, loss_ce: 0.017316
[17:49:03.250] iteration 2600 : loss : 0.349956, loss_ce: 0.049886
[17:49:09.654] iteration 2610 : loss : 0.243197, loss_ce: 0.008359
[17:49:16.063] iteration 2620 : loss : 0.298669, loss_ce: 0.034746
[17:49:22.470] iteration 2630 : loss : 0.216557, loss_ce: 0.006669
[17:49:28.875] iteration 2640 : loss : 0.221617, loss_ce: 0.018129
[17:49:35.290] iteration 2650 : loss : 0.334330, loss_ce: 0.017343
[17:49:41.687] iteration 2660 : loss : 0.232449, loss_ce: 0.012935
[17:49:48.097] iteration 2670 : loss : 0.108619, loss_ce: 0.014002
[17:49:54.497] iteration 2680 : loss : 0.246319, loss_ce: 0.037921
[17:50:00.912] iteration 2690 : loss : 0.285874, loss_ce: 0.007998
[17:50:07.315] iteration 2700 : loss : 0.228495, loss_ce: 0.015426
[17:50:13.731] iteration 2710 : loss : 0.077591, loss_ce: 0.007318
[17:50:20.134] iteration 2720 : loss : 0.176976, loss_ce: 0.004710
[17:50:26.550] iteration 2730 : loss : 0.281181, loss_ce: 0.007471
[17:50:32.945] iteration 2740 : loss : 0.235434, loss_ce: 0.013964
[17:50:39.365] iteration 2750 : loss : 0.283374, loss_ce: 0.015309
[17:50:45.767] iteration 2760 : loss : 0.229839, loss_ce: 0.013285
[17:50:52.186] iteration 2770 : loss : 0.256715, loss_ce: 0.009503
[17:50:58.596] iteration 2780 : loss : 0.238744, loss_ce: 0.016616
[17:51:05.018] iteration 2790 : loss : 0.314778, loss_ce: 0.008856
[17:51:11.418] iteration 2800 : loss : 0.039489, loss_ce: 0.005301
[17:51:17.832] iteration 2810 : loss : 0.207997, loss_ce: 0.016843
[17:51:24.233] iteration 2820 : loss : 0.235623, loss_ce: 0.017402
[17:51:30.224] iteration 2830 : loss : 0.268717, loss_ce: 0.010694
[17:51:30.963] Epoch 4: Average loss: 0.2348
[17:51:48.934] iteration 2840 : loss : 0.050703, loss_ce: 0.010076
[17:51:55.330] iteration 2850 : loss : 0.285789, loss_ce: 0.013884
[17:52:01.712] iteration 2860 : loss : 0.281959, loss_ce: 0.015200
[17:52:08.104] iteration 2870 : loss : 0.197788, loss_ce: 0.008479
[17:52:14.495] iteration 2880 : loss : 0.213007, loss_ce: 0.008984
[17:52:20.893] iteration 2890 : loss : 0.276790, loss_ce: 0.025741
[17:52:27.279] iteration 2900 : loss : 0.220984, loss_ce: 0.023436
[17:52:33.676] iteration 2910 : loss : 0.288065, loss_ce: 0.014927
[17:52:40.062] iteration 2920 : loss : 0.242674, loss_ce: 0.010126
[17:52:46.459] iteration 2930 : loss : 0.263211, loss_ce: 0.011839
[17:52:52.848] iteration 2940 : loss : 0.188662, loss_ce: 0.011252
[17:52:59.249] iteration 2950 : loss : 0.235738, loss_ce: 0.035336
[17:53:05.637] iteration 2960 : loss : 0.215773, loss_ce: 0.015516
[17:53:12.039] iteration 2970 : loss : 0.241932, loss_ce: 0.015323
[17:53:18.435] iteration 2980 : loss : 0.232326, loss_ce: 0.009185
[17:53:24.843] iteration 2990 : loss : 0.251790, loss_ce: 0.013247
[17:53:31.236] iteration 3000 : loss : 0.188296, loss_ce: 0.008562
[17:53:37.645] iteration 3010 : loss : 0.245752, loss_ce: 0.019013
[17:53:44.042] iteration 3020 : loss : 0.294450, loss_ce: 0.015871
[17:53:50.453] iteration 3030 : loss : 0.029668, loss_ce: 0.006072
[17:53:56.851] iteration 3040 : loss : 0.227064, loss_ce: 0.016205
[17:54:03.257] iteration 3050 : loss : 0.212676, loss_ce: 0.019709
[17:54:09.659] iteration 3060 : loss : 0.053624, loss_ce: 0.005569
[17:54:16.069] iteration 3070 : loss : 0.278874, loss_ce: 0.009322
[17:54:22.467] iteration 3080 : loss : 0.313686, loss_ce: 0.007170
[17:54:28.878] iteration 3090 : loss : 0.262435, loss_ce: 0.015232
[17:54:35.277] iteration 3100 : loss : 0.238224, loss_ce: 0.014833
[17:54:41.693] iteration 3110 : loss : 0.262451, loss_ce: 0.011449
[17:54:48.094] iteration 3120 : loss : 0.201114, loss_ce: 0.010251
[17:54:54.508] iteration 3130 : loss : 0.232640, loss_ce: 0.008797
[17:55:00.920] iteration 3140 : loss : 0.035487, loss_ce: 0.004930
[17:55:07.328] iteration 3150 : loss : 0.261842, loss_ce: 0.006769
[17:55:13.730] iteration 3160 : loss : 0.199969, loss_ce: 0.007982
[17:55:20.144] iteration 3170 : loss : 0.311799, loss_ce: 0.008861
[17:55:26.545] iteration 3180 : loss : 0.241928, loss_ce: 0.011802
[17:55:32.957] iteration 3190 : loss : 0.190065, loss_ce: 0.008824
[17:55:39.360] iteration 3200 : loss : 0.269004, loss_ce: 0.025267
[17:55:45.773] iteration 3210 : loss : 0.284682, loss_ce: 0.009930
[17:55:52.174] iteration 3220 : loss : 0.213004, loss_ce: 0.014711
[17:55:58.587] iteration 3230 : loss : 0.292674, loss_ce: 0.019652
[17:56:04.990] iteration 3240 : loss : 0.308542, loss_ce: 0.012430
[17:56:11.411] iteration 3250 : loss : 0.258173, loss_ce: 0.010033
[17:56:17.820] iteration 3260 : loss : 0.236786, loss_ce: 0.012521
[17:56:24.238] iteration 3270 : loss : 0.228151, loss_ce: 0.012093
[17:56:30.642] iteration 3280 : loss : 0.232341, loss_ce: 0.011107
[17:56:37.064] iteration 3290 : loss : 0.209447, loss_ce: 0.012946
[17:56:43.466] iteration 3300 : loss : 0.229506, loss_ce: 0.008062
[17:56:49.888] iteration 3310 : loss : 0.197884, loss_ce: 0.008939
[17:56:56.292] iteration 3320 : loss : 0.227841, loss_ce: 0.010338
[17:57:02.708] iteration 3330 : loss : 0.202409, loss_ce: 0.009409
[17:57:09.117] iteration 3340 : loss : 0.156638, loss_ce: 0.009197
[17:57:15.537] iteration 3350 : loss : 0.076631, loss_ce: 0.020635
[17:57:21.941] iteration 3360 : loss : 0.209672, loss_ce: 0.007728
[17:57:28.364] iteration 3370 : loss : 0.243631, loss_ce: 0.007160
[17:57:34.773] iteration 3380 : loss : 0.180180, loss_ce: 0.007325
[17:57:41.193] iteration 3390 : loss : 0.178358, loss_ce: 0.008656
[17:57:45.295] Epoch 5: Average loss: 0.2271
[18:03:34.461] iteration 3400 : loss : 0.210064, loss_ce: 0.008106
[18:03:40.825] iteration 3410 : loss : 0.231110, loss_ce: 0.007610
[18:03:47.183] iteration 3420 : loss : 0.232567, loss_ce: 0.016964
[18:03:53.550] iteration 3430 : loss : 0.249852, loss_ce: 0.017363
[18:03:59.908] iteration 3440 : loss : 0.200698, loss_ce: 0.011290
[18:04:06.285] iteration 3450 : loss : 0.320411, loss_ce: 0.005061
[18:04:12.647] iteration 3460 : loss : 0.156201, loss_ce: 0.004710
[18:04:19.018] iteration 3470 : loss : 0.208716, loss_ce: 0.014260
[18:04:25.385] iteration 3480 : loss : 0.239988, loss_ce: 0.013779
[18:04:31.770] iteration 3490 : loss : 0.212066, loss_ce: 0.009220
[18:04:38.139] iteration 3500 : loss : 0.201061, loss_ce: 0.005400
[18:04:44.524] iteration 3510 : loss : 0.208951, loss_ce: 0.007085
[18:04:50.897] iteration 3520 : loss : 0.203591, loss_ce: 0.007035
[18:04:57.283] iteration 3530 : loss : 0.227830, loss_ce: 0.016241
[18:05:03.656] iteration 3540 : loss : 0.321992, loss_ce: 0.006295
[18:05:10.043] iteration 3550 : loss : 0.226011, loss_ce: 0.016674
[18:05:16.421] iteration 3560 : loss : 0.230856, loss_ce: 0.011700
[18:05:22.813] iteration 3570 : loss : 0.256299, loss_ce: 0.016571
[18:05:29.198] iteration 3580 : loss : 0.249474, loss_ce: 0.008194
[18:05:35.594] iteration 3590 : loss : 0.258977, loss_ce: 0.007061
[18:05:41.979] iteration 3600 : loss : 0.299731, loss_ce: 0.006912
[18:05:48.374] iteration 3610 : loss : 0.215594, loss_ce: 0.013688
[18:05:54.759] iteration 3620 : loss : 0.215314, loss_ce: 0.009699
[18:06:01.151] iteration 3630 : loss : 0.300321, loss_ce: 0.012306
[18:06:07.537] iteration 3640 : loss : 0.204965, loss_ce: 0.007756
[18:06:13.934] iteration 3650 : loss : 0.225235, loss_ce: 0.007790
[18:06:20.324] iteration 3660 : loss : 0.247826, loss_ce: 0.015683
[18:06:26.720] iteration 3670 : loss : 0.213112, loss_ce: 0.011004
[18:06:33.110] iteration 3680 : loss : 0.209956, loss_ce: 0.015508
[18:06:39.511] iteration 3690 : loss : 0.278605, loss_ce: 0.012194
[18:06:45.901] iteration 3700 : loss : 0.229479, loss_ce: 0.007336
[18:06:52.304] iteration 3710 : loss : 0.324591, loss_ce: 0.009148
[18:06:58.694] iteration 3720 : loss : 0.290856, loss_ce: 0.007239
[18:07:05.097] iteration 3730 : loss : 0.240438, loss_ce: 0.010327
[18:07:11.496] iteration 3740 : loss : 0.239346, loss_ce: 0.011767
[18:07:17.900] iteration 3750 : loss : 0.220275, loss_ce: 0.009263
[18:07:24.293] iteration 3760 : loss : 0.296133, loss_ce: 0.010471
[18:07:30.695] iteration 3770 : loss : 0.191783, loss_ce: 0.004605
[18:07:37.088] iteration 3780 : loss : 0.189951, loss_ce: 0.009590
[18:07:43.496] iteration 3790 : loss : 0.241779, loss_ce: 0.008637
[18:07:49.891] iteration 3800 : loss : 0.229530, loss_ce: 0.017938
[18:07:56.302] iteration 3810 : loss : 0.216867, loss_ce: 0.016680
[18:08:02.702] iteration 3820 : loss : 0.190594, loss_ce: 0.010665
[18:08:09.112] iteration 3830 : loss : 0.204742, loss_ce: 0.012481
[18:08:15.507] iteration 3840 : loss : 0.211626, loss_ce: 0.010330
[18:08:21.914] iteration 3850 : loss : 0.217625, loss_ce: 0.006237
[18:08:28.303] iteration 3860 : loss : 0.184052, loss_ce: 0.007021
[18:08:34.716] iteration 3870 : loss : 0.208659, loss_ce: 0.018437
[18:08:41.112] iteration 3880 : loss : 0.214720, loss_ce: 0.011663
[18:08:47.520] iteration 3890 : loss : 0.192889, loss_ce: 0.008023
[18:08:53.917] iteration 3900 : loss : 0.200999, loss_ce: 0.008502
[18:09:00.333] iteration 3910 : loss : 0.208426, loss_ce: 0.009602
[18:09:06.736] iteration 3920 : loss : 0.270238, loss_ce: 0.008474
[18:09:13.144] iteration 3930 : loss : 0.076506, loss_ce: 0.009882
[18:09:19.548] iteration 3940 : loss : 0.218698, loss_ce: 0.004265
[18:09:25.960] iteration 3950 : loss : 0.212303, loss_ce: 0.009384
[18:09:32.358] iteration 3960 : loss : 0.259498, loss_ce: 0.006363
[18:09:33.846] Epoch 6: Average loss: 0.2230
[18:09:49.726] iteration 3970 : loss : 0.184277, loss_ce: 0.008868
[18:09:56.104] iteration 3980 : loss : 0.101169, loss_ce: 0.011304
[18:10:02.489] iteration 3990 : loss : 0.115298, loss_ce: 0.007081
[18:10:08.864] iteration 4000 : loss : 0.258341, loss_ce: 0.008529
[18:10:15.253] iteration 4010 : loss : 0.185970, loss_ce: 0.005144
[18:10:21.631] iteration 4020 : loss : 0.275516, loss_ce: 0.012517
[18:10:28.026] iteration 4030 : loss : 0.189959, loss_ce: 0.008637
[18:10:34.406] iteration 4040 : loss : 0.244063, loss_ce: 0.022380
[18:10:40.794] iteration 4050 : loss : 0.262304, loss_ce: 0.012663
[18:10:47.178] iteration 4060 : loss : 0.214532, loss_ce: 0.007803
[18:10:53.571] iteration 4070 : loss : 0.297385, loss_ce: 0.014283
[18:10:59.956] iteration 4080 : loss : 0.216459, loss_ce: 0.009593
[18:11:06.348] iteration 4090 : loss : 0.232477, loss_ce: 0.014323
[18:11:12.733] iteration 4100 : loss : 0.226469, loss_ce: 0.009034
[18:11:19.128] iteration 4110 : loss : 0.226800, loss_ce: 0.015244
[18:11:25.514] iteration 4120 : loss : 0.197986, loss_ce: 0.009117
[18:11:31.910] iteration 4130 : loss : 0.203283, loss_ce: 0.009184
[18:11:38.297] iteration 4140 : loss : 0.092016, loss_ce: 0.003363
[18:11:44.697] iteration 4150 : loss : 0.271670, loss_ce: 0.018300
[18:11:51.087] iteration 4160 : loss : 0.268563, loss_ce: 0.010591
[18:11:57.481] iteration 4170 : loss : 0.268496, loss_ce: 0.007864
[18:12:03.868] iteration 4180 : loss : 0.255795, loss_ce: 0.009480
[18:12:10.266] iteration 4190 : loss : 0.204798, loss_ce: 0.005671
[18:12:16.655] iteration 4200 : loss : 0.217825, loss_ce: 0.013174
[18:12:23.058] iteration 4210 : loss : 0.227305, loss_ce: 0.010657
[18:12:29.446] iteration 4220 : loss : 0.238769, loss_ce: 0.020730
[18:12:35.847] iteration 4230 : loss : 0.201941, loss_ce: 0.009101
[18:12:42.234] iteration 4240 : loss : 0.215146, loss_ce: 0.007898
[18:12:48.638] iteration 4250 : loss : 0.215291, loss_ce: 0.010486
[18:12:55.028] iteration 4260 : loss : 0.235215, loss_ce: 0.013692
[18:13:01.436] iteration 4270 : loss : 0.263759, loss_ce: 0.011284
[18:13:07.830] iteration 4280 : loss : 0.284802, loss_ce: 0.008077
[18:13:14.233] iteration 4290 : loss : 0.065006, loss_ce: 0.013683
[18:13:20.624] iteration 4300 : loss : 0.191425, loss_ce: 0.007188
[18:13:27.024] iteration 4310 : loss : 0.179079, loss_ce: 0.006643
[18:13:33.420] iteration 4320 : loss : 0.210814, loss_ce: 0.005471
[18:13:39.820] iteration 4330 : loss : 0.126386, loss_ce: 0.003809
[18:13:46.209] iteration 4340 : loss : 0.216422, loss_ce: 0.016271
[18:13:52.612] iteration 4350 : loss : 0.242043, loss_ce: 0.007302
[18:13:59.008] iteration 4360 : loss : 0.239573, loss_ce: 0.008140
[18:14:05.413] iteration 4370 : loss : 0.303438, loss_ce: 0.016965
[18:14:11.809] iteration 4380 : loss : 0.046865, loss_ce: 0.006386
[18:14:18.209] iteration 4390 : loss : 0.331122, loss_ce: 0.028577
[18:14:24.611] iteration 4400 : loss : 0.117403, loss_ce: 0.009923
[18:14:31.018] iteration 4410 : loss : 0.053598, loss_ce: 0.006607
[18:14:37.420] iteration 4420 : loss : 0.205673, loss_ce: 0.011667
[18:14:43.826] iteration 4430 : loss : 0.183249, loss_ce: 0.007823
[18:14:50.225] iteration 4440 : loss : 0.208484, loss_ce: 0.010932
[18:14:56.634] iteration 4450 : loss : 0.229748, loss_ce: 0.013916
[18:15:03.035] iteration 4460 : loss : 0.196725, loss_ce: 0.006939
[18:15:09.450] iteration 4470 : loss : 0.155202, loss_ce: 0.002441
[18:15:15.850] iteration 4480 : loss : 0.222330, loss_ce: 0.014443
[18:15:22.257] iteration 4490 : loss : 0.231019, loss_ce: 0.013956
[18:15:28.664] iteration 4500 : loss : 0.198083, loss_ce: 0.009867
[18:15:35.082] iteration 4510 : loss : 0.324886, loss_ce: 0.008785
[18:15:41.482] iteration 4520 : loss : 0.266590, loss_ce: 0.013661
[18:15:46.825] Epoch 7: Average loss: 0.2178
[18:15:58.393] iteration 4530 : loss : 0.247595, loss_ce: 0.017819
[18:16:04.767] iteration 4540 : loss : 0.149433, loss_ce: 0.014485
[18:16:11.154] iteration 4550 : loss : 0.270770, loss_ce: 0.025990
[18:16:17.529] iteration 4560 : loss : 0.224246, loss_ce: 0.027793
[18:16:23.917] iteration 4570 : loss : 0.223785, loss_ce: 0.011399
[18:16:30.298] iteration 4580 : loss : 0.311025, loss_ce: 0.016317
[18:16:36.690] iteration 4590 : loss : 0.250631, loss_ce: 0.008074
[18:16:43.076] iteration 4600 : loss : 0.206838, loss_ce: 0.012409
[18:16:49.473] iteration 4610 : loss : 0.277774, loss_ce: 0.010868
[18:16:55.862] iteration 4620 : loss : 0.401570, loss_ce: 0.053491
[18:17:02.261] iteration 4630 : loss : 0.404457, loss_ce: 0.020156
[18:17:08.649] iteration 4640 : loss : 0.365779, loss_ce: 0.028489
[18:17:15.053] iteration 4650 : loss : 0.414626, loss_ce: 0.053524
[18:17:21.449] iteration 4660 : loss : 0.523720, loss_ce: 0.181491
[18:17:27.855] iteration 4670 : loss : 0.472311, loss_ce: 0.061586
[18:17:34.252] iteration 4680 : loss : 0.453304, loss_ce: 0.062700
[18:17:40.656] iteration 4690 : loss : 0.455802, loss_ce: 0.071454
[18:17:47.051] iteration 4700 : loss : 0.446038, loss_ce: 0.065674
[18:17:53.459] iteration 4710 : loss : 0.453749, loss_ce: 0.061973
[18:17:59.856] iteration 4720 : loss : 0.462358, loss_ce: 0.031307
[18:18:06.263] iteration 4730 : loss : 0.468233, loss_ce: 0.049095
[18:18:12.661] iteration 4740 : loss : 0.467696, loss_ce: 0.072109
[18:18:19.072] iteration 4750 : loss : 0.454320, loss_ce: 0.059904
[18:18:25.474] iteration 4760 : loss : 0.435038, loss_ce: 0.070613
[18:18:31.886] iteration 4770 : loss : 0.441014, loss_ce: 0.048075
[18:18:38.297] iteration 4780 : loss : 0.437344, loss_ce: 0.056779
[18:18:44.711] iteration 4790 : loss : 0.441137, loss_ce: 0.091368
[18:18:51.109] iteration 4800 : loss : 0.447867, loss_ce: 0.065785
[18:18:57.523] iteration 4810 : loss : 0.446802, loss_ce: 0.078744
[18:19:03.927] iteration 4820 : loss : 0.445768, loss_ce: 0.063577
[18:19:10.339] iteration 4830 : loss : 0.292343, loss_ce: 0.040574
[18:19:16.741] iteration 4840 : loss : 0.448612, loss_ce: 0.052194
[18:19:23.164] iteration 4850 : loss : 0.446561, loss_ce: 0.042760
[18:19:29.575] iteration 4860 : loss : 0.444539, loss_ce: 0.067582
[18:19:35.994] iteration 4870 : loss : 0.436224, loss_ce: 0.052449
[18:19:42.407] iteration 4880 : loss : 0.454569, loss_ce: 0.069855
[18:19:48.816] iteration 4890 : loss : 0.431751, loss_ce: 0.066205
[18:19:55.226] iteration 4900 : loss : 0.439563, loss_ce: 0.055911
[18:20:01.640] iteration 4910 : loss : 0.433656, loss_ce: 0.081514
[18:20:08.055] iteration 4920 : loss : 0.440337, loss_ce: 0.068376
[18:20:14.469] iteration 4930 : loss : 0.442589, loss_ce: 0.049180
[18:20:20.875] iteration 4940 : loss : 0.442439, loss_ce: 0.052248
[18:20:27.294] iteration 4950 : loss : 0.444427, loss_ce: 0.073884
[18:20:33.707] iteration 4960 : loss : 0.438382, loss_ce: 0.054724
[18:20:40.131] iteration 4970 : loss : 0.435165, loss_ce: 0.070972
[18:20:46.539] iteration 4980 : loss : 0.441423, loss_ce: 0.051590
[18:20:52.960] iteration 4990 : loss : 0.437150, loss_ce: 0.055242
[18:20:59.370] iteration 5000 : loss : 0.430096, loss_ce: 0.050936
[18:21:05.782] iteration 5010 : loss : 0.447440, loss_ce: 0.058321
[18:21:12.191] iteration 5020 : loss : 0.442315, loss_ce: 0.074578
[18:21:18.609] iteration 5030 : loss : 0.474259, loss_ce: 0.060969
[18:21:25.016] iteration 5040 : loss : 0.468350, loss_ce: 0.078095
[18:21:31.434] iteration 5050 : loss : 0.470672, loss_ce: 0.063321
[18:21:37.836] iteration 5060 : loss : 0.470387, loss_ce: 0.074760
[18:21:44.259] iteration 5070 : loss : 0.466467, loss_ce: 0.067476
[18:21:50.667] iteration 5080 : loss : 0.467850, loss_ce: 0.066088
[18:21:57.088] iteration 5090 : loss : 0.461887, loss_ce: 0.059772
[18:21:59.866] Epoch 8: Average loss: 0.4073
[18:27:35.102] iteration 5100 : loss : 0.313019, loss_ce: 0.057091
[18:27:41.462] iteration 5110 : loss : 0.466485, loss_ce: 0.064766
[18:27:47.816] iteration 5120 : loss : 0.463623, loss_ce: 0.073604
[18:27:54.179] iteration 5130 : loss : 0.470813, loss_ce: 0.078658
[18:28:00.532] iteration 5140 : loss : 0.463233, loss_ce: 0.071765
[18:28:06.896] iteration 5150 : loss : 0.467003, loss_ce: 0.073793
[18:28:13.255] iteration 5160 : loss : 0.466368, loss_ce: 0.082597
[18:28:19.628] iteration 5170 : loss : 0.313585, loss_ce: 0.053289
[18:28:25.989] iteration 5180 : loss : 0.464120, loss_ce: 0.066116
[18:28:32.361] iteration 5190 : loss : 0.312793, loss_ce: 0.067968
[18:28:38.722] iteration 5200 : loss : 0.471499, loss_ce: 0.081493
[18:28:45.099] iteration 5210 : loss : 0.462888, loss_ce: 0.050162
[18:28:51.469] iteration 5220 : loss : 0.461629, loss_ce: 0.051757
[18:28:57.851] iteration 5230 : loss : 0.303278, loss_ce: 0.056114
[18:29:04.222] iteration 5240 : loss : 0.309116, loss_ce: 0.044595
[18:29:10.604] iteration 5250 : loss : 0.462399, loss_ce: 0.065968
[18:29:16.977] iteration 5260 : loss : 0.458283, loss_ce: 0.065770
[18:29:23.362] iteration 5270 : loss : 0.310728, loss_ce: 0.077257
[18:29:29.736] iteration 5280 : loss : 0.453501, loss_ce: 0.062988
[18:29:36.125] iteration 5290 : loss : 0.306322, loss_ce: 0.056941
[18:29:42.501] iteration 5300 : loss : 0.457003, loss_ce: 0.069048
[18:29:48.890] iteration 5310 : loss : 0.297533, loss_ce: 0.045382
[18:29:55.270] iteration 5320 : loss : 0.446667, loss_ce: 0.044251
[18:30:01.659] iteration 5330 : loss : 0.464264, loss_ce: 0.079354
[18:30:08.043] iteration 5340 : loss : 0.452759, loss_ce: 0.078413
[18:30:14.433] iteration 5350 : loss : 0.450998, loss_ce: 0.061629
[18:30:20.815] iteration 5360 : loss : 0.451246, loss_ce: 0.036511
[18:30:27.209] iteration 5370 : loss : 0.464846, loss_ce: 0.093499
[18:30:33.595] iteration 5380 : loss : 0.446497, loss_ce: 0.053152
[18:30:39.995] iteration 5390 : loss : 0.460399, loss_ce: 0.103112
[18:30:46.384] iteration 5400 : loss : 0.450428, loss_ce: 0.044816
[18:30:52.780] iteration 5410 : loss : 0.459951, loss_ce: 0.087230
[18:30:59.172] iteration 5420 : loss : 0.453818, loss_ce: 0.068814
[18:31:05.579] iteration 5430 : loss : 0.455244, loss_ce: 0.057541
[18:31:11.977] iteration 5440 : loss : 0.450334, loss_ce: 0.067713
[18:31:18.377] iteration 5450 : loss : 0.451995, loss_ce: 0.072982
[18:31:24.774] iteration 5460 : loss : 0.451700, loss_ce: 0.075233
[18:31:31.178] iteration 5470 : loss : 0.497851, loss_ce: 0.171413
[18:31:37.570] iteration 5480 : loss : 0.454581, loss_ce: 0.052371
[18:31:43.975] iteration 5490 : loss : 0.448033, loss_ce: 0.110869
[18:31:50.370] iteration 5500 : loss : 0.436744, loss_ce: 0.049135
[18:31:56.775] iteration 5510 : loss : 0.455551, loss_ce: 0.069768
[18:32:03.170] iteration 5520 : loss : 0.443527, loss_ce: 0.087767
[18:32:09.577] iteration 5530 : loss : 0.448797, loss_ce: 0.079016
[18:32:15.978] iteration 5540 : loss : 0.440882, loss_ce: 0.079347
[18:32:22.385] iteration 5550 : loss : 0.475015, loss_ce: 0.083361
[18:32:28.780] iteration 5560 : loss : 0.442958, loss_ce: 0.048999
[18:32:35.190] iteration 5570 : loss : 0.436371, loss_ce: 0.034365
[18:32:41.596] iteration 5580 : loss : 0.440485, loss_ce: 0.074411
[18:32:48.006] iteration 5590 : loss : 0.436405, loss_ce: 0.069005
[18:32:54.404] iteration 5600 : loss : 0.445823, loss_ce: 0.063005
[18:33:00.823] iteration 5610 : loss : 0.440335, loss_ce: 0.077124
[18:33:07.228] iteration 5620 : loss : 0.281161, loss_ce: 0.049590
[18:33:13.641] iteration 5630 : loss : 0.279262, loss_ce: 0.049346
[18:33:20.044] iteration 5640 : loss : 0.434838, loss_ce: 0.054335
[18:33:26.456] iteration 5650 : loss : 0.442152, loss_ce: 0.081685
[18:33:32.433] iteration 5660 : loss : 0.280825, loss_ce: 0.047893
[18:33:33.078] Epoch 9: Average loss: 0.4407
[18:33:33.184] save model to ./finetune_tpgm_kits23_continual_fixed\finetuned_epoch_9.pth
[18:33:49.978] iteration 5670 : loss : 0.425994, loss_ce: 0.064514
[18:33:56.354] iteration 5680 : loss : 0.429993, loss_ce: 0.043754
[18:34:02.742] iteration 5690 : loss : 0.425374, loss_ce: 0.053013
[18:34:09.124] iteration 5700 : loss : 0.419073, loss_ce: 0.045669
[18:34:15.513] iteration 5710 : loss : 0.401890, loss_ce: 0.042274
[18:34:21.894] iteration 5720 : loss : 0.419865, loss_ce: 0.029276
[18:34:28.287] iteration 5730 : loss : 0.447322, loss_ce: 0.065323
[18:34:34.674] iteration 5740 : loss : 0.447280, loss_ce: 0.052994
[18:34:41.072] iteration 5750 : loss : 0.450250, loss_ce: 0.087690
[18:34:47.454] iteration 5760 : loss : 0.447351, loss_ce: 0.052175
[18:34:53.852] iteration 5770 : loss : 0.453047, loss_ce: 0.051959
[18:35:00.241] iteration 5780 : loss : 0.428447, loss_ce: 0.061471
[18:35:06.641] iteration 5790 : loss : 0.441220, loss_ce: 0.067197
[18:35:13.029] iteration 5800 : loss : 0.459511, loss_ce: 0.072911
[18:35:19.426] iteration 5810 : loss : 0.463986, loss_ce: 0.083890
[18:35:25.818] iteration 5820 : loss : 0.460409, loss_ce: 0.051124
[18:35:32.220] iteration 5830 : loss : 0.460904, loss_ce: 0.061965
[18:35:38.610] iteration 5840 : loss : 0.470617, loss_ce: 0.080389
[18:35:45.010] iteration 5850 : loss : 0.463810, loss_ce: 0.069055
[18:35:51.408] iteration 5860 : loss : 0.460448, loss_ce: 0.056735
[18:35:57.819] iteration 5870 : loss : 0.462846, loss_ce: 0.068160
[18:36:04.213] iteration 5880 : loss : 0.469660, loss_ce: 0.094059
[18:36:10.617] iteration 5890 : loss : 0.306731, loss_ce: 0.047420
[18:36:17.015] iteration 5900 : loss : 0.457750, loss_ce: 0.053057
[18:36:23.429] iteration 5910 : loss : 0.462070, loss_ce: 0.079264
[18:36:29.830] iteration 5920 : loss : 0.464824, loss_ce: 0.045974
[18:36:36.245] iteration 5930 : loss : 0.479681, loss_ce: 0.122310
[18:36:42.646] iteration 5940 : loss : 0.466305, loss_ce: 0.068243
[18:36:49.058] iteration 5950 : loss : 0.462505, loss_ce: 0.070997
[18:36:55.461] iteration 5960 : loss : 0.460342, loss_ce: 0.064393
[18:37:01.875] iteration 5970 : loss : 0.459345, loss_ce: 0.075996
[18:37:08.283] iteration 5980 : loss : 0.451455, loss_ce: 0.057972
[18:37:14.708] iteration 5990 : loss : 0.455804, loss_ce: 0.057405
[18:37:21.110] iteration 6000 : loss : 0.463426, loss_ce: 0.087784
[18:37:27.521] iteration 6010 : loss : 0.461428, loss_ce: 0.064378
[18:37:33.930] iteration 6020 : loss : 0.457948, loss_ce: 0.065609
[18:37:40.346] iteration 6030 : loss : 0.461287, loss_ce: 0.052582
[18:37:46.751] iteration 6040 : loss : 0.454323, loss_ce: 0.066117
[18:37:53.161] iteration 6050 : loss : 0.466216, loss_ce: 0.082814
[18:37:59.567] iteration 6060 : loss : 0.448897, loss_ce: 0.050807
[18:38:05.978] iteration 6070 : loss : 0.458516, loss_ce: 0.080241
[18:38:12.387] iteration 6080 : loss : 0.454830, loss_ce: 0.057526
[18:38:18.806] iteration 6090 : loss : 0.449431, loss_ce: 0.057268
[18:38:25.212] iteration 6100 : loss : 0.456641, loss_ce: 0.070167
[18:38:31.630] iteration 6110 : loss : 0.454277, loss_ce: 0.063338
[18:38:38.041] iteration 6120 : loss : 0.456855, loss_ce: 0.071755
[18:38:44.457] iteration 6130 : loss : 0.305798, loss_ce: 0.039615
[18:38:50.870] iteration 6140 : loss : 0.461255, loss_ce: 0.065031
[18:38:57.296] iteration 6150 : loss : 0.462380, loss_ce: 0.085278
[18:39:03.698] iteration 6160 : loss : 0.451348, loss_ce: 0.059534
[18:39:10.122] iteration 6170 : loss : 0.290884, loss_ce: 0.053283
[18:39:16.539] iteration 6180 : loss : 0.447114, loss_ce: 0.061471
[18:39:22.954] iteration 6190 : loss : 0.443710, loss_ce: 0.043954
[18:39:29.366] iteration 6200 : loss : 0.444878, loss_ce: 0.062963
[18:39:35.793] iteration 6210 : loss : 0.444266, loss_ce: 0.079996
[18:39:42.199] iteration 6220 : loss : 0.442493, loss_ce: 0.047821
[18:39:46.259] Epoch 10: Average loss: 0.4391
[18:39:59.006] iteration 6230 : loss : 0.450151, loss_ce: 0.070997
[18:40:05.380] iteration 6240 : loss : 0.445478, loss_ce: 0.045781
[18:40:11.769] iteration 6250 : loss : 0.448881, loss_ce: 0.046370
[18:40:18.145] iteration 6260 : loss : 0.442777, loss_ce: 0.082790
[18:40:24.537] iteration 6270 : loss : 0.285692, loss_ce: 0.037006
[18:40:30.921] iteration 6280 : loss : 0.447255, loss_ce: 0.066901
[18:40:37.317] iteration 6290 : loss : 0.438565, loss_ce: 0.077643
[18:40:43.706] iteration 6300 : loss : 0.447231, loss_ce: 0.061348
[18:40:50.100] iteration 6310 : loss : 0.433003, loss_ce: 0.058987
[18:40:56.490] iteration 6320 : loss : 0.434256, loss_ce: 0.049873
[18:41:02.892] iteration 6330 : loss : 0.431999, loss_ce: 0.044697
[18:41:09.289] iteration 6340 : loss : 0.426682, loss_ce: 0.062973
[18:41:15.695] iteration 6350 : loss : 0.289333, loss_ce: 0.052948
[18:41:22.092] iteration 6360 : loss : 0.452037, loss_ce: 0.079173
[18:41:28.501] iteration 6370 : loss : 0.441523, loss_ce: 0.075083
[18:41:34.901] iteration 6380 : loss : 0.445561, loss_ce: 0.055499
[18:41:41.304] iteration 6390 : loss : 0.440714, loss_ce: 0.051578
[18:41:47.706] iteration 6400 : loss : 0.446243, loss_ce: 0.058358
[18:41:54.117] iteration 6410 : loss : 0.436555, loss_ce: 0.085099
[18:42:00.529] iteration 6420 : loss : 0.426659, loss_ce: 0.041051
[18:42:06.944] iteration 6430 : loss : 0.423672, loss_ce: 0.043949
[18:42:13.344] iteration 6440 : loss : 0.456365, loss_ce: 0.054339
[18:42:19.762] iteration 6450 : loss : 0.294300, loss_ce: 0.073431
[18:42:26.162] iteration 6460 : loss : 0.424124, loss_ce: 0.061428
[18:42:32.580] iteration 6470 : loss : 0.422594, loss_ce: 0.090873
[18:42:38.986] iteration 6480 : loss : 0.433748, loss_ce: 0.051602
[18:42:45.399] iteration 6490 : loss : 0.436286, loss_ce: 0.052175
[18:42:51.810] iteration 6500 : loss : 0.410009, loss_ce: 0.048055
[18:42:58.229] iteration 6510 : loss : 0.415767, loss_ce: 0.053482
[18:43:04.635] iteration 6520 : loss : 0.423492, loss_ce: 0.039255
[18:43:11.056] iteration 6530 : loss : 0.434126, loss_ce: 0.044652
[18:43:17.468] iteration 6540 : loss : 0.294254, loss_ce: 0.059536
[18:43:23.889] iteration 6550 : loss : 0.454736, loss_ce: 0.067562
[18:43:30.299] iteration 6560 : loss : 0.428051, loss_ce: 0.046261
[18:43:36.728] iteration 6570 : loss : 0.424077, loss_ce: 0.057057
[18:43:43.135] iteration 6580 : loss : 0.424173, loss_ce: 0.048029
[18:43:49.550] iteration 6590 : loss : 0.270360, loss_ce: 0.050944
[18:43:55.968] iteration 6600 : loss : 0.434435, loss_ce: 0.072671
[18:44:02.393] iteration 6610 : loss : 0.422647, loss_ce: 0.055678
[18:44:08.808] iteration 6620 : loss : 0.437299, loss_ce: 0.027302
[18:44:15.224] iteration 6630 : loss : 0.446023, loss_ce: 0.053538
[18:44:21.630] iteration 6640 : loss : 0.440768, loss_ce: 0.082776
[18:44:28.049] iteration 6650 : loss : 0.433536, loss_ce: 0.050918
[18:44:34.461] iteration 6660 : loss : 0.446796, loss_ce: 0.055234
[18:44:40.882] iteration 6670 : loss : 0.423435, loss_ce: 0.056218
[18:44:47.301] iteration 6680 : loss : 0.456481, loss_ce: 0.057736
[18:44:53.720] iteration 6690 : loss : 0.458395, loss_ce: 0.055849
[18:45:00.125] iteration 6700 : loss : 0.458901, loss_ce: 0.058494
[18:45:06.547] iteration 6710 : loss : 0.456403, loss_ce: 0.042086
[18:45:12.952] iteration 6720 : loss : 0.475050, loss_ce: 0.100466
[18:45:19.370] iteration 6730 : loss : 0.449653, loss_ce: 0.051506
[18:45:25.780] iteration 6740 : loss : 0.425769, loss_ce: 0.038953
[18:45:32.205] iteration 6750 : loss : 0.459125, loss_ce: 0.088260
[18:45:38.626] iteration 6760 : loss : 0.459607, loss_ce: 0.076628
[18:45:45.053] iteration 6770 : loss : 0.458723, loss_ce: 0.044476
[18:45:51.462] iteration 6780 : loss : 0.446304, loss_ce: 0.065114
[18:45:57.895] iteration 6790 : loss : 0.448396, loss_ce: 0.055883
[18:45:59.378] Epoch 11: Average loss: 0.4269
[18:51:37.747] iteration 6800 : loss : 0.441719, loss_ce: 0.070898
[18:51:44.107] iteration 6810 : loss : 0.301676, loss_ce: 0.091373
[18:51:50.459] iteration 6820 : loss : 0.451690, loss_ce: 0.076706
[18:51:56.824] iteration 6830 : loss : 0.463425, loss_ce: 0.073254
[18:52:03.184] iteration 6840 : loss : 0.443120, loss_ce: 0.044699
[18:52:09.554] iteration 6850 : loss : 0.443848, loss_ce: 0.060044
[18:52:15.914] iteration 6860 : loss : 0.306033, loss_ce: 0.055737
[18:52:22.291] iteration 6870 : loss : 0.439477, loss_ce: 0.058560
[18:52:28.653] iteration 6880 : loss : 0.438432, loss_ce: 0.065351
[18:52:35.031] iteration 6890 : loss : 0.471746, loss_ce: 0.061811
[18:52:41.401] iteration 6900 : loss : 0.461108, loss_ce: 0.061291
[18:52:47.781] iteration 6910 : loss : 0.455866, loss_ce: 0.059175
[18:52:54.152] iteration 6920 : loss : 0.459407, loss_ce: 0.080479
[18:53:00.537] iteration 6930 : loss : 0.296869, loss_ce: 0.068101
[18:53:06.912] iteration 6940 : loss : 0.296972, loss_ce: 0.058982
[18:53:13.304] iteration 6950 : loss : 0.441729, loss_ce: 0.070165
[18:53:19.686] iteration 6960 : loss : 0.451101, loss_ce: 0.070792
[18:53:26.081] iteration 6970 : loss : 0.444177, loss_ce: 0.093790
[18:53:32.463] iteration 6980 : loss : 0.448484, loss_ce: 0.067070
[18:53:38.857] iteration 6990 : loss : 0.442326, loss_ce: 0.047820
[18:53:45.243] iteration 7000 : loss : 0.442776, loss_ce: 0.072804
[18:53:51.640] iteration 7010 : loss : 0.442246, loss_ce: 0.067304
[18:53:58.029] iteration 7020 : loss : 0.441136, loss_ce: 0.060584
[18:54:04.440] iteration 7030 : loss : 0.282494, loss_ce: 0.053941
[18:54:10.867] iteration 7040 : loss : 0.434148, loss_ce: 0.069081
[18:54:17.264] iteration 7050 : loss : 0.431684, loss_ce: 0.057684
[18:54:23.650] iteration 7060 : loss : 0.437823, loss_ce: 0.072983
[18:54:30.055] iteration 7070 : loss : 0.435264, loss_ce: 0.058944
[18:54:36.445] iteration 7080 : loss : 0.437686, loss_ce: 0.058890
[18:54:42.845] iteration 7090 : loss : 0.431502, loss_ce: 0.057385
[18:54:49.242] iteration 7100 : loss : 0.435574, loss_ce: 0.065599
[18:54:55.650] iteration 7110 : loss : 0.418210, loss_ce: 0.062010
[18:55:02.042] iteration 7120 : loss : 0.275033, loss_ce: 0.057477
[18:55:08.448] iteration 7130 : loss : 0.427194, loss_ce: 0.078062
[18:55:14.841] iteration 7140 : loss : 0.436424, loss_ce: 0.056345
[18:55:21.247] iteration 7150 : loss : 0.427377, loss_ce: 0.053118
[18:55:27.640] iteration 7160 : loss : 0.280231, loss_ce: 0.030778
[18:55:34.053] iteration 7170 : loss : 0.454552, loss_ce: 0.043108
[18:55:40.453] iteration 7180 : loss : 0.451357, loss_ce: 0.050317
[18:55:46.855] iteration 7190 : loss : 0.277826, loss_ce: 0.076549
[18:55:53.255] iteration 7200 : loss : 0.426067, loss_ce: 0.051478
[18:55:59.667] iteration 7210 : loss : 0.427796, loss_ce: 0.063166
[18:56:06.063] iteration 7220 : loss : 0.424798, loss_ce: 0.053942
[18:56:12.478] iteration 7230 : loss : 0.437646, loss_ce: 0.039128
[18:56:18.875] iteration 7240 : loss : 0.434672, loss_ce: 0.035842
[18:56:25.292] iteration 7250 : loss : 0.427350, loss_ce: 0.045934
[18:56:31.695] iteration 7260 : loss : 0.288209, loss_ce: 0.050163
[18:56:38.109] iteration 7270 : loss : 0.431386, loss_ce: 0.066495
[18:56:44.518] iteration 7280 : loss : 0.405767, loss_ce: 0.046065
[18:56:50.932] iteration 7290 : loss : 0.430780, loss_ce: 0.040271
[18:56:57.339] iteration 7300 : loss : 0.279651, loss_ce: 0.069313
[18:57:03.755] iteration 7310 : loss : 0.423297, loss_ce: 0.057070
[18:57:10.158] iteration 7320 : loss : 0.424626, loss_ce: 0.059823
[18:57:16.580] iteration 7330 : loss : 0.428665, loss_ce: 0.050067
[18:57:22.993] iteration 7340 : loss : 0.442304, loss_ce: 0.044219
[18:57:29.410] iteration 7350 : loss : 0.423367, loss_ce: 0.031851
[18:57:34.745] Epoch 12: Average loss: 0.4258
[18:57:46.261] iteration 7360 : loss : 0.427536, loss_ce: 0.037027
[18:57:52.645] iteration 7370 : loss : 0.428743, loss_ce: 0.057352
[18:57:59.027] iteration 7380 : loss : 0.433669, loss_ce: 0.067349
[18:58:05.417] iteration 7390 : loss : 0.410468, loss_ce: 0.046209
[18:58:11.802] iteration 7400 : loss : 0.438232, loss_ce: 0.062956
[18:58:18.197] iteration 7410 : loss : 0.425021, loss_ce: 0.039606
[18:58:24.582] iteration 7420 : loss : 0.441845, loss_ce: 0.042618
[18:58:30.978] iteration 7430 : loss : 0.441271, loss_ce: 0.048151
[18:58:37.368] iteration 7440 : loss : 0.441178, loss_ce: 0.044014
[18:58:43.767] iteration 7450 : loss : 0.429959, loss_ce: 0.055899
[18:58:50.160] iteration 7460 : loss : 0.433534, loss_ce: 0.043816
[18:58:56.569] iteration 7470 : loss : 0.437909, loss_ce: 0.053769
[18:59:02.966] iteration 7480 : loss : 0.441724, loss_ce: 0.062189
[18:59:09.377] iteration 7490 : loss : 0.427373, loss_ce: 0.067083
[18:59:15.783] iteration 7500 : loss : 0.426817, loss_ce: 0.055078
[18:59:22.189] iteration 7510 : loss : 0.418401, loss_ce: 0.069083
[18:59:28.594] iteration 7520 : loss : 0.408121, loss_ce: 0.056723
[18:59:35.015] iteration 7530 : loss : 0.426353, loss_ce: 0.048478
[18:59:41.418] iteration 7540 : loss : 0.422378, loss_ce: 0.064371
[18:59:47.830] iteration 7550 : loss : 0.433318, loss_ce: 0.051569
[18:59:54.230] iteration 7560 : loss : 0.267059, loss_ce: 0.042790
[19:00:00.647] iteration 7570 : loss : 0.428918, loss_ce: 0.062021
[19:00:07.056] iteration 7580 : loss : 0.301834, loss_ce: 0.095784
[19:00:13.473] iteration 7590 : loss : 0.453246, loss_ce: 0.083308
[19:00:19.880] iteration 7600 : loss : 0.413671, loss_ce: 0.052061
[19:00:26.295] iteration 7610 : loss : 0.422975, loss_ce: 0.055404
[19:00:32.709] iteration 7620 : loss : 0.424039, loss_ce: 0.056654
[19:00:39.137] iteration 7630 : loss : 0.419045, loss_ce: 0.035712
[19:00:45.544] iteration 7640 : loss : 0.426118, loss_ce: 0.069282
[19:00:51.963] iteration 7650 : loss : 0.445416, loss_ce: 0.080156
[19:00:58.376] iteration 7660 : loss : 0.429430, loss_ce: 0.059364
[19:01:04.796] iteration 7670 : loss : 0.428635, loss_ce: 0.052956
[19:01:11.210] iteration 7680 : loss : 0.446018, loss_ce: 0.057301
[19:01:17.631] iteration 7690 : loss : 0.435057, loss_ce: 0.066268
[19:01:24.045] iteration 7700 : loss : 0.424114, loss_ce: 0.061248
[19:01:30.474] iteration 7710 : loss : 0.426781, loss_ce: 0.042606
[19:01:36.890] iteration 7720 : loss : 0.420367, loss_ce: 0.045662
[19:01:43.330] iteration 7730 : loss : 0.282676, loss_ce: 0.046384
[19:01:49.751] iteration 7740 : loss : 0.431992, loss_ce: 0.036151
[19:01:56.173] iteration 7750 : loss : 0.432539, loss_ce: 0.050414
[19:02:02.593] iteration 7760 : loss : 0.425735, loss_ce: 0.048794
[19:02:09.020] iteration 7770 : loss : 0.429794, loss_ce: 0.075269
[19:02:15.443] iteration 7780 : loss : 0.405351, loss_ce: 0.062415
[19:02:21.870] iteration 7790 : loss : 0.421515, loss_ce: 0.047828
[19:02:28.293] iteration 7800 : loss : 0.436447, loss_ce: 0.048287
[19:02:34.722] iteration 7810 : loss : 0.422769, loss_ce: 0.045158
[19:02:41.147] iteration 7820 : loss : 0.411929, loss_ce: 0.039143
[19:02:47.577] iteration 7830 : loss : 0.418336, loss_ce: 0.043215
[19:02:53.997] iteration 7840 : loss : 0.409946, loss_ce: 0.047066
[19:03:00.426] iteration 7850 : loss : 0.430951, loss_ce: 0.039612
[19:03:06.846] iteration 7860 : loss : 0.428573, loss_ce: 0.035426
[19:03:13.276] iteration 7870 : loss : 0.439080, loss_ce: 0.071152
[19:03:19.696] iteration 7880 : loss : 0.416245, loss_ce: 0.056532
[19:03:26.124] iteration 7890 : loss : 0.444328, loss_ce: 0.056553
[19:03:32.541] iteration 7900 : loss : 0.437325, loss_ce: 0.063273
[19:03:38.973] iteration 7910 : loss : 0.438969, loss_ce: 0.064643
[19:03:45.393] iteration 7920 : loss : 0.420266, loss_ce: 0.050485
[19:03:48.183] Epoch 13: Average loss: 0.4151
[19:04:02.654] iteration 7930 : loss : 0.413443, loss_ce: 0.051089
[19:04:09.033] iteration 7940 : loss : 0.438064, loss_ce: 0.050123
[19:04:15.427] iteration 7950 : loss : 0.412912, loss_ce: 0.055818
[19:04:21.811] iteration 7960 : loss : 0.430640, loss_ce: 0.052529
[19:04:28.209] iteration 7970 : loss : 0.433754, loss_ce: 0.041217
[19:04:34.595] iteration 7980 : loss : 0.414042, loss_ce: 0.060478
[19:04:41.000] iteration 7990 : loss : 0.417163, loss_ce: 0.046142
[19:04:47.398] iteration 8000 : loss : 0.406702, loss_ce: 0.055520
[19:04:53.805] iteration 8010 : loss : 0.421748, loss_ce: 0.058321
[19:05:00.200] iteration 8020 : loss : 0.282178, loss_ce: 0.049141
[19:05:06.611] iteration 8030 : loss : 0.414313, loss_ce: 0.048951
[19:05:13.008] iteration 8040 : loss : 0.413220, loss_ce: 0.039447
[19:05:19.418] iteration 8050 : loss : 0.267806, loss_ce: 0.059535
[19:05:25.827] iteration 8060 : loss : 0.416211, loss_ce: 0.056339
[19:05:32.249] iteration 8070 : loss : 0.416947, loss_ce: 0.053581
[19:05:38.660] iteration 8080 : loss : 0.423822, loss_ce: 0.060155
[19:05:45.078] iteration 8090 : loss : 0.417846, loss_ce: 0.059943
[19:05:51.484] iteration 8100 : loss : 0.419415, loss_ce: 0.074721
[19:05:57.906] iteration 8110 : loss : 0.404945, loss_ce: 0.050257
[19:06:04.322] iteration 8120 : loss : 0.395090, loss_ce: 0.070750
[19:06:10.741] iteration 8130 : loss : 0.459850, loss_ce: 0.047425
[19:06:17.158] iteration 8140 : loss : 0.419529, loss_ce: 0.046167
[19:06:23.581] iteration 8150 : loss : 0.424256, loss_ce: 0.053524
[19:06:29.987] iteration 8160 : loss : 0.403436, loss_ce: 0.048829
[19:06:36.418] iteration 8170 : loss : 0.414862, loss_ce: 0.046997
[19:06:42.830] iteration 8180 : loss : 0.417705, loss_ce: 0.062607
[19:06:49.256] iteration 8190 : loss : 0.422621, loss_ce: 0.049821
[19:06:55.669] iteration 8200 : loss : 0.422230, loss_ce: 0.055390
[19:07:02.092] iteration 8210 : loss : 0.405809, loss_ce: 0.055290
[19:07:08.506] iteration 8220 : loss : 0.427085, loss_ce: 0.041755
[19:07:14.930] iteration 8230 : loss : 0.403733, loss_ce: 0.046983
[19:07:21.342] iteration 8240 : loss : 0.397874, loss_ce: 0.042900
[19:07:27.773] iteration 8250 : loss : 0.438957, loss_ce: 0.042066
[19:07:34.191] iteration 8260 : loss : 0.413486, loss_ce: 0.075859
[19:07:40.617] iteration 8270 : loss : 0.425747, loss_ce: 0.043629
[19:07:47.026] iteration 8280 : loss : 0.403620, loss_ce: 0.042175
[19:07:53.448] iteration 8290 : loss : 0.420071, loss_ce: 0.055828
[19:07:59.868] iteration 8300 : loss : 0.409026, loss_ce: 0.042493
[19:08:06.295] iteration 8310 : loss : 0.279772, loss_ce: 0.037994
[19:08:12.714] iteration 8320 : loss : 0.406611, loss_ce: 0.052978
[19:08:19.143] iteration 8330 : loss : 0.401661, loss_ce: 0.051990
[19:08:25.560] iteration 8340 : loss : 0.409681, loss_ce: 0.037251
[19:08:31.984] iteration 8350 : loss : 0.389079, loss_ce: 0.053060
[19:08:38.404] iteration 8360 : loss : 0.272083, loss_ce: 0.037903
[19:08:44.837] iteration 8370 : loss : 0.415521, loss_ce: 0.042113
[19:08:51.258] iteration 8380 : loss : 0.255579, loss_ce: 0.057446
[19:08:57.685] iteration 8390 : loss : 0.431210, loss_ce: 0.047423
[19:09:04.097] iteration 8400 : loss : 0.424991, loss_ce: 0.048825
[19:09:10.529] iteration 8410 : loss : 0.406140, loss_ce: 0.044335
[19:09:16.943] iteration 8420 : loss : 0.417565, loss_ce: 0.037243
[19:09:23.377] iteration 8430 : loss : 0.414812, loss_ce: 0.053883
[19:09:29.798] iteration 8440 : loss : 0.414526, loss_ce: 0.049663
[19:09:36.221] iteration 8450 : loss : 0.395649, loss_ce: 0.058305
[19:09:42.634] iteration 8460 : loss : 0.431091, loss_ce: 0.031337
[19:09:49.055] iteration 8470 : loss : 0.421929, loss_ce: 0.042736
[19:09:55.473] iteration 8480 : loss : 0.423415, loss_ce: 0.052524
[19:10:01.480] iteration 8490 : loss : 0.257806, loss_ce: 0.015701
[19:10:02.122] Epoch 14: Average loss: 0.4044
[19:15:45.765] iteration 8500 : loss : 0.417873, loss_ce: 0.058342
[19:15:52.131] iteration 8510 : loss : 0.414305, loss_ce: 0.069964
[19:15:58.489] iteration 8520 : loss : 0.459410, loss_ce: 0.051568
[19:16:04.856] iteration 8530 : loss : 0.432027, loss_ce: 0.073470
[19:16:11.219] iteration 8540 : loss : 0.427551, loss_ce: 0.050235
[19:16:17.595] iteration 8550 : loss : 0.436346, loss_ce: 0.041498
[19:16:23.964] iteration 8560 : loss : 0.458968, loss_ce: 0.048370
[19:16:30.344] iteration 8570 : loss : 0.455777, loss_ce: 0.063224
[19:16:36.716] iteration 8580 : loss : 0.450262, loss_ce: 0.069741
[19:16:43.101] iteration 8590 : loss : 0.447215, loss_ce: 0.082150
[19:16:49.475] iteration 8600 : loss : 0.441496, loss_ce: 0.053640
[19:16:55.860] iteration 8610 : loss : 0.445287, loss_ce: 0.071407
[19:17:02.242] iteration 8620 : loss : 0.440550, loss_ce: 0.046225
[19:17:08.631] iteration 8630 : loss : 0.434331, loss_ce: 0.037360
[19:17:15.018] iteration 8640 : loss : 0.284812, loss_ce: 0.060982
[19:17:21.409] iteration 8650 : loss : 0.440432, loss_ce: 0.054754
[19:17:27.791] iteration 8660 : loss : 0.432004, loss_ce: 0.056281
[19:17:34.187] iteration 8670 : loss : 0.285892, loss_ce: 0.045253
[19:17:40.570] iteration 8680 : loss : 0.429456, loss_ce: 0.056643
[19:17:46.964] iteration 8690 : loss : 0.424039, loss_ce: 0.059105
[19:17:53.347] iteration 8700 : loss : 0.431047, loss_ce: 0.068541
[19:17:59.743] iteration 8710 : loss : 0.433765, loss_ce: 0.060008
[19:18:06.133] iteration 8720 : loss : 0.439556, loss_ce: 0.042198
[19:18:12.536] iteration 8730 : loss : 0.424045, loss_ce: 0.057183
[19:18:18.924] iteration 8740 : loss : 0.423313, loss_ce: 0.054277
[19:18:25.332] iteration 8750 : loss : 0.426480, loss_ce: 0.047670
[19:18:31.722] iteration 8760 : loss : 0.283528, loss_ce: 0.056778
[19:18:38.125] iteration 8770 : loss : 0.419067, loss_ce: 0.057613
[19:18:44.521] iteration 8780 : loss : 0.281366, loss_ce: 0.039031
[19:18:50.927] iteration 8790 : loss : 0.427126, loss_ce: 0.051376
[19:18:57.326] iteration 8800 : loss : 0.450898, loss_ce: 0.059858
[19:19:03.728] iteration 8810 : loss : 0.436949, loss_ce: 0.075903
[19:19:10.130] iteration 8820 : loss : 0.424766, loss_ce: 0.050469
[19:19:16.543] iteration 8830 : loss : 0.270486, loss_ce: 0.048619
[19:19:22.938] iteration 8840 : loss : 0.440512, loss_ce: 0.044039
[19:19:29.349] iteration 8850 : loss : 0.448472, loss_ce: 0.044365
[19:19:35.747] iteration 8860 : loss : 0.419987, loss_ce: 0.055694
[19:19:42.164] iteration 8870 : loss : 0.426213, loss_ce: 0.046540
[19:19:48.564] iteration 8880 : loss : 0.429886, loss_ce: 0.030481
[19:19:54.973] iteration 8890 : loss : 0.265166, loss_ce: 0.045839
[19:20:01.379] iteration 8900 : loss : 0.423634, loss_ce: 0.066045
[19:20:07.798] iteration 8910 : loss : 0.430704, loss_ce: 0.051551
[19:20:14.200] iteration 8920 : loss : 0.436312, loss_ce: 0.051615
[19:20:20.611] iteration 8930 : loss : 0.431610, loss_ce: 0.063292
[19:20:27.029] iteration 8940 : loss : 0.286494, loss_ce: 0.040215
[19:20:33.449] iteration 8950 : loss : 0.431982, loss_ce: 0.062688
[19:20:39.862] iteration 8960 : loss : 0.273699, loss_ce: 0.053698
[19:20:46.283] iteration 8970 : loss : 0.426308, loss_ce: 0.048286
[19:20:52.700] iteration 8980 : loss : 0.428232, loss_ce: 0.048985
[19:20:59.125] iteration 8990 : loss : 0.420489, loss_ce: 0.042518
[19:21:05.536] iteration 9000 : loss : 0.423860, loss_ce: 0.053207
[19:21:11.962] iteration 9010 : loss : 0.294319, loss_ce: 0.053835
[19:21:18.376] iteration 9020 : loss : 0.435493, loss_ce: 0.063408
[19:21:24.798] iteration 9030 : loss : 0.429894, loss_ce: 0.066217
[19:21:31.215] iteration 9040 : loss : 0.420724, loss_ce: 0.048061
[19:21:37.634] iteration 9050 : loss : 0.431299, loss_ce: 0.038888
[19:21:41.714] Epoch 15: Average loss: 0.4181
[19:21:55.070] iteration 9060 : loss : 0.429172, loss_ce: 0.052862
[19:22:01.458] iteration 9070 : loss : 0.434725, loss_ce: 0.047514
[19:22:07.846] iteration 9080 : loss : 0.269274, loss_ce: 0.048362
[19:22:14.237] iteration 9090 : loss : 0.426138, loss_ce: 0.080467
[19:22:20.627] iteration 9100 : loss : 0.418166, loss_ce: 0.044849
[19:22:27.022] iteration 9110 : loss : 0.413235, loss_ce: 0.053117
[19:22:33.409] iteration 9120 : loss : 0.273361, loss_ce: 0.048678
[19:22:39.813] iteration 9130 : loss : 0.416040, loss_ce: 0.067392
[19:22:46.204] iteration 9140 : loss : 0.417093, loss_ce: 0.048242
[19:22:52.605] iteration 9150 : loss : 0.426322, loss_ce: 0.050587
[19:22:59.002] iteration 9160 : loss : 0.431000, loss_ce: 0.073893
[19:23:05.415] iteration 9170 : loss : 0.442709, loss_ce: 0.054509
[19:23:11.814] iteration 9180 : loss : 0.428094, loss_ce: 0.050463
[19:23:18.220] iteration 9190 : loss : 0.436798, loss_ce: 0.035988
[19:23:24.620] iteration 9200 : loss : 0.428434, loss_ce: 0.047210
[19:23:31.032] iteration 9210 : loss : 0.430904, loss_ce: 0.055551
[19:23:37.432] iteration 9220 : loss : 0.438428, loss_ce: 0.032908
[19:23:43.842] iteration 9230 : loss : 0.438440, loss_ce: 0.095161
[19:23:50.248] iteration 9240 : loss : 0.437481, loss_ce: 0.054686
[19:23:56.671] iteration 9250 : loss : 0.426905, loss_ce: 0.043753
[19:24:03.076] iteration 9260 : loss : 0.422592, loss_ce: 0.052512
[19:24:09.486] iteration 9270 : loss : 0.421643, loss_ce: 0.060125
[19:24:15.895] iteration 9280 : loss : 0.413347, loss_ce: 0.041512
[19:24:22.316] iteration 9290 : loss : 0.437665, loss_ce: 0.051885
[19:24:28.727] iteration 9300 : loss : 0.435169, loss_ce: 0.056660
[19:24:35.149] iteration 9310 : loss : 0.434429, loss_ce: 0.044489
[19:24:41.559] iteration 9320 : loss : 0.434707, loss_ce: 0.064231
[19:24:47.988] iteration 9330 : loss : 0.438435, loss_ce: 0.038026
[19:24:54.405] iteration 9340 : loss : 0.427220, loss_ce: 0.071929
[19:25:00.833] iteration 9350 : loss : 0.448835, loss_ce: 0.048614
[19:25:07.254] iteration 9360 : loss : 0.433570, loss_ce: 0.065961
[19:25:13.680] iteration 9370 : loss : 0.427100, loss_ce: 0.048446
[19:25:20.098] iteration 9380 : loss : 0.441622, loss_ce: 0.046828
[19:25:26.526] iteration 9390 : loss : 0.444713, loss_ce: 0.058517
[19:25:32.945] iteration 9400 : loss : 0.429759, loss_ce: 0.062590
[19:25:39.362] iteration 9410 : loss : 0.441584, loss_ce: 0.023589
[19:25:45.766] iteration 9420 : loss : 0.453722, loss_ce: 0.089259
[19:25:52.190] iteration 9430 : loss : 0.459437, loss_ce: 0.061693
[19:25:58.595] iteration 9440 : loss : 0.306747, loss_ce: 0.053470
[19:26:05.023] iteration 9450 : loss : 0.460229, loss_ce: 0.063710
[19:26:11.439] iteration 9460 : loss : 0.457197, loss_ce: 0.068286
[19:26:17.864] iteration 9470 : loss : 0.474912, loss_ce: 0.100218
[19:26:24.287] iteration 9480 : loss : 0.455252, loss_ce: 0.078889
[19:26:30.716] iteration 9490 : loss : 0.454875, loss_ce: 0.076205
[19:26:37.133] iteration 9500 : loss : 0.450804, loss_ce: 0.054546
[19:26:43.559] iteration 9510 : loss : 0.449794, loss_ce: 0.066040
[19:26:49.975] iteration 9520 : loss : 0.446358, loss_ce: 0.107465
[19:26:56.406] iteration 9530 : loss : 0.431760, loss_ce: 0.043044
[19:27:02.822] iteration 9540 : loss : 0.447259, loss_ce: 0.037726
[19:27:09.253] iteration 9550 : loss : 0.446472, loss_ce: 0.063898
[19:27:15.671] iteration 9560 : loss : 0.424401, loss_ce: 0.046077
[19:27:22.101] iteration 9570 : loss : 0.428080, loss_ce: 0.053701
[19:27:28.514] iteration 9580 : loss : 0.432288, loss_ce: 0.052826
[19:27:34.939] iteration 9590 : loss : 0.435008, loss_ce: 0.071618
[19:27:41.356] iteration 9600 : loss : 0.281866, loss_ce: 0.036990
[19:27:47.779] iteration 9610 : loss : 0.429221, loss_ce: 0.056117
[19:27:54.197] iteration 9620 : loss : 0.436615, loss_ce: 0.079605
[19:27:55.699] Epoch 16: Average loss: 0.4277
[19:28:11.503] iteration 9630 : loss : 0.400104, loss_ce: 0.054499
[19:28:17.880] iteration 9640 : loss : 0.424100, loss_ce: 0.042287
[19:28:24.273] iteration 9650 : loss : 0.421260, loss_ce: 0.042539
[19:28:30.659] iteration 9660 : loss : 0.412252, loss_ce: 0.047291
[19:28:37.052] iteration 9670 : loss : 0.420759, loss_ce: 0.055197
[19:28:43.438] iteration 9680 : loss : 0.436266, loss_ce: 0.086709
[19:28:49.832] iteration 9690 : loss : 0.419878, loss_ce: 0.050500
[19:28:56.223] iteration 9700 : loss : 0.419563, loss_ce: 0.056927
[19:29:02.623] iteration 9710 : loss : 0.406900, loss_ce: 0.042748
[19:29:09.020] iteration 9720 : loss : 0.423126, loss_ce: 0.052367
[19:29:15.430] iteration 9730 : loss : 0.418046, loss_ce: 0.055484
[19:29:21.824] iteration 9740 : loss : 0.410590, loss_ce: 0.053532
[19:29:28.234] iteration 9750 : loss : 0.423709, loss_ce: 0.050444
[19:29:34.636] iteration 9760 : loss : 0.403116, loss_ce: 0.051037
[19:29:41.046] iteration 9770 : loss : 0.420388, loss_ce: 0.056335
[19:29:47.452] iteration 9780 : loss : 0.421499, loss_ce: 0.030244
[19:29:53.866] iteration 9790 : loss : 0.419054, loss_ce: 0.049550
[19:30:00.275] iteration 9800 : loss : 0.417529, loss_ce: 0.054940
[19:30:06.699] iteration 9810 : loss : 0.428977, loss_ce: 0.070657
[19:30:13.104] iteration 9820 : loss : 0.415714, loss_ce: 0.044840
[19:30:19.524] iteration 9830 : loss : 0.433999, loss_ce: 0.046038
[19:30:25.931] iteration 9840 : loss : 0.269732, loss_ce: 0.036728
[19:30:32.352] iteration 9850 : loss : 0.405354, loss_ce: 0.065940
[19:30:38.758] iteration 9860 : loss : 0.399728, loss_ce: 0.068315
[19:30:45.182] iteration 9870 : loss : 0.425857, loss_ce: 0.046788
[19:30:51.592] iteration 9880 : loss : 0.410745, loss_ce: 0.042043
[19:30:58.016] iteration 9890 : loss : 0.411667, loss_ce: 0.077611
[19:31:04.434] iteration 9900 : loss : 0.394823, loss_ce: 0.043621
[19:31:10.857] iteration 9910 : loss : 0.425282, loss_ce: 0.030589
[19:31:17.271] iteration 9920 : loss : 0.434877, loss_ce: 0.048548
[19:31:23.690] iteration 9930 : loss : 0.419797, loss_ce: 0.037833
[19:31:30.107] iteration 9940 : loss : 0.423999, loss_ce: 0.053032
[19:31:36.533] iteration 9950 : loss : 0.430877, loss_ce: 0.038948
[19:31:42.947] iteration 9960 : loss : 0.407560, loss_ce: 0.041468
[19:31:49.378] iteration 9970 : loss : 0.424909, loss_ce: 0.077617
[19:31:55.794] iteration 9980 : loss : 0.427776, loss_ce: 0.060241
[19:32:02.217] iteration 9990 : loss : 0.418920, loss_ce: 0.041468
[19:32:08.631] iteration 10000 : loss : 0.421419, loss_ce: 0.051189
[19:32:15.059] iteration 10010 : loss : 0.429122, loss_ce: 0.048951
[19:32:21.476] iteration 10020 : loss : 0.398229, loss_ce: 0.056572
[19:32:27.904] iteration 10030 : loss : 0.420632, loss_ce: 0.057823
[19:32:34.324] iteration 10040 : loss : 0.430663, loss_ce: 0.071166
[19:32:40.747] iteration 10050 : loss : 0.411141, loss_ce: 0.041168
[19:32:47.167] iteration 10060 : loss : 0.428496, loss_ce: 0.042010
[19:32:53.599] iteration 10070 : loss : 0.416270, loss_ce: 0.047140
[19:33:00.017] iteration 10080 : loss : 0.403086, loss_ce: 0.042264
[19:33:06.453] iteration 10090 : loss : 0.406594, loss_ce: 0.056458
[19:33:12.875] iteration 10100 : loss : 0.411708, loss_ce: 0.058918
[19:33:19.303] iteration 10110 : loss : 0.292778, loss_ce: 0.059580
[19:33:25.726] iteration 10120 : loss : 0.419003, loss_ce: 0.059506
[19:33:32.161] iteration 10130 : loss : 0.422228, loss_ce: 0.057753
[19:33:38.581] iteration 10140 : loss : 0.417744, loss_ce: 0.058991
[19:33:45.016] iteration 10150 : loss : 0.412203, loss_ce: 0.053899
[19:33:51.434] iteration 10160 : loss : 0.277843, loss_ce: 0.038766
[19:33:57.870] iteration 10170 : loss : 0.417384, loss_ce: 0.036203
[19:34:04.293] iteration 10180 : loss : 0.420089, loss_ce: 0.030064
[19:34:09.714] Epoch 17: Average loss: 0.4056
[19:39:56.059] iteration 10190 : loss : 0.423038, loss_ce: 0.066783
[19:40:02.408] iteration 10200 : loss : 0.422751, loss_ce: 0.051249
[19:40:08.769] iteration 10210 : loss : 0.419173, loss_ce: 0.069336
[19:40:15.126] iteration 10220 : loss : 0.414869, loss_ce: 0.048897
[19:40:21.497] iteration 10230 : loss : 0.418385, loss_ce: 0.043789
[19:40:27.856] iteration 10240 : loss : 0.419121, loss_ce: 0.036748
[19:40:34.229] iteration 10250 : loss : 0.420614, loss_ce: 0.052342
[19:40:40.592] iteration 10260 : loss : 0.421252, loss_ce: 0.064552
[19:40:46.969] iteration 10270 : loss : 0.441147, loss_ce: 0.038969
[19:40:53.341] iteration 10280 : loss : 0.273506, loss_ce: 0.050162
[19:40:59.724] iteration 10290 : loss : 0.424166, loss_ce: 0.069881
[19:41:06.100] iteration 10300 : loss : 0.411120, loss_ce: 0.045214
[19:41:12.485] iteration 10310 : loss : 0.425173, loss_ce: 0.041484
[19:41:18.856] iteration 10320 : loss : 0.421072, loss_ce: 0.057129
[19:41:25.243] iteration 10330 : loss : 0.414565, loss_ce: 0.037067
[19:41:31.622] iteration 10340 : loss : 0.422727, loss_ce: 0.050461
[19:41:38.011] iteration 10350 : loss : 0.393392, loss_ce: 0.060795
[19:41:44.387] iteration 10360 : loss : 0.431226, loss_ce: 0.049948
[19:41:50.776] iteration 10370 : loss : 0.425315, loss_ce: 0.038860
[19:41:57.157] iteration 10380 : loss : 0.427827, loss_ce: 0.044733
[19:42:03.546] iteration 10390 : loss : 0.413727, loss_ce: 0.038292
[19:42:09.927] iteration 10400 : loss : 0.420169, loss_ce: 0.046208
[19:42:16.320] iteration 10410 : loss : 0.412103, loss_ce: 0.048155
[19:42:22.701] iteration 10420 : loss : 0.399536, loss_ce: 0.058266
[19:42:29.098] iteration 10430 : loss : 0.407294, loss_ce: 0.034099
[19:42:35.479] iteration 10440 : loss : 0.410571, loss_ce: 0.042643
[19:42:41.874] iteration 10450 : loss : 0.398458, loss_ce: 0.063779
[19:42:48.259] iteration 10460 : loss : 0.410735, loss_ce: 0.049121
[19:42:54.658] iteration 10470 : loss : 0.421592, loss_ce: 0.046188
[19:43:01.045] iteration 10480 : loss : 0.420650, loss_ce: 0.048163
[19:43:07.447] iteration 10490 : loss : 0.409205, loss_ce: 0.056737
[19:43:13.834] iteration 10500 : loss : 0.388491, loss_ce: 0.050390
[19:43:20.234] iteration 10510 : loss : 0.424634, loss_ce: 0.042428
[19:43:26.618] iteration 10520 : loss : 0.409216, loss_ce: 0.048069
[19:43:33.016] iteration 10530 : loss : 0.416236, loss_ce: 0.042446
[19:43:39.406] iteration 10540 : loss : 0.413829, loss_ce: 0.044715
[19:43:45.810] iteration 10550 : loss : 0.406796, loss_ce: 0.055089
[19:43:52.196] iteration 10560 : loss : 0.258189, loss_ce: 0.047443
[19:43:58.593] iteration 10570 : loss : 0.417931, loss_ce: 0.055209
[19:44:04.983] iteration 10580 : loss : 0.440908, loss_ce: 0.032930
[19:44:11.386] iteration 10590 : loss : 0.424694, loss_ce: 0.061066
[19:44:17.775] iteration 10600 : loss : 0.425461, loss_ce: 0.041499
[19:44:24.184] iteration 10610 : loss : 0.414514, loss_ce: 0.052112
[19:44:30.574] iteration 10620 : loss : 0.437843, loss_ce: 0.036153
[19:44:36.984] iteration 10630 : loss : 0.422542, loss_ce: 0.041218
[19:44:43.379] iteration 10640 : loss : 0.262294, loss_ce: 0.041344
[19:44:49.784] iteration 10650 : loss : 0.406585, loss_ce: 0.064996
[19:44:56.180] iteration 10660 : loss : 0.426502, loss_ce: 0.055838
[19:45:02.586] iteration 10670 : loss : 0.401296, loss_ce: 0.050296
[19:45:08.984] iteration 10680 : loss : 0.405024, loss_ce: 0.054344
[19:45:15.389] iteration 10690 : loss : 0.279115, loss_ce: 0.036477
[19:45:21.786] iteration 10700 : loss : 0.261086, loss_ce: 0.040963
[19:45:28.200] iteration 10710 : loss : 0.416007, loss_ce: 0.052535
[19:45:34.597] iteration 10720 : loss : 0.395690, loss_ce: 0.035694
[19:45:41.015] iteration 10730 : loss : 0.399445, loss_ce: 0.055152
[19:45:47.421] iteration 10740 : loss : 0.405550, loss_ce: 0.045842
[19:45:53.824] iteration 10750 : loss : 0.451513, loss_ce: 0.058098
[19:45:56.655] Epoch 18: Average loss: 0.4002
[19:46:11.490] iteration 10760 : loss : 0.270457, loss_ce: 0.030038
[19:46:17.876] iteration 10770 : loss : 0.278977, loss_ce: 0.043123
[19:46:24.252] iteration 10780 : loss : 0.421369, loss_ce: 0.062869
[19:46:30.638] iteration 10790 : loss : 0.420862, loss_ce: 0.065312
[19:46:37.016] iteration 10800 : loss : 0.432454, loss_ce: 0.073511
[19:46:43.412] iteration 10810 : loss : 0.425936, loss_ce: 0.041577
[19:46:49.796] iteration 10820 : loss : 0.274151, loss_ce: 0.050955
[19:46:56.188] iteration 10830 : loss : 0.417384, loss_ce: 0.051733
[19:47:02.576] iteration 10840 : loss : 0.401869, loss_ce: 0.037848
[19:47:08.968] iteration 10850 : loss : 0.455140, loss_ce: 0.077185
[19:47:15.355] iteration 10860 : loss : 0.452862, loss_ce: 0.054376
[19:47:21.752] iteration 10870 : loss : 0.452104, loss_ce: 0.061927
[19:47:28.151] iteration 10880 : loss : 0.444552, loss_ce: 0.074444
[19:47:34.550] iteration 10890 : loss : 0.443514, loss_ce: 0.047797
[19:47:40.941] iteration 10900 : loss : 0.436867, loss_ce: 0.074646
[19:47:47.340] iteration 10910 : loss : 0.435850, loss_ce: 0.045387
[19:47:53.731] iteration 10920 : loss : 0.440149, loss_ce: 0.042408
[19:48:00.133] iteration 10930 : loss : 0.455228, loss_ce: 0.116380
[19:48:06.530] iteration 10940 : loss : 0.468679, loss_ce: 0.076746
[19:48:12.929] iteration 10950 : loss : 0.452166, loss_ce: 0.052137
[19:48:19.324] iteration 10960 : loss : 0.473165, loss_ce: 0.112664
[19:48:25.727] iteration 10970 : loss : 0.465349, loss_ce: 0.049443
[19:48:32.119] iteration 10980 : loss : 0.466777, loss_ce: 0.046230
[19:48:38.524] iteration 10990 : loss : 0.462180, loss_ce: 0.039874
[19:48:44.923] iteration 11000 : loss : 0.307094, loss_ce: 0.051479
[19:48:51.333] iteration 11010 : loss : 0.452689, loss_ce: 0.068154
[19:48:57.729] iteration 11020 : loss : 0.451195, loss_ce: 0.058557
[19:49:04.140] iteration 11030 : loss : 0.456297, loss_ce: 0.070889
[19:49:10.536] iteration 11040 : loss : 0.303366, loss_ce: 0.074101
[19:49:16.945] iteration 11050 : loss : 0.452659, loss_ce: 0.071661
[19:49:23.338] iteration 11060 : loss : 0.449577, loss_ce: 0.072671
[19:49:29.751] iteration 11070 : loss : 0.447743, loss_ce: 0.065590
[19:49:36.150] iteration 11080 : loss : 0.290587, loss_ce: 0.065061
[19:49:42.559] iteration 11090 : loss : 0.444010, loss_ce: 0.045213
[19:49:48.955] iteration 11100 : loss : 0.451090, loss_ce: 0.076913
[19:49:55.363] iteration 11110 : loss : 0.450721, loss_ce: 0.049126
[19:50:01.769] iteration 11120 : loss : 0.447325, loss_ce: 0.076803
[19:50:08.181] iteration 11130 : loss : 0.421184, loss_ce: 0.068854
[19:50:14.577] iteration 11140 : loss : 0.313893, loss_ce: 0.054983
[19:50:20.986] iteration 11150 : loss : 0.436574, loss_ce: 0.062635
[19:50:27.386] iteration 11160 : loss : 0.433838, loss_ce: 0.044693
[19:50:33.800] iteration 11170 : loss : 0.426918, loss_ce: 0.066100
[19:50:40.204] iteration 11180 : loss : 0.422681, loss_ce: 0.050939
[19:50:46.617] iteration 11190 : loss : 0.428141, loss_ce: 0.056641
[19:50:53.016] iteration 11200 : loss : 0.417766, loss_ce: 0.048955
[19:50:59.428] iteration 11210 : loss : 0.439338, loss_ce: 0.070627
[19:51:05.833] iteration 11220 : loss : 0.268684, loss_ce: 0.041504
[19:51:12.250] iteration 11230 : loss : 0.425904, loss_ce: 0.051300
[19:51:18.656] iteration 11240 : loss : 0.421916, loss_ce: 0.046530
[19:51:25.069] iteration 11250 : loss : 0.417012, loss_ce: 0.056993
[19:51:31.473] iteration 11260 : loss : 0.281792, loss_ce: 0.050172
[19:51:37.886] iteration 11270 : loss : 0.423937, loss_ce: 0.053521
[19:51:44.289] iteration 11280 : loss : 0.429054, loss_ce: 0.051236
[19:51:50.704] iteration 11290 : loss : 0.425347, loss_ce: 0.042306
[19:51:57.106] iteration 11300 : loss : 0.430158, loss_ce: 0.062701
[19:52:03.518] iteration 11310 : loss : 0.445704, loss_ce: 0.078181
[19:52:09.489] iteration 11320 : loss : 0.398014, loss_ce: 0.049408
[19:52:10.181] Epoch 19: Average loss: 0.4242
[19:52:10.279] save model to ./finetune_tpgm_kits23_continual_fixed\finetuned_epoch_19.pth
[19:52:27.534] iteration 11330 : loss : 0.431282, loss_ce: 0.045417
[19:52:33.908] iteration 11340 : loss : 0.435811, loss_ce: 0.055293
[19:52:40.297] iteration 11350 : loss : 0.435762, loss_ce: 0.068316
[19:52:46.678] iteration 11360 : loss : 0.449383, loss_ce: 0.067034
[19:52:53.068] iteration 11370 : loss : 0.436485, loss_ce: 0.064481
[19:52:59.447] iteration 11380 : loss : 0.440552, loss_ce: 0.052905
[19:53:05.840] iteration 11390 : loss : 0.284166, loss_ce: 0.040231
[19:53:12.222] iteration 11400 : loss : 0.437734, loss_ce: 0.060136
[19:53:18.615] iteration 11410 : loss : 0.438149, loss_ce: 0.072103
[19:53:25.000] iteration 11420 : loss : 0.436772, loss_ce: 0.058498
[19:53:31.397] iteration 11430 : loss : 0.433626, loss_ce: 0.052954
[19:53:37.788] iteration 11440 : loss : 0.436039, loss_ce: 0.049093
[19:53:44.199] iteration 11450 : loss : 0.427906, loss_ce: 0.067414
[19:53:50.590] iteration 11460 : loss : 0.421779, loss_ce: 0.056799
[19:53:56.993] iteration 11470 : loss : 0.425583, loss_ce: 0.046798
[19:54:03.391] iteration 11480 : loss : 0.419855, loss_ce: 0.046903
[19:54:09.805] iteration 11490 : loss : 0.444990, loss_ce: 0.069204
[19:54:16.202] iteration 11500 : loss : 0.410634, loss_ce: 0.054533
[19:54:22.606] iteration 11510 : loss : 0.266030, loss_ce: 0.043318
[19:54:29.001] iteration 11520 : loss : 0.407999, loss_ce: 0.041530
[19:54:35.415] iteration 11530 : loss : 0.407616, loss_ce: 0.047157
[19:54:41.814] iteration 11540 : loss : 0.267038, loss_ce: 0.033299
[19:54:48.220] iteration 11550 : loss : 0.412039, loss_ce: 0.049614
[19:54:54.619] iteration 11560 : loss : 0.422449, loss_ce: 0.063514
[19:55:01.033] iteration 11570 : loss : 0.425189, loss_ce: 0.054487
[19:55:07.432] iteration 11580 : loss : 0.275383, loss_ce: 0.055852
[19:55:13.840] iteration 11590 : loss : 0.422730, loss_ce: 0.045622
[19:55:20.236] iteration 11600 : loss : 0.266657, loss_ce: 0.033136
[19:55:26.658] iteration 11610 : loss : 0.416656, loss_ce: 0.036508
[19:55:33.070] iteration 11620 : loss : 0.411153, loss_ce: 0.042610
[19:55:39.481] iteration 11630 : loss : 0.418744, loss_ce: 0.062045
[19:55:45.889] iteration 11640 : loss : 0.435356, loss_ce: 0.066022
[19:55:52.300] iteration 11650 : loss : 0.420023, loss_ce: 0.042855
[19:55:58.698] iteration 11660 : loss : 0.412206, loss_ce: 0.043690
[19:56:05.114] iteration 11670 : loss : 0.428012, loss_ce: 0.070164
[19:56:11.517] iteration 11680 : loss : 0.419941, loss_ce: 0.059243
[19:56:17.934] iteration 11690 : loss : 0.423430, loss_ce: 0.055890
[19:56:24.333] iteration 11700 : loss : 0.399396, loss_ce: 0.041452
[19:56:30.751] iteration 11710 : loss : 0.403259, loss_ce: 0.047214
[19:56:37.155] iteration 11720 : loss : 0.395386, loss_ce: 0.049097
[19:56:43.572] iteration 11730 : loss : 0.423067, loss_ce: 0.047803
[19:56:49.980] iteration 11740 : loss : 0.395346, loss_ce: 0.051192
[19:56:56.398] iteration 11750 : loss : 0.402206, loss_ce: 0.040550
[19:57:02.808] iteration 11760 : loss : 0.406139, loss_ce: 0.037192
[19:57:09.231] iteration 11770 : loss : 0.401412, loss_ce: 0.050546
[19:57:15.636] iteration 11780 : loss : 0.407165, loss_ce: 0.040251
[19:57:22.051] iteration 11790 : loss : 0.414068, loss_ce: 0.070726
[19:57:28.459] iteration 11800 : loss : 0.396184, loss_ce: 0.051103
[19:57:34.871] iteration 11810 : loss : 0.378419, loss_ce: 0.027394
[19:57:41.278] iteration 11820 : loss : 0.388307, loss_ce: 0.041996
[19:57:47.688] iteration 11830 : loss : 0.406618, loss_ce: 0.042105
[19:57:54.103] iteration 11840 : loss : 0.394047, loss_ce: 0.054647
[19:58:00.525] iteration 11850 : loss : 0.419765, loss_ce: 0.078074
[19:58:06.928] iteration 11860 : loss : 0.396919, loss_ce: 0.041194
[19:58:13.344] iteration 11870 : loss : 0.399450, loss_ce: 0.045131
[19:58:19.747] iteration 11880 : loss : 0.390034, loss_ce: 0.040996
[19:58:23.839] Epoch 20: Average loss: 0.4044
[20:04:07.478] iteration 11890 : loss : 0.386750, loss_ce: 0.051477
[20:04:13.827] iteration 11900 : loss : 0.381275, loss_ce: 0.034727
[20:04:20.192] iteration 11910 : loss : 0.387127, loss_ce: 0.032182
[20:04:26.553] iteration 11920 : loss : 0.381420, loss_ce: 0.037276
[20:04:32.925] iteration 11930 : loss : 0.406865, loss_ce: 0.045965
[20:04:39.289] iteration 11940 : loss : 0.402925, loss_ce: 0.040181
[20:04:45.659] iteration 11950 : loss : 0.376188, loss_ce: 0.039834
[20:04:52.024] iteration 11960 : loss : 0.391581, loss_ce: 0.032132
[20:04:58.408] iteration 11970 : loss : 0.397378, loss_ce: 0.040600
[20:05:04.777] iteration 11980 : loss : 0.381888, loss_ce: 0.049312
[20:05:11.160] iteration 11990 : loss : 0.373363, loss_ce: 0.036723
[20:05:17.533] iteration 12000 : loss : 0.382424, loss_ce: 0.028511
[20:05:23.919] iteration 12010 : loss : 0.386931, loss_ce: 0.034616
[20:05:30.296] iteration 12020 : loss : 0.229672, loss_ce: 0.037541
[20:05:36.687] iteration 12030 : loss : 0.372372, loss_ce: 0.036541
[20:05:43.064] iteration 12040 : loss : 0.390949, loss_ce: 0.037457
[20:05:49.452] iteration 12050 : loss : 0.400905, loss_ce: 0.044234
[20:05:55.831] iteration 12060 : loss : 0.395890, loss_ce: 0.044810
[20:06:02.222] iteration 12070 : loss : 0.381110, loss_ce: 0.031181
[20:06:08.601] iteration 12080 : loss : 0.382337, loss_ce: 0.048427
[20:06:14.992] iteration 12090 : loss : 0.370633, loss_ce: 0.039152
[20:06:21.376] iteration 12100 : loss : 0.397841, loss_ce: 0.050026
[20:06:27.774] iteration 12110 : loss : 0.394585, loss_ce: 0.042878
[20:06:34.159] iteration 12120 : loss : 0.371208, loss_ce: 0.040652
[20:06:40.552] iteration 12130 : loss : 0.222844, loss_ce: 0.030790
[20:06:46.933] iteration 12140 : loss : 0.386640, loss_ce: 0.054791
[20:06:53.331] iteration 12150 : loss : 0.375453, loss_ce: 0.044455
[20:06:59.721] iteration 12160 : loss : 0.422591, loss_ce: 0.059281
[20:07:06.119] iteration 12170 : loss : 0.383709, loss_ce: 0.055168
[20:07:12.504] iteration 12180 : loss : 0.373236, loss_ce: 0.037482
[20:07:18.903] iteration 12190 : loss : 0.378877, loss_ce: 0.032410
[20:07:25.288] iteration 12200 : loss : 0.399628, loss_ce: 0.069899
[20:07:31.688] iteration 12210 : loss : 0.396724, loss_ce: 0.045392
[20:07:38.074] iteration 12220 : loss : 0.381068, loss_ce: 0.041811
[20:07:44.471] iteration 12230 : loss : 0.374241, loss_ce: 0.041736
[20:07:50.858] iteration 12240 : loss : 0.363870, loss_ce: 0.027713
[20:07:57.260] iteration 12250 : loss : 0.389744, loss_ce: 0.039453
[20:08:03.652] iteration 12260 : loss : 0.381699, loss_ce: 0.057107
[20:08:10.052] iteration 12270 : loss : 0.380529, loss_ce: 0.035729
[20:08:16.447] iteration 12280 : loss : 0.363163, loss_ce: 0.026198
[20:08:22.846] iteration 12290 : loss : 0.378599, loss_ce: 0.063340
[20:08:29.238] iteration 12300 : loss : 0.401390, loss_ce: 0.036210
[20:08:35.642] iteration 12310 : loss : 0.387665, loss_ce: 0.031593
[20:08:42.035] iteration 12320 : loss : 0.356631, loss_ce: 0.020148
[20:08:48.441] iteration 12330 : loss : 0.366735, loss_ce: 0.024391
[20:08:54.838] iteration 12340 : loss : 0.353360, loss_ce: 0.039932
[20:09:01.247] iteration 12350 : loss : 0.392013, loss_ce: 0.043570
[20:09:07.640] iteration 12360 : loss : 0.362330, loss_ce: 0.041417
[20:09:14.042] iteration 12370 : loss : 0.351428, loss_ce: 0.029629
[20:09:20.438] iteration 12380 : loss : 0.378000, loss_ce: 0.040981
[20:09:26.844] iteration 12390 : loss : 0.360332, loss_ce: 0.041965
[20:09:33.248] iteration 12400 : loss : 0.205288, loss_ce: 0.031694
[20:09:39.654] iteration 12410 : loss : 0.420038, loss_ce: 0.046290
[20:09:46.052] iteration 12420 : loss : 0.279572, loss_ce: 0.068259
[20:09:52.463] iteration 12430 : loss : 0.399070, loss_ce: 0.051668
[20:09:58.859] iteration 12440 : loss : 0.405725, loss_ce: 0.039450
[20:10:05.266] iteration 12450 : loss : 0.389617, loss_ce: 0.038541
[20:10:06.792] Epoch 21: Average loss: 0.3732
[20:10:22.727] iteration 12460 : loss : 0.391637, loss_ce: 0.028250
[20:10:29.113] iteration 12470 : loss : 0.405820, loss_ce: 0.046003
[20:10:35.492] iteration 12480 : loss : 0.380515, loss_ce: 0.032477
[20:10:41.880] iteration 12490 : loss : 0.386849, loss_ce: 0.059788
[20:10:48.256] iteration 12500 : loss : 0.381139, loss_ce: 0.048283
[20:10:54.647] iteration 12510 : loss : 0.373225, loss_ce: 0.025859
[20:11:01.026] iteration 12520 : loss : 0.386865, loss_ce: 0.037827
[20:11:07.423] iteration 12530 : loss : 0.384549, loss_ce: 0.041215
[20:11:13.805] iteration 12540 : loss : 0.386193, loss_ce: 0.034825
[20:11:20.197] iteration 12550 : loss : 0.398579, loss_ce: 0.040060
[20:11:26.587] iteration 12560 : loss : 0.389164, loss_ce: 0.046016
[20:11:32.984] iteration 12570 : loss : 0.382288, loss_ce: 0.055985
[20:11:39.375] iteration 12580 : loss : 0.401711, loss_ce: 0.049995
[20:11:45.775] iteration 12590 : loss : 0.390996, loss_ce: 0.038415
[20:11:52.165] iteration 12600 : loss : 0.396943, loss_ce: 0.054750
[20:11:58.565] iteration 12610 : loss : 0.395729, loss_ce: 0.049823
[20:12:04.957] iteration 12620 : loss : 0.369940, loss_ce: 0.041204
[20:12:11.363] iteration 12630 : loss : 0.396301, loss_ce: 0.043843
[20:12:17.758] iteration 12640 : loss : 0.237093, loss_ce: 0.036787
[20:12:24.158] iteration 12650 : loss : 0.396346, loss_ce: 0.046831
[20:12:30.551] iteration 12660 : loss : 0.371369, loss_ce: 0.032892
[20:12:36.954] iteration 12670 : loss : 0.382635, loss_ce: 0.039056
[20:12:43.348] iteration 12680 : loss : 0.397824, loss_ce: 0.050681
[20:12:49.752] iteration 12690 : loss : 0.390036, loss_ce: 0.028740
[20:12:56.145] iteration 12700 : loss : 0.403918, loss_ce: 0.049133
[20:13:02.551] iteration 12710 : loss : 0.368308, loss_ce: 0.046611
[20:13:08.946] iteration 12720 : loss : 0.386099, loss_ce: 0.037461
[20:13:15.360] iteration 12730 : loss : 0.232663, loss_ce: 0.027750
[20:13:21.762] iteration 12740 : loss : 0.381847, loss_ce: 0.039960
[20:13:28.175] iteration 12750 : loss : 0.374577, loss_ce: 0.035699
[20:13:34.572] iteration 12760 : loss : 0.411622, loss_ce: 0.063609
[20:13:40.971] iteration 12770 : loss : 0.413483, loss_ce: 0.041947
[20:13:47.366] iteration 12780 : loss : 0.393505, loss_ce: 0.034757
[20:13:53.776] iteration 12790 : loss : 0.390023, loss_ce: 0.049513
[20:14:00.172] iteration 12800 : loss : 0.366130, loss_ce: 0.047858
[20:14:06.589] iteration 12810 : loss : 0.398699, loss_ce: 0.042615
[20:14:12.989] iteration 12820 : loss : 0.372160, loss_ce: 0.041611
[20:14:19.402] iteration 12830 : loss : 0.372560, loss_ce: 0.033566
[20:14:25.801] iteration 12840 : loss : 0.378558, loss_ce: 0.050703
[20:14:32.203] iteration 12850 : loss : 0.276258, loss_ce: 0.032165
[20:14:38.600] iteration 12860 : loss : 0.422134, loss_ce: 0.081782
[20:14:45.015] iteration 12870 : loss : 0.380256, loss_ce: 0.040601
[20:14:51.412] iteration 12880 : loss : 0.419636, loss_ce: 0.043109
[20:14:57.830] iteration 12890 : loss : 0.408922, loss_ce: 0.028797
[20:15:04.233] iteration 12900 : loss : 0.408800, loss_ce: 0.053557
[20:15:10.644] iteration 12910 : loss : 0.385731, loss_ce: 0.043814
[20:15:17.042] iteration 12920 : loss : 0.381176, loss_ce: 0.021043
[20:15:23.456] iteration 12930 : loss : 0.360892, loss_ce: 0.029475
[20:15:29.862] iteration 12940 : loss : 0.388167, loss_ce: 0.036839
[20:15:36.273] iteration 12950 : loss : 0.377360, loss_ce: 0.035047
[20:15:42.669] iteration 12960 : loss : 0.372609, loss_ce: 0.025325
[20:15:49.086] iteration 12970 : loss : 0.380069, loss_ce: 0.066545
[20:15:55.483] iteration 12980 : loss : 0.388708, loss_ce: 0.040191
[20:16:01.892] iteration 12990 : loss : 0.369092, loss_ce: 0.033524
[20:16:08.292] iteration 13000 : loss : 0.376010, loss_ce: 0.034847
[20:16:14.705] iteration 13010 : loss : 0.232038, loss_ce: 0.032307
[20:16:20.075] Epoch 22: Average loss: 0.3763
[20:16:32.383] iteration 13020 : loss : 0.386751, loss_ce: 0.044863
[20:16:38.767] iteration 13030 : loss : 0.415292, loss_ce: 0.030334
[20:16:45.150] iteration 13040 : loss : 0.356318, loss_ce: 0.033602
[20:16:51.544] iteration 13050 : loss : 0.391475, loss_ce: 0.053263
[20:16:57.922] iteration 13060 : loss : 0.383184, loss_ce: 0.029971
[20:17:04.316] iteration 13070 : loss : 0.386788, loss_ce: 0.049131
[20:17:10.700] iteration 13080 : loss : 0.370746, loss_ce: 0.035443
[20:17:17.096] iteration 13090 : loss : 0.381420, loss_ce: 0.037909
[20:17:23.484] iteration 13100 : loss : 0.391041, loss_ce: 0.048367
[20:17:29.896] iteration 13110 : loss : 0.350222, loss_ce: 0.044528
[20:17:36.279] iteration 13120 : loss : 0.367488, loss_ce: 0.043930
[20:17:42.679] iteration 13130 : loss : 0.372762, loss_ce: 0.065415
[20:17:49.066] iteration 13140 : loss : 0.381664, loss_ce: 0.043464
[20:17:55.464] iteration 13150 : loss : 0.373519, loss_ce: 0.031584
[20:18:01.855] iteration 13160 : loss : 0.348928, loss_ce: 0.027132
[20:18:08.257] iteration 13170 : loss : 0.399073, loss_ce: 0.035669
[20:18:14.652] iteration 13180 : loss : 0.394233, loss_ce: 0.026380
[20:18:21.056] iteration 13190 : loss : 0.384849, loss_ce: 0.040075
[20:18:27.453] iteration 13200 : loss : 0.360785, loss_ce: 0.044538
[20:18:33.856] iteration 13210 : loss : 0.373020, loss_ce: 0.047994
[20:18:40.251] iteration 13220 : loss : 0.373679, loss_ce: 0.054976
[20:18:46.659] iteration 13230 : loss : 0.358161, loss_ce: 0.036512
[20:18:53.055] iteration 13240 : loss : 0.364168, loss_ce: 0.034830
[20:18:59.467] iteration 13250 : loss : 0.369520, loss_ce: 0.029142
[20:19:05.872] iteration 13260 : loss : 0.371034, loss_ce: 0.034030
[20:19:12.280] iteration 13270 : loss : 0.362784, loss_ce: 0.037727
[20:19:18.682] iteration 13280 : loss : 0.215682, loss_ce: 0.024953
[20:19:25.091] iteration 13290 : loss : 0.385539, loss_ce: 0.056925
[20:19:31.493] iteration 13300 : loss : 0.369689, loss_ce: 0.044495
[20:19:37.904] iteration 13310 : loss : 0.356180, loss_ce: 0.041232
[20:19:44.315] iteration 13320 : loss : 0.367176, loss_ce: 0.031670
[20:19:50.723] iteration 13330 : loss : 0.367059, loss_ce: 0.032978
[20:19:57.120] iteration 13340 : loss : 0.215667, loss_ce: 0.021475
[20:20:03.534] iteration 13350 : loss : 0.369001, loss_ce: 0.046120
[20:20:09.932] iteration 13360 : loss : 0.381681, loss_ce: 0.041670
[20:20:16.353] iteration 13370 : loss : 0.366708, loss_ce: 0.029466
[20:20:22.761] iteration 13380 : loss : 0.383320, loss_ce: 0.051459
[20:20:29.174] iteration 13390 : loss : 0.375472, loss_ce: 0.029663
[20:20:35.576] iteration 13400 : loss : 0.402113, loss_ce: 0.039364
[20:20:41.983] iteration 13410 : loss : 0.232005, loss_ce: 0.046946
[20:20:48.384] iteration 13420 : loss : 0.372208, loss_ce: 0.049073
[20:20:54.799] iteration 13430 : loss : 0.368048, loss_ce: 0.029487
[20:21:01.206] iteration 13440 : loss : 0.361671, loss_ce: 0.032302
[20:21:07.615] iteration 13450 : loss : 0.244975, loss_ce: 0.028770
[20:21:14.015] iteration 13460 : loss : 0.376241, loss_ce: 0.029343
[20:21:20.433] iteration 13470 : loss : 0.378179, loss_ce: 0.049119
[20:21:26.835] iteration 13480 : loss : 0.370214, loss_ce: 0.035114
[20:21:33.252] iteration 13490 : loss : 0.398384, loss_ce: 0.048398
[20:21:39.651] iteration 13500 : loss : 0.363816, loss_ce: 0.034913
[20:21:46.075] iteration 13510 : loss : 0.377019, loss_ce: 0.037281
[20:21:52.476] iteration 13520 : loss : 0.345078, loss_ce: 0.028476
[20:21:58.888] iteration 13530 : loss : 0.372848, loss_ce: 0.036319
[20:22:05.295] iteration 13540 : loss : 0.369768, loss_ce: 0.045385
[20:22:11.702] iteration 13550 : loss : 0.372997, loss_ce: 0.028988
[20:22:18.100] iteration 13560 : loss : 0.369645, loss_ce: 0.053205
[20:22:24.510] iteration 13570 : loss : 0.385773, loss_ce: 0.027591
[20:22:30.917] iteration 13580 : loss : 0.386275, loss_ce: 0.047639
[20:22:33.715] Epoch 23: Average loss: 0.3594
[20:28:17.484] iteration 13590 : loss : 0.384434, loss_ce: 0.041566
[20:28:23.837] iteration 13600 : loss : 0.390466, loss_ce: 0.031425
[20:28:30.204] iteration 13610 : loss : 0.401768, loss_ce: 0.044079
[20:28:36.564] iteration 13620 : loss : 0.419014, loss_ce: 0.042680
[20:28:42.935] iteration 13630 : loss : 0.259733, loss_ce: 0.042212
[20:28:49.305] iteration 13640 : loss : 0.391297, loss_ce: 0.027655
[20:28:55.680] iteration 13650 : loss : 0.373559, loss_ce: 0.028988
[20:29:02.045] iteration 13660 : loss : 0.407257, loss_ce: 0.048872
[20:29:08.424] iteration 13670 : loss : 0.385115, loss_ce: 0.044170
[20:29:14.796] iteration 13680 : loss : 0.397318, loss_ce: 0.044214
[20:29:21.175] iteration 13690 : loss : 0.381051, loss_ce: 0.070417
[20:29:27.544] iteration 13700 : loss : 0.376900, loss_ce: 0.049820
[20:29:33.929] iteration 13710 : loss : 0.385799, loss_ce: 0.045602
[20:29:40.301] iteration 13720 : loss : 0.374271, loss_ce: 0.037731
[20:29:46.690] iteration 13730 : loss : 0.376450, loss_ce: 0.040871
[20:29:53.063] iteration 13740 : loss : 0.424813, loss_ce: 0.062641
[20:29:59.453] iteration 13750 : loss : 0.376670, loss_ce: 0.031864
[20:30:05.832] iteration 13760 : loss : 0.239192, loss_ce: 0.019013
[20:30:12.219] iteration 13770 : loss : 0.392877, loss_ce: 0.053591
[20:30:18.598] iteration 13780 : loss : 0.372024, loss_ce: 0.033677
[20:30:24.988] iteration 13790 : loss : 0.381773, loss_ce: 0.034181
[20:30:31.370] iteration 13800 : loss : 0.361298, loss_ce: 0.032571
[20:30:37.764] iteration 13810 : loss : 0.378593, loss_ce: 0.038152
[20:30:44.143] iteration 13820 : loss : 0.363486, loss_ce: 0.051605
[20:30:50.539] iteration 13830 : loss : 0.357532, loss_ce: 0.030325
[20:30:56.920] iteration 13840 : loss : 0.394628, loss_ce: 0.040273
[20:31:03.315] iteration 13850 : loss : 0.385478, loss_ce: 0.030399
[20:31:09.704] iteration 13860 : loss : 0.391830, loss_ce: 0.059892
[20:31:16.099] iteration 13870 : loss : 0.232897, loss_ce: 0.027471
[20:31:22.485] iteration 13880 : loss : 0.366922, loss_ce: 0.025427
[20:31:28.879] iteration 13890 : loss : 0.395687, loss_ce: 0.047168
[20:31:35.273] iteration 13900 : loss : 0.355874, loss_ce: 0.045069
[20:31:41.673] iteration 13910 : loss : 0.363687, loss_ce: 0.042226
[20:31:48.058] iteration 13920 : loss : 0.364592, loss_ce: 0.025985
[20:31:54.457] iteration 13930 : loss : 0.225743, loss_ce: 0.024299
[20:32:00.843] iteration 13940 : loss : 0.233284, loss_ce: 0.061288
[20:32:07.242] iteration 13950 : loss : 0.371210, loss_ce: 0.042201
[20:32:13.632] iteration 13960 : loss : 0.375492, loss_ce: 0.038807
[20:32:20.032] iteration 13970 : loss : 0.362654, loss_ce: 0.019056
[20:32:26.424] iteration 13980 : loss : 0.219763, loss_ce: 0.031366
[20:32:32.830] iteration 13990 : loss : 0.363047, loss_ce: 0.029672
[20:32:39.219] iteration 14000 : loss : 0.410409, loss_ce: 0.044770
[20:32:45.622] iteration 14010 : loss : 0.386938, loss_ce: 0.062503
[20:32:52.011] iteration 14020 : loss : 0.363505, loss_ce: 0.033918
[20:32:58.416] iteration 14030 : loss : 0.383701, loss_ce: 0.031168
[20:33:04.809] iteration 14040 : loss : 0.365446, loss_ce: 0.032698
[20:33:11.209] iteration 14050 : loss : 0.356424, loss_ce: 0.036570
[20:33:17.602] iteration 14060 : loss : 0.368322, loss_ce: 0.052280
[20:33:24.009] iteration 14070 : loss : 0.216498, loss_ce: 0.049496
[20:33:30.405] iteration 14080 : loss : 0.385251, loss_ce: 0.048263
[20:33:36.809] iteration 14090 : loss : 0.376228, loss_ce: 0.031714
[20:33:43.203] iteration 14100 : loss : 0.366608, loss_ce: 0.034216
[20:33:49.608] iteration 14110 : loss : 0.362934, loss_ce: 0.039794
[20:33:56.006] iteration 14120 : loss : 0.402120, loss_ce: 0.047946
[20:34:02.416] iteration 14130 : loss : 0.388028, loss_ce: 0.047729
[20:34:08.813] iteration 14140 : loss : 0.371237, loss_ce: 0.046024
[20:34:14.793] iteration 14150 : loss : 0.230356, loss_ce: 0.026662
[20:34:15.448] Epoch 24: Average loss: 0.3651
[20:34:32.593] iteration 14160 : loss : 0.379047, loss_ce: 0.030313
[20:34:38.974] iteration 14170 : loss : 0.366834, loss_ce: 0.027959
[20:34:45.350] iteration 14180 : loss : 0.226190, loss_ce: 0.048667
[20:34:51.740] iteration 14190 : loss : 0.378883, loss_ce: 0.041323
[20:34:58.120] iteration 14200 : loss : 0.382313, loss_ce: 0.034143
[20:35:04.518] iteration 14210 : loss : 0.392973, loss_ce: 0.061636
[20:35:10.902] iteration 14220 : loss : 0.370462, loss_ce: 0.048684
[20:35:17.295] iteration 14230 : loss : 0.230212, loss_ce: 0.036806
[20:35:23.679] iteration 14240 : loss : 0.361824, loss_ce: 0.038080
[20:35:30.075] iteration 14250 : loss : 0.358419, loss_ce: 0.029853
[20:35:36.470] iteration 14260 : loss : 0.386999, loss_ce: 0.029897
[20:35:42.871] iteration 14270 : loss : 0.388220, loss_ce: 0.038356
[20:35:49.259] iteration 14280 : loss : 0.362708, loss_ce: 0.042356
[20:35:55.663] iteration 14290 : loss : 0.383664, loss_ce: 0.033840
[20:36:02.055] iteration 14300 : loss : 0.357830, loss_ce: 0.028282
[20:36:08.453] iteration 14310 : loss : 0.228795, loss_ce: 0.029923
[20:36:14.849] iteration 14320 : loss : 0.365640, loss_ce: 0.029903
[20:36:21.260] iteration 14330 : loss : 0.236549, loss_ce: 0.020147
[20:36:27.664] iteration 14340 : loss : 0.212392, loss_ce: 0.027674
[20:36:34.074] iteration 14350 : loss : 0.349499, loss_ce: 0.022411
[20:36:40.470] iteration 14360 : loss : 0.366429, loss_ce: 0.027404
[20:36:46.872] iteration 14370 : loss : 0.352806, loss_ce: 0.041058
[20:36:53.266] iteration 14380 : loss : 0.341273, loss_ce: 0.034362
[20:36:59.676] iteration 14390 : loss : 0.350073, loss_ce: 0.021441
[20:37:06.069] iteration 14400 : loss : 0.179497, loss_ce: 0.027097
[20:37:12.476] iteration 14410 : loss : 0.397893, loss_ce: 0.031844
[20:37:18.880] iteration 14420 : loss : 0.360727, loss_ce: 0.030786
[20:37:25.294] iteration 14430 : loss : 0.375029, loss_ce: 0.043258
[20:37:31.693] iteration 14440 : loss : 0.372290, loss_ce: 0.042078
[20:37:38.103] iteration 14450 : loss : 0.362759, loss_ce: 0.031088
[20:37:44.499] iteration 14460 : loss : 0.361289, loss_ce: 0.053032
[20:37:50.907] iteration 14470 : loss : 0.207190, loss_ce: 0.031177
[20:37:57.309] iteration 14480 : loss : 0.354028, loss_ce: 0.028920
[20:38:03.726] iteration 14490 : loss : 0.358710, loss_ce: 0.041063
[20:38:10.124] iteration 14500 : loss : 0.383861, loss_ce: 0.055257
[20:38:16.531] iteration 14510 : loss : 0.367516, loss_ce: 0.035167
[20:38:22.934] iteration 14520 : loss : 0.374315, loss_ce: 0.048345
[20:38:29.348] iteration 14530 : loss : 0.209493, loss_ce: 0.035384
[20:38:35.745] iteration 14540 : loss : 0.355839, loss_ce: 0.030336
[20:38:42.158] iteration 14550 : loss : 0.362910, loss_ce: 0.034283
[20:38:48.561] iteration 14560 : loss : 0.363643, loss_ce: 0.045259
[20:38:54.976] iteration 14570 : loss : 0.363105, loss_ce: 0.039538
[20:39:01.374] iteration 14580 : loss : 0.354454, loss_ce: 0.027479
[20:39:07.784] iteration 14590 : loss : 0.196289, loss_ce: 0.024613
[20:39:14.185] iteration 14600 : loss : 0.348912, loss_ce: 0.036692
[20:39:20.600] iteration 14610 : loss : 0.370741, loss_ce: 0.031503
[20:39:27.001] iteration 14620 : loss : 0.368890, loss_ce: 0.035197
[20:39:33.413] iteration 14630 : loss : 0.388342, loss_ce: 0.025046
[20:39:39.818] iteration 14640 : loss : 0.345052, loss_ce: 0.025133
[20:39:46.225] iteration 14650 : loss : 0.370795, loss_ce: 0.031981
[20:39:52.625] iteration 14660 : loss : 0.338937, loss_ce: 0.018299
[20:39:59.036] iteration 14670 : loss : 0.361311, loss_ce: 0.026643
[20:40:05.436] iteration 14680 : loss : 0.370998, loss_ce: 0.055001
[20:40:11.847] iteration 14690 : loss : 0.346800, loss_ce: 0.023912
[20:40:18.247] iteration 14700 : loss : 0.323903, loss_ce: 0.029934
[20:40:24.665] iteration 14710 : loss : 0.376218, loss_ce: 0.026112
[20:40:28.759] Epoch 25: Average loss: 0.3510
[20:40:42.209] iteration 14720 : loss : 0.378841, loss_ce: 0.029075
[20:40:48.595] iteration 14730 : loss : 0.346172, loss_ce: 0.036461
[20:40:54.974] iteration 14740 : loss : 0.350040, loss_ce: 0.024418
[20:41:01.362] iteration 14750 : loss : 0.350774, loss_ce: 0.028626
[20:41:07.743] iteration 14760 : loss : 0.366384, loss_ce: 0.033520
[20:41:14.133] iteration 14770 : loss : 0.364833, loss_ce: 0.030263
[20:41:20.515] iteration 14780 : loss : 0.376851, loss_ce: 0.033027
[20:41:26.914] iteration 14790 : loss : 0.359559, loss_ce: 0.040893
[20:41:33.298] iteration 14800 : loss : 0.347453, loss_ce: 0.027967
[20:41:39.694] iteration 14810 : loss : 0.371195, loss_ce: 0.049437
[20:41:46.083] iteration 14820 : loss : 0.330966, loss_ce: 0.019905
[20:41:52.484] iteration 14830 : loss : 0.351247, loss_ce: 0.027587
[20:41:58.872] iteration 14840 : loss : 0.356725, loss_ce: 0.032382
[20:42:05.272] iteration 14850 : loss : 0.356926, loss_ce: 0.030313
[20:42:11.664] iteration 14860 : loss : 0.340069, loss_ce: 0.023555
[20:42:18.066] iteration 14870 : loss : 0.370362, loss_ce: 0.025475
[20:42:24.461] iteration 14880 : loss : 0.336306, loss_ce: 0.032761
[20:42:30.864] iteration 14890 : loss : 0.350143, loss_ce: 0.024946
[20:42:37.257] iteration 14900 : loss : 0.385994, loss_ce: 0.035545
[20:42:43.663] iteration 14910 : loss : 0.189850, loss_ce: 0.026717
[20:42:50.061] iteration 14920 : loss : 0.192742, loss_ce: 0.032379
[20:42:56.478] iteration 14930 : loss : 0.344620, loss_ce: 0.026852
[20:43:02.873] iteration 14940 : loss : 0.368425, loss_ce: 0.030090
[20:43:09.286] iteration 14950 : loss : 0.345507, loss_ce: 0.036426
[20:43:15.688] iteration 14960 : loss : 0.364322, loss_ce: 0.043771
[20:43:22.096] iteration 14970 : loss : 0.352180, loss_ce: 0.027063
[20:43:28.491] iteration 14980 : loss : 0.370649, loss_ce: 0.026154
[20:43:34.898] iteration 14990 : loss : 0.345604, loss_ce: 0.037303
[20:43:41.295] iteration 15000 : loss : 0.348315, loss_ce: 0.021033
[20:43:47.709] iteration 15010 : loss : 0.189320, loss_ce: 0.038633
[20:43:54.113] iteration 15020 : loss : 0.367631, loss_ce: 0.031247
[20:44:00.521] iteration 15030 : loss : 0.352450, loss_ce: 0.040419
[20:44:06.928] iteration 15040 : loss : 0.339064, loss_ce: 0.038312
[20:44:13.335] iteration 15050 : loss : 0.346255, loss_ce: 0.028423
[20:44:19.735] iteration 15060 : loss : 0.357818, loss_ce: 0.041605
[20:44:26.149] iteration 15070 : loss : 0.208579, loss_ce: 0.034399
[20:44:32.549] iteration 15080 : loss : 0.348359, loss_ce: 0.032551
[20:44:38.962] iteration 15090 : loss : 0.366099, loss_ce: 0.044621
[20:44:45.363] iteration 15100 : loss : 0.367374, loss_ce: 0.029975
[20:44:51.779] iteration 15110 : loss : 0.344498, loss_ce: 0.024412
[20:44:58.179] iteration 15120 : loss : 0.363248, loss_ce: 0.032686
[20:45:04.590] iteration 15130 : loss : 0.342473, loss_ce: 0.033933
[20:45:10.990] iteration 15140 : loss : 0.349189, loss_ce: 0.025896
[20:45:17.397] iteration 15150 : loss : 0.356390, loss_ce: 0.023411
[20:45:23.796] iteration 15160 : loss : 0.366839, loss_ce: 0.023432
[20:45:30.204] iteration 15170 : loss : 0.351215, loss_ce: 0.033218
[20:45:36.603] iteration 15180 : loss : 0.364093, loss_ce: 0.036478
[20:45:43.014] iteration 15190 : loss : 0.365990, loss_ce: 0.039929
[20:45:49.417] iteration 15200 : loss : 0.327338, loss_ce: 0.038023
[20:45:55.828] iteration 15210 : loss : 0.366619, loss_ce: 0.032334
[20:46:02.226] iteration 15220 : loss : 0.355788, loss_ce: 0.032827
[20:46:08.641] iteration 15230 : loss : 0.367397, loss_ce: 0.034444
[20:46:15.041] iteration 15240 : loss : 0.353841, loss_ce: 0.036680
[20:46:21.453] iteration 15250 : loss : 0.337890, loss_ce: 0.029530
[20:46:27.852] iteration 15260 : loss : 0.360056, loss_ce: 0.033017
[20:46:34.263] iteration 15270 : loss : 0.372136, loss_ce: 0.025722
[20:46:40.665] iteration 15280 : loss : 0.355728, loss_ce: 0.029881
[20:46:42.190] Epoch 26: Average loss: 0.3412
[20:52:26.936] iteration 15290 : loss : 0.200071, loss_ce: 0.017724
[20:52:33.292] iteration 15300 : loss : 0.337505, loss_ce: 0.023552
[20:52:39.663] iteration 15310 : loss : 0.368744, loss_ce: 0.022731
[20:52:46.026] iteration 15320 : loss : 0.404921, loss_ce: 0.045184
[20:52:52.400] iteration 15330 : loss : 0.380579, loss_ce: 0.026368
[20:52:58.763] iteration 15340 : loss : 0.355283, loss_ce: 0.028209
[20:53:05.138] iteration 15350 : loss : 0.198307, loss_ce: 0.021912
[20:53:11.513] iteration 15360 : loss : 0.213711, loss_ce: 0.045048
[20:53:17.904] iteration 15370 : loss : 0.360702, loss_ce: 0.036483
[20:53:24.276] iteration 15380 : loss : 0.355064, loss_ce: 0.023532
[20:53:30.670] iteration 15390 : loss : 0.367910, loss_ce: 0.036584
[20:53:37.054] iteration 15400 : loss : 0.345302, loss_ce: 0.028746
[20:53:43.445] iteration 15410 : loss : 0.348241, loss_ce: 0.036092
[20:53:49.826] iteration 15420 : loss : 0.347585, loss_ce: 0.025985
[20:53:56.220] iteration 15430 : loss : 0.355773, loss_ce: 0.033747
[20:54:02.601] iteration 15440 : loss : 0.386978, loss_ce: 0.047007
[20:54:08.996] iteration 15450 : loss : 0.357320, loss_ce: 0.033951
[20:54:15.382] iteration 15460 : loss : 0.366300, loss_ce: 0.038405
[20:54:21.785] iteration 15470 : loss : 0.347967, loss_ce: 0.024462
[20:54:28.175] iteration 15480 : loss : 0.367993, loss_ce: 0.039041
[20:54:34.583] iteration 15490 : loss : 0.361900, loss_ce: 0.037317
[20:54:40.975] iteration 15500 : loss : 0.367485, loss_ce: 0.037600
[20:54:47.377] iteration 15510 : loss : 0.369680, loss_ce: 0.060133
[20:54:53.769] iteration 15520 : loss : 0.350789, loss_ce: 0.031157
[20:55:00.175] iteration 15530 : loss : 0.218711, loss_ce: 0.039059
[20:55:06.571] iteration 15540 : loss : 0.354133, loss_ce: 0.051340
[20:55:12.973] iteration 15550 : loss : 0.374854, loss_ce: 0.036652
[20:55:19.368] iteration 15560 : loss : 0.354461, loss_ce: 0.044064
[20:55:25.772] iteration 15570 : loss : 0.366114, loss_ce: 0.038672
[20:55:32.172] iteration 15580 : loss : 0.351025, loss_ce: 0.039161
[20:55:38.575] iteration 15590 : loss : 0.381835, loss_ce: 0.027882
[20:55:44.968] iteration 15600 : loss : 0.382297, loss_ce: 0.038144
[20:55:51.385] iteration 15610 : loss : 0.352151, loss_ce: 0.030573
[20:55:57.784] iteration 15620 : loss : 0.331497, loss_ce: 0.032654
[20:56:04.198] iteration 15630 : loss : 0.364655, loss_ce: 0.033060
[20:56:10.603] iteration 15640 : loss : 0.352051, loss_ce: 0.029215
[20:56:17.027] iteration 15650 : loss : 0.351799, loss_ce: 0.032501
[20:56:23.428] iteration 15660 : loss : 0.347506, loss_ce: 0.031111
[20:56:29.851] iteration 15670 : loss : 0.361767, loss_ce: 0.041555
[20:56:36.258] iteration 15680 : loss : 0.358229, loss_ce: 0.037457
[20:56:42.681] iteration 15690 : loss : 0.363942, loss_ce: 0.030717
[20:56:49.093] iteration 15700 : loss : 0.189147, loss_ce: 0.031433
[20:56:55.522] iteration 15710 : loss : 0.220983, loss_ce: 0.049529
[20:57:01.934] iteration 15720 : loss : 0.395943, loss_ce: 0.047638
[20:57:08.352] iteration 15730 : loss : 0.371310, loss_ce: 0.029158
[20:57:14.762] iteration 15740 : loss : 0.351837, loss_ce: 0.035432
[20:57:21.191] iteration 15750 : loss : 0.376909, loss_ce: 0.041492
[20:57:27.606] iteration 15760 : loss : 0.348851, loss_ce: 0.041832
[20:57:34.042] iteration 15770 : loss : 0.346801, loss_ce: 0.034227
[20:57:40.457] iteration 15780 : loss : 0.320552, loss_ce: 0.020720
[20:57:46.887] iteration 15790 : loss : 0.369386, loss_ce: 0.022431
[20:57:53.304] iteration 15800 : loss : 0.339479, loss_ce: 0.030456
[20:57:59.733] iteration 15810 : loss : 0.370733, loss_ce: 0.055107
[20:58:06.148] iteration 15820 : loss : 0.397590, loss_ce: 0.039995
[20:58:12.568] iteration 15830 : loss : 0.358600, loss_ce: 0.023624
[20:58:18.982] iteration 15840 : loss : 0.438399, loss_ce: 0.062009
[20:58:24.407] Epoch 27: Average loss: 0.3473
[20:58:37.424] iteration 15850 : loss : 0.443129, loss_ce: 0.051334
[20:58:43.809] iteration 15860 : loss : 0.444065, loss_ce: 0.072490
[20:58:50.203] iteration 15870 : loss : 0.431174, loss_ce: 0.063127
[20:58:56.589] iteration 15880 : loss : 0.428531, loss_ce: 0.054528
[20:59:02.991] iteration 15890 : loss : 0.441470, loss_ce: 0.023549
[20:59:09.378] iteration 15900 : loss : 0.432804, loss_ce: 0.053531
[20:59:15.785] iteration 15910 : loss : 0.257554, loss_ce: 0.043246
[20:59:22.178] iteration 15920 : loss : 0.429209, loss_ce: 0.051277
[20:59:28.586] iteration 15930 : loss : 0.403613, loss_ce: 0.053899
[20:59:34.982] iteration 15940 : loss : 0.412109, loss_ce: 0.056307
[20:59:41.394] iteration 15950 : loss : 0.396547, loss_ce: 0.041066
[20:59:47.794] iteration 15960 : loss : 0.400715, loss_ce: 0.039385
[20:59:54.206] iteration 15970 : loss : 0.397143, loss_ce: 0.051014
[21:00:00.607] iteration 15980 : loss : 0.392461, loss_ce: 0.049483
[21:00:07.021] iteration 15990 : loss : 0.401410, loss_ce: 0.052129
[21:00:13.430] iteration 16000 : loss : 0.384463, loss_ce: 0.040172
[21:00:19.841] iteration 16010 : loss : 0.375137, loss_ce: 0.036077
[21:00:26.242] iteration 16020 : loss : 0.384600, loss_ce: 0.032926
[21:00:32.660] iteration 16030 : loss : 0.407998, loss_ce: 0.052347
[21:00:39.068] iteration 16040 : loss : 0.378051, loss_ce: 0.040293
[21:00:45.485] iteration 16050 : loss : 0.359316, loss_ce: 0.030106
[21:00:51.893] iteration 16060 : loss : 0.367523, loss_ce: 0.036109
[21:00:58.309] iteration 16070 : loss : 0.370999, loss_ce: 0.023453
[21:01:04.723] iteration 16080 : loss : 0.377277, loss_ce: 0.028998
[21:01:11.143] iteration 16090 : loss : 0.381877, loss_ce: 0.038873
[21:01:17.549] iteration 16100 : loss : 0.370988, loss_ce: 0.043786
[21:01:23.964] iteration 16110 : loss : 0.354133, loss_ce: 0.034390
[21:01:30.377] iteration 16120 : loss : 0.378702, loss_ce: 0.041219
[21:01:36.797] iteration 16130 : loss : 0.376596, loss_ce: 0.044654
[21:01:43.199] iteration 16140 : loss : 0.387603, loss_ce: 0.053091
[21:01:49.626] iteration 16150 : loss : 0.359027, loss_ce: 0.042009
[21:01:56.031] iteration 16160 : loss : 0.371378, loss_ce: 0.031860
[21:02:02.452] iteration 16170 : loss : 0.379864, loss_ce: 0.048054
[21:02:08.869] iteration 16180 : loss : 0.368719, loss_ce: 0.041300
[21:02:15.281] iteration 16190 : loss : 0.373711, loss_ce: 0.043947
[21:02:21.691] iteration 16200 : loss : 0.350969, loss_ce: 0.031372
[21:02:28.114] iteration 16210 : loss : 0.347422, loss_ce: 0.022924
[21:02:34.527] iteration 16220 : loss : 0.366514, loss_ce: 0.034406
[21:02:40.956] iteration 16230 : loss : 0.370503, loss_ce: 0.035396
[21:02:47.373] iteration 16240 : loss : 0.362009, loss_ce: 0.034421
[21:02:53.795] iteration 16250 : loss : 0.402500, loss_ce: 0.038190
[21:03:00.208] iteration 16260 : loss : 0.350262, loss_ce: 0.037556
[21:03:06.629] iteration 16270 : loss : 0.356898, loss_ce: 0.031262
[21:03:13.039] iteration 16280 : loss : 0.367937, loss_ce: 0.035571
[21:03:19.461] iteration 16290 : loss : 0.348443, loss_ce: 0.029976
[21:03:25.866] iteration 16300 : loss : 0.404454, loss_ce: 0.030291
[21:03:32.288] iteration 16310 : loss : 0.365152, loss_ce: 0.044543
[21:03:38.699] iteration 16320 : loss : 0.374684, loss_ce: 0.053640
[21:03:45.121] iteration 16330 : loss : 0.360167, loss_ce: 0.031183
[21:03:51.538] iteration 16340 : loss : 0.200855, loss_ce: 0.030153
[21:03:57.960] iteration 16350 : loss : 0.362254, loss_ce: 0.036549
[21:04:04.373] iteration 16360 : loss : 0.365944, loss_ce: 0.037027
[21:04:10.795] iteration 16370 : loss : 0.364090, loss_ce: 0.029882
[21:04:17.211] iteration 16380 : loss : 0.361872, loss_ce: 0.040331
[21:04:23.637] iteration 16390 : loss : 0.358143, loss_ce: 0.029487
[21:04:30.042] iteration 16400 : loss : 0.230380, loss_ce: 0.045490
[21:04:36.465] iteration 16410 : loss : 0.354753, loss_ce: 0.032785
[21:04:39.307] Epoch 28: Average loss: 0.3717
[21:04:55.443] iteration 16420 : loss : 0.198575, loss_ce: 0.028017
[21:05:01.835] iteration 16430 : loss : 0.362653, loss_ce: 0.037552
[21:05:08.222] iteration 16440 : loss : 0.383360, loss_ce: 0.048145
[21:05:14.619] iteration 16450 : loss : 0.357407, loss_ce: 0.042335
[21:05:21.010] iteration 16460 : loss : 0.349153, loss_ce: 0.051169
[21:05:27.411] iteration 16470 : loss : 0.365174, loss_ce: 0.021058
[21:05:33.798] iteration 16480 : loss : 0.199653, loss_ce: 0.025744
[21:05:40.200] iteration 16490 : loss : 0.360133, loss_ce: 0.028912
[21:05:46.590] iteration 16500 : loss : 0.354199, loss_ce: 0.043785
[21:05:52.994] iteration 16510 : loss : 0.375708, loss_ce: 0.041170
[21:05:59.387] iteration 16520 : loss : 0.361357, loss_ce: 0.024243
[21:06:05.798] iteration 16530 : loss : 0.389106, loss_ce: 0.045865
[21:06:12.193] iteration 16540 : loss : 0.354693, loss_ce: 0.032447
[21:06:18.608] iteration 16550 : loss : 0.345575, loss_ce: 0.043447
[21:06:25.009] iteration 16560 : loss : 0.347803, loss_ce: 0.035642
[21:06:31.426] iteration 16570 : loss : 0.378438, loss_ce: 0.049381
[21:06:37.827] iteration 16580 : loss : 0.377810, loss_ce: 0.032527
[21:06:44.243] iteration 16590 : loss : 0.364922, loss_ce: 0.023847
[21:06:50.647] iteration 16600 : loss : 0.359890, loss_ce: 0.051154
[21:06:57.060] iteration 16610 : loss : 0.361562, loss_ce: 0.033317
[21:07:03.460] iteration 16620 : loss : 0.354284, loss_ce: 0.038757
[21:07:09.875] iteration 16630 : loss : 0.342252, loss_ce: 0.027109
[21:07:16.287] iteration 16640 : loss : 0.365595, loss_ce: 0.035223
[21:07:22.709] iteration 16650 : loss : 0.355274, loss_ce: 0.034649
[21:07:29.123] iteration 16660 : loss : 0.349204, loss_ce: 0.021262
[21:07:35.540] iteration 16670 : loss : 0.361552, loss_ce: 0.027612
[21:07:41.942] iteration 16680 : loss : 0.347239, loss_ce: 0.040163
[21:07:48.365] iteration 16690 : loss : 0.349301, loss_ce: 0.032654
[21:07:54.775] iteration 16700 : loss : 0.370743, loss_ce: 0.034305
[21:08:01.191] iteration 16710 : loss : 0.319394, loss_ce: 0.024028
[21:08:07.604] iteration 16720 : loss : 0.359020, loss_ce: 0.029834
[21:08:14.030] iteration 16730 : loss : 0.357442, loss_ce: 0.021797
[21:08:20.437] iteration 16740 : loss : 0.360119, loss_ce: 0.017832
[21:08:26.858] iteration 16750 : loss : 0.371044, loss_ce: 0.034329
[21:08:33.267] iteration 16760 : loss : 0.362780, loss_ce: 0.029567
[21:08:39.688] iteration 16770 : loss : 0.365637, loss_ce: 0.022724
[21:08:46.101] iteration 16780 : loss : 0.341236, loss_ce: 0.027846
[21:08:52.522] iteration 16790 : loss : 0.335816, loss_ce: 0.035781
[21:08:58.931] iteration 16800 : loss : 0.333485, loss_ce: 0.036061
[21:09:05.347] iteration 16810 : loss : 0.380500, loss_ce: 0.031832
[21:09:11.757] iteration 16820 : loss : 0.347970, loss_ce: 0.021253
[21:09:18.182] iteration 16830 : loss : 0.346216, loss_ce: 0.034874
[21:09:24.592] iteration 16840 : loss : 0.369404, loss_ce: 0.031474
[21:09:31.010] iteration 16850 : loss : 0.354332, loss_ce: 0.027171
[21:09:37.418] iteration 16860 : loss : 0.320830, loss_ce: 0.024831
[21:09:43.836] iteration 16870 : loss : 0.350565, loss_ce: 0.029337
[21:09:50.247] iteration 16880 : loss : 0.209972, loss_ce: 0.024567
[21:09:56.665] iteration 16890 : loss : 0.373803, loss_ce: 0.036107
[21:10:03.083] iteration 16900 : loss : 0.351325, loss_ce: 0.037836
[21:10:09.502] iteration 16910 : loss : 0.370749, loss_ce: 0.024155
[21:10:15.914] iteration 16920 : loss : 0.364426, loss_ce: 0.025499
[21:10:22.336] iteration 16930 : loss : 0.354783, loss_ce: 0.032093
[21:10:28.738] iteration 16940 : loss : 0.333793, loss_ce: 0.024461
[21:10:35.168] iteration 16950 : loss : 0.335206, loss_ce: 0.014526
[21:10:41.574] iteration 16960 : loss : 0.356433, loss_ce: 0.041007
[21:10:47.993] iteration 16970 : loss : 0.353974, loss_ce: 0.034619
[21:10:53.977] iteration 16980 : loss : 0.241863, loss_ce: 0.036376
[21:10:54.699] Epoch 29: Average loss: 0.3469
[21:16:38.372] save model to ./finetune_tpgm_kits23_continual_fixed\finetuned_epoch_29.pth
[21:16:56.767] iteration 16990 : loss : 0.343225, loss_ce: 0.032215
[21:17:03.125] iteration 17000 : loss : 0.356932, loss_ce: 0.037219
[21:17:09.495] iteration 17010 : loss : 0.339309, loss_ce: 0.029879
[21:17:15.854] iteration 17020 : loss : 0.358652, loss_ce: 0.027579
[21:17:22.228] iteration 17030 : loss : 0.363463, loss_ce: 0.030288
[21:17:28.605] iteration 17040 : loss : 0.380075, loss_ce: 0.045510
[21:17:34.990] iteration 17050 : loss : 0.332284, loss_ce: 0.025729
[21:17:41.361] iteration 17060 : loss : 0.335348, loss_ce: 0.027006
[21:17:47.740] iteration 17070 : loss : 0.350460, loss_ce: 0.042760
[21:17:54.114] iteration 17080 : loss : 0.340093, loss_ce: 0.020147
[21:18:00.502] iteration 17090 : loss : 0.333284, loss_ce: 0.026840
[21:18:06.877] iteration 17100 : loss : 0.365626, loss_ce: 0.031920
[21:18:13.264] iteration 17110 : loss : 0.360065, loss_ce: 0.049193
[21:18:19.640] iteration 17120 : loss : 0.342772, loss_ce: 0.023415
[21:18:26.031] iteration 17130 : loss : 0.189752, loss_ce: 0.026844
[21:18:32.415] iteration 17140 : loss : 0.355207, loss_ce: 0.034864
[21:18:38.808] iteration 17150 : loss : 0.356951, loss_ce: 0.022937
[21:18:45.194] iteration 17160 : loss : 0.363709, loss_ce: 0.044726
[21:18:51.586] iteration 17170 : loss : 0.352396, loss_ce: 0.029192
[21:18:57.971] iteration 17180 : loss : 0.357928, loss_ce: 0.042669
[21:19:04.367] iteration 17190 : loss : 0.342727, loss_ce: 0.041329
[21:19:10.755] iteration 17200 : loss : 0.227354, loss_ce: 0.036838
[21:19:17.152] iteration 17210 : loss : 0.329572, loss_ce: 0.029648
[21:19:23.537] iteration 17220 : loss : 0.342985, loss_ce: 0.029806
[21:19:29.939] iteration 17230 : loss : 0.344795, loss_ce: 0.030601
[21:19:36.328] iteration 17240 : loss : 0.342553, loss_ce: 0.021549
[21:19:42.728] iteration 17250 : loss : 0.359154, loss_ce: 0.038243
[21:19:49.119] iteration 17260 : loss : 0.360668, loss_ce: 0.032449
[21:19:55.523] iteration 17270 : loss : 0.343496, loss_ce: 0.031184
[21:20:01.919] iteration 17280 : loss : 0.341997, loss_ce: 0.024014
[21:20:08.327] iteration 17290 : loss : 0.367974, loss_ce: 0.039943
[21:20:14.722] iteration 17300 : loss : 0.343825, loss_ce: 0.024803
[21:20:21.135] iteration 17310 : loss : 0.333453, loss_ce: 0.020310
[21:20:27.535] iteration 17320 : loss : 0.363070, loss_ce: 0.036404
[21:20:33.947] iteration 17330 : loss : 0.352381, loss_ce: 0.029355
[21:20:40.355] iteration 17340 : loss : 0.348557, loss_ce: 0.036995
[21:20:46.766] iteration 17350 : loss : 0.358752, loss_ce: 0.023597
[21:20:53.167] iteration 17360 : loss : 0.357870, loss_ce: 0.034205
[21:20:59.579] iteration 17370 : loss : 0.356754, loss_ce: 0.034858
[21:21:05.981] iteration 17380 : loss : 0.347543, loss_ce: 0.032589
[21:21:12.404] iteration 17390 : loss : 0.349549, loss_ce: 0.039195
[21:21:18.809] iteration 17400 : loss : 0.338963, loss_ce: 0.030308
[21:21:25.222] iteration 17410 : loss : 0.326061, loss_ce: 0.022175
[21:21:31.622] iteration 17420 : loss : 0.342049, loss_ce: 0.028713
[21:21:38.040] iteration 17430 : loss : 0.358998, loss_ce: 0.033444
[21:21:44.452] iteration 17440 : loss : 0.363704, loss_ce: 0.044035
[21:21:50.869] iteration 17450 : loss : 0.334623, loss_ce: 0.020055
[21:21:57.280] iteration 17460 : loss : 0.353785, loss_ce: 0.032497
[21:22:03.711] iteration 17470 : loss : 0.323126, loss_ce: 0.031954
[21:22:10.116] iteration 17480 : loss : 0.357269, loss_ce: 0.018263
[21:22:16.545] iteration 17490 : loss : 0.352586, loss_ce: 0.019320
[21:22:22.955] iteration 17500 : loss : 0.331426, loss_ce: 0.030195
[21:22:29.386] iteration 17510 : loss : 0.210941, loss_ce: 0.035582
[21:22:35.801] iteration 17520 : loss : 0.376102, loss_ce: 0.049753
[21:22:42.223] iteration 17530 : loss : 0.362114, loss_ce: 0.027117
[21:22:48.641] iteration 17540 : loss : 0.344110, loss_ce: 0.037249
[21:22:52.782] Epoch 30: Average loss: 0.3374
[21:23:07.639] iteration 17550 : loss : 0.365742, loss_ce: 0.048941
[21:23:14.017] iteration 17560 : loss : 0.339491, loss_ce: 0.015444
[21:23:20.411] iteration 17570 : loss : 0.344135, loss_ce: 0.018007
[21:23:26.795] iteration 17580 : loss : 0.338341, loss_ce: 0.057134
[21:23:33.191] iteration 17590 : loss : 0.354941, loss_ce: 0.026910
[21:23:39.580] iteration 17600 : loss : 0.339512, loss_ce: 0.038893
[21:23:45.981] iteration 17610 : loss : 0.323695, loss_ce: 0.025280
[21:23:52.372] iteration 17620 : loss : 0.363960, loss_ce: 0.041216
[21:23:58.775] iteration 17630 : loss : 0.337121, loss_ce: 0.017698
[21:24:05.165] iteration 17640 : loss : 0.194990, loss_ce: 0.012253
[21:24:11.568] iteration 17650 : loss : 0.327982, loss_ce: 0.022537
[21:24:17.960] iteration 17660 : loss : 0.171374, loss_ce: 0.020369
[21:24:24.364] iteration 17670 : loss : 0.194478, loss_ce: 0.010436
[21:24:30.755] iteration 17680 : loss : 0.359916, loss_ce: 0.039680
[21:24:37.157] iteration 17690 : loss : 0.331983, loss_ce: 0.027905
[21:24:43.549] iteration 17700 : loss : 0.358597, loss_ce: 0.027198
[21:24:49.956] iteration 17710 : loss : 0.310415, loss_ce: 0.014739
[21:24:56.352] iteration 17720 : loss : 0.355022, loss_ce: 0.034181
[21:25:02.760] iteration 17730 : loss : 0.334518, loss_ce: 0.033210
[21:25:09.164] iteration 17740 : loss : 0.344582, loss_ce: 0.024050
[21:25:15.571] iteration 17750 : loss : 0.346306, loss_ce: 0.025434
[21:25:21.969] iteration 17760 : loss : 0.327337, loss_ce: 0.034224
[21:25:28.386] iteration 17770 : loss : 0.339097, loss_ce: 0.047687
[21:25:34.787] iteration 17780 : loss : 0.208032, loss_ce: 0.028892
[21:25:41.198] iteration 17790 : loss : 0.317809, loss_ce: 0.028105
[21:25:47.599] iteration 17800 : loss : 0.344485, loss_ce: 0.022929
[21:25:54.011] iteration 17810 : loss : 0.349300, loss_ce: 0.030636
[21:26:00.417] iteration 17820 : loss : 0.335573, loss_ce: 0.020359
[21:26:06.839] iteration 17830 : loss : 0.313603, loss_ce: 0.021698
[21:26:13.241] iteration 17840 : loss : 0.333726, loss_ce: 0.031974
[21:26:19.660] iteration 17850 : loss : 0.362206, loss_ce: 0.035892
[21:26:26.067] iteration 17860 : loss : 0.345964, loss_ce: 0.015741
[21:26:32.485] iteration 17870 : loss : 0.317081, loss_ce: 0.021905
[21:26:38.891] iteration 17880 : loss : 0.202566, loss_ce: 0.034606
[21:26:45.306] iteration 17890 : loss : 0.346116, loss_ce: 0.033904
[21:26:51.712] iteration 17900 : loss : 0.347387, loss_ce: 0.022879
[21:26:58.128] iteration 17910 : loss : 0.191697, loss_ce: 0.042908
[21:27:04.532] iteration 17920 : loss : 0.320948, loss_ce: 0.026048
[21:27:10.951] iteration 17930 : loss : 0.358756, loss_ce: 0.022421
[21:27:17.352] iteration 17940 : loss : 0.343313, loss_ce: 0.050722
[21:27:23.767] iteration 17950 : loss : 0.312193, loss_ce: 0.020972
[21:27:30.169] iteration 17960 : loss : 0.333189, loss_ce: 0.028708
[21:27:36.587] iteration 17970 : loss : 0.341051, loss_ce: 0.019504
[21:27:42.997] iteration 17980 : loss : 0.341562, loss_ce: 0.036226
[21:27:49.411] iteration 17990 : loss : 0.335971, loss_ce: 0.027972
[21:27:55.818] iteration 18000 : loss : 0.338571, loss_ce: 0.030973
[21:28:02.246] iteration 18010 : loss : 0.360451, loss_ce: 0.035722
[21:28:08.659] iteration 18020 : loss : 0.322323, loss_ce: 0.020259
[21:28:15.079] iteration 18030 : loss : 0.356553, loss_ce: 0.047160
[21:28:21.487] iteration 18040 : loss : 0.359154, loss_ce: 0.029723
[21:28:27.906] iteration 18050 : loss : 0.356322, loss_ce: 0.031882
[21:28:34.314] iteration 18060 : loss : 0.337908, loss_ce: 0.022866
[21:28:40.732] iteration 18070 : loss : 0.336342, loss_ce: 0.024094
[21:28:47.137] iteration 18080 : loss : 0.349717, loss_ce: 0.020770
[21:28:53.558] iteration 18090 : loss : 0.313860, loss_ce: 0.038672
[21:28:59.970] iteration 18100 : loss : 0.195334, loss_ce: 0.022594
[21:29:06.387] iteration 18110 : loss : 0.304097, loss_ce: 0.022496
[21:29:07.921] Epoch 31: Average loss: 0.3293
[21:29:24.883] iteration 18120 : loss : 0.361066, loss_ce: 0.041822
[21:29:31.271] iteration 18130 : loss : 0.346903, loss_ce: 0.023548
[21:29:37.658] iteration 18140 : loss : 0.378042, loss_ce: 0.062546
[21:29:44.054] iteration 18150 : loss : 0.341465, loss_ce: 0.023340
[21:29:50.440] iteration 18160 : loss : 0.346253, loss_ce: 0.039191
[21:29:56.836] iteration 18170 : loss : 0.208214, loss_ce: 0.026136
[21:30:03.221] iteration 18180 : loss : 0.351946, loss_ce: 0.030402
[21:30:09.619] iteration 18190 : loss : 0.308796, loss_ce: 0.021396
[21:30:16.008] iteration 18200 : loss : 0.334878, loss_ce: 0.021336
[21:30:22.417] iteration 18210 : loss : 0.315027, loss_ce: 0.029833
[21:30:28.807] iteration 18220 : loss : 0.341874, loss_ce: 0.032007
[21:30:35.209] iteration 18230 : loss : 0.184931, loss_ce: 0.026082
[21:30:41.604] iteration 18240 : loss : 0.340708, loss_ce: 0.047418
[21:30:48.008] iteration 18250 : loss : 0.380556, loss_ce: 0.032583
[21:30:54.405] iteration 18260 : loss : 0.332096, loss_ce: 0.015001
[21:31:00.811] iteration 18270 : loss : 0.362744, loss_ce: 0.035333
[21:31:07.209] iteration 18280 : loss : 0.342905, loss_ce: 0.031346
[21:31:13.622] iteration 18290 : loss : 0.324338, loss_ce: 0.035687
[21:31:20.021] iteration 18300 : loss : 0.344002, loss_ce: 0.031448
[21:31:26.433] iteration 18310 : loss : 0.359975, loss_ce: 0.047327
[21:31:32.835] iteration 18320 : loss : 0.310027, loss_ce: 0.023957
[21:31:39.248] iteration 18330 : loss : 0.333339, loss_ce: 0.016306
[21:31:45.655] iteration 18340 : loss : 0.334305, loss_ce: 0.018285
[21:31:52.070] iteration 18350 : loss : 0.171495, loss_ce: 0.028345
[21:31:58.474] iteration 18360 : loss : 0.370997, loss_ce: 0.034096
[21:32:04.890] iteration 18370 : loss : 0.344503, loss_ce: 0.023596
[21:32:11.291] iteration 18380 : loss : 0.332178, loss_ce: 0.033120
[21:32:17.705] iteration 18390 : loss : 0.349413, loss_ce: 0.017757
[21:32:24.109] iteration 18400 : loss : 0.355526, loss_ce: 0.023596
[21:32:30.530] iteration 18410 : loss : 0.343795, loss_ce: 0.025874
[21:32:36.930] iteration 18420 : loss : 0.196753, loss_ce: 0.029302
[21:32:43.347] iteration 18430 : loss : 0.309579, loss_ce: 0.018127
[21:32:49.750] iteration 18440 : loss : 0.341489, loss_ce: 0.038611
[21:32:56.171] iteration 18450 : loss : 0.344840, loss_ce: 0.040291
[21:33:02.573] iteration 18460 : loss : 0.359861, loss_ce: 0.033693
[21:33:08.991] iteration 18470 : loss : 0.354238, loss_ce: 0.031654
[21:33:15.400] iteration 18480 : loss : 0.354635, loss_ce: 0.033188
[21:33:21.818] iteration 18490 : loss : 0.323667, loss_ce: 0.015876
[21:33:28.226] iteration 18500 : loss : 0.321014, loss_ce: 0.022571
[21:33:34.640] iteration 18510 : loss : 0.176056, loss_ce: 0.028725
[21:33:41.052] iteration 18520 : loss : 0.340606, loss_ce: 0.023066
[21:33:47.478] iteration 18530 : loss : 0.320863, loss_ce: 0.015495
[21:33:53.888] iteration 18540 : loss : 0.318539, loss_ce: 0.020745
[21:34:00.308] iteration 18550 : loss : 0.364419, loss_ce: 0.036693
[21:34:06.722] iteration 18560 : loss : 0.341903, loss_ce: 0.031110
[21:34:13.136] iteration 18570 : loss : 0.353085, loss_ce: 0.035999
[21:34:19.541] iteration 18580 : loss : 0.187854, loss_ce: 0.031957
[21:34:25.958] iteration 18590 : loss : 0.353031, loss_ce: 0.043197
[21:34:32.367] iteration 18600 : loss : 0.355420, loss_ce: 0.034612
[21:34:38.783] iteration 18610 : loss : 0.323950, loss_ce: 0.036867
[21:34:45.188] iteration 18620 : loss : 0.342179, loss_ce: 0.042693
[21:34:51.611] iteration 18630 : loss : 0.298615, loss_ce: 0.014831
[21:34:58.015] iteration 18640 : loss : 0.377586, loss_ce: 0.029717
[21:35:04.443] iteration 18650 : loss : 0.335454, loss_ce: 0.028747
[21:35:10.851] iteration 18660 : loss : 0.348435, loss_ce: 0.028997
[21:35:17.269] iteration 18670 : loss : 0.348515, loss_ce: 0.045729
[21:35:22.696] Epoch 32: Average loss: 0.3288
[21:41:20.845] iteration 18680 : loss : 0.287521, loss_ce: 0.015419
[21:41:27.204] iteration 18690 : loss : 0.347346, loss_ce: 0.035783
[21:41:33.556] iteration 18700 : loss : 0.326422, loss_ce: 0.029691
[21:41:39.919] iteration 18710 : loss : 0.351652, loss_ce: 0.037012
[21:41:46.278] iteration 18720 : loss : 0.338540, loss_ce: 0.016874
[21:41:52.648] iteration 18730 : loss : 0.333393, loss_ce: 0.037932
[21:41:59.016] iteration 18740 : loss : 0.319785, loss_ce: 0.022107
[21:42:05.399] iteration 18750 : loss : 0.339863, loss_ce: 0.035629
[21:42:11.767] iteration 18760 : loss : 0.357849, loss_ce: 0.024384
[21:42:18.148] iteration 18770 : loss : 0.331388, loss_ce: 0.031542
[21:42:24.518] iteration 18780 : loss : 0.343304, loss_ce: 0.021662
[21:42:30.902] iteration 18790 : loss : 0.334048, loss_ce: 0.035405
[21:42:37.274] iteration 18800 : loss : 0.338225, loss_ce: 0.039798
[21:42:43.659] iteration 18810 : loss : 0.354266, loss_ce: 0.033098
[21:42:50.043] iteration 18820 : loss : 0.341154, loss_ce: 0.040844
[21:42:56.436] iteration 18830 : loss : 0.324089, loss_ce: 0.029470
[21:43:02.819] iteration 18840 : loss : 0.328895, loss_ce: 0.033342
[21:43:09.216] iteration 18850 : loss : 0.317128, loss_ce: 0.020971
[21:43:15.600] iteration 18860 : loss : 0.394552, loss_ce: 0.045655
[21:43:21.995] iteration 18870 : loss : 0.329503, loss_ce: 0.025461
[21:43:28.382] iteration 18880 : loss : 0.329103, loss_ce: 0.025493
[21:43:34.780] iteration 18890 : loss : 0.334148, loss_ce: 0.020812
[21:43:41.167] iteration 18900 : loss : 0.339546, loss_ce: 0.020246
[21:43:47.567] iteration 18910 : loss : 0.333824, loss_ce: 0.027852
[21:43:53.955] iteration 18920 : loss : 0.189545, loss_ce: 0.045638
[21:44:00.357] iteration 18930 : loss : 0.371837, loss_ce: 0.028236
[21:44:06.748] iteration 18940 : loss : 0.327253, loss_ce: 0.022669
[21:44:13.153] iteration 18950 : loss : 0.333979, loss_ce: 0.032008
[21:44:19.543] iteration 18960 : loss : 0.174429, loss_ce: 0.032265
[21:44:25.945] iteration 18970 : loss : 0.316043, loss_ce: 0.024935
[21:44:32.337] iteration 18980 : loss : 0.325361, loss_ce: 0.025258
[21:44:38.740] iteration 18990 : loss : 0.316816, loss_ce: 0.036942
[21:44:45.133] iteration 19000 : loss : 0.314663, loss_ce: 0.026147
[21:44:51.543] iteration 19010 : loss : 0.185235, loss_ce: 0.030462
[21:44:57.943] iteration 19020 : loss : 0.344501, loss_ce: 0.034347
[21:45:04.350] iteration 19030 : loss : 0.341161, loss_ce: 0.026303
[21:45:10.746] iteration 19040 : loss : 0.355788, loss_ce: 0.024603
[21:45:17.161] iteration 19050 : loss : 0.329347, loss_ce: 0.019366
[21:45:23.567] iteration 19060 : loss : 0.335885, loss_ce: 0.017710
[21:45:29.978] iteration 19070 : loss : 0.349040, loss_ce: 0.028877
[21:45:36.377] iteration 19080 : loss : 0.166177, loss_ce: 0.022560
[21:45:42.797] iteration 19090 : loss : 0.320996, loss_ce: 0.024610
[21:45:49.203] iteration 19100 : loss : 0.346560, loss_ce: 0.036489
[21:45:55.619] iteration 19110 : loss : 0.356472, loss_ce: 0.026671
[21:46:02.020] iteration 19120 : loss : 0.344450, loss_ce: 0.029181
[21:46:08.433] iteration 19130 : loss : 0.325761, loss_ce: 0.021826
[21:46:14.840] iteration 19140 : loss : 0.345671, loss_ce: 0.021123
[21:46:21.267] iteration 19150 : loss : 0.342346, loss_ce: 0.042203
[21:46:27.679] iteration 19160 : loss : 0.325635, loss_ce: 0.030588
[21:46:34.097] iteration 19170 : loss : 0.354671, loss_ce: 0.025490
[21:46:40.503] iteration 19180 : loss : 0.337301, loss_ce: 0.019530
[21:46:46.927] iteration 19190 : loss : 0.313842, loss_ce: 0.012324
[21:46:53.338] iteration 19200 : loss : 0.168055, loss_ce: 0.021434
[21:46:59.766] iteration 19210 : loss : 0.189193, loss_ce: 0.029977
[21:47:06.182] iteration 19220 : loss : 0.327728, loss_ce: 0.018502
[21:47:12.606] iteration 19230 : loss : 0.301643, loss_ce: 0.016654
[21:47:19.028] iteration 19240 : loss : 0.173591, loss_ce: 0.018397
[21:47:21.885] Epoch 33: Average loss: 0.3168
[21:47:38.071] iteration 19250 : loss : 0.331488, loss_ce: 0.021528
[21:47:44.454] iteration 19260 : loss : 0.330898, loss_ce: 0.029001
[21:47:50.847] iteration 19270 : loss : 0.314389, loss_ce: 0.023663
[21:47:57.234] iteration 19280 : loss : 0.322118, loss_ce: 0.023536
[21:48:03.636] iteration 19290 : loss : 0.375087, loss_ce: 0.029193
[21:48:10.028] iteration 19300 : loss : 0.318230, loss_ce: 0.021426
[21:48:16.428] iteration 19310 : loss : 0.352017, loss_ce: 0.023717
[21:48:22.818] iteration 19320 : loss : 0.325407, loss_ce: 0.025661
[21:48:29.219] iteration 19330 : loss : 0.370433, loss_ce: 0.034733
[21:48:35.616] iteration 19340 : loss : 0.332523, loss_ce: 0.038031
[21:48:42.020] iteration 19350 : loss : 0.339588, loss_ce: 0.031672
[21:48:48.417] iteration 19360 : loss : 0.362402, loss_ce: 0.040564
[21:48:54.822] iteration 19370 : loss : 0.325122, loss_ce: 0.022800
[21:49:01.218] iteration 19380 : loss : 0.303171, loss_ce: 0.023210
[21:49:07.629] iteration 19390 : loss : 0.195037, loss_ce: 0.030305
[21:49:14.029] iteration 19400 : loss : 0.308154, loss_ce: 0.027318
[21:49:20.441] iteration 19410 : loss : 0.326413, loss_ce: 0.019456
[21:49:26.841] iteration 19420 : loss : 0.335028, loss_ce: 0.027519
[21:49:33.248] iteration 19430 : loss : 0.170419, loss_ce: 0.018703
[21:49:39.648] iteration 19440 : loss : 0.326241, loss_ce: 0.030591
[21:49:46.057] iteration 19450 : loss : 0.321474, loss_ce: 0.033022
[21:49:52.461] iteration 19460 : loss : 0.317958, loss_ce: 0.013524
[21:49:58.874] iteration 19470 : loss : 0.315863, loss_ce: 0.017288
[21:50:05.276] iteration 19480 : loss : 0.314772, loss_ce: 0.029099
[21:50:11.695] iteration 19490 : loss : 0.342520, loss_ce: 0.027648
[21:50:18.101] iteration 19500 : loss : 0.186077, loss_ce: 0.028562
[21:50:24.511] iteration 19510 : loss : 0.161596, loss_ce: 0.024140
[21:50:30.910] iteration 19520 : loss : 0.340076, loss_ce: 0.024290
[21:50:37.324] iteration 19530 : loss : 0.327545, loss_ce: 0.021791
[21:50:43.728] iteration 19540 : loss : 0.375122, loss_ce: 0.022645
[21:50:50.137] iteration 19550 : loss : 0.329617, loss_ce: 0.017032
[21:50:56.538] iteration 19560 : loss : 0.317567, loss_ce: 0.019191
[21:51:02.960] iteration 19570 : loss : 0.329554, loss_ce: 0.025105
[21:51:09.365] iteration 19580 : loss : 0.321485, loss_ce: 0.034178
[21:51:15.785] iteration 19590 : loss : 0.341041, loss_ce: 0.022466
[21:51:22.194] iteration 19600 : loss : 0.340485, loss_ce: 0.020295
[21:51:28.617] iteration 19610 : loss : 0.346528, loss_ce: 0.022985
[21:51:35.023] iteration 19620 : loss : 0.152507, loss_ce: 0.012812
[21:51:41.445] iteration 19630 : loss : 0.173830, loss_ce: 0.024829
[21:51:47.849] iteration 19640 : loss : 0.347469, loss_ce: 0.044430
[21:51:54.271] iteration 19650 : loss : 0.317301, loss_ce: 0.016479
[21:52:00.681] iteration 19660 : loss : 0.320473, loss_ce: 0.019588
[21:52:07.102] iteration 19670 : loss : 0.320537, loss_ce: 0.031235
[21:52:13.506] iteration 19680 : loss : 0.310320, loss_ce: 0.017290
[21:52:19.919] iteration 19690 : loss : 0.314105, loss_ce: 0.026341
[21:52:26.324] iteration 19700 : loss : 0.333985, loss_ce: 0.044039
[21:52:32.743] iteration 19710 : loss : 0.308403, loss_ce: 0.023339
[21:52:39.152] iteration 19720 : loss : 0.347215, loss_ce: 0.035226
[21:52:45.574] iteration 19730 : loss : 0.343254, loss_ce: 0.029485
[21:52:51.981] iteration 19740 : loss : 0.312480, loss_ce: 0.015253
[21:52:58.401] iteration 19750 : loss : 0.310088, loss_ce: 0.021594
[21:53:04.813] iteration 19760 : loss : 0.287477, loss_ce: 0.029225
[21:53:11.232] iteration 19770 : loss : 0.329307, loss_ce: 0.055721
[21:53:17.640] iteration 19780 : loss : 0.317121, loss_ce: 0.030648
[21:53:24.061] iteration 19790 : loss : 0.319906, loss_ce: 0.023375
[21:53:30.465] iteration 19800 : loss : 0.323988, loss_ce: 0.021506
[21:53:36.457] iteration 19810 : loss : 0.192207, loss_ce: 0.027748
[21:53:37.179] Epoch 34: Average loss: 0.3109
[21:53:55.323] iteration 19820 : loss : 0.309172, loss_ce: 0.018721
[21:54:01.717] iteration 19830 : loss : 0.344517, loss_ce: 0.024641
[21:54:08.098] iteration 19840 : loss : 0.299120, loss_ce: 0.015665
[21:54:14.491] iteration 19850 : loss : 0.321260, loss_ce: 0.020926
[21:54:20.877] iteration 19860 : loss : 0.334075, loss_ce: 0.016524
[21:54:27.275] iteration 19870 : loss : 0.294759, loss_ce: 0.017386
[21:54:33.662] iteration 19880 : loss : 0.352719, loss_ce: 0.044939
[21:54:40.059] iteration 19890 : loss : 0.310689, loss_ce: 0.023433
[21:54:46.447] iteration 19900 : loss : 0.325036, loss_ce: 0.021745
[21:54:52.849] iteration 19910 : loss : 0.338808, loss_ce: 0.033558
[21:54:59.239] iteration 19920 : loss : 0.324484, loss_ce: 0.027334
[21:55:05.639] iteration 19930 : loss : 0.317600, loss_ce: 0.017556
[21:55:12.034] iteration 19940 : loss : 0.318928, loss_ce: 0.018772
[21:55:18.449] iteration 19950 : loss : 0.318130, loss_ce: 0.021852
[21:55:24.845] iteration 19960 : loss : 0.311996, loss_ce: 0.021761
[21:55:31.253] iteration 19970 : loss : 0.314136, loss_ce: 0.012705
[21:55:37.650] iteration 19980 : loss : 0.351887, loss_ce: 0.031920
[21:55:44.052] iteration 19990 : loss : 0.278113, loss_ce: 0.014360
[21:55:50.451] iteration 20000 : loss : 0.362504, loss_ce: 0.016919
[21:55:56.862] iteration 20010 : loss : 0.291832, loss_ce: 0.021103
[21:56:03.264] iteration 20020 : loss : 0.315318, loss_ce: 0.028040
[21:56:09.676] iteration 20030 : loss : 0.335653, loss_ce: 0.049017
[21:56:16.080] iteration 20040 : loss : 0.189642, loss_ce: 0.018126
[21:56:22.521] iteration 20050 : loss : 0.327330, loss_ce: 0.053566
[21:56:28.921] iteration 20060 : loss : 0.334641, loss_ce: 0.035675
[21:56:35.332] iteration 20070 : loss : 0.308535, loss_ce: 0.022231
[21:56:41.740] iteration 20080 : loss : 0.308265, loss_ce: 0.020171
[21:56:48.153] iteration 20090 : loss : 0.308161, loss_ce: 0.044217
[21:56:54.553] iteration 20100 : loss : 0.323090, loss_ce: 0.016155
[21:57:00.971] iteration 20110 : loss : 0.343035, loss_ce: 0.017459
[21:57:07.375] iteration 20120 : loss : 0.305037, loss_ce: 0.030013
[21:57:13.795] iteration 20130 : loss : 0.171981, loss_ce: 0.014880
[21:57:20.198] iteration 20140 : loss : 0.321822, loss_ce: 0.014952
[21:57:26.629] iteration 20150 : loss : 0.328955, loss_ce: 0.025042
[21:57:33.042] iteration 20160 : loss : 0.315777, loss_ce: 0.021059
[21:57:39.461] iteration 20170 : loss : 0.322202, loss_ce: 0.020422
[21:57:45.866] iteration 20180 : loss : 0.338135, loss_ce: 0.031400
[21:57:52.281] iteration 20190 : loss : 0.280831, loss_ce: 0.014751
[21:57:58.691] iteration 20200 : loss : 0.316701, loss_ce: 0.025024
[21:58:05.107] iteration 20210 : loss : 0.329235, loss_ce: 0.030445
[21:58:11.510] iteration 20220 : loss : 0.293081, loss_ce: 0.024344
[21:58:17.927] iteration 20230 : loss : 0.335911, loss_ce: 0.017650
[21:58:24.329] iteration 20240 : loss : 0.351278, loss_ce: 0.033799
[21:58:30.745] iteration 20250 : loss : 0.328032, loss_ce: 0.024595
[21:58:37.156] iteration 20260 : loss : 0.337534, loss_ce: 0.021586
[21:58:43.574] iteration 20270 : loss : 0.274434, loss_ce: 0.023424
[21:58:49.977] iteration 20280 : loss : 0.311661, loss_ce: 0.033490
[21:58:56.396] iteration 20290 : loss : 0.312183, loss_ce: 0.014189
[21:59:02.805] iteration 20300 : loss : 0.331922, loss_ce: 0.037442
[21:59:09.226] iteration 20310 : loss : 0.317003, loss_ce: 0.018806
[21:59:15.635] iteration 20320 : loss : 0.311936, loss_ce: 0.023179
[21:59:22.051] iteration 20330 : loss : 0.317177, loss_ce: 0.034433
[21:59:28.458] iteration 20340 : loss : 0.343391, loss_ce: 0.033417
[21:59:34.874] iteration 20350 : loss : 0.340111, loss_ce: 0.014178
[21:59:41.279] iteration 20360 : loss : 0.322849, loss_ce: 0.029712
[21:59:47.706] iteration 20370 : loss : 0.299006, loss_ce: 0.030166
[21:59:51.804] Epoch 35: Average loss: 0.3066
[22:05:46.465] iteration 20380 : loss : 0.328060, loss_ce: 0.022516
[22:05:52.825] iteration 20390 : loss : 0.343716, loss_ce: 0.022154
[22:05:59.182] iteration 20400 : loss : 0.295588, loss_ce: 0.019433
[22:06:05.554] iteration 20410 : loss : 0.303035, loss_ce: 0.032361
[22:06:11.920] iteration 20420 : loss : 0.297545, loss_ce: 0.013585
[22:06:18.297] iteration 20430 : loss : 0.332782, loss_ce: 0.034016
[22:06:24.666] iteration 20440 : loss : 0.307978, loss_ce: 0.018524
[22:06:31.045] iteration 20450 : loss : 0.323388, loss_ce: 0.039121
[22:06:37.416] iteration 20460 : loss : 0.309030, loss_ce: 0.020354
[22:06:43.801] iteration 20470 : loss : 0.322913, loss_ce: 0.028233
[22:06:50.180] iteration 20480 : loss : 0.309469, loss_ce: 0.025825
[22:06:56.568] iteration 20490 : loss : 0.337410, loss_ce: 0.020816
[22:07:02.941] iteration 20500 : loss : 0.318229, loss_ce: 0.028483
[22:07:09.328] iteration 20510 : loss : 0.322184, loss_ce: 0.025804
[22:07:15.710] iteration 20520 : loss : 0.308710, loss_ce: 0.028223
[22:07:22.102] iteration 20530 : loss : 0.282777, loss_ce: 0.017698
[22:07:28.482] iteration 20540 : loss : 0.327898, loss_ce: 0.028053
[22:07:34.874] iteration 20550 : loss : 0.305981, loss_ce: 0.032309
[22:07:41.261] iteration 20560 : loss : 0.308920, loss_ce: 0.023297
[22:07:47.658] iteration 20570 : loss : 0.312668, loss_ce: 0.022363
[22:07:54.045] iteration 20580 : loss : 0.317231, loss_ce: 0.017817
[22:08:00.442] iteration 20590 : loss : 0.315450, loss_ce: 0.028466
[22:08:06.830] iteration 20600 : loss : 0.348323, loss_ce: 0.022251
[22:08:13.230] iteration 20610 : loss : 0.351087, loss_ce: 0.061169
[22:08:19.618] iteration 20620 : loss : 0.347352, loss_ce: 0.035181
[22:08:26.016] iteration 20630 : loss : 0.330435, loss_ce: 0.020846
[22:08:32.404] iteration 20640 : loss : 0.342081, loss_ce: 0.034438
[22:08:38.808] iteration 20650 : loss : 0.322112, loss_ce: 0.019219
[22:08:45.198] iteration 20660 : loss : 0.154062, loss_ce: 0.028473
[22:08:51.600] iteration 20670 : loss : 0.339816, loss_ce: 0.019683
[22:08:57.992] iteration 20680 : loss : 0.336162, loss_ce: 0.018489
[22:09:04.397] iteration 20690 : loss : 0.314128, loss_ce: 0.026975
[22:09:10.797] iteration 20700 : loss : 0.334072, loss_ce: 0.024968
[22:09:17.203] iteration 20710 : loss : 0.333853, loss_ce: 0.024622
[22:09:23.600] iteration 20720 : loss : 0.309982, loss_ce: 0.021534
[22:09:30.016] iteration 20730 : loss : 0.321047, loss_ce: 0.015574
[22:09:36.412] iteration 20740 : loss : 0.286607, loss_ce: 0.020701
[22:09:42.826] iteration 20750 : loss : 0.283119, loss_ce: 0.023961
[22:09:49.227] iteration 20760 : loss : 0.299621, loss_ce: 0.018932
[22:09:55.639] iteration 20770 : loss : 0.303403, loss_ce: 0.032714
[22:10:02.047] iteration 20780 : loss : 0.300858, loss_ce: 0.016624
[22:10:08.468] iteration 20790 : loss : 0.317709, loss_ce: 0.028286
[22:10:14.873] iteration 20800 : loss : 0.303742, loss_ce: 0.028015
[22:10:21.294] iteration 20810 : loss : 0.298591, loss_ce: 0.027878
[22:10:27.698] iteration 20820 : loss : 0.294574, loss_ce: 0.014062
[22:10:34.116] iteration 20830 : loss : 0.322749, loss_ce: 0.052488
[22:10:40.521] iteration 20840 : loss : 0.318273, loss_ce: 0.017542
[22:10:46.943] iteration 20850 : loss : 0.327599, loss_ce: 0.012291
[22:10:53.348] iteration 20860 : loss : 0.320787, loss_ce: 0.018234
[22:10:59.770] iteration 20870 : loss : 0.319176, loss_ce: 0.034917
[22:11:06.182] iteration 20880 : loss : 0.261252, loss_ce: 0.019863
[22:11:12.602] iteration 20890 : loss : 0.312819, loss_ce: 0.029521
[22:11:19.015] iteration 20900 : loss : 0.335823, loss_ce: 0.026430
[22:11:25.433] iteration 20910 : loss : 0.337371, loss_ce: 0.021532
[22:11:31.847] iteration 20920 : loss : 0.297973, loss_ce: 0.027286
[22:11:38.265] iteration 20930 : loss : 0.281694, loss_ce: 0.033592
[22:11:44.688] iteration 20940 : loss : 0.291983, loss_ce: 0.026333
[22:11:46.245] Epoch 36: Average loss: 0.3046
[22:12:03.293] iteration 20950 : loss : 0.308931, loss_ce: 0.027077
[22:12:09.675] iteration 20960 : loss : 0.160318, loss_ce: 0.012590
[22:12:16.073] iteration 20970 : loss : 0.329961, loss_ce: 0.034928
[22:12:22.460] iteration 20980 : loss : 0.312007, loss_ce: 0.030513
[22:12:28.857] iteration 20990 : loss : 0.324608, loss_ce: 0.020506
[22:12:35.244] iteration 21000 : loss : 0.304383, loss_ce: 0.031335
[22:12:41.644] iteration 21010 : loss : 0.309834, loss_ce: 0.020617
[22:12:48.032] iteration 21020 : loss : 0.354552, loss_ce: 0.025566
[22:12:54.434] iteration 21030 : loss : 0.301492, loss_ce: 0.034406
[22:13:00.829] iteration 21040 : loss : 0.130517, loss_ce: 0.009947
[22:13:07.238] iteration 21050 : loss : 0.298403, loss_ce: 0.019250
[22:13:13.635] iteration 21060 : loss : 0.291480, loss_ce: 0.023274
[22:13:20.048] iteration 21070 : loss : 0.282073, loss_ce: 0.031695
[22:13:26.447] iteration 21080 : loss : 0.293043, loss_ce: 0.016252
[22:13:32.860] iteration 21090 : loss : 0.331873, loss_ce: 0.022808
[22:13:39.263] iteration 21100 : loss : 0.334185, loss_ce: 0.023542
[22:13:45.677] iteration 21110 : loss : 0.316315, loss_ce: 0.013384
[22:13:52.082] iteration 21120 : loss : 0.315946, loss_ce: 0.023390
[22:13:58.504] iteration 21130 : loss : 0.297515, loss_ce: 0.035420
[22:14:04.904] iteration 21140 : loss : 0.304334, loss_ce: 0.014774
[22:14:11.324] iteration 21150 : loss : 0.346916, loss_ce: 0.012874
[22:14:17.726] iteration 21160 : loss : 0.323542, loss_ce: 0.015638
[22:14:24.141] iteration 21170 : loss : 0.346335, loss_ce: 0.066838
[22:14:30.547] iteration 21180 : loss : 0.275418, loss_ce: 0.025480
[22:14:36.962] iteration 21190 : loss : 0.310627, loss_ce: 0.014267
[22:14:43.370] iteration 21200 : loss : 0.287061, loss_ce: 0.021158
[22:14:49.792] iteration 21210 : loss : 0.327364, loss_ce: 0.024879
[22:14:56.194] iteration 21220 : loss : 0.314240, loss_ce: 0.015074
[22:15:02.610] iteration 21230 : loss : 0.344084, loss_ce: 0.038324
[22:15:09.017] iteration 21240 : loss : 0.200311, loss_ce: 0.017087
[22:15:15.438] iteration 21250 : loss : 0.317845, loss_ce: 0.020647
[22:15:21.844] iteration 21260 : loss : 0.180482, loss_ce: 0.027627
[22:15:28.259] iteration 21270 : loss : 0.297535, loss_ce: 0.015208
[22:15:34.663] iteration 21280 : loss : 0.315365, loss_ce: 0.020334
[22:15:41.083] iteration 21290 : loss : 0.297274, loss_ce: 0.026753
[22:15:47.489] iteration 21300 : loss : 0.302521, loss_ce: 0.025705
[22:15:53.905] iteration 21310 : loss : 0.328243, loss_ce: 0.034077
[22:16:00.315] iteration 21320 : loss : 0.343092, loss_ce: 0.020856
[22:16:06.735] iteration 21330 : loss : 0.314669, loss_ce: 0.017029
[22:16:13.137] iteration 21340 : loss : 0.302947, loss_ce: 0.025806
[22:16:19.561] iteration 21350 : loss : 0.155773, loss_ce: 0.017764
[22:16:25.966] iteration 21360 : loss : 0.296407, loss_ce: 0.013152
[22:16:32.385] iteration 21370 : loss : 0.329670, loss_ce: 0.016806
[22:16:38.793] iteration 21380 : loss : 0.311850, loss_ce: 0.025484
[22:16:45.212] iteration 21390 : loss : 0.296061, loss_ce: 0.027308
[22:16:51.617] iteration 21400 : loss : 0.317646, loss_ce: 0.022371
[22:16:58.035] iteration 21410 : loss : 0.352395, loss_ce: 0.029055
[22:17:04.442] iteration 21420 : loss : 0.344498, loss_ce: 0.020925
[22:17:10.864] iteration 21430 : loss : 0.281891, loss_ce: 0.016682
[22:17:17.270] iteration 21440 : loss : 0.295814, loss_ce: 0.021453
[22:17:23.688] iteration 21450 : loss : 0.282788, loss_ce: 0.023393
[22:17:30.155] iteration 21460 : loss : 0.326842, loss_ce: 0.030760
[22:17:36.575] iteration 21470 : loss : 0.258831, loss_ce: 0.019049
[22:17:42.983] iteration 21480 : loss : 0.173903, loss_ce: 0.017028
[22:17:49.405] iteration 21490 : loss : 0.319286, loss_ce: 0.008945
[22:17:55.819] iteration 21500 : loss : 0.324959, loss_ce: 0.040918
[22:18:01.244] Epoch 37: Average loss: 0.2964
[22:18:14.355] iteration 21510 : loss : 0.334336, loss_ce: 0.017471
[22:18:20.733] iteration 21520 : loss : 0.270909, loss_ce: 0.016070
[22:18:27.127] iteration 21530 : loss : 0.313173, loss_ce: 0.030369
[22:18:33.509] iteration 21540 : loss : 0.286214, loss_ce: 0.019281
[22:18:39.898] iteration 21550 : loss : 0.278035, loss_ce: 0.016383
[22:18:46.283] iteration 21560 : loss : 0.145810, loss_ce: 0.019191
[22:18:52.683] iteration 21570 : loss : 0.342796, loss_ce: 0.019372
[22:18:59.073] iteration 21580 : loss : 0.317043, loss_ce: 0.030517
[22:19:05.477] iteration 21590 : loss : 0.317725, loss_ce: 0.019207
[22:19:11.869] iteration 21600 : loss : 0.292833, loss_ce: 0.012544
[22:19:18.273] iteration 21610 : loss : 0.289795, loss_ce: 0.015622
[22:19:24.666] iteration 21620 : loss : 0.350703, loss_ce: 0.015928
[22:19:31.073] iteration 21630 : loss : 0.338951, loss_ce: 0.020396
[22:19:37.468] iteration 21640 : loss : 0.272618, loss_ce: 0.018169
[22:19:43.874] iteration 21650 : loss : 0.335479, loss_ce: 0.014320
[22:19:50.269] iteration 21660 : loss : 0.289285, loss_ce: 0.020822
[22:19:56.678] iteration 21670 : loss : 0.316975, loss_ce: 0.028430
[22:20:03.082] iteration 21680 : loss : 0.310286, loss_ce: 0.016484
[22:20:09.497] iteration 21690 : loss : 0.263936, loss_ce: 0.014730
[22:20:15.898] iteration 21700 : loss : 0.133833, loss_ce: 0.018854
[22:20:22.309] iteration 21710 : loss : 0.320190, loss_ce: 0.034886
[22:20:28.713] iteration 21720 : loss : 0.306066, loss_ce: 0.016215
[22:20:35.123] iteration 21730 : loss : 0.337448, loss_ce: 0.029605
[22:20:41.521] iteration 21740 : loss : 0.336041, loss_ce: 0.020109
[22:20:47.935] iteration 21750 : loss : 0.290232, loss_ce: 0.023103
[22:20:54.337] iteration 21760 : loss : 0.336940, loss_ce: 0.016137
[22:21:00.753] iteration 21770 : loss : 0.278570, loss_ce: 0.022552
[22:21:07.153] iteration 21780 : loss : 0.286267, loss_ce: 0.032232
[22:21:13.576] iteration 21790 : loss : 0.310245, loss_ce: 0.016817
[22:21:19.986] iteration 21800 : loss : 0.155716, loss_ce: 0.010758
[22:21:26.406] iteration 21810 : loss : 0.326742, loss_ce: 0.028705
[22:21:32.814] iteration 21820 : loss : 0.321717, loss_ce: 0.021942
[22:21:39.230] iteration 21830 : loss : 0.346103, loss_ce: 0.029830
[22:21:45.640] iteration 21840 : loss : 0.286172, loss_ce: 0.018824
[22:21:52.056] iteration 21850 : loss : 0.256922, loss_ce: 0.019901
[22:21:58.453] iteration 21860 : loss : 0.300922, loss_ce: 0.033523
[22:22:04.868] iteration 21870 : loss : 0.298875, loss_ce: 0.016356
[22:22:11.269] iteration 21880 : loss : 0.272648, loss_ce: 0.022273
[22:22:17.688] iteration 21890 : loss : 0.307654, loss_ce: 0.018642
[22:22:24.095] iteration 21900 : loss : 0.137133, loss_ce: 0.018278
[22:22:30.517] iteration 21910 : loss : 0.304491, loss_ce: 0.016944
[22:22:36.924] iteration 21920 : loss : 0.319761, loss_ce: 0.017208
[22:22:43.338] iteration 21930 : loss : 0.323394, loss_ce: 0.034957
[22:22:49.750] iteration 21940 : loss : 0.270012, loss_ce: 0.019640
[22:22:56.161] iteration 21950 : loss : 0.303685, loss_ce: 0.021293
[22:23:02.567] iteration 21960 : loss : 0.307498, loss_ce: 0.021343
[22:23:08.987] iteration 21970 : loss : 0.315634, loss_ce: 0.018514
[22:23:15.399] iteration 21980 : loss : 0.327712, loss_ce: 0.031777
[22:23:21.812] iteration 21990 : loss : 0.176774, loss_ce: 0.013901
[22:23:28.221] iteration 22000 : loss : 0.288325, loss_ce: 0.016295
[22:23:34.634] iteration 22010 : loss : 0.181236, loss_ce: 0.021811
[22:23:41.038] iteration 22020 : loss : 0.280142, loss_ce: 0.027012
[22:23:47.455] iteration 22030 : loss : 0.317405, loss_ce: 0.034354
[22:23:53.863] iteration 22040 : loss : 0.291385, loss_ce: 0.019811
[22:24:00.280] iteration 22050 : loss : 0.324696, loss_ce: 0.033657
[22:24:06.692] iteration 22060 : loss : 0.152161, loss_ce: 0.015807
[22:24:13.115] iteration 22070 : loss : 0.315673, loss_ce: 0.009926
[22:24:15.959] Epoch 38: Average loss: 0.2942
[22:30:03.668] iteration 22080 : loss : 0.291756, loss_ce: 0.019008
[22:30:10.025] iteration 22090 : loss : 0.290907, loss_ce: 0.016883
[22:30:16.378] iteration 22100 : loss : 0.300794, loss_ce: 0.018375
[22:30:22.742] iteration 22110 : loss : 0.298015, loss_ce: 0.022776
[22:30:29.098] iteration 22120 : loss : 0.325860, loss_ce: 0.024554
[22:30:35.470] iteration 22130 : loss : 0.321189, loss_ce: 0.024400
[22:30:41.835] iteration 22140 : loss : 0.338996, loss_ce: 0.023929
[22:30:48.210] iteration 22150 : loss : 0.304977, loss_ce: 0.017645
[22:30:54.579] iteration 22160 : loss : 0.311803, loss_ce: 0.018807
[22:31:00.961] iteration 22170 : loss : 0.299760, loss_ce: 0.022157
[22:31:07.332] iteration 22180 : loss : 0.307697, loss_ce: 0.020819
[22:31:13.715] iteration 22190 : loss : 0.149698, loss_ce: 0.014354
[22:31:20.091] iteration 22200 : loss : 0.294360, loss_ce: 0.016190
[22:31:26.471] iteration 22210 : loss : 0.311052, loss_ce: 0.026255
[22:31:32.846] iteration 22220 : loss : 0.269037, loss_ce: 0.019941
[22:31:39.233] iteration 22230 : loss : 0.304802, loss_ce: 0.026406
[22:31:45.606] iteration 22240 : loss : 0.290700, loss_ce: 0.020784
[22:31:51.992] iteration 22250 : loss : 0.301969, loss_ce: 0.029723
[22:31:58.369] iteration 22260 : loss : 0.292790, loss_ce: 0.022256
[22:32:04.758] iteration 22270 : loss : 0.293511, loss_ce: 0.013465
[22:32:11.137] iteration 22280 : loss : 0.296359, loss_ce: 0.019241
[22:32:17.526] iteration 22290 : loss : 0.254149, loss_ce: 0.014789
[22:32:23.907] iteration 22300 : loss : 0.295944, loss_ce: 0.028333
[22:32:30.300] iteration 22310 : loss : 0.143683, loss_ce: 0.009397
[22:32:36.682] iteration 22320 : loss : 0.307517, loss_ce: 0.018314
[22:32:43.079] iteration 22330 : loss : 0.344761, loss_ce: 0.027158
[22:32:49.465] iteration 22340 : loss : 0.301205, loss_ce: 0.023841
[22:32:55.864] iteration 22350 : loss : 0.312371, loss_ce: 0.018029
[22:33:02.254] iteration 22360 : loss : 0.321512, loss_ce: 0.020101
[22:33:08.649] iteration 22370 : loss : 0.302951, loss_ce: 0.018010
[22:33:15.038] iteration 22380 : loss : 0.349120, loss_ce: 0.027846
[22:33:21.439] iteration 22390 : loss : 0.334235, loss_ce: 0.016236
[22:33:27.828] iteration 22400 : loss : 0.303139, loss_ce: 0.020646
[22:33:34.228] iteration 22410 : loss : 0.290994, loss_ce: 0.014835
[22:33:40.617] iteration 22420 : loss : 0.269875, loss_ce: 0.016950
[22:33:47.021] iteration 22430 : loss : 0.299012, loss_ce: 0.015025
[22:33:53.411] iteration 22440 : loss : 0.268838, loss_ce: 0.017335
[22:33:59.809] iteration 22450 : loss : 0.322317, loss_ce: 0.013862
[22:34:06.204] iteration 22460 : loss : 0.327351, loss_ce: 0.026836
[22:34:12.612] iteration 22470 : loss : 0.254822, loss_ce: 0.012153
[22:34:19.008] iteration 22480 : loss : 0.324957, loss_ce: 0.009533
[22:34:25.411] iteration 22490 : loss : 0.197585, loss_ce: 0.011830
[22:34:31.809] iteration 22500 : loss : 0.306037, loss_ce: 0.030571
[22:34:38.218] iteration 22510 : loss : 0.334578, loss_ce: 0.018803
[22:34:44.617] iteration 22520 : loss : 0.339603, loss_ce: 0.017122
[22:34:51.026] iteration 22530 : loss : 0.291289, loss_ce: 0.027084
[22:34:57.424] iteration 22540 : loss : 0.278409, loss_ce: 0.019690
[22:35:03.837] iteration 22550 : loss : 0.253905, loss_ce: 0.020240
[22:35:10.240] iteration 22560 : loss : 0.240422, loss_ce: 0.016521
[22:35:16.651] iteration 22570 : loss : 0.343101, loss_ce: 0.030764
[22:35:23.056] iteration 22580 : loss : 0.287059, loss_ce: 0.013486
[22:35:29.464] iteration 22590 : loss : 0.287018, loss_ce: 0.020373
[22:35:35.864] iteration 22600 : loss : 0.293168, loss_ce: 0.014573
[22:35:42.277] iteration 22610 : loss : 0.330825, loss_ce: 0.018564
[22:35:48.682] iteration 22620 : loss : 0.300723, loss_ce: 0.014131
[22:35:55.101] iteration 22630 : loss : 0.300950, loss_ce: 0.014676
[22:36:01.085] iteration 22640 : loss : 0.370621, loss_ce: 0.029528
[22:36:01.756] Epoch 39: Average loss: 0.2891
[22:36:01.856] save model to ./finetune_tpgm_kits23_continual_fixed\finetuned_epoch_39.pth
[22:36:18.932] iteration 22650 : loss : 0.295395, loss_ce: 0.011024
[22:36:25.309] iteration 22660 : loss : 0.356055, loss_ce: 0.033598
[22:36:31.698] iteration 22670 : loss : 0.307398, loss_ce: 0.032881
[22:36:38.074] iteration 22680 : loss : 0.329124, loss_ce: 0.012924
[22:36:44.468] iteration 22690 : loss : 0.276878, loss_ce: 0.024167
[22:36:50.850] iteration 22700 : loss : 0.264256, loss_ce: 0.017730
[22:36:57.247] iteration 22710 : loss : 0.334382, loss_ce: 0.017438
[22:37:03.632] iteration 22720 : loss : 0.309448, loss_ce: 0.018294
[22:37:10.030] iteration 22730 : loss : 0.330394, loss_ce: 0.025071
[22:37:16.421] iteration 22740 : loss : 0.285001, loss_ce: 0.017145
[22:37:22.824] iteration 22750 : loss : 0.292554, loss_ce: 0.024367
[22:37:29.221] iteration 22760 : loss : 0.339374, loss_ce: 0.023117
[22:37:35.623] iteration 22770 : loss : 0.300993, loss_ce: 0.016162
[22:37:42.017] iteration 22780 : loss : 0.251866, loss_ce: 0.016228
[22:37:48.423] iteration 22790 : loss : 0.287635, loss_ce: 0.012504
[22:37:54.819] iteration 22800 : loss : 0.157155, loss_ce: 0.015977
[22:38:01.222] iteration 22810 : loss : 0.314849, loss_ce: 0.020030
[22:38:07.619] iteration 22820 : loss : 0.332624, loss_ce: 0.028930
[22:38:14.034] iteration 22830 : loss : 0.287935, loss_ce: 0.026763
[22:38:20.437] iteration 22840 : loss : 0.254367, loss_ce: 0.023648
[22:38:26.850] iteration 22850 : loss : 0.244493, loss_ce: 0.019000
[22:38:33.248] iteration 22860 : loss : 0.290083, loss_ce: 0.040083
[22:38:39.664] iteration 22870 : loss : 0.293351, loss_ce: 0.021299
[22:38:46.075] iteration 22880 : loss : 0.339199, loss_ce: 0.021220
[22:38:52.483] iteration 22890 : loss : 0.321095, loss_ce: 0.024200
[22:38:58.886] iteration 22900 : loss : 0.300084, loss_ce: 0.026612
[22:39:05.302] iteration 22910 : loss : 0.309350, loss_ce: 0.028047
[22:39:11.710] iteration 22920 : loss : 0.295337, loss_ce: 0.019548
[22:39:18.130] iteration 22930 : loss : 0.319654, loss_ce: 0.012813
[22:39:24.534] iteration 22940 : loss : 0.294759, loss_ce: 0.019633
[22:39:30.954] iteration 22950 : loss : 0.302534, loss_ce: 0.014022
[22:39:37.358] iteration 22960 : loss : 0.334340, loss_ce: 0.013979
[22:39:43.782] iteration 22970 : loss : 0.320254, loss_ce: 0.024525
[22:39:50.186] iteration 22980 : loss : 0.312428, loss_ce: 0.012319
[22:39:56.605] iteration 22990 : loss : 0.265825, loss_ce: 0.021323
[22:40:03.012] iteration 23000 : loss : 0.277500, loss_ce: 0.019668
[22:40:09.436] iteration 23010 : loss : 0.302164, loss_ce: 0.019509
[22:40:15.841] iteration 23020 : loss : 0.320570, loss_ce: 0.023337
[22:40:22.261] iteration 23030 : loss : 0.294065, loss_ce: 0.018848
[22:40:28.673] iteration 23040 : loss : 0.313278, loss_ce: 0.042270
[22:40:35.092] iteration 23050 : loss : 0.349826, loss_ce: 0.013859
[22:40:41.510] iteration 23060 : loss : 0.343147, loss_ce: 0.036565
[22:40:47.932] iteration 23070 : loss : 0.289135, loss_ce: 0.013688
[22:40:54.350] iteration 23080 : loss : 0.180082, loss_ce: 0.013527
[22:41:00.771] iteration 23090 : loss : 0.182793, loss_ce: 0.018784
[22:41:07.186] iteration 23100 : loss : 0.316280, loss_ce: 0.020748
[22:41:13.613] iteration 23110 : loss : 0.250074, loss_ce: 0.022065
[22:41:20.022] iteration 23120 : loss : 0.333996, loss_ce: 0.019997
[22:41:26.449] iteration 23130 : loss : 0.326912, loss_ce: 0.028010
[22:41:32.864] iteration 23140 : loss : 0.142165, loss_ce: 0.019129
[22:41:39.294] iteration 23150 : loss : 0.334569, loss_ce: 0.033772
[22:41:45.704] iteration 23160 : loss : 0.305032, loss_ce: 0.019680
[22:41:52.123] iteration 23170 : loss : 0.292221, loss_ce: 0.018191
[22:41:58.543] iteration 23180 : loss : 0.278266, loss_ce: 0.018614
[22:42:04.962] iteration 23190 : loss : 0.255449, loss_ce: 0.019871
[22:42:11.374] iteration 23200 : loss : 0.120567, loss_ce: 0.026989
[22:42:15.452] Epoch 40: Average loss: 0.2857
[22:42:28.807] iteration 23210 : loss : 0.342156, loss_ce: 0.014765
[22:42:35.183] iteration 23220 : loss : 0.258107, loss_ce: 0.020505
[22:42:41.573] iteration 23230 : loss : 0.302062, loss_ce: 0.017854
[22:42:47.952] iteration 23240 : loss : 0.268145, loss_ce: 0.016035
[22:42:54.343] iteration 23250 : loss : 0.351356, loss_ce: 0.033632
[22:43:00.727] iteration 23260 : loss : 0.086837, loss_ce: 0.016319
[22:43:07.125] iteration 23270 : loss : 0.286492, loss_ce: 0.020353
[22:43:13.512] iteration 23280 : loss : 0.258412, loss_ce: 0.018559
[22:43:19.911] iteration 23290 : loss : 0.272545, loss_ce: 0.024413
[22:43:26.299] iteration 23300 : loss : 0.321452, loss_ce: 0.013707
[22:43:32.703] iteration 23310 : loss : 0.269617, loss_ce: 0.015398
[22:43:39.103] iteration 23320 : loss : 0.273134, loss_ce: 0.019042
[22:43:45.501] iteration 23330 : loss : 0.326721, loss_ce: 0.020788
[22:43:51.893] iteration 23340 : loss : 0.326594, loss_ce: 0.020284
[22:43:58.310] iteration 23350 : loss : 0.304080, loss_ce: 0.016724
[22:44:04.711] iteration 23360 : loss : 0.259160, loss_ce: 0.022000
[22:44:11.118] iteration 23370 : loss : 0.268759, loss_ce: 0.011143
[22:44:17.517] iteration 23380 : loss : 0.308141, loss_ce: 0.022871
[22:44:23.933] iteration 23390 : loss : 0.316441, loss_ce: 0.023398
[22:44:30.342] iteration 23400 : loss : 0.233220, loss_ce: 0.013973
[22:44:36.757] iteration 23410 : loss : 0.289935, loss_ce: 0.024921
[22:44:43.159] iteration 23420 : loss : 0.267975, loss_ce: 0.020696
[22:44:49.577] iteration 23430 : loss : 0.337654, loss_ce: 0.015509
[22:44:55.984] iteration 23440 : loss : 0.284989, loss_ce: 0.021201
[22:45:02.400] iteration 23450 : loss : 0.197950, loss_ce: 0.016293
[22:45:08.804] iteration 23460 : loss : 0.172781, loss_ce: 0.027905
[22:45:15.214] iteration 23470 : loss : 0.278508, loss_ce: 0.019408
[22:45:21.614] iteration 23480 : loss : 0.266730, loss_ce: 0.025200
[22:45:28.031] iteration 23490 : loss : 0.354729, loss_ce: 0.046829
[22:45:34.446] iteration 23500 : loss : 0.291665, loss_ce: 0.014498
[22:45:40.866] iteration 23510 : loss : 0.266133, loss_ce: 0.019903
[22:45:47.279] iteration 23520 : loss : 0.312312, loss_ce: 0.026650
[22:45:53.711] iteration 23530 : loss : 0.245263, loss_ce: 0.020134
[22:46:00.129] iteration 23540 : loss : 0.346895, loss_ce: 0.027073
[22:46:06.548] iteration 23550 : loss : 0.099520, loss_ce: 0.011157
[22:46:12.958] iteration 23560 : loss : 0.336235, loss_ce: 0.029590
[22:46:19.384] iteration 23570 : loss : 0.254927, loss_ce: 0.019752
[22:46:25.800] iteration 23580 : loss : 0.328181, loss_ce: 0.015868
[22:46:32.224] iteration 23590 : loss : 0.273734, loss_ce: 0.016128
[22:46:38.642] iteration 23600 : loss : 0.271754, loss_ce: 0.025203
[22:46:45.068] iteration 23610 : loss : 0.326462, loss_ce: 0.021565
[22:46:51.482] iteration 23620 : loss : 0.327370, loss_ce: 0.014230
[22:46:57.906] iteration 23630 : loss : 0.296671, loss_ce: 0.023891
[22:47:04.319] iteration 23640 : loss : 0.317777, loss_ce: 0.018999
[22:47:10.746] iteration 23650 : loss : 0.275786, loss_ce: 0.024360
[22:47:17.171] iteration 23660 : loss : 0.254165, loss_ce: 0.016812
[22:47:23.596] iteration 23670 : loss : 0.292051, loss_ce: 0.026390
[22:47:30.017] iteration 23680 : loss : 0.239323, loss_ce: 0.017910
[22:47:36.440] iteration 23690 : loss : 0.321127, loss_ce: 0.031743
[22:47:42.866] iteration 23700 : loss : 0.277814, loss_ce: 0.014915
[22:47:49.295] iteration 23710 : loss : 0.306866, loss_ce: 0.020823
[22:47:55.709] iteration 23720 : loss : 0.297827, loss_ce: 0.024307
[22:48:02.139] iteration 23730 : loss : 0.236016, loss_ce: 0.022823
[22:48:08.558] iteration 23740 : loss : 0.248240, loss_ce: 0.012103
[22:48:14.986] iteration 23750 : loss : 0.309779, loss_ce: 0.021692
[22:48:21.408] iteration 23760 : loss : 0.333399, loss_ce: 0.020353
[22:48:27.838] iteration 23770 : loss : 0.310271, loss_ce: 0.025526
[22:48:29.366] Epoch 41: Average loss: 0.2824
[22:54:15.711] iteration 23780 : loss : 0.282085, loss_ce: 0.022003
[22:54:22.081] iteration 23790 : loss : 0.261796, loss_ce: 0.016911
[22:54:28.441] iteration 23800 : loss : 0.280778, loss_ce: 0.022248
[22:54:34.808] iteration 23810 : loss : 0.281926, loss_ce: 0.028089
[22:54:41.164] iteration 23820 : loss : 0.309066, loss_ce: 0.026735
[22:54:47.540] iteration 23830 : loss : 0.297835, loss_ce: 0.024623
[22:54:53.906] iteration 23840 : loss : 0.270038, loss_ce: 0.015368
[22:55:00.284] iteration 23850 : loss : 0.340372, loss_ce: 0.029522
[22:55:06.656] iteration 23860 : loss : 0.337235, loss_ce: 0.021648
[22:55:13.038] iteration 23870 : loss : 0.294874, loss_ce: 0.020863
[22:55:19.411] iteration 23880 : loss : 0.297725, loss_ce: 0.015939
[22:55:25.794] iteration 23890 : loss : 0.128053, loss_ce: 0.016510
[22:55:32.170] iteration 23900 : loss : 0.289011, loss_ce: 0.023343
[22:55:38.555] iteration 23910 : loss : 0.263808, loss_ce: 0.028301
[22:55:44.930] iteration 23920 : loss : 0.288038, loss_ce: 0.024819
[22:55:51.321] iteration 23930 : loss : 0.287646, loss_ce: 0.018084
[22:55:57.701] iteration 23940 : loss : 0.288049, loss_ce: 0.026455
[22:56:04.089] iteration 23950 : loss : 0.317827, loss_ce: 0.014102
[22:56:10.470] iteration 23960 : loss : 0.242974, loss_ce: 0.013099
[22:56:16.866] iteration 23970 : loss : 0.305285, loss_ce: 0.029441
[22:56:23.252] iteration 23980 : loss : 0.302464, loss_ce: 0.021958
[22:56:29.645] iteration 23990 : loss : 0.239738, loss_ce: 0.015440
[22:56:36.030] iteration 24000 : loss : 0.291985, loss_ce: 0.013758
[22:56:42.427] iteration 24010 : loss : 0.277381, loss_ce: 0.022928
[22:56:48.813] iteration 24020 : loss : 0.260625, loss_ce: 0.016800
[22:56:55.212] iteration 24030 : loss : 0.268096, loss_ce: 0.025977
[22:57:01.596] iteration 24040 : loss : 0.250320, loss_ce: 0.022899
[22:57:07.992] iteration 24050 : loss : 0.280521, loss_ce: 0.023480
[22:57:14.384] iteration 24060 : loss : 0.334442, loss_ce: 0.012915
[22:57:20.787] iteration 24070 : loss : 0.318382, loss_ce: 0.015186
[22:57:27.180] iteration 24080 : loss : 0.310914, loss_ce: 0.020170
[22:57:33.582] iteration 24090 : loss : 0.303949, loss_ce: 0.018695
[22:57:39.974] iteration 24100 : loss : 0.268318, loss_ce: 0.010599
[22:57:46.379] iteration 24110 : loss : 0.281961, loss_ce: 0.013931
[22:57:52.771] iteration 24120 : loss : 0.243290, loss_ce: 0.014633
[22:57:59.175] iteration 24130 : loss : 0.298347, loss_ce: 0.024408
[22:58:05.571] iteration 24140 : loss : 0.272162, loss_ce: 0.014323
[22:58:11.976] iteration 24150 : loss : 0.292266, loss_ce: 0.025660
[22:58:18.372] iteration 24160 : loss : 0.314179, loss_ce: 0.028180
[22:58:24.782] iteration 24170 : loss : 0.259192, loss_ce: 0.019542
[22:58:31.184] iteration 24180 : loss : 0.263008, loss_ce: 0.017474
[22:58:37.597] iteration 24190 : loss : 0.273630, loss_ce: 0.022909
[22:58:43.996] iteration 24200 : loss : 0.179631, loss_ce: 0.014999
[22:58:50.404] iteration 24210 : loss : 0.283791, loss_ce: 0.015473
[22:58:56.804] iteration 24220 : loss : 0.272945, loss_ce: 0.021034
[22:59:03.215] iteration 24230 : loss : 0.263939, loss_ce: 0.030115
[22:59:09.614] iteration 24240 : loss : 0.284728, loss_ce: 0.015434
[22:59:16.025] iteration 24250 : loss : 0.334985, loss_ce: 0.025252
[22:59:22.435] iteration 24260 : loss : 0.142464, loss_ce: 0.020658
[22:59:28.849] iteration 24270 : loss : 0.281858, loss_ce: 0.019934
[22:59:35.250] iteration 24280 : loss : 0.326039, loss_ce: 0.033526
[22:59:41.668] iteration 24290 : loss : 0.284280, loss_ce: 0.029088
[22:59:48.070] iteration 24300 : loss : 0.169664, loss_ce: 0.017446
[22:59:54.480] iteration 24310 : loss : 0.284534, loss_ce: 0.016192
[23:00:00.886] iteration 24320 : loss : 0.289365, loss_ce: 0.019028
[23:00:07.299] iteration 24330 : loss : 0.265257, loss_ce: 0.014281
[23:00:12.609] Epoch 42: Average loss: 0.2837
[23:00:24.621] iteration 24340 : loss : 0.300883, loss_ce: 0.018728
[23:00:31.007] iteration 24350 : loss : 0.324414, loss_ce: 0.021713
[23:00:37.385] iteration 24360 : loss : 0.249861, loss_ce: 0.011695
[23:00:43.784] iteration 24370 : loss : 0.271297, loss_ce: 0.025431
[23:00:50.167] iteration 24380 : loss : 0.328329, loss_ce: 0.015318
[23:00:56.562] iteration 24390 : loss : 0.253038, loss_ce: 0.012892
[23:01:02.950] iteration 24400 : loss : 0.076384, loss_ce: 0.008997
[23:01:09.347] iteration 24410 : loss : 0.308232, loss_ce: 0.017562
[23:01:15.737] iteration 24420 : loss : 0.292466, loss_ce: 0.021708
[23:01:22.143] iteration 24430 : loss : 0.321461, loss_ce: 0.025870
[23:01:28.536] iteration 24440 : loss : 0.284770, loss_ce: 0.024426
[23:01:34.933] iteration 24450 : loss : 0.318891, loss_ce: 0.044704
[23:01:41.328] iteration 24460 : loss : 0.275714, loss_ce: 0.015656
[23:01:47.730] iteration 24470 : loss : 0.287588, loss_ce: 0.012769
[23:01:54.128] iteration 24480 : loss : 0.291162, loss_ce: 0.019290
[23:02:00.539] iteration 24490 : loss : 0.309774, loss_ce: 0.021336
[23:02:06.938] iteration 24500 : loss : 0.267444, loss_ce: 0.031364
[23:02:13.351] iteration 24510 : loss : 0.307249, loss_ce: 0.017579
[23:02:19.755] iteration 24520 : loss : 0.288728, loss_ce: 0.019089
[23:02:26.165] iteration 24530 : loss : 0.325706, loss_ce: 0.012004
[23:02:32.569] iteration 24540 : loss : 0.319312, loss_ce: 0.031765
[23:02:38.978] iteration 24550 : loss : 0.332522, loss_ce: 0.027284
[23:02:45.382] iteration 24560 : loss : 0.292853, loss_ce: 0.028270
[23:02:51.794] iteration 24570 : loss : 0.312512, loss_ce: 0.024515
[23:02:58.197] iteration 24580 : loss : 0.267242, loss_ce: 0.037345
[23:03:04.606] iteration 24590 : loss : 0.242084, loss_ce: 0.015333
[23:03:11.010] iteration 24600 : loss : 0.120622, loss_ce: 0.015873
[23:03:17.430] iteration 24610 : loss : 0.309865, loss_ce: 0.015498
[23:03:23.832] iteration 24620 : loss : 0.300764, loss_ce: 0.022396
[23:03:30.248] iteration 24630 : loss : 0.304731, loss_ce: 0.023137
[23:03:36.644] iteration 24640 : loss : 0.288991, loss_ce: 0.018074
[23:03:43.060] iteration 24650 : loss : 0.243734, loss_ce: 0.021098
[23:03:49.464] iteration 24660 : loss : 0.285866, loss_ce: 0.015984
[23:03:55.878] iteration 24670 : loss : 0.291283, loss_ce: 0.022462
[23:04:02.285] iteration 24680 : loss : 0.283192, loss_ce: 0.026888
[23:04:08.697] iteration 24690 : loss : 0.256925, loss_ce: 0.010394
[23:04:15.095] iteration 24700 : loss : 0.301510, loss_ce: 0.019924
[23:04:21.497] iteration 24710 : loss : 0.275363, loss_ce: 0.021320
[23:04:27.897] iteration 24720 : loss : 0.339439, loss_ce: 0.022078
[23:04:34.307] iteration 24730 : loss : 0.269401, loss_ce: 0.027315
[23:04:40.695] iteration 24740 : loss : 0.304668, loss_ce: 0.028441
[23:04:47.106] iteration 24750 : loss : 0.330638, loss_ce: 0.011733
[23:04:53.498] iteration 24760 : loss : 0.299868, loss_ce: 0.030226
[23:04:59.910] iteration 24770 : loss : 0.346887, loss_ce: 0.019707
[23:05:06.305] iteration 24780 : loss : 0.285670, loss_ce: 0.016389
[23:05:12.712] iteration 24790 : loss : 0.278914, loss_ce: 0.026225
[23:05:19.109] iteration 24800 : loss : 0.265877, loss_ce: 0.018322
[23:05:25.515] iteration 24810 : loss : 0.307276, loss_ce: 0.020261
[23:05:31.910] iteration 24820 : loss : 0.337333, loss_ce: 0.026514
[23:05:38.318] iteration 24830 : loss : 0.308723, loss_ce: 0.018194
[23:05:44.711] iteration 24840 : loss : 0.287493, loss_ce: 0.016055
[23:05:51.118] iteration 24850 : loss : 0.276401, loss_ce: 0.015244
[23:05:57.512] iteration 24860 : loss : 0.255769, loss_ce: 0.018263
[23:06:03.925] iteration 24870 : loss : 0.291237, loss_ce: 0.015555
[23:06:10.324] iteration 24880 : loss : 0.304586, loss_ce: 0.036944
[23:06:16.731] iteration 24890 : loss : 0.266866, loss_ce: 0.020446
[23:06:23.127] iteration 24900 : loss : 0.278181, loss_ce: 0.028010
[23:06:25.933] Epoch 43: Average loss: 0.2812
[23:06:41.232] iteration 24910 : loss : 0.328278, loss_ce: 0.021304
[23:06:47.604] iteration 24920 : loss : 0.324868, loss_ce: 0.008889
[23:06:53.989] iteration 24930 : loss : 0.303705, loss_ce: 0.025165
[23:07:00.366] iteration 24940 : loss : 0.184413, loss_ce: 0.011012
[23:07:06.753] iteration 24950 : loss : 0.247285, loss_ce: 0.016703
[23:07:13.136] iteration 24960 : loss : 0.347577, loss_ce: 0.016166
[23:07:19.529] iteration 24970 : loss : 0.288591, loss_ce: 0.010622
[23:07:25.915] iteration 24980 : loss : 0.291731, loss_ce: 0.011364
[23:07:32.308] iteration 24990 : loss : 0.285209, loss_ce: 0.034222
[23:07:38.693] iteration 25000 : loss : 0.314389, loss_ce: 0.018484
[23:07:45.089] iteration 25010 : loss : 0.333786, loss_ce: 0.014739
[23:07:51.475] iteration 25020 : loss : 0.356519, loss_ce: 0.019461
[23:07:57.886] iteration 25030 : loss : 0.316052, loss_ce: 0.012117
[23:08:04.279] iteration 25040 : loss : 0.306459, loss_ce: 0.016777
[23:08:10.681] iteration 25050 : loss : 0.266445, loss_ce: 0.025721
[23:08:17.066] iteration 25060 : loss : 0.252343, loss_ce: 0.012053
[23:08:23.466] iteration 25070 : loss : 0.302602, loss_ce: 0.011284
[23:08:29.858] iteration 25080 : loss : 0.291066, loss_ce: 0.015227
[23:08:36.257] iteration 25090 : loss : 0.285323, loss_ce: 0.016629
[23:08:42.644] iteration 25100 : loss : 0.328597, loss_ce: 0.018492
[23:08:49.047] iteration 25110 : loss : 0.300469, loss_ce: 0.018358
[23:08:55.440] iteration 25120 : loss : 0.356177, loss_ce: 0.043013
[23:09:01.844] iteration 25130 : loss : 0.299967, loss_ce: 0.031302
[23:09:08.232] iteration 25140 : loss : 0.320426, loss_ce: 0.021130
[23:09:14.633] iteration 25150 : loss : 0.231640, loss_ce: 0.011719
[23:09:21.028] iteration 25160 : loss : 0.341338, loss_ce: 0.022791
[23:09:27.426] iteration 25170 : loss : 0.258269, loss_ce: 0.018051
[23:09:33.814] iteration 25180 : loss : 0.320201, loss_ce: 0.029345
[23:09:40.212] iteration 25190 : loss : 0.288100, loss_ce: 0.020812
[23:09:46.603] iteration 25200 : loss : 0.313628, loss_ce: 0.026225
[23:09:53.010] iteration 25210 : loss : 0.159286, loss_ce: 0.022447
[23:09:59.398] iteration 25220 : loss : 0.182064, loss_ce: 0.017907
[23:10:05.796] iteration 25230 : loss : 0.252115, loss_ce: 0.012447
[23:10:12.185] iteration 25240 : loss : 0.268316, loss_ce: 0.020201
[23:10:18.589] iteration 25250 : loss : 0.258492, loss_ce: 0.013734
[23:10:24.981] iteration 25260 : loss : 0.323653, loss_ce: 0.030594
[23:10:31.387] iteration 25270 : loss : 0.289901, loss_ce: 0.019233
[23:10:37.777] iteration 25280 : loss : 0.135221, loss_ce: 0.016988
[23:10:44.179] iteration 25290 : loss : 0.270078, loss_ce: 0.026988
[23:10:50.570] iteration 25300 : loss : 0.280597, loss_ce: 0.029415
[23:10:56.972] iteration 25310 : loss : 0.246035, loss_ce: 0.021259
[23:11:03.365] iteration 25320 : loss : 0.328279, loss_ce: 0.012464
[23:11:09.764] iteration 25330 : loss : 0.328686, loss_ce: 0.021317
[23:11:16.156] iteration 25340 : loss : 0.274744, loss_ce: 0.011971
[23:11:22.557] iteration 25350 : loss : 0.286729, loss_ce: 0.009666
[23:11:28.944] iteration 25360 : loss : 0.267170, loss_ce: 0.021021
[23:11:35.349] iteration 25370 : loss : 0.321415, loss_ce: 0.020366
[23:11:41.740] iteration 25380 : loss : 0.320010, loss_ce: 0.030456
[23:11:48.142] iteration 25390 : loss : 0.351535, loss_ce: 0.026193
[23:11:54.535] iteration 25400 : loss : 0.315466, loss_ce: 0.047905
[23:12:00.935] iteration 25410 : loss : 0.277619, loss_ce: 0.016203
[23:12:07.326] iteration 25420 : loss : 0.338365, loss_ce: 0.025461
[23:12:13.730] iteration 25430 : loss : 0.314569, loss_ce: 0.022306
[23:12:20.118] iteration 25440 : loss : 0.350636, loss_ce: 0.019363
[23:12:26.521] iteration 25450 : loss : 0.298729, loss_ce: 0.024523
[23:12:32.911] iteration 25460 : loss : 0.343089, loss_ce: 0.017340
[23:12:38.885] iteration 25470 : loss : 0.314309, loss_ce: 0.012540
[23:12:39.566] Epoch 44: Average loss: 0.2883
[23:18:32.723] iteration 25480 : loss : 0.286245, loss_ce: 0.019843
[23:18:39.088] iteration 25490 : loss : 0.310704, loss_ce: 0.029445
[23:18:45.443] iteration 25500 : loss : 0.289229, loss_ce: 0.031386
[23:18:51.812] iteration 25510 : loss : 0.274563, loss_ce: 0.021433
[23:18:58.174] iteration 25520 : loss : 0.276833, loss_ce: 0.020104
[23:19:04.549] iteration 25530 : loss : 0.144383, loss_ce: 0.011298
[23:19:10.911] iteration 25540 : loss : 0.326480, loss_ce: 0.026774
[23:19:17.289] iteration 25550 : loss : 0.269281, loss_ce: 0.025520
[23:19:23.657] iteration 25560 : loss : 0.298759, loss_ce: 0.026550
[23:19:30.040] iteration 25570 : loss : 0.304702, loss_ce: 0.025945
[23:19:36.412] iteration 25580 : loss : 0.292841, loss_ce: 0.023716
[23:19:42.792] iteration 25590 : loss : 0.293080, loss_ce: 0.019446
[23:19:49.163] iteration 25600 : loss : 0.338580, loss_ce: 0.026246
[23:19:55.549] iteration 25610 : loss : 0.305128, loss_ce: 0.019345
[23:20:01.923] iteration 25620 : loss : 0.316554, loss_ce: 0.025959
[23:20:08.309] iteration 25630 : loss : 0.294900, loss_ce: 0.024379
[23:20:14.687] iteration 25640 : loss : 0.313517, loss_ce: 0.021788
[23:20:21.071] iteration 25650 : loss : 0.308804, loss_ce: 0.016551
[23:20:27.446] iteration 25660 : loss : 0.121226, loss_ce: 0.019979
[23:20:33.833] iteration 25670 : loss : 0.315947, loss_ce: 0.029259
[23:20:40.213] iteration 25680 : loss : 0.265957, loss_ce: 0.014304
[23:20:46.604] iteration 25690 : loss : 0.291775, loss_ce: 0.022724
[23:20:52.984] iteration 25700 : loss : 0.324754, loss_ce: 0.019857
[23:20:59.379] iteration 25710 : loss : 0.272753, loss_ce: 0.023667
[23:21:05.760] iteration 25720 : loss : 0.330232, loss_ce: 0.027591
[23:21:12.156] iteration 25730 : loss : 0.245593, loss_ce: 0.021576
[23:21:18.541] iteration 25740 : loss : 0.281739, loss_ce: 0.018006
[23:21:24.936] iteration 25750 : loss : 0.341903, loss_ce: 0.026640
[23:21:31.321] iteration 25760 : loss : 0.339840, loss_ce: 0.020260
[23:21:37.714] iteration 25770 : loss : 0.303054, loss_ce: 0.018779
[23:21:44.101] iteration 25780 : loss : 0.143634, loss_ce: 0.007905
[23:21:50.500] iteration 25790 : loss : 0.262843, loss_ce: 0.015233
[23:21:56.885] iteration 25800 : loss : 0.329826, loss_ce: 0.029092
[23:22:03.279] iteration 25810 : loss : 0.300291, loss_ce: 0.014342
[23:22:09.663] iteration 25820 : loss : 0.271540, loss_ce: 0.028281
[23:22:16.061] iteration 25830 : loss : 0.303373, loss_ce: 0.022547
[23:22:22.450] iteration 25840 : loss : 0.269334, loss_ce: 0.021437
[23:22:28.853] iteration 25850 : loss : 0.319911, loss_ce: 0.021351
[23:22:35.242] iteration 25860 : loss : 0.330352, loss_ce: 0.020168
[23:22:41.637] iteration 25870 : loss : 0.323867, loss_ce: 0.014682
[23:22:48.027] iteration 25880 : loss : 0.245502, loss_ce: 0.015604
[23:22:54.425] iteration 25890 : loss : 0.307380, loss_ce: 0.023669
[23:23:00.812] iteration 25900 : loss : 0.289534, loss_ce: 0.022996
[23:23:07.205] iteration 25910 : loss : 0.315021, loss_ce: 0.027092
[23:23:13.588] iteration 25920 : loss : 0.283910, loss_ce: 0.019795
[23:23:19.983] iteration 25930 : loss : 0.297124, loss_ce: 0.035815
[23:23:26.369] iteration 25940 : loss : 0.283407, loss_ce: 0.028133
[23:23:32.766] iteration 25950 : loss : 0.316455, loss_ce: 0.013553
[23:23:39.156] iteration 25960 : loss : 0.326772, loss_ce: 0.027314
[23:23:45.556] iteration 25970 : loss : 0.293900, loss_ce: 0.011470
[23:23:51.941] iteration 25980 : loss : 0.308217, loss_ce: 0.029874
[23:23:58.338] iteration 25990 : loss : 0.313254, loss_ce: 0.019274
[23:24:04.721] iteration 26000 : loss : 0.306961, loss_ce: 0.016744
[23:24:11.117] iteration 26010 : loss : 0.310798, loss_ce: 0.028997
[23:24:17.505] iteration 26020 : loss : 0.296386, loss_ce: 0.014228
[23:24:23.907] iteration 26030 : loss : 0.272911, loss_ce: 0.022881
[23:24:27.999] Epoch 45: Average loss: 0.2894
[23:24:42.026] iteration 26040 : loss : 0.247366, loss_ce: 0.010404
[23:24:48.402] iteration 26050 : loss : 0.272162, loss_ce: 0.012393
[23:24:54.771] iteration 26060 : loss : 0.322340, loss_ce: 0.020175
[23:25:01.156] iteration 26070 : loss : 0.280914, loss_ce: 0.020618
[23:25:07.529] iteration 26080 : loss : 0.300649, loss_ce: 0.014814
[23:25:13.917] iteration 26090 : loss : 0.347738, loss_ce: 0.035482
[23:25:20.296] iteration 26100 : loss : 0.321625, loss_ce: 0.030077
[23:25:26.689] iteration 26110 : loss : 0.321238, loss_ce: 0.028046
[23:25:33.072] iteration 26120 : loss : 0.291729, loss_ce: 0.026964
[23:25:39.464] iteration 26130 : loss : 0.287045, loss_ce: 0.023477
[23:25:45.845] iteration 26140 : loss : 0.286927, loss_ce: 0.027264
[23:25:52.236] iteration 26150 : loss : 0.334387, loss_ce: 0.016975
[23:25:58.611] iteration 26160 : loss : 0.264447, loss_ce: 0.015503
[23:26:05.004] iteration 26170 : loss : 0.346441, loss_ce: 0.037871
[23:26:11.385] iteration 26180 : loss : 0.244469, loss_ce: 0.016428
[23:26:17.779] iteration 26190 : loss : 0.307956, loss_ce: 0.028020
[23:26:24.164] iteration 26200 : loss : 0.260539, loss_ce: 0.021950
[23:26:30.557] iteration 26210 : loss : 0.321726, loss_ce: 0.024349
[23:26:36.942] iteration 26220 : loss : 0.252953, loss_ce: 0.025889
[23:26:43.334] iteration 26230 : loss : 0.119015, loss_ce: 0.016882
[23:26:49.723] iteration 26240 : loss : 0.301556, loss_ce: 0.015755
[23:26:56.118] iteration 26250 : loss : 0.305258, loss_ce: 0.024476
[23:27:02.502] iteration 26260 : loss : 0.320999, loss_ce: 0.020923
[23:27:08.902] iteration 26270 : loss : 0.284153, loss_ce: 0.024585
[23:27:15.285] iteration 26280 : loss : 0.328658, loss_ce: 0.023313
[23:27:21.686] iteration 26290 : loss : 0.320404, loss_ce: 0.031791
[23:27:28.077] iteration 26300 : loss : 0.319101, loss_ce: 0.025147
[23:27:34.478] iteration 26310 : loss : 0.296732, loss_ce: 0.022077
[23:27:40.867] iteration 26320 : loss : 0.200600, loss_ce: 0.023083
[23:27:47.266] iteration 26330 : loss : 0.274048, loss_ce: 0.018137
[23:27:53.657] iteration 26340 : loss : 0.322167, loss_ce: 0.031463
[23:28:00.058] iteration 26350 : loss : 0.272073, loss_ce: 0.023433
[23:28:06.443] iteration 26360 : loss : 0.319571, loss_ce: 0.014669
[23:28:12.842] iteration 26370 : loss : 0.323190, loss_ce: 0.013318
[23:28:19.229] iteration 26380 : loss : 0.272921, loss_ce: 0.013744
[23:28:25.629] iteration 26390 : loss : 0.287718, loss_ce: 0.028405
[23:28:32.017] iteration 26400 : loss : 0.292561, loss_ce: 0.017482
[23:28:38.413] iteration 26410 : loss : 0.299350, loss_ce: 0.029047
[23:28:44.801] iteration 26420 : loss : 0.273407, loss_ce: 0.014961
[23:28:51.199] iteration 26430 : loss : 0.271220, loss_ce: 0.015108
[23:28:57.588] iteration 26440 : loss : 0.149490, loss_ce: 0.022394
[23:29:03.993] iteration 26450 : loss : 0.324917, loss_ce: 0.012111
[23:29:10.386] iteration 26460 : loss : 0.313233, loss_ce: 0.010819
[23:29:16.788] iteration 26470 : loss : 0.325691, loss_ce: 0.024321
[23:29:23.180] iteration 26480 : loss : 0.292787, loss_ce: 0.017768
[23:29:29.577] iteration 26490 : loss : 0.306350, loss_ce: 0.024899
[23:29:35.966] iteration 26500 : loss : 0.337976, loss_ce: 0.011682
[23:29:42.368] iteration 26510 : loss : 0.122419, loss_ce: 0.018398
[23:29:48.760] iteration 26520 : loss : 0.262715, loss_ce: 0.016744
[23:29:55.159] iteration 26530 : loss : 0.158707, loss_ce: 0.011862
[23:30:01.547] iteration 26540 : loss : 0.299026, loss_ce: 0.015846
[23:30:07.946] iteration 26550 : loss : 0.295123, loss_ce: 0.026579
[23:30:14.335] iteration 26560 : loss : 0.310151, loss_ce: 0.013983
[23:30:20.736] iteration 26570 : loss : 0.300136, loss_ce: 0.025379
[23:30:27.126] iteration 26580 : loss : 0.305900, loss_ce: 0.026459
[23:30:33.527] iteration 26590 : loss : 0.156338, loss_ce: 0.026793
[23:30:39.918] iteration 26600 : loss : 0.353830, loss_ce: 0.030001
[23:30:41.473] Epoch 46: Average loss: 0.2859
[23:30:57.844] iteration 26610 : loss : 0.281337, loss_ce: 0.023554
[23:31:04.213] iteration 26620 : loss : 0.318780, loss_ce: 0.032225
[23:31:10.597] iteration 26630 : loss : 0.264082, loss_ce: 0.012123
[23:31:16.977] iteration 26640 : loss : 0.318776, loss_ce: 0.022480
[23:31:23.366] iteration 26650 : loss : 0.330189, loss_ce: 0.017729
[23:31:29.746] iteration 26660 : loss : 0.295929, loss_ce: 0.024643
[23:31:36.136] iteration 26670 : loss : 0.334377, loss_ce: 0.023623
[23:31:42.519] iteration 26680 : loss : 0.339851, loss_ce: 0.017470
[23:31:48.911] iteration 26690 : loss : 0.158393, loss_ce: 0.020173
[23:31:55.293] iteration 26700 : loss : 0.085413, loss_ce: 0.007675
[23:32:01.688] iteration 26710 : loss : 0.303429, loss_ce: 0.018579
[23:32:08.069] iteration 26720 : loss : 0.168956, loss_ce: 0.016179
[23:32:14.465] iteration 26730 : loss : 0.129998, loss_ce: 0.029575
[23:32:20.850] iteration 26740 : loss : 0.282045, loss_ce: 0.016341
[23:32:27.241] iteration 26750 : loss : 0.342350, loss_ce: 0.053519
[23:32:33.632] iteration 26760 : loss : 0.321186, loss_ce: 0.015825
[23:32:40.035] iteration 26770 : loss : 0.328721, loss_ce: 0.025617
[23:32:46.422] iteration 26780 : loss : 0.303698, loss_ce: 0.025075
[23:32:52.820] iteration 26790 : loss : 0.286721, loss_ce: 0.019891
[23:32:59.208] iteration 26800 : loss : 0.349225, loss_ce: 0.016369
[23:33:05.606] iteration 26810 : loss : 0.290762, loss_ce: 0.018038
[23:33:11.996] iteration 26820 : loss : 0.282918, loss_ce: 0.021624
[23:33:18.401] iteration 26830 : loss : 0.203255, loss_ce: 0.015766
[23:33:24.791] iteration 26840 : loss : 0.264431, loss_ce: 0.019996
[23:33:31.187] iteration 26850 : loss : 0.163885, loss_ce: 0.018962
[23:33:37.576] iteration 26860 : loss : 0.267088, loss_ce: 0.020624
[23:33:43.980] iteration 26870 : loss : 0.311948, loss_ce: 0.021807
[23:33:50.370] iteration 26880 : loss : 0.279444, loss_ce: 0.025702
[23:33:56.770] iteration 26890 : loss : 0.280152, loss_ce: 0.017164
[23:34:03.156] iteration 26900 : loss : 0.151693, loss_ce: 0.006509
[23:34:09.560] iteration 26910 : loss : 0.102661, loss_ce: 0.016532
[23:34:15.948] iteration 26920 : loss : 0.268297, loss_ce: 0.015030
[23:34:22.347] iteration 26930 : loss : 0.259027, loss_ce: 0.022787
[23:34:28.738] iteration 26940 : loss : 0.290396, loss_ce: 0.019932
[23:34:35.135] iteration 26950 : loss : 0.269525, loss_ce: 0.021456
[23:34:41.524] iteration 26960 : loss : 0.288317, loss_ce: 0.017475
[23:34:47.922] iteration 26970 : loss : 0.084671, loss_ce: 0.009365
[23:34:54.309] iteration 26980 : loss : 0.358063, loss_ce: 0.015206
[23:35:00.710] iteration 26990 : loss : 0.326172, loss_ce: 0.025918
[23:35:07.098] iteration 27000 : loss : 0.339240, loss_ce: 0.012594
[23:35:13.502] iteration 27010 : loss : 0.287008, loss_ce: 0.031051
[23:35:19.892] iteration 27020 : loss : 0.292090, loss_ce: 0.016433
[23:35:26.291] iteration 27030 : loss : 0.297615, loss_ce: 0.020019
[23:35:32.677] iteration 27040 : loss : 0.338053, loss_ce: 0.028437
[23:35:39.073] iteration 27050 : loss : 0.310428, loss_ce: 0.012048
[23:35:45.459] iteration 27060 : loss : 0.322209, loss_ce: 0.026033
[23:35:51.861] iteration 27070 : loss : 0.288838, loss_ce: 0.017356
[23:35:58.254] iteration 27080 : loss : 0.303879, loss_ce: 0.051068
[23:36:04.654] iteration 27090 : loss : 0.130739, loss_ce: 0.017870
[23:36:11.047] iteration 27100 : loss : 0.252780, loss_ce: 0.019467
[23:36:17.448] iteration 27110 : loss : 0.276670, loss_ce: 0.016500
[23:36:23.838] iteration 27120 : loss : 0.256561, loss_ce: 0.019819
[23:36:30.242] iteration 27130 : loss : 0.304309, loss_ce: 0.018734
[23:36:36.638] iteration 27140 : loss : 0.304415, loss_ce: 0.028170
[23:36:43.041] iteration 27150 : loss : 0.297361, loss_ce: 0.022220
[23:36:49.430] iteration 27160 : loss : 0.297240, loss_ce: 0.026901
[23:36:54.807] Epoch 47: Average loss: 0.2806
[23:42:42.220] iteration 27170 : loss : 0.339502, loss_ce: 0.021163
[23:42:48.576] iteration 27180 : loss : 0.330182, loss_ce: 0.022656
[23:42:54.941] iteration 27190 : loss : 0.287314, loss_ce: 0.011549
[23:43:01.292] iteration 27200 : loss : 0.315001, loss_ce: 0.010608
[23:43:07.660] iteration 27210 : loss : 0.347288, loss_ce: 0.015036
[23:43:14.019] iteration 27220 : loss : 0.321523, loss_ce: 0.025793
[23:43:20.390] iteration 27230 : loss : 0.312939, loss_ce: 0.025287
[23:43:26.751] iteration 27240 : loss : 0.281033, loss_ce: 0.018278
[23:43:33.130] iteration 27250 : loss : 0.326977, loss_ce: 0.052067
[23:43:39.496] iteration 27260 : loss : 0.297908, loss_ce: 0.023263
[23:43:45.875] iteration 27270 : loss : 0.277230, loss_ce: 0.011029
[23:43:52.244] iteration 27280 : loss : 0.317069, loss_ce: 0.017376
[23:43:58.621] iteration 27290 : loss : 0.116069, loss_ce: 0.017516
[23:44:04.994] iteration 27300 : loss : 0.293819, loss_ce: 0.024942
[23:44:11.375] iteration 27310 : loss : 0.351938, loss_ce: 0.030733
[23:44:17.750] iteration 27320 : loss : 0.319164, loss_ce: 0.017995
[23:44:24.131] iteration 27330 : loss : 0.259080, loss_ce: 0.016961
[23:44:30.500] iteration 27340 : loss : 0.297909, loss_ce: 0.025679
[23:44:36.884] iteration 27350 : loss : 0.332734, loss_ce: 0.023981
[23:44:43.257] iteration 27360 : loss : 0.337204, loss_ce: 0.021049
[23:44:49.643] iteration 27370 : loss : 0.248392, loss_ce: 0.018495
[23:44:56.023] iteration 27380 : loss : 0.295179, loss_ce: 0.018597
[23:45:02.411] iteration 27390 : loss : 0.113484, loss_ce: 0.018968
[23:45:08.793] iteration 27400 : loss : 0.326870, loss_ce: 0.017018
[23:45:15.188] iteration 27410 : loss : 0.267691, loss_ce: 0.025145
[23:45:21.568] iteration 27420 : loss : 0.330685, loss_ce: 0.027811
[23:45:27.959] iteration 27430 : loss : 0.277783, loss_ce: 0.018400
[23:45:34.342] iteration 27440 : loss : 0.154147, loss_ce: 0.018842
[23:45:40.733] iteration 27450 : loss : 0.327382, loss_ce: 0.019814
[23:45:47.120] iteration 27460 : loss : 0.261929, loss_ce: 0.022971
[23:45:53.511] iteration 27470 : loss : 0.315785, loss_ce: 0.023179
[23:45:59.892] iteration 27480 : loss : 0.307577, loss_ce: 0.026700
[23:46:06.290] iteration 27490 : loss : 0.255254, loss_ce: 0.014696
[23:46:12.674] iteration 27500 : loss : 0.293412, loss_ce: 0.017198
[23:46:19.071] iteration 27510 : loss : 0.119701, loss_ce: 0.014489
[23:46:25.455] iteration 27520 : loss : 0.319455, loss_ce: 0.024399
[23:46:31.848] iteration 27530 : loss : 0.288962, loss_ce: 0.019364
[23:46:38.230] iteration 27540 : loss : 0.257762, loss_ce: 0.021268
[23:46:44.626] iteration 27550 : loss : 0.334738, loss_ce: 0.040719
[23:46:51.013] iteration 27560 : loss : 0.326865, loss_ce: 0.028029
[23:46:57.410] iteration 27570 : loss : 0.260710, loss_ce: 0.016053
[23:47:03.797] iteration 27580 : loss : 0.271156, loss_ce: 0.026441
[23:47:10.197] iteration 27590 : loss : 0.253322, loss_ce: 0.015937
[23:47:16.583] iteration 27600 : loss : 0.342716, loss_ce: 0.022250
[23:47:22.980] iteration 27610 : loss : 0.263729, loss_ce: 0.021666
[23:47:29.368] iteration 27620 : loss : 0.332376, loss_ce: 0.021990
[23:47:35.772] iteration 27630 : loss : 0.318402, loss_ce: 0.021006
[23:47:42.161] iteration 27640 : loss : 0.271475, loss_ce: 0.020429
[23:47:48.559] iteration 27650 : loss : 0.261855, loss_ce: 0.019947
[23:47:54.943] iteration 27660 : loss : 0.120125, loss_ce: 0.012758
[23:48:01.338] iteration 27670 : loss : 0.122115, loss_ce: 0.017034
[23:48:07.727] iteration 27680 : loss : 0.321838, loss_ce: 0.010160
[23:48:14.127] iteration 27690 : loss : 0.290116, loss_ce: 0.018529
[23:48:20.511] iteration 27700 : loss : 0.286753, loss_ce: 0.051539
[23:48:26.904] iteration 27710 : loss : 0.273469, loss_ce: 0.026115
[23:48:33.290] iteration 27720 : loss : 0.312516, loss_ce: 0.020985
[23:48:39.689] iteration 27730 : loss : 0.174555, loss_ce: 0.015510
[23:48:42.499] Epoch 48: Average loss: 0.2827
[23:48:57.673] iteration 27740 : loss : 0.281497, loss_ce: 0.019158
[23:49:04.048] iteration 27750 : loss : 0.289554, loss_ce: 0.021175
[23:49:10.420] iteration 27760 : loss : 0.092873, loss_ce: 0.020801
[23:49:16.803] iteration 27770 : loss : 0.325731, loss_ce: 0.015727
[23:49:23.178] iteration 27780 : loss : 0.300011, loss_ce: 0.026033
[23:49:29.564] iteration 27790 : loss : 0.219623, loss_ce: 0.011324
[23:49:35.934] iteration 27800 : loss : 0.312253, loss_ce: 0.023484
[23:49:42.321] iteration 27810 : loss : 0.279798, loss_ce: 0.016766
[23:49:48.703] iteration 27820 : loss : 0.282063, loss_ce: 0.012928
[23:49:55.090] iteration 27830 : loss : 0.279278, loss_ce: 0.019828
[23:50:01.470] iteration 27840 : loss : 0.308774, loss_ce: 0.022595
[23:50:07.863] iteration 27850 : loss : 0.301586, loss_ce: 0.026993
[23:50:14.249] iteration 27860 : loss : 0.320514, loss_ce: 0.015083
[23:50:20.640] iteration 27870 : loss : 0.262286, loss_ce: 0.013465
[23:50:27.023] iteration 27880 : loss : 0.300342, loss_ce: 0.024780
[23:50:33.417] iteration 27890 : loss : 0.285906, loss_ce: 0.009660
[23:50:39.803] iteration 27900 : loss : 0.354607, loss_ce: 0.032519
[23:50:46.197] iteration 27910 : loss : 0.305399, loss_ce: 0.030028
[23:50:52.582] iteration 27920 : loss : 0.283755, loss_ce: 0.032432
[23:50:58.973] iteration 27930 : loss : 0.277933, loss_ce: 0.015775
[23:51:05.356] iteration 27940 : loss : 0.308454, loss_ce: 0.014424
[23:51:11.751] iteration 27950 : loss : 0.258416, loss_ce: 0.023061
[23:51:18.138] iteration 27960 : loss : 0.327727, loss_ce: 0.014370
[23:51:24.532] iteration 27970 : loss : 0.287663, loss_ce: 0.032839
[23:51:30.916] iteration 27980 : loss : 0.275811, loss_ce: 0.034550
[23:51:37.310] iteration 27990 : loss : 0.308697, loss_ce: 0.028698
[23:51:43.697] iteration 28000 : loss : 0.274979, loss_ce: 0.026546
[23:51:50.091] iteration 28010 : loss : 0.259928, loss_ce: 0.017958
[23:51:56.481] iteration 28020 : loss : 0.281394, loss_ce: 0.020140
[23:52:02.879] iteration 28030 : loss : 0.271487, loss_ce: 0.014698
[23:52:09.265] iteration 28040 : loss : 0.365578, loss_ce: 0.016610
[23:52:15.656] iteration 28050 : loss : 0.335010, loss_ce: 0.010397
[23:52:22.042] iteration 28060 : loss : 0.297395, loss_ce: 0.024636
[23:52:28.438] iteration 28070 : loss : 0.257945, loss_ce: 0.015210
[23:52:34.826] iteration 28080 : loss : 0.166842, loss_ce: 0.011098
[23:52:41.228] iteration 28090 : loss : 0.261947, loss_ce: 0.024337
[23:52:47.612] iteration 28100 : loss : 0.318122, loss_ce: 0.026675
[23:52:54.006] iteration 28110 : loss : 0.322181, loss_ce: 0.016763
[23:53:00.395] iteration 28120 : loss : 0.311352, loss_ce: 0.011650
[23:53:06.793] iteration 28130 : loss : 0.179289, loss_ce: 0.014671
[23:53:13.180] iteration 28140 : loss : 0.332309, loss_ce: 0.010910
[23:53:19.577] iteration 28150 : loss : 0.242185, loss_ce: 0.017682
[23:53:25.963] iteration 28160 : loss : 0.284542, loss_ce: 0.025328
[23:53:32.363] iteration 28170 : loss : 0.239129, loss_ce: 0.027319
[23:53:38.753] iteration 28180 : loss : 0.143005, loss_ce: 0.017617
[23:53:45.154] iteration 28190 : loss : 0.267298, loss_ce: 0.028219
[23:53:51.544] iteration 28200 : loss : 0.298916, loss_ce: 0.026664
[23:53:57.946] iteration 28210 : loss : 0.338776, loss_ce: 0.023835
[23:54:04.337] iteration 28220 : loss : 0.270949, loss_ce: 0.020671
[23:54:10.738] iteration 28230 : loss : 0.178989, loss_ce: 0.021493
[23:54:17.124] iteration 28240 : loss : 0.239505, loss_ce: 0.018704
[23:54:23.521] iteration 28250 : loss : 0.282653, loss_ce: 0.013162
[23:54:29.909] iteration 28260 : loss : 0.244478, loss_ce: 0.021895
[23:54:36.313] iteration 28270 : loss : 0.288685, loss_ce: 0.017018
[23:54:42.704] iteration 28280 : loss : 0.325311, loss_ce: 0.026940
[23:54:49.100] iteration 28290 : loss : 0.305274, loss_ce: 0.036390
[23:54:55.059] iteration 28300 : loss : 0.286243, loss_ce: 0.034557
[23:54:55.740] Epoch 49: Average loss: 0.2773
[23:54:55.844] save model to ./finetune_tpgm_kits23_continual_fixed\finetuned_epoch_49.pth
[23:54:56.063] save final model to ./finetune_tpgm_kits23_continual_fixed\finetuned_final.pth
