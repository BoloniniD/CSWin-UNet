[15:23:53.549] Namespace(root_path='./datasets/kits23/train_npz', dataset='kits23', list_dir='./lists/kits23', num_classes_old=9, num_classes_new=4, output_dir='./debug_fixed_tpgm', max_iterations=10000, max_epochs=15, batch_size=32, n_gpu=1, deterministic=1, base_lr=0.001, img_size=224, seed=1234, cfg='configs/finetune.yaml', pretrained_path='./pretrain/epoch_149.pth', data_fraction=0.35, kd_temperature=3.0, kd_weight=0.2, freeze_old_classes=False, auto_tune='RGN', gradient_batches=5, tpgm_norm_mode='l2', tpgm_lr=0.05, tpgm_iters=500, tpgm_exclude=[], tpgm_frequency=2, tpgm_start_epoch=2, disable_tpgm=False, tpgm_data_fraction=0.3, opts=None, zip=False, cache_mode='part', resume=None, accumulation_steps=None, use_checkpoint=False, amp_opt_level='O1', tag=None, eval=False, throughput=False)
[15:23:53.568] Using 33327/95221 samples (35.0%) for continual learning
[15:23:53.568] Old classes: 9, New classes: 4, Total: 12
[15:23:53.568] TPGM enabled: True
[15:23:53.568] Surgical fine-tuning method: RGN
[15:24:10.218] Namespace(root_path='./datasets/kits23/train_npz', dataset='kits23', list_dir='./lists/kits23', num_classes_old=9, num_classes_new=4, output_dir='./debug_fixed_tpgm', max_iterations=10000, max_epochs=15, batch_size=32, n_gpu=1, deterministic=1, base_lr=0.001, img_size=224, seed=1234, cfg='configs/finetune.yaml', pretrained_path='./pretrain/epoch_149.pth', data_fraction=0.35, kd_temperature=3.0, kd_weight=0.2, freeze_old_classes=False, auto_tune='none', gradient_batches=5, tpgm_norm_mode='l2', tpgm_lr=0.05, tpgm_iters=500, tpgm_exclude=[], tpgm_frequency=2, tpgm_start_epoch=2, disable_tpgm=False, tpgm_data_fraction=0.3, opts=None, zip=False, cache_mode='part', resume=None, accumulation_steps=None, use_checkpoint=False, amp_opt_level='O1', tag=None, eval=False, throughput=False)
[15:24:10.236] Using 33327/95221 samples (35.0%) for continual learning
[15:24:10.236] Old classes: 9, New classes: 4, Total: 12
[15:24:10.236] TPGM enabled: True
[15:24:10.236] Surgical fine-tuning method: none
[15:27:08.314] Combined Continual Learning + Surgical + TPGM Configuration:
[15:27:08.314] KD Temperature: 3.0
[15:27:08.314] KD Weight: 0.2
[15:27:08.314] Auto-tune method: none
[15:27:08.314] TPGM start epoch: 2
[15:27:08.316] TPGM frequency: 2
[15:27:08.316] 1042 iterations per epoch. 15630 max iterations 
[15:27:25.088] iteration 10 : loss : 5603.246582, loss_ce: 0.254506, loss_kd: 28013.501953
[15:27:30.571] iteration 20 : loss : 3771.561279, loss_ce: 0.232940, loss_kd: 18854.687500
[15:27:36.178] iteration 30 : loss : 4068.643311, loss_ce: 0.170892, loss_kd: 20340.373047
[15:27:41.673] iteration 40 : loss : 2952.815674, loss_ce: 0.147216, loss_kd: 14761.041016
[15:27:47.186] iteration 50 : loss : 1991.151123, loss_ce: 0.134721, loss_kd: 9952.947266
[15:27:52.688] iteration 60 : loss : 1787.323975, loss_ce: 0.171531, loss_kd: 8933.642578
[15:27:58.199] iteration 70 : loss : 1302.562500, loss_ce: 0.168004, loss_kd: 6509.942871
[15:28:03.703] iteration 80 : loss : 1267.604736, loss_ce: 0.093403, loss_kd: 6335.222168
[15:28:09.217] iteration 90 : loss : 1514.672241, loss_ce: 0.126000, loss_kd: 7570.385254
[15:28:14.717] iteration 100 : loss : 1292.782593, loss_ce: 0.098314, loss_kd: 6461.148926
[15:28:20.238] iteration 110 : loss : 1334.174072, loss_ce: 0.080514, loss_kd: 6667.932617
[15:28:25.749] iteration 120 : loss : 1364.823608, loss_ce: 0.078627, loss_kd: 6821.250000
[15:28:31.270] iteration 130 : loss : 1067.468506, loss_ce: 0.098510, loss_kd: 5334.640625
[15:28:36.785] iteration 140 : loss : 1271.808838, loss_ce: 0.058937, loss_kd: 6356.400391
[15:28:42.314] iteration 150 : loss : 1064.039795, loss_ce: 0.085945, loss_kd: 5317.400391
[15:28:47.832] iteration 160 : loss : 1198.357788, loss_ce: 0.024793, loss_kd: 5989.071289
[15:28:53.361] iteration 170 : loss : 911.944824, loss_ce: 0.026217, loss_kd: 4557.009766
[15:28:58.886] iteration 180 : loss : 1339.675537, loss_ce: 0.018147, loss_kd: 6695.767090
[15:29:04.416] iteration 190 : loss : 909.561035, loss_ce: 0.043075, loss_kd: 4545.091309
[15:29:09.952] iteration 200 : loss : 862.236206, loss_ce: 0.034092, loss_kd: 4308.442383
[15:29:15.487] iteration 210 : loss : 838.607788, loss_ce: 0.025415, loss_kd: 4190.500000
[15:29:21.009] iteration 220 : loss : 907.366760, loss_ce: 0.021083, loss_kd: 4534.179199
[15:29:26.544] iteration 230 : loss : 1259.537231, loss_ce: 0.018248, loss_kd: 6295.015137
[15:29:32.078] iteration 240 : loss : 662.233398, loss_ce: 0.017866, loss_kd: 3308.486084
[15:29:37.616] iteration 250 : loss : 664.609619, loss_ce: 0.021476, loss_kd: 3320.434082
[15:29:43.145] iteration 260 : loss : 1170.447998, loss_ce: 0.030219, loss_kd: 5849.553711
[15:29:48.684] iteration 270 : loss : 840.907898, loss_ce: 0.012443, loss_kd: 4202.014160
[15:29:54.210] iteration 280 : loss : 951.925598, loss_ce: 0.027856, loss_kd: 4757.088379
[15:29:59.749] iteration 290 : loss : 781.685608, loss_ce: 0.009956, loss_kd: 3905.769775
[15:30:05.280] iteration 300 : loss : 727.529602, loss_ce: 0.010693, loss_kd: 3635.146484
[15:30:10.823] iteration 310 : loss : 841.190918, loss_ce: 0.022380, loss_kd: 4203.367676
[15:30:16.360] iteration 320 : loss : 1059.872925, loss_ce: 0.016011, loss_kd: 5296.823730
[15:30:21.901] iteration 330 : loss : 832.491272, loss_ce: 0.019374, loss_kd: 4159.865234
[15:30:27.436] iteration 340 : loss : 807.053101, loss_ce: 0.015402, loss_kd: 4032.727295
[15:30:32.979] iteration 350 : loss : 780.537109, loss_ce: 0.027872, loss_kd: 3900.122070
[15:30:38.513] iteration 360 : loss : 651.616821, loss_ce: 0.025221, loss_kd: 3255.549561
[15:30:44.056] iteration 370 : loss : 691.620728, loss_ce: 0.018099, loss_kd: 3455.562744
[15:30:49.594] iteration 380 : loss : 653.950623, loss_ce: 0.022522, loss_kd: 3267.224121
[15:30:55.138] iteration 390 : loss : 864.127869, loss_ce: 0.010945, loss_kd: 4318.078125
[15:31:00.675] iteration 400 : loss : 968.035828, loss_ce: 0.016071, loss_kd: 4837.653809
[15:31:06.222] iteration 410 : loss : 944.567200, loss_ce: 0.024826, loss_kd: 4720.268066
[15:31:11.760] iteration 420 : loss : 811.525940, loss_ce: 0.022086, loss_kd: 4055.094971
[15:31:17.307] iteration 430 : loss : 663.257751, loss_ce: 0.013856, loss_kd: 3313.819824
[15:31:22.848] iteration 440 : loss : 881.240173, loss_ce: 0.019214, loss_kd: 4403.725586
[15:31:28.397] iteration 450 : loss : 422.091400, loss_ce: 0.015780, loss_kd: 2107.873047
[15:31:33.934] iteration 460 : loss : 673.163757, loss_ce: 0.022679, loss_kd: 3363.295166
[15:31:39.484] iteration 470 : loss : 725.383789, loss_ce: 0.021429, loss_kd: 3624.394531
[15:31:45.023] iteration 480 : loss : 928.828247, loss_ce: 0.028458, loss_kd: 4641.640137
[15:31:50.576] iteration 490 : loss : 719.796387, loss_ce: 0.021234, loss_kd: 3596.501953
[15:31:56.117] iteration 500 : loss : 633.446045, loss_ce: 0.022232, loss_kd: 3164.729980
[15:32:01.671] iteration 510 : loss : 632.843079, loss_ce: 0.032295, loss_kd: 3161.754395
[15:32:07.218] iteration 520 : loss : 595.767456, loss_ce: 0.027955, loss_kd: 2976.213379
[15:32:12.771] iteration 530 : loss : 698.667603, loss_ce: 0.015485, loss_kd: 3490.791504
[15:32:18.319] iteration 540 : loss : 670.178711, loss_ce: 0.020205, loss_kd: 3348.348145
[15:32:23.875] iteration 550 : loss : 810.671631, loss_ce: 0.027695, loss_kd: 4050.761230
[15:32:29.424] iteration 560 : loss : 917.016113, loss_ce: 0.017088, loss_kd: 4582.431641
[15:32:34.984] iteration 570 : loss : 715.640076, loss_ce: 0.030183, loss_kd: 3575.730469
[15:32:40.530] iteration 580 : loss : 491.049988, loss_ce: 0.027736, loss_kd: 2452.772217
[15:32:46.088] iteration 590 : loss : 593.401489, loss_ce: 0.011959, loss_kd: 2964.468262
[15:32:51.640] iteration 600 : loss : 845.662842, loss_ce: 0.026428, loss_kd: 4225.774902
[15:32:57.208] iteration 610 : loss : 553.627136, loss_ce: 0.026654, loss_kd: 2765.651611
[15:33:02.762] iteration 620 : loss : 750.811279, loss_ce: 0.013163, loss_kd: 3751.528564
[15:33:08.328] iteration 630 : loss : 601.464478, loss_ce: 0.029541, loss_kd: 3004.751953
[15:33:13.879] iteration 640 : loss : 570.588257, loss_ce: 0.034777, loss_kd: 2850.468262
[15:33:19.445] iteration 650 : loss : 471.446289, loss_ce: 0.032394, loss_kd: 2354.735352
[15:33:25.005] iteration 660 : loss : 811.087646, loss_ce: 0.028226, loss_kd: 4052.979980
[15:33:30.572] iteration 670 : loss : 629.304749, loss_ce: 0.022235, loss_kd: 3144.053223
[15:33:36.130] iteration 680 : loss : 449.536713, loss_ce: 0.022644, loss_kd: 2245.185303
[15:33:41.693] iteration 690 : loss : 711.032776, loss_ce: 0.021610, loss_kd: 3552.645020
[15:33:47.256] iteration 700 : loss : 544.096558, loss_ce: 0.020175, loss_kd: 2717.778076
[15:33:52.828] iteration 710 : loss : 675.687744, loss_ce: 0.029739, loss_kd: 3375.739990
[15:33:58.391] iteration 720 : loss : 639.881836, loss_ce: 0.019859, loss_kd: 3196.955566
[15:34:03.954] iteration 730 : loss : 694.106384, loss_ce: 0.038939, loss_kd: 3467.986084
[15:34:09.515] iteration 740 : loss : 532.615906, loss_ce: 0.025773, loss_kd: 2660.572754
[15:34:15.085] iteration 750 : loss : 526.581787, loss_ce: 0.022426, loss_kd: 2630.363770
[15:34:20.663] iteration 760 : loss : 536.041443, loss_ce: 0.028603, loss_kd: 2677.488525
[15:34:26.232] iteration 770 : loss : 603.981323, loss_ce: 0.034181, loss_kd: 3017.374756
[15:34:31.800] iteration 780 : loss : 571.653442, loss_ce: 0.033517, loss_kd: 2855.755615
[15:34:37.372] iteration 790 : loss : 561.791809, loss_ce: 0.017171, loss_kd: 2806.466309
[15:34:42.933] iteration 800 : loss : 632.052185, loss_ce: 0.033404, loss_kd: 3157.659180
[15:34:48.517] iteration 810 : loss : 610.029785, loss_ce: 0.024912, loss_kd: 3047.596680
[15:34:54.084] iteration 820 : loss : 548.138855, loss_ce: 0.022109, loss_kd: 2738.201172
[15:34:59.659] iteration 830 : loss : 590.406189, loss_ce: 0.027461, loss_kd: 2949.470947
[15:35:05.225] iteration 840 : loss : 589.569702, loss_ce: 0.020586, loss_kd: 2945.408447
[15:35:10.807] iteration 850 : loss : 655.125549, loss_ce: 0.030032, loss_kd: 3273.090332
[15:35:16.372] iteration 860 : loss : 563.401611, loss_ce: 0.028497, loss_kd: 2814.505615
[15:35:21.957] iteration 870 : loss : 488.075439, loss_ce: 0.020553, loss_kd: 2437.838135
[15:35:27.519] iteration 880 : loss : 504.083862, loss_ce: 0.039870, loss_kd: 2517.945068
[15:35:33.099] iteration 890 : loss : 574.257141, loss_ce: 0.023527, loss_kd: 2868.891602
[15:35:38.666] iteration 900 : loss : 497.354889, loss_ce: 0.027568, loss_kd: 2484.265625
[15:35:44.251] iteration 910 : loss : 536.381226, loss_ce: 0.017047, loss_kd: 2679.436035
[15:35:49.827] iteration 920 : loss : 338.371033, loss_ce: 0.015665, loss_kd: 1689.400635
[15:35:55.420] iteration 930 : loss : 733.632996, loss_ce: 0.020874, loss_kd: 3665.660156
[15:36:00.988] iteration 940 : loss : 707.759094, loss_ce: 0.018978, loss_kd: 3536.263428
[15:36:06.570] iteration 950 : loss : 516.808350, loss_ce: 0.018901, loss_kd: 2581.474365
[15:36:12.150] iteration 960 : loss : 803.667908, loss_ce: 0.033328, loss_kd: 4015.752441
[15:36:17.737] iteration 970 : loss : 538.848511, loss_ce: 0.022242, loss_kd: 2691.707275
[15:36:23.309] iteration 980 : loss : 733.242310, loss_ce: 0.028122, loss_kd: 3663.610107
[15:36:28.888] iteration 990 : loss : 583.406555, loss_ce: 0.023614, loss_kd: 2914.543945
[15:36:34.462] iteration 1000 : loss : 668.314148, loss_ce: 0.022032, loss_kd: 3338.942627
[15:36:40.058] iteration 1010 : loss : 608.197205, loss_ce: 0.027397, loss_kd: 3038.499023
[15:36:45.629] iteration 1020 : loss : 710.695007, loss_ce: 0.028599, loss_kd: 3550.827881
[15:36:51.213] iteration 1030 : loss : 371.426361, loss_ce: 0.031638, loss_kd: 1854.553711
[15:36:56.793] iteration 1040 : loss : 463.645935, loss_ce: 0.025338, loss_kd: 2315.783936
[15:37:13.558] iteration 1050 : loss : 693.265869, loss_ce: 0.029213, loss_kd: 3463.863525
[15:37:19.089] iteration 1060 : loss : 526.721313, loss_ce: 0.026412, loss_kd: 2631.070801
[15:37:24.631] iteration 1070 : loss : 531.308167, loss_ce: 0.021096, loss_kd: 2654.069824
[15:37:30.173] iteration 1080 : loss : 465.289429, loss_ce: 0.024918, loss_kd: 2323.877441
[15:37:35.725] iteration 1090 : loss : 557.345154, loss_ce: 0.024157, loss_kd: 2784.248291
[15:37:41.270] iteration 1100 : loss : 488.818604, loss_ce: 0.018032, loss_kd: 2441.529541
[15:37:46.836] iteration 1110 : loss : 367.081024, loss_ce: 0.030003, loss_kd: 1832.895020
[15:37:52.394] iteration 1120 : loss : 761.583252, loss_ce: 0.018275, loss_kd: 3805.383545
[15:37:57.957] iteration 1130 : loss : 321.110199, loss_ce: 0.023297, loss_kd: 1603.010620
[15:38:03.513] iteration 1140 : loss : 421.631256, loss_ce: 0.023388, loss_kd: 2105.510742
[15:38:09.087] iteration 1150 : loss : 339.904968, loss_ce: 0.020129, loss_kd: 1697.022095
[15:38:14.655] iteration 1160 : loss : 542.822754, loss_ce: 0.029395, loss_kd: 2711.549072
[15:38:20.227] iteration 1170 : loss : 543.898987, loss_ce: 0.020503, loss_kd: 2716.927246
[15:38:25.798] iteration 1180 : loss : 489.604614, loss_ce: 0.015428, loss_kd: 2445.551758
[15:38:31.376] iteration 1190 : loss : 527.399109, loss_ce: 0.047504, loss_kd: 2634.424072
[15:38:36.939] iteration 1200 : loss : 383.224213, loss_ce: 0.028175, loss_kd: 1913.571167
[15:38:42.523] iteration 1210 : loss : 555.650635, loss_ce: 0.016882, loss_kd: 2775.752686
[15:38:48.095] iteration 1220 : loss : 734.489380, loss_ce: 0.014769, loss_kd: 3669.793457
[15:38:53.673] iteration 1230 : loss : 600.111450, loss_ce: 0.027435, loss_kd: 2998.081543
[15:38:59.256] iteration 1240 : loss : 560.240479, loss_ce: 0.022770, loss_kd: 2798.692627
[15:39:04.845] iteration 1250 : loss : 578.350159, loss_ce: 0.021862, loss_kd: 2889.231445
[15:39:10.419] iteration 1260 : loss : 513.895752, loss_ce: 0.020263, loss_kd: 2566.952637
[15:39:16.001] iteration 1270 : loss : 403.630890, loss_ce: 0.024735, loss_kd: 2015.665161
[15:39:21.582] iteration 1280 : loss : 450.795990, loss_ce: 0.017674, loss_kd: 2251.488281
[15:39:27.169] iteration 1290 : loss : 488.983002, loss_ce: 0.038278, loss_kd: 2442.421631
[15:39:32.747] iteration 1300 : loss : 442.602417, loss_ce: 0.050059, loss_kd: 2210.478516
[15:39:38.336] iteration 1310 : loss : 621.733215, loss_ce: 0.024205, loss_kd: 3106.199707
[15:39:43.912] iteration 1320 : loss : 494.742035, loss_ce: 0.034197, loss_kd: 2471.221191
[15:39:49.508] iteration 1330 : loss : 462.519531, loss_ce: 0.044558, loss_kd: 2310.078125
[15:39:55.096] iteration 1340 : loss : 484.624176, loss_ce: 0.021962, loss_kd: 2420.602783
[15:40:00.697] iteration 1350 : loss : 489.185913, loss_ce: 0.022276, loss_kd: 2443.464844
[15:40:06.296] iteration 1360 : loss : 447.813080, loss_ce: 0.021522, loss_kd: 2236.587158
[15:40:11.894] iteration 1370 : loss : 345.241547, loss_ce: 0.031159, loss_kd: 1723.673706
[15:40:17.488] iteration 1380 : loss : 437.907471, loss_ce: 0.037494, loss_kd: 2187.033203
[15:40:23.088] iteration 1390 : loss : 422.919373, loss_ce: 0.026022, loss_kd: 2112.125244
[15:40:28.678] iteration 1400 : loss : 464.317322, loss_ce: 0.026824, loss_kd: 2319.073975
[15:40:34.289] iteration 1410 : loss : 611.156616, loss_ce: 0.034536, loss_kd: 3053.287354
[15:40:39.880] iteration 1420 : loss : 481.393738, loss_ce: 0.020125, loss_kd: 2404.471191
[15:40:45.477] iteration 1430 : loss : 473.608459, loss_ce: 0.021267, loss_kd: 2365.627197
[15:40:48.350] iteration 1440 : loss : 443.332886, loss_ce: 0.028150, loss_kd: 2214.163818
[15:40:53.949] iteration 1450 : loss : 390.313080, loss_ce: 0.024271, loss_kd: 1949.092529
[15:40:59.544] iteration 1460 : loss : 480.257935, loss_ce: 0.025838, loss_kd: 2398.823486
[15:41:05.143] iteration 1470 : loss : 427.195007, loss_ce: 0.018336, loss_kd: 2133.534424
[15:41:10.732] iteration 1480 : loss : 500.947510, loss_ce: 0.019746, loss_kd: 2502.224121
[15:41:16.333] iteration 1490 : loss : 436.116302, loss_ce: 0.020804, loss_kd: 2178.084717
[15:41:21.930] iteration 1500 : loss : 413.759460, loss_ce: 0.017168, loss_kd: 2066.320801
[15:41:27.528] iteration 1510 : loss : 369.127502, loss_ce: 0.024736, loss_kd: 1843.124023
[15:41:33.119] iteration 1520 : loss : 493.222321, loss_ce: 0.019509, loss_kd: 2463.644287
[15:41:38.717] iteration 1530 : loss : 507.556366, loss_ce: 0.026606, loss_kd: 2535.323730
[15:41:44.309] iteration 1540 : loss : 424.680939, loss_ce: 0.030737, loss_kd: 2120.926758
[15:41:49.908] iteration 1550 : loss : 387.585114, loss_ce: 0.036477, loss_kd: 1935.456177
[15:41:55.500] iteration 1560 : loss : 353.994293, loss_ce: 0.035776, loss_kd: 1767.444214
[15:42:01.108] iteration 1570 : loss : 428.760468, loss_ce: 0.044744, loss_kd: 2141.295898
[15:42:06.693] iteration 1580 : loss : 440.287262, loss_ce: 0.022619, loss_kd: 2198.962646
[15:42:12.290] iteration 1590 : loss : 436.309113, loss_ce: 0.045775, loss_kd: 2179.011475
[15:42:17.884] iteration 1600 : loss : 473.530457, loss_ce: 0.023171, loss_kd: 2365.172607
[15:42:23.486] iteration 1610 : loss : 446.578888, loss_ce: 0.025705, loss_kd: 2230.471680
[15:42:29.081] iteration 1620 : loss : 484.461517, loss_ce: 0.024397, loss_kd: 2419.770508
[15:42:34.688] iteration 1630 : loss : 495.829620, loss_ce: 0.028396, loss_kd: 2476.646240
[15:42:40.285] iteration 1640 : loss : 569.037415, loss_ce: 0.021248, loss_kd: 2842.662598
[15:42:45.887] iteration 1650 : loss : 375.513306, loss_ce: 0.035308, loss_kd: 1875.105957
[15:42:51.488] iteration 1660 : loss : 370.453644, loss_ce: 0.038489, loss_kd: 1849.803223
[15:42:57.089] iteration 1670 : loss : 343.608856, loss_ce: 0.032383, loss_kd: 1715.508301
[15:43:02.679] iteration 1680 : loss : 498.630280, loss_ce: 0.019233, loss_kd: 2490.681152
[15:43:08.280] iteration 1690 : loss : 402.872772, loss_ce: 0.029012, loss_kd: 2011.862793
[15:43:13.871] iteration 1700 : loss : 465.833801, loss_ce: 0.021927, loss_kd: 2326.657715
[15:43:19.470] iteration 1710 : loss : 508.357788, loss_ce: 0.027184, loss_kd: 2539.237305
[15:43:25.064] iteration 1720 : loss : 443.846741, loss_ce: 0.031986, loss_kd: 2216.768066
[15:43:30.665] iteration 1730 : loss : 369.209930, loss_ce: 0.029868, loss_kd: 1843.567261
[15:43:36.263] iteration 1740 : loss : 418.791687, loss_ce: 0.031939, loss_kd: 2091.475098
[15:43:41.872] iteration 1750 : loss : 381.472961, loss_ce: 0.023700, loss_kd: 1904.811523
[15:43:47.466] iteration 1760 : loss : 403.712891, loss_ce: 0.021867, loss_kd: 2015.932861
[15:43:53.081] iteration 1770 : loss : 377.155151, loss_ce: 0.037700, loss_kd: 1883.295288
[15:43:58.673] iteration 1780 : loss : 355.336456, loss_ce: 0.027009, loss_kd: 1774.249268
[15:44:04.284] iteration 1790 : loss : 443.065643, loss_ce: 0.028031, loss_kd: 2212.818848
[15:44:09.883] iteration 1800 : loss : 404.587219, loss_ce: 0.015077, loss_kd: 2020.462280
[15:44:15.483] iteration 1810 : loss : 436.346954, loss_ce: 0.019905, loss_kd: 2179.250977
[15:44:21.077] iteration 1820 : loss : 322.580536, loss_ce: 0.041179, loss_kd: 1610.405640
[15:44:26.684] iteration 1830 : loss : 581.137207, loss_ce: 0.033286, loss_kd: 2903.178711
[15:44:32.271] iteration 1840 : loss : 413.239532, loss_ce: 0.017926, loss_kd: 2063.731201
[15:44:37.875] iteration 1850 : loss : 434.467316, loss_ce: 0.026543, loss_kd: 2169.846924
[15:44:43.477] iteration 1860 : loss : 387.596527, loss_ce: 0.024065, loss_kd: 1935.537598
[15:44:49.082] iteration 1870 : loss : 343.008881, loss_ce: 0.025856, loss_kd: 1712.559570
[15:44:54.671] iteration 1880 : loss : 349.085144, loss_ce: 0.022076, loss_kd: 1742.927368
[15:45:00.273] iteration 1890 : loss : 348.053040, loss_ce: 0.032114, loss_kd: 1737.772583
[15:45:05.866] iteration 1900 : loss : 386.604218, loss_ce: 0.033050, loss_kd: 1930.529053
[15:45:11.470] iteration 1910 : loss : 349.128326, loss_ce: 0.016922, loss_kd: 1743.180542
[15:45:17.064] iteration 1920 : loss : 464.618500, loss_ce: 0.034436, loss_kd: 2320.575439
[15:45:22.674] iteration 1930 : loss : 435.191193, loss_ce: 0.016058, loss_kd: 2173.431641
[15:45:28.270] iteration 1940 : loss : 439.529846, loss_ce: 0.028180, loss_kd: 2195.162842
[15:45:33.887] iteration 1950 : loss : 407.325165, loss_ce: 0.020396, loss_kd: 2034.183350
[15:45:39.503] iteration 1960 : loss : 392.358215, loss_ce: 0.021760, loss_kd: 1959.324585
[15:45:45.121] iteration 1970 : loss : 410.936493, loss_ce: 0.025998, loss_kd: 2052.179688
[15:45:50.716] iteration 1980 : loss : 280.842102, loss_ce: 0.025671, loss_kd: 1401.737915
[15:45:56.319] iteration 1990 : loss : 450.641602, loss_ce: 0.024872, loss_kd: 2250.731934
[15:46:01.918] iteration 2000 : loss : 319.088593, loss_ce: 0.023453, loss_kd: 1592.948975
[15:46:07.525] iteration 2010 : loss : 415.261261, loss_ce: 0.028410, loss_kd: 2073.841553
[15:46:13.132] iteration 2020 : loss : 520.594421, loss_ce: 0.041041, loss_kd: 2600.488037
[15:46:18.744] iteration 2030 : loss : 383.054108, loss_ce: 0.018546, loss_kd: 1912.800293
[15:46:24.350] iteration 2040 : loss : 376.415100, loss_ce: 0.020207, loss_kd: 1879.630127
[15:46:29.963] iteration 2050 : loss : 341.688507, loss_ce: 0.018652, loss_kd: 1705.937500
[15:46:35.590] iteration 2060 : loss : 396.873230, loss_ce: 0.030433, loss_kd: 1981.800415
[15:46:41.211] iteration 2070 : loss : 516.271484, loss_ce: 0.027175, loss_kd: 2578.863037
[15:46:46.813] iteration 2080 : loss : 462.741608, loss_ce: 0.024481, loss_kd: 2311.213379
[15:47:03.157] iteration 2090 : loss : 406.593384, loss_ce: 0.026788, loss_kd: 2030.544189
[15:47:08.697] iteration 2100 : loss : 398.468719, loss_ce: 0.027213, loss_kd: 1989.870483
[15:47:14.257] iteration 2110 : loss : 404.846436, loss_ce: 0.024529, loss_kd: 2021.762573
[15:47:19.809] iteration 2120 : loss : 396.612335, loss_ce: 0.026003, loss_kd: 1980.564209
[15:47:25.376] iteration 2130 : loss : 389.742889, loss_ce: 0.030157, loss_kd: 1946.263184
[15:47:30.940] iteration 2140 : loss : 329.923737, loss_ce: 0.025831, loss_kd: 1647.155151
[15:47:36.505] iteration 2150 : loss : 277.155640, loss_ce: 0.023165, loss_kd: 1383.241699
[15:47:42.071] iteration 2160 : loss : 358.749390, loss_ce: 0.025110, loss_kd: 1791.259033
[15:47:47.652] iteration 2170 : loss : 393.665405, loss_ce: 0.020241, loss_kd: 1965.880859
[15:47:53.223] iteration 2180 : loss : 296.275024, loss_ce: 0.040443, loss_kd: 1478.927612
[15:47:58.807] iteration 2190 : loss : 298.518127, loss_ce: 0.023690, loss_kd: 1490.174805
[15:48:04.387] iteration 2200 : loss : 275.940796, loss_ce: 0.025061, loss_kd: 1377.189941
[15:48:09.970] iteration 2210 : loss : 291.772614, loss_ce: 0.035156, loss_kd: 1456.394287
[15:48:15.545] iteration 2220 : loss : 255.664780, loss_ce: 0.030381, loss_kd: 1275.872314
[15:48:21.135] iteration 2230 : loss : 451.895874, loss_ce: 0.015102, loss_kd: 2257.014648
[15:48:26.729] iteration 2240 : loss : 409.749115, loss_ce: 0.017897, loss_kd: 2046.249878
[15:48:32.329] iteration 2250 : loss : 435.650574, loss_ce: 0.017574, loss_kd: 2175.815674
[15:48:37.924] iteration 2260 : loss : 312.269012, loss_ce: 0.028740, loss_kd: 1558.844482
[15:48:43.525] iteration 2270 : loss : 306.164337, loss_ce: 0.021456, loss_kd: 1528.351318
[15:48:49.119] iteration 2280 : loss : 403.637238, loss_ce: 0.029145, loss_kd: 2015.707520
[15:48:54.723] iteration 2290 : loss : 320.881439, loss_ce: 0.022401, loss_kd: 1601.947754
[15:49:00.322] iteration 2300 : loss : 329.431915, loss_ce: 0.031655, loss_kd: 1644.670532
[15:49:05.920] iteration 2310 : loss : 337.295135, loss_ce: 0.033414, loss_kd: 1684.024170
[15:49:11.516] iteration 2320 : loss : 512.650940, loss_ce: 0.018641, loss_kd: 2560.846191
[15:49:17.121] iteration 2330 : loss : 352.736237, loss_ce: 0.025737, loss_kd: 1761.221313
[15:49:22.716] iteration 2340 : loss : 372.817963, loss_ce: 0.018901, loss_kd: 1861.646118
[15:49:28.321] iteration 2350 : loss : 459.992218, loss_ce: 0.019477, loss_kd: 2297.517822
[15:49:33.922] iteration 2360 : loss : 381.181610, loss_ce: 0.031295, loss_kd: 1903.443237
[15:49:39.524] iteration 2370 : loss : 308.375916, loss_ce: 0.028470, loss_kd: 1539.422363
[15:49:45.132] iteration 2380 : loss : 314.881134, loss_ce: 0.020878, loss_kd: 1571.958130
[15:49:50.740] iteration 2390 : loss : 412.009979, loss_ce: 0.022398, loss_kd: 2057.572754
[15:49:56.335] iteration 2400 : loss : 466.298309, loss_ce: 0.022636, loss_kd: 2329.008789
[15:50:01.938] iteration 2410 : loss : 354.750824, loss_ce: 0.027618, loss_kd: 1771.299072
[15:50:07.528] iteration 2420 : loss : 390.386505, loss_ce: 0.033520, loss_kd: 1949.417603
[15:50:13.127] iteration 2430 : loss : 292.625946, loss_ce: 0.026239, loss_kd: 1460.657349
[15:50:18.722] iteration 2440 : loss : 427.761719, loss_ce: 0.020482, loss_kd: 2136.368652
[15:50:24.333] iteration 2450 : loss : 415.832092, loss_ce: 0.022368, loss_kd: 2076.694824
[15:50:29.937] iteration 2460 : loss : 370.437225, loss_ce: 0.023227, loss_kd: 1849.673828
[15:50:35.546] iteration 2470 : loss : 370.853943, loss_ce: 0.018083, loss_kd: 1851.808228
[15:50:41.142] iteration 2480 : loss : 381.018646, loss_ce: 0.023557, loss_kd: 1902.617798
[15:50:46.765] iteration 2490 : loss : 425.777527, loss_ce: 0.050965, loss_kd: 2126.360107
[15:50:52.370] iteration 2500 : loss : 474.376678, loss_ce: 0.024487, loss_kd: 2369.435547
[15:50:57.985] iteration 2510 : loss : 432.694855, loss_ce: 0.025441, loss_kd: 2161.005371
[15:51:03.583] iteration 2520 : loss : 533.434204, loss_ce: 0.024471, loss_kd: 2664.686523
[15:51:09.188] iteration 2530 : loss : 368.105713, loss_ce: 0.020799, loss_kd: 1838.087158
[15:51:14.799] iteration 2540 : loss : 309.775299, loss_ce: 0.026528, loss_kd: 1546.387207
[15:51:20.432] iteration 2550 : loss : 277.341766, loss_ce: 0.031820, loss_kd: 1384.198364
[15:51:26.033] iteration 2560 : loss : 328.917847, loss_ce: 0.024474, loss_kd: 1642.143311
[15:51:31.641] iteration 2570 : loss : 213.874908, loss_ce: 0.030338, loss_kd: 1066.927734
[15:51:37.238] iteration 2580 : loss : 356.929626, loss_ce: 0.025878, loss_kd: 1782.170898
[15:51:42.849] iteration 2590 : loss : 352.952240, loss_ce: 0.025267, loss_kd: 1762.320801
[15:51:48.453] iteration 2600 : loss : 352.939667, loss_ce: 0.031212, loss_kd: 1762.200928
[15:51:54.080] iteration 2610 : loss : 267.740662, loss_ce: 0.020374, loss_kd: 1336.207275
[15:51:59.691] iteration 2620 : loss : 322.806183, loss_ce: 0.034244, loss_kd: 1611.557983
[15:52:05.299] iteration 2630 : loss : 373.826172, loss_ce: 0.029612, loss_kd: 1866.652954
[15:52:10.902] iteration 2640 : loss : 362.833374, loss_ce: 0.026957, loss_kd: 1811.665039
[15:52:16.520] iteration 2650 : loss : 621.838135, loss_ce: 0.024466, loss_kd: 3106.672119
[15:52:22.142] iteration 2660 : loss : 463.371704, loss_ce: 0.021755, loss_kd: 2314.413574
[15:52:27.761] iteration 2670 : loss : 321.995667, loss_ce: 0.024888, loss_kd: 1607.495117
[15:52:33.362] iteration 2680 : loss : 377.688080, loss_ce: 0.018671, loss_kd: 1885.938477
[15:52:38.984] iteration 2690 : loss : 416.882263, loss_ce: 0.020598, loss_kd: 2081.958008
[15:52:44.594] iteration 2700 : loss : 501.679504, loss_ce: 0.021356, loss_kd: 2505.972168
[15:52:50.242] iteration 2710 : loss : 334.501831, loss_ce: 0.028317, loss_kd: 1670.032104
[15:52:55.853] iteration 2720 : loss : 319.249512, loss_ce: 0.014054, loss_kd: 1593.768555
[15:53:01.477] iteration 2730 : loss : 315.174896, loss_ce: 0.030695, loss_kd: 1573.401489
[15:53:07.088] iteration 2740 : loss : 571.047180, loss_ce: 0.022057, loss_kd: 2852.742432
[15:53:12.704] iteration 2750 : loss : 342.544159, loss_ce: 0.028824, loss_kd: 1710.247437
[15:53:18.308] iteration 2760 : loss : 317.398956, loss_ce: 0.032375, loss_kd: 1584.502930
[15:53:23.933] iteration 2770 : loss : 357.542419, loss_ce: 0.035021, loss_kd: 1785.172729
[15:53:29.548] iteration 2780 : loss : 291.454498, loss_ce: 0.023394, loss_kd: 1454.805420
[15:53:35.181] iteration 2790 : loss : 366.698212, loss_ce: 0.031641, loss_kd: 1831.001465
[15:53:40.795] iteration 2800 : loss : 321.711792, loss_ce: 0.023722, loss_kd: 1606.082764
[15:53:46.422] iteration 2810 : loss : 286.916138, loss_ce: 0.030028, loss_kd: 1432.065186
[15:53:52.027] iteration 2820 : loss : 393.482819, loss_ce: 0.029424, loss_kd: 1964.931396
[15:53:57.637] iteration 2830 : loss : 379.245270, loss_ce: 0.025024, loss_kd: 1893.706543
[15:54:03.240] iteration 2840 : loss : 358.832336, loss_ce: 0.023424, loss_kd: 1791.695801
[15:54:08.862] iteration 2850 : loss : 307.480988, loss_ce: 0.016983, loss_kd: 1534.779907
[15:54:14.482] iteration 2860 : loss : 324.710175, loss_ce: 0.028524, loss_kd: 1621.058228
[15:54:20.096] iteration 2870 : loss : 348.354187, loss_ce: 0.022030, loss_kd: 1739.239258
[15:54:25.698] iteration 2880 : loss : 279.473907, loss_ce: 0.022782, loss_kd: 1394.880249
[15:54:31.340] iteration 2890 : loss : 314.898651, loss_ce: 0.024049, loss_kd: 1572.028198
[15:54:36.945] iteration 2900 : loss : 309.424561, loss_ce: 0.026483, loss_kd: 1544.650635
[15:54:42.571] iteration 2910 : loss : 412.062134, loss_ce: 0.042918, loss_kd: 2057.824707
[15:54:48.178] iteration 2920 : loss : 374.089661, loss_ce: 0.028137, loss_kd: 1867.945312
[15:54:53.810] iteration 2930 : loss : 310.584808, loss_ce: 0.026090, loss_kd: 1550.459839
[15:54:59.422] iteration 2940 : loss : 320.908356, loss_ce: 0.022602, loss_kd: 1602.050537
[15:55:05.060] iteration 2950 : loss : 364.546051, loss_ce: 0.018796, loss_kd: 1820.275269
[15:55:10.673] iteration 2960 : loss : 297.922089, loss_ce: 0.025077, loss_kd: 1487.147095
[15:55:16.286] iteration 2970 : loss : 236.914185, loss_ce: 0.015439, loss_kd: 1182.134521
[15:55:21.887] iteration 2980 : loss : 347.711914, loss_ce: 0.016265, loss_kd: 1736.115845
[15:55:27.507] iteration 2990 : loss : 255.793365, loss_ce: 0.019269, loss_kd: 1276.514648
[15:55:33.115] iteration 3000 : loss : 321.209900, loss_ce: 0.026664, loss_kd: 1603.602783
[15:55:38.738] iteration 3010 : loss : 340.702881, loss_ce: 0.013937, loss_kd: 1701.092773
[15:55:44.350] iteration 3020 : loss : 476.679443, loss_ce: 0.022540, loss_kd: 2380.921143
[15:55:49.986] iteration 3030 : loss : 614.429626, loss_ce: 0.028505, loss_kd: 3069.699219
[15:55:55.600] iteration 3040 : loss : 342.468872, loss_ce: 0.017271, loss_kd: 1709.885254
[15:56:01.226] iteration 3050 : loss : 257.580505, loss_ce: 0.020110, loss_kd: 1285.403564
[15:56:06.835] iteration 3060 : loss : 324.133636, loss_ce: 0.022027, loss_kd: 1618.218384
[15:56:12.467] iteration 3070 : loss : 306.142822, loss_ce: 0.019896, loss_kd: 1528.255615
[15:56:18.078] iteration 3080 : loss : 258.001556, loss_ce: 0.024418, loss_kd: 1287.503662
[15:56:23.710] iteration 3090 : loss : 293.342133, loss_ce: 0.021920, loss_kd: 1464.210815
[15:56:29.320] iteration 3100 : loss : 295.828339, loss_ce: 0.017178, loss_kd: 1476.575317
[15:56:34.936] iteration 3110 : loss : 304.069122, loss_ce: 0.026184, loss_kd: 1517.823242
[15:56:40.550] iteration 3120 : loss : 273.601685, loss_ce: 0.022780, loss_kd: 1365.553345
[15:56:44.230] Running TPGM constraint optimization after epoch 3
[16:01:27.191] iteration 3130 : loss : 282.918121, loss_ce: 0.020199, loss_kd: 1412.126587
[16:01:32.712] iteration 3140 : loss : 355.758636, loss_ce: 0.016767, loss_kd: 1776.323730
[16:01:38.254] iteration 3150 : loss : 297.407623, loss_ce: 0.032947, loss_kd: 1484.526489
[16:01:43.788] iteration 3160 : loss : 325.154297, loss_ce: 0.039892, loss_kd: 1623.307373
[16:01:49.331] iteration 3170 : loss : 297.252350, loss_ce: 0.024469, loss_kd: 1483.818726
[16:01:54.870] iteration 3180 : loss : 414.890594, loss_ce: 0.023423, loss_kd: 2071.982422
[16:02:00.427] iteration 3190 : loss : 306.729645, loss_ce: 0.020564, loss_kd: 1531.166260
[16:02:05.972] iteration 3200 : loss : 229.978058, loss_ce: 0.015838, loss_kd: 1147.416382
[16:02:11.532] iteration 3210 : loss : 340.663940, loss_ce: 0.035101, loss_kd: 1700.854248
[16:02:17.089] iteration 3220 : loss : 330.934265, loss_ce: 0.025240, loss_kd: 1652.168213
[16:02:22.655] iteration 3230 : loss : 322.813965, loss_ce: 0.036268, loss_kd: 1611.592896
[16:02:28.215] iteration 3240 : loss : 304.766510, loss_ce: 0.024895, loss_kd: 1521.373535
[16:02:33.778] iteration 3250 : loss : 294.646912, loss_ce: 0.017291, loss_kd: 1470.799561
[16:02:39.342] iteration 3260 : loss : 295.306580, loss_ce: 0.019842, loss_kd: 1474.069580
[16:02:44.923] iteration 3270 : loss : 312.922241, loss_ce: 0.014199, loss_kd: 1562.154297
[16:02:50.488] iteration 3280 : loss : 270.215332, loss_ce: 0.027218, loss_kd: 1348.603882
[16:02:56.068] iteration 3290 : loss : 310.986511, loss_ce: 0.023605, loss_kd: 1552.386475
[16:03:01.637] iteration 3300 : loss : 307.650024, loss_ce: 0.028041, loss_kd: 1535.774902
[16:03:07.233] iteration 3310 : loss : 303.346802, loss_ce: 0.032690, loss_kd: 1514.293701
[16:03:12.809] iteration 3320 : loss : 280.648254, loss_ce: 0.019731, loss_kd: 1400.777466
[16:03:18.403] iteration 3330 : loss : 397.600037, loss_ce: 0.026265, loss_kd: 1985.508057
[16:03:23.987] iteration 3340 : loss : 289.386597, loss_ce: 0.030001, loss_kd: 1444.460083
[16:03:29.583] iteration 3350 : loss : 345.921875, loss_ce: 0.027438, loss_kd: 1727.170410
[16:03:35.168] iteration 3360 : loss : 325.287170, loss_ce: 0.020872, loss_kd: 1624.004761
[16:03:40.757] iteration 3370 : loss : 306.734863, loss_ce: 0.023767, loss_kd: 1531.224731
[16:03:46.346] iteration 3380 : loss : 324.438202, loss_ce: 0.026500, loss_kd: 1619.738037
[16:03:51.938] iteration 3390 : loss : 279.731079, loss_ce: 0.017841, loss_kd: 1396.180420
[16:03:57.538] iteration 3400 : loss : 227.207886, loss_ce: 0.018353, loss_kd: 1133.579468
[16:04:03.138] iteration 3410 : loss : 304.550690, loss_ce: 0.024336, loss_kd: 1520.288940
[16:04:08.732] iteration 3420 : loss : 293.576996, loss_ce: 0.013942, loss_kd: 1465.436890
[16:04:14.335] iteration 3430 : loss : 359.976501, loss_ce: 0.033916, loss_kd: 1797.393921
[16:04:19.932] iteration 3440 : loss : 222.597092, loss_ce: 0.020137, loss_kd: 1110.494385
[16:04:25.532] iteration 3450 : loss : 250.856720, loss_ce: 0.030799, loss_kd: 1251.831787
[16:04:31.133] iteration 3460 : loss : 358.978516, loss_ce: 0.019350, loss_kd: 1792.454590
[16:04:36.734] iteration 3470 : loss : 267.206635, loss_ce: 0.032447, loss_kd: 1333.553955
[16:04:42.328] iteration 3480 : loss : 270.591431, loss_ce: 0.026850, loss_kd: 1350.474121
[16:04:47.935] iteration 3490 : loss : 405.023499, loss_ce: 0.018597, loss_kd: 2022.676270
[16:04:53.526] iteration 3500 : loss : 485.187408, loss_ce: 0.010404, loss_kd: 2423.449219
[16:04:59.133] iteration 3510 : loss : 454.680786, loss_ce: 0.029304, loss_kd: 2270.945068
[16:05:04.735] iteration 3520 : loss : 369.249146, loss_ce: 0.013991, loss_kd: 1843.848999
[16:05:10.350] iteration 3530 : loss : 352.621857, loss_ce: 0.021264, loss_kd: 1760.667603
[16:05:15.941] iteration 3540 : loss : 321.374786, loss_ce: 0.029045, loss_kd: 1604.351562
[16:05:21.566] iteration 3550 : loss : 337.165985, loss_ce: 0.026060, loss_kd: 1683.351807
[16:05:27.176] iteration 3560 : loss : 339.174194, loss_ce: 0.026563, loss_kd: 1693.386353
[16:05:32.787] iteration 3570 : loss : 299.494751, loss_ce: 0.021359, loss_kd: 1495.030273
[16:05:38.393] iteration 3580 : loss : 300.945953, loss_ce: 0.037362, loss_kd: 1502.250732
[16:05:44.001] iteration 3590 : loss : 286.957245, loss_ce: 0.028107, loss_kd: 1432.366699
[16:05:49.609] iteration 3600 : loss : 270.594299, loss_ce: 0.022328, loss_kd: 1350.511108
[16:05:55.231] iteration 3610 : loss : 362.264160, loss_ce: 0.023326, loss_kd: 1808.835205
[16:06:00.842] iteration 3620 : loss : 293.554291, loss_ce: 0.020551, loss_kd: 1465.311401
[16:06:06.459] iteration 3630 : loss : 278.221527, loss_ce: 0.020228, loss_kd: 1388.665527
[16:06:12.074] iteration 3640 : loss : 260.141479, loss_ce: 0.014953, loss_kd: 1298.265503
[16:06:17.702] iteration 3650 : loss : 299.436890, loss_ce: 0.022852, loss_kd: 1494.700806
[16:06:23.310] iteration 3660 : loss : 294.147797, loss_ce: 0.033238, loss_kd: 1468.245850
[16:06:28.931] iteration 3670 : loss : 312.002777, loss_ce: 0.015666, loss_kd: 1557.524780
[16:06:34.550] iteration 3680 : loss : 540.763672, loss_ce: 0.029899, loss_kd: 2701.337646
[16:06:40.173] iteration 3690 : loss : 319.470581, loss_ce: 0.019831, loss_kd: 1594.852783
[16:06:45.781] iteration 3700 : loss : 336.596252, loss_ce: 0.015878, loss_kd: 1680.546997
[16:06:51.401] iteration 3710 : loss : 298.233551, loss_ce: 0.031860, loss_kd: 1488.733887
[16:06:56.999] iteration 3720 : loss : 325.524170, loss_ce: 0.023380, loss_kd: 1625.178101
[16:07:02.621] iteration 3730 : loss : 232.166962, loss_ce: 0.021970, loss_kd: 1158.397583
[16:07:08.227] iteration 3740 : loss : 354.605225, loss_ce: 0.022523, loss_kd: 1770.561523
[16:07:13.833] iteration 3750 : loss : 331.932800, loss_ce: 0.022097, loss_kd: 1657.221436
[16:07:19.435] iteration 3760 : loss : 409.177399, loss_ce: 0.021987, loss_kd: 2043.447998
[16:07:25.055] iteration 3770 : loss : 281.027466, loss_ce: 0.022736, loss_kd: 1402.698364
[16:07:30.668] iteration 3780 : loss : 305.533356, loss_ce: 0.023043, loss_kd: 1525.208618
[16:07:36.288] iteration 3790 : loss : 331.326660, loss_ce: 0.018911, loss_kd: 1654.189209
[16:07:41.906] iteration 3800 : loss : 333.354279, loss_ce: 0.017231, loss_kd: 1664.238770
[16:07:47.518] iteration 3810 : loss : 232.451904, loss_ce: 0.021284, loss_kd: 1159.780396
[16:07:53.149] iteration 3820 : loss : 269.447266, loss_ce: 0.021392, loss_kd: 1344.790039
[16:07:58.760] iteration 3830 : loss : 319.644104, loss_ce: 0.028757, loss_kd: 1595.718994
[16:08:04.376] iteration 3840 : loss : 246.894180, loss_ce: 0.029284, loss_kd: 1232.024658
[16:08:09.998] iteration 3850 : loss : 236.775055, loss_ce: 0.027669, loss_kd: 1181.387329
[16:08:15.624] iteration 3860 : loss : 347.378082, loss_ce: 0.030220, loss_kd: 1734.442749
[16:08:21.236] iteration 3870 : loss : 298.210449, loss_ce: 0.019431, loss_kd: 1488.614990
[16:08:26.856] iteration 3880 : loss : 307.912262, loss_ce: 0.033924, loss_kd: 1537.084106
[16:08:32.482] iteration 3890 : loss : 262.951782, loss_ce: 0.022191, loss_kd: 1312.306030
[16:08:38.087] iteration 3900 : loss : 348.360626, loss_ce: 0.022469, loss_kd: 1739.366455
[16:08:43.712] iteration 3910 : loss : 269.896179, loss_ce: 0.017627, loss_kd: 1347.033936
[16:08:49.314] iteration 3920 : loss : 339.342285, loss_ce: 0.013476, loss_kd: 1694.310669
[16:08:54.945] iteration 3930 : loss : 239.341721, loss_ce: 0.020480, loss_kd: 1194.267700
[16:09:00.562] iteration 3940 : loss : 256.527039, loss_ce: 0.020488, loss_kd: 1280.148926
[16:09:06.197] iteration 3950 : loss : 289.939453, loss_ce: 0.019671, loss_kd: 1447.232544
[16:09:11.825] iteration 3960 : loss : 283.064209, loss_ce: 0.017408, loss_kd: 1412.864258
[16:09:17.443] iteration 3970 : loss : 259.809753, loss_ce: 0.027786, loss_kd: 1296.608276
[16:09:23.062] iteration 3980 : loss : 235.239517, loss_ce: 0.014470, loss_kd: 1173.741943
[16:09:28.683] iteration 3990 : loss : 345.750519, loss_ce: 0.022880, loss_kd: 1726.302490
[16:09:34.301] iteration 4000 : loss : 277.229767, loss_ce: 0.024744, loss_kd: 1383.692017
[16:09:39.933] iteration 4010 : loss : 261.216766, loss_ce: 0.032446, loss_kd: 1303.624268
[16:09:45.552] iteration 4020 : loss : 288.545105, loss_ce: 0.026744, loss_kd: 1440.243042
[16:09:51.177] iteration 4030 : loss : 238.848053, loss_ce: 0.013672, loss_kd: 1191.810181
[16:09:56.800] iteration 4040 : loss : 240.348801, loss_ce: 0.023962, loss_kd: 1199.283081
[16:10:02.426] iteration 4050 : loss : 427.095337, loss_ce: 0.029839, loss_kd: 2132.950439
[16:10:08.043] iteration 4060 : loss : 294.140198, loss_ce: 0.037204, loss_kd: 1468.200562
[16:10:13.679] iteration 4070 : loss : 405.568390, loss_ce: 0.027713, loss_kd: 2025.361328
[16:10:19.296] iteration 4080 : loss : 308.624603, loss_ce: 0.030546, loss_kd: 1540.670898
[16:10:24.913] iteration 4090 : loss : 265.867798, loss_ce: 0.021290, loss_kd: 1326.862915
[16:10:30.540] iteration 4100 : loss : 252.173813, loss_ce: 0.023814, loss_kd: 1258.445801
[16:10:36.156] iteration 4110 : loss : 283.924164, loss_ce: 0.022270, loss_kd: 1417.125000
[16:10:41.772] iteration 4120 : loss : 342.347015, loss_ce: 0.028588, loss_kd: 1709.270508
[16:10:47.413] iteration 4130 : loss : 231.426666, loss_ce: 0.025777, loss_kd: 1154.642822
[16:10:53.020] iteration 4140 : loss : 254.432068, loss_ce: 0.024485, loss_kd: 1269.712402
[16:10:58.650] iteration 4150 : loss : 238.294174, loss_ce: 0.021492, loss_kd: 1189.030762
[16:11:04.273] iteration 4160 : loss : 305.278839, loss_ce: 0.022962, loss_kd: 1523.932495
[16:11:20.525] iteration 4170 : loss : 325.487701, loss_ce: 0.033384, loss_kd: 1624.975342
[16:11:26.065] iteration 4180 : loss : 257.078674, loss_ce: 0.018934, loss_kd: 1282.963867
[16:11:31.621] iteration 4190 : loss : 322.018768, loss_ce: 0.019438, loss_kd: 1607.629395
[16:11:37.176] iteration 4200 : loss : 226.693039, loss_ce: 0.027714, loss_kd: 1131.007202
[16:11:42.750] iteration 4210 : loss : 285.438202, loss_ce: 0.024032, loss_kd: 1424.785767
[16:11:48.305] iteration 4220 : loss : 357.628174, loss_ce: 0.024416, loss_kd: 1785.682861
[16:11:53.877] iteration 4230 : loss : 212.775146, loss_ce: 0.025466, loss_kd: 1061.423340
[16:11:59.455] iteration 4240 : loss : 247.342255, loss_ce: 0.025814, loss_kd: 1234.212524
[16:12:05.052] iteration 4250 : loss : 208.031235, loss_ce: 0.022504, loss_kd: 1037.708862
[16:12:10.634] iteration 4260 : loss : 287.141022, loss_ce: 0.021246, loss_kd: 1433.215088
[16:12:16.234] iteration 4270 : loss : 242.740005, loss_ce: 0.029671, loss_kd: 1211.210815
[16:12:21.812] iteration 4280 : loss : 274.501678, loss_ce: 0.046414, loss_kd: 1369.997314
[16:12:27.405] iteration 4290 : loss : 205.208755, loss_ce: 0.026234, loss_kd: 1023.605042
[16:12:32.994] iteration 4300 : loss : 288.270538, loss_ce: 0.022102, loss_kd: 1438.925293
[16:12:38.606] iteration 4310 : loss : 262.481110, loss_ce: 0.025025, loss_kd: 1309.922974
[16:12:44.200] iteration 4320 : loss : 218.894699, loss_ce: 0.023295, loss_kd: 1092.050171
[16:12:49.802] iteration 4330 : loss : 248.121613, loss_ce: 0.032130, loss_kd: 1238.159424
[16:12:55.399] iteration 4340 : loss : 282.791595, loss_ce: 0.022460, loss_kd: 1411.533936
[16:13:01.008] iteration 4350 : loss : 303.536102, loss_ce: 0.023533, loss_kd: 1515.193726
[16:13:06.605] iteration 4360 : loss : 269.227966, loss_ce: 0.022309, loss_kd: 1343.717773
[16:13:12.209] iteration 4370 : loss : 287.506653, loss_ce: 0.025551, loss_kd: 1435.075073
[16:13:17.805] iteration 4380 : loss : 302.582397, loss_ce: 0.020489, loss_kd: 1510.457520
[16:13:23.417] iteration 4390 : loss : 269.317139, loss_ce: 0.024572, loss_kd: 1344.084961
[16:13:29.015] iteration 4400 : loss : 266.121033, loss_ce: 0.018528, loss_kd: 1328.156738
[16:13:34.641] iteration 4410 : loss : 285.720947, loss_ce: 0.028977, loss_kd: 1426.124268
[16:13:40.256] iteration 4420 : loss : 252.877823, loss_ce: 0.012989, loss_kd: 1261.965820
[16:13:45.865] iteration 4430 : loss : 230.530945, loss_ce: 0.017976, loss_kd: 1150.199097
[16:13:51.477] iteration 4440 : loss : 202.554077, loss_ce: 0.023957, loss_kd: 1010.303955
[16:13:57.080] iteration 4450 : loss : 227.309143, loss_ce: 0.024853, loss_kd: 1134.084229
[16:14:02.683] iteration 4460 : loss : 197.274048, loss_ce: 0.029516, loss_kd: 983.904175
[16:14:08.312] iteration 4470 : loss : 241.590897, loss_ce: 0.014937, loss_kd: 1205.517334
[16:14:13.919] iteration 4480 : loss : 231.955139, loss_ce: 0.039479, loss_kd: 1157.316284
[16:14:19.541] iteration 4490 : loss : 274.775604, loss_ce: 0.017381, loss_kd: 1371.415039
[16:14:25.144] iteration 4500 : loss : 207.011566, loss_ce: 0.020708, loss_kd: 1032.612915
[16:14:30.771] iteration 4510 : loss : 317.241455, loss_ce: 0.021723, loss_kd: 1583.755981
[16:14:36.385] iteration 4520 : loss : 291.244080, loss_ce: 0.031143, loss_kd: 1453.740601
[16:14:42.014] iteration 4530 : loss : 343.931335, loss_ce: 0.034285, loss_kd: 1717.196533
[16:14:47.638] iteration 4540 : loss : 349.447113, loss_ce: 0.015314, loss_kd: 1744.789673
[16:14:53.249] iteration 4550 : loss : 246.921127, loss_ce: 0.028033, loss_kd: 1232.149292
[16:14:58.864] iteration 4560 : loss : 225.180283, loss_ce: 0.027374, loss_kd: 1123.425293
[16:15:04.497] iteration 4570 : loss : 230.567169, loss_ce: 0.021368, loss_kd: 1150.393799
[16:15:10.119] iteration 4580 : loss : 266.144043, loss_ce: 0.018136, loss_kd: 1328.236572
[16:15:15.740] iteration 4590 : loss : 285.950836, loss_ce: 0.015472, loss_kd: 1427.338013
[16:15:21.353] iteration 4600 : loss : 343.770599, loss_ce: 0.018029, loss_kd: 1716.307983
[16:15:26.984] iteration 4610 : loss : 239.542862, loss_ce: 0.017118, loss_kd: 1195.280396
[16:15:32.599] iteration 4620 : loss : 253.585785, loss_ce: 0.038698, loss_kd: 1265.485718
[16:15:38.237] iteration 4630 : loss : 261.018707, loss_ce: 0.022812, loss_kd: 1302.631470
[16:15:43.845] iteration 4640 : loss : 227.737000, loss_ce: 0.030032, loss_kd: 1136.206665
[16:15:49.460] iteration 4650 : loss : 177.114273, loss_ce: 0.023063, loss_kd: 883.131348
[16:15:55.068] iteration 4660 : loss : 290.099915, loss_ce: 0.032413, loss_kd: 1448.017578
[16:16:00.710] iteration 4670 : loss : 188.778717, loss_ce: 0.024765, loss_kd: 941.383789
[16:16:06.322] iteration 4680 : loss : 222.700989, loss_ce: 0.027171, loss_kd: 1111.067871
[16:16:11.957] iteration 4690 : loss : 229.895325, loss_ce: 0.023658, loss_kd: 1147.034546
[16:16:17.569] iteration 4700 : loss : 211.267670, loss_ce: 0.017235, loss_kd: 1053.911987
[16:16:23.187] iteration 4710 : loss : 209.756012, loss_ce: 0.027466, loss_kd: 1046.296509
[16:16:28.801] iteration 4720 : loss : 242.896149, loss_ce: 0.018109, loss_kd: 1212.004761
[16:16:34.435] iteration 4730 : loss : 321.338379, loss_ce: 0.031954, loss_kd: 1604.229980
[16:16:40.044] iteration 4740 : loss : 201.817123, loss_ce: 0.020040, loss_kd: 1006.627869
[16:16:45.665] iteration 4750 : loss : 238.605911, loss_ce: 0.030519, loss_kd: 1190.571167
[16:16:51.285] iteration 4760 : loss : 281.892273, loss_ce: 0.039017, loss_kd: 1407.034424
[16:16:56.910] iteration 4770 : loss : 319.414764, loss_ce: 0.022745, loss_kd: 1594.615845
[16:17:02.515] iteration 4780 : loss : 235.477280, loss_ce: 0.016959, loss_kd: 1174.951660
[16:17:08.127] iteration 4790 : loss : 304.840057, loss_ce: 0.028502, loss_kd: 1521.731689
[16:17:13.748] iteration 4800 : loss : 257.532349, loss_ce: 0.035578, loss_kd: 1285.220337
[16:17:19.379] iteration 4810 : loss : 241.886978, loss_ce: 0.016206, loss_kd: 1206.889404
[16:17:25.010] iteration 4820 : loss : 200.065872, loss_ce: 0.017161, loss_kd: 997.915527
[16:17:30.642] iteration 4830 : loss : 307.838104, loss_ce: 0.018886, loss_kd: 1536.772705
[16:17:36.249] iteration 4840 : loss : 288.332489, loss_ce: 0.019568, loss_kd: 1439.215088
[16:17:41.854] iteration 4850 : loss : 300.113281, loss_ce: 0.022408, loss_kd: 1498.148315
[16:17:47.493] iteration 4860 : loss : 253.840958, loss_ce: 0.030127, loss_kd: 1266.738037
[16:17:53.116] iteration 4870 : loss : 267.597015, loss_ce: 0.036402, loss_kd: 1335.526611
[16:17:58.733] iteration 4880 : loss : 254.995361, loss_ce: 0.021728, loss_kd: 1272.545898
[16:18:04.362] iteration 4890 : loss : 268.545868, loss_ce: 0.022244, loss_kd: 1340.298584
[16:18:09.973] iteration 4900 : loss : 286.134064, loss_ce: 0.030689, loss_kd: 1428.157593
[16:18:15.594] iteration 4910 : loss : 323.012268, loss_ce: 0.029612, loss_kd: 1612.564453
[16:18:21.219] iteration 4920 : loss : 234.324188, loss_ce: 0.031380, loss_kd: 1169.158691
[16:18:26.861] iteration 4930 : loss : 189.233734, loss_ce: 0.022862, loss_kd: 943.725708
[16:18:32.483] iteration 4940 : loss : 243.562027, loss_ce: 0.026612, loss_kd: 1215.363647
[16:18:38.100] iteration 4950 : loss : 239.258301, loss_ce: 0.026370, loss_kd: 1193.783325
[16:18:43.721] iteration 4960 : loss : 209.886932, loss_ce: 0.015639, loss_kd: 1047.004395
[16:18:49.353] iteration 4970 : loss : 256.555634, loss_ce: 0.020256, loss_kd: 1280.278931
[16:18:54.972] iteration 4980 : loss : 222.102234, loss_ce: 0.021355, loss_kd: 1107.994629
[16:19:00.608] iteration 4990 : loss : 216.464996, loss_ce: 0.029897, loss_kd: 1079.874512
[16:19:06.220] iteration 5000 : loss : 207.140762, loss_ce: 0.017682, loss_kd: 1033.257568
[16:19:11.865] iteration 5010 : loss : 209.763245, loss_ce: 0.029793, loss_kd: 1046.339111
[16:19:17.501] iteration 5020 : loss : 242.224075, loss_ce: 0.022156, loss_kd: 1208.678711
[16:19:23.136] iteration 5030 : loss : 260.547546, loss_ce: 0.027167, loss_kd: 1300.268921
[16:19:28.755] iteration 5040 : loss : 218.912094, loss_ce: 0.024996, loss_kd: 1092.095581
[16:19:34.432] iteration 5050 : loss : 266.333313, loss_ce: 0.046540, loss_kd: 1329.170898
[16:19:40.046] iteration 5060 : loss : 172.375320, loss_ce: 0.023840, loss_kd: 859.432739
[16:19:45.690] iteration 5070 : loss : 411.980164, loss_ce: 0.015933, loss_kd: 2057.483398
[16:19:51.319] iteration 5080 : loss : 299.618652, loss_ce: 0.028151, loss_kd: 1495.644043
[16:19:56.958] iteration 5090 : loss : 311.501221, loss_ce: 0.015558, loss_kd: 1555.084839
[16:20:02.582] iteration 5100 : loss : 291.210114, loss_ce: 0.018879, loss_kd: 1453.593262
[16:20:08.223] iteration 5110 : loss : 264.771332, loss_ce: 0.021826, loss_kd: 1321.391357
[16:20:13.837] iteration 5120 : loss : 205.523788, loss_ce: 0.038441, loss_kd: 1025.161255
[16:20:19.453] iteration 5130 : loss : 314.971252, loss_ce: 0.019376, loss_kd: 1572.442139
[16:20:25.079] iteration 5140 : loss : 197.106384, loss_ce: 0.021374, loss_kd: 983.101746
[16:20:30.705] iteration 5150 : loss : 247.599655, loss_ce: 0.019151, loss_kd: 1235.560913
[16:20:36.344] iteration 5160 : loss : 238.981964, loss_ce: 0.021152, loss_kd: 1192.464600
[16:20:41.973] iteration 5170 : loss : 223.808838, loss_ce: 0.030660, loss_kd: 1116.571045
[16:20:47.578] iteration 5180 : loss : 262.054657, loss_ce: 0.032878, loss_kd: 1307.840332
[16:20:53.225] iteration 5190 : loss : 228.444687, loss_ce: 0.017353, loss_kd: 1139.789307
[16:20:58.845] iteration 5200 : loss : 223.510895, loss_ce: 0.023099, loss_kd: 1115.106934
[16:21:04.188] iteration 5210 : loss : 223.018356, loss_ce: 0.031072, loss_kd: 1112.603149
[16:21:04.884] save model to ./debug_fixed_tpgm\continual_surgical_tpgm_epoch_4.pth
[16:21:04.886] Running TPGM constraint optimization after epoch 5
[16:26:03.053] iteration 5220 : loss : 284.482910, loss_ce: 0.027459, loss_kd: 1419.940308
[16:26:08.590] iteration 5230 : loss : 337.244995, loss_ce: 0.031451, loss_kd: 1683.702881
[16:26:14.115] iteration 5240 : loss : 307.743652, loss_ce: 0.020009, loss_kd: 1536.233154
[16:26:19.653] iteration 5250 : loss : 280.900085, loss_ce: 0.020680, loss_kd: 1402.072632
[16:26:25.192] iteration 5260 : loss : 176.476990, loss_ce: 0.026789, loss_kd: 879.931519
[16:26:30.733] iteration 5270 : loss : 285.768402, loss_ce: 0.029621, loss_kd: 1426.390381
[16:26:36.269] iteration 5280 : loss : 259.424500, loss_ce: 0.032028, loss_kd: 1294.678589
[16:26:41.821] iteration 5290 : loss : 224.069748, loss_ce: 0.016387, loss_kd: 1117.872314
[16:26:47.365] iteration 5300 : loss : 272.468201, loss_ce: 0.030102, loss_kd: 1359.917969
[16:26:52.926] iteration 5310 : loss : 244.222046, loss_ce: 0.018767, loss_kd: 1218.672485
[16:26:58.476] iteration 5320 : loss : 225.858597, loss_ce: 0.019335, loss_kd: 1126.851562
[16:27:04.037] iteration 5330 : loss : 260.549805, loss_ce: 0.024466, loss_kd: 1300.308350
[16:27:09.599] iteration 5340 : loss : 211.952911, loss_ce: 0.033763, loss_kd: 1057.349365
[16:27:15.177] iteration 5350 : loss : 244.484375, loss_ce: 0.024632, loss_kd: 1220.001709
[16:27:20.745] iteration 5360 : loss : 255.805908, loss_ce: 0.031379, loss_kd: 1276.613037
[16:27:26.334] iteration 5370 : loss : 255.239517, loss_ce: 0.013445, loss_kd: 1273.741211
[16:27:31.899] iteration 5380 : loss : 235.685349, loss_ce: 0.015161, loss_kd: 1176.009155
[16:27:37.480] iteration 5390 : loss : 243.793106, loss_ce: 0.030490, loss_kd: 1216.483643
[16:27:43.056] iteration 5400 : loss : 267.385254, loss_ce: 0.036345, loss_kd: 1334.516113
[16:27:48.649] iteration 5410 : loss : 233.656219, loss_ce: 0.026960, loss_kd: 1165.816162
[16:27:54.255] iteration 5420 : loss : 178.460876, loss_ce: 0.031591, loss_kd: 889.854614
[16:27:59.855] iteration 5430 : loss : 226.540527, loss_ce: 0.020157, loss_kd: 1130.327881
[16:28:05.445] iteration 5440 : loss : 281.620422, loss_ce: 0.018395, loss_kd: 1405.629150
[16:28:11.048] iteration 5450 : loss : 192.927856, loss_ce: 0.015482, loss_kd: 962.181641
[16:28:16.630] iteration 5460 : loss : 207.692368, loss_ce: 0.016048, loss_kd: 1035.980957
[16:28:22.223] iteration 5470 : loss : 276.996887, loss_ce: 0.032701, loss_kd: 1382.534058
[16:28:27.817] iteration 5480 : loss : 239.423370, loss_ce: 0.017322, loss_kd: 1194.673828
[16:28:33.418] iteration 5490 : loss : 224.023895, loss_ce: 0.033715, loss_kd: 1117.674561
[16:28:39.007] iteration 5500 : loss : 210.908783, loss_ce: 0.018506, loss_kd: 1052.104614
[16:28:44.610] iteration 5510 : loss : 191.421478, loss_ce: 0.014738, loss_kd: 954.671936
[16:28:50.204] iteration 5520 : loss : 283.285400, loss_ce: 0.016979, loss_kd: 1413.962402
[16:28:55.853] iteration 5530 : loss : 285.975159, loss_ce: 0.025111, loss_kd: 1427.429199
[16:29:01.453] iteration 5540 : loss : 240.037964, loss_ce: 0.019956, loss_kd: 1197.763184
[16:29:07.056] iteration 5550 : loss : 195.682419, loss_ce: 0.019169, loss_kd: 975.971619
[16:29:12.650] iteration 5560 : loss : 305.052216, loss_ce: 0.026484, loss_kd: 1522.777344
[16:29:18.253] iteration 5570 : loss : 221.885254, loss_ce: 0.021508, loss_kd: 1106.955811
[16:29:23.844] iteration 5580 : loss : 217.144928, loss_ce: 0.013590, loss_kd: 1083.260010
[16:29:29.446] iteration 5590 : loss : 179.790070, loss_ce: 0.019363, loss_kd: 896.520630
[16:29:35.048] iteration 5600 : loss : 275.653107, loss_ce: 0.014509, loss_kd: 1375.801147
[16:29:40.660] iteration 5610 : loss : 215.079132, loss_ce: 0.016325, loss_kd: 1072.904053
[16:29:46.275] iteration 5620 : loss : 268.016113, loss_ce: 0.022610, loss_kd: 1337.681641
[16:29:51.898] iteration 5630 : loss : 342.788666, loss_ce: 0.019532, loss_kd: 1711.519531
[16:29:57.503] iteration 5640 : loss : 194.490051, loss_ce: 0.016367, loss_kd: 970.061462
[16:30:03.116] iteration 5650 : loss : 236.843063, loss_ce: 0.017864, loss_kd: 1181.779907
[16:30:08.730] iteration 5660 : loss : 178.729660, loss_ce: 0.017295, loss_kd: 891.210266
[16:30:14.349] iteration 5670 : loss : 188.953644, loss_ce: 0.023699, loss_kd: 942.320312
[16:30:19.970] iteration 5680 : loss : 285.885986, loss_ce: 0.020098, loss_kd: 1426.977173
[16:30:25.580] iteration 5690 : loss : 245.933044, loss_ce: 0.026817, loss_kd: 1227.242432
[16:30:31.183] iteration 5700 : loss : 205.434296, loss_ce: 0.016666, loss_kd: 1024.722412
[16:30:36.807] iteration 5710 : loss : 188.778290, loss_ce: 0.018548, loss_kd: 941.460693
[16:30:42.427] iteration 5720 : loss : 245.160889, loss_ce: 0.026537, loss_kd: 1223.407593
[16:30:48.053] iteration 5730 : loss : 188.909439, loss_ce: 0.020657, loss_kd: 942.060730
[16:30:53.662] iteration 5740 : loss : 203.538498, loss_ce: 0.013840, loss_kd: 1015.276245
[16:30:59.297] iteration 5750 : loss : 263.718781, loss_ce: 0.014162, loss_kd: 1316.117188
[16:31:04.915] iteration 5760 : loss : 397.220764, loss_ce: 0.020660, loss_kd: 1983.642944
[16:31:10.533] iteration 5770 : loss : 266.582581, loss_ce: 0.013396, loss_kd: 1330.477783
[16:31:16.143] iteration 5780 : loss : 326.908936, loss_ce: 0.031896, loss_kd: 1632.095947
[16:31:21.771] iteration 5790 : loss : 226.491165, loss_ce: 0.022524, loss_kd: 1129.993042
[16:31:27.389] iteration 5800 : loss : 266.904846, loss_ce: 0.012693, loss_kd: 1332.098999
[16:31:33.017] iteration 5810 : loss : 264.431183, loss_ce: 0.023754, loss_kd: 1319.698364
[16:31:38.628] iteration 5820 : loss : 225.583954, loss_ce: 0.019394, loss_kd: 1125.542236
[16:31:44.254] iteration 5830 : loss : 255.280655, loss_ce: 0.013422, loss_kd: 1273.956665
[16:31:49.858] iteration 5840 : loss : 248.195450, loss_ce: 0.027779, loss_kd: 1238.506836
[16:31:55.492] iteration 5850 : loss : 208.797394, loss_ce: 0.025643, loss_kd: 1041.516235
[16:32:01.109] iteration 5860 : loss : 225.438934, loss_ce: 0.021947, loss_kd: 1124.716797
[16:32:06.740] iteration 5870 : loss : 248.764343, loss_ce: 0.025380, loss_kd: 1241.386963
[16:32:12.362] iteration 5880 : loss : 202.942032, loss_ce: 0.023670, loss_kd: 1012.291443
[16:32:17.984] iteration 5890 : loss : 191.008026, loss_ce: 0.016515, loss_kd: 952.623413
[16:32:23.594] iteration 5900 : loss : 256.098999, loss_ce: 0.018672, loss_kd: 1278.066772
[16:32:29.226] iteration 5910 : loss : 264.960907, loss_ce: 0.025581, loss_kd: 1322.325806
[16:32:34.836] iteration 5920 : loss : 285.827179, loss_ce: 0.023337, loss_kd: 1426.684326
[16:32:40.470] iteration 5930 : loss : 368.012848, loss_ce: 0.017291, loss_kd: 1837.659790
[16:32:46.094] iteration 5940 : loss : 217.577789, loss_ce: 0.034944, loss_kd: 1085.442261
[16:32:51.719] iteration 5950 : loss : 222.816406, loss_ce: 0.026958, loss_kd: 1111.624878
[16:32:57.357] iteration 5960 : loss : 236.417282, loss_ce: 0.022144, loss_kd: 1179.606812
[16:33:02.983] iteration 5970 : loss : 222.551025, loss_ce: 0.023737, loss_kd: 1110.307739
[16:33:08.588] iteration 5980 : loss : 292.783081, loss_ce: 0.023977, loss_kd: 1461.389404
[16:33:14.221] iteration 5990 : loss : 250.046509, loss_ce: 0.027426, loss_kd: 1247.775513
[16:33:19.835] iteration 6000 : loss : 204.905426, loss_ce: 0.017662, loss_kd: 1022.084412
[16:33:25.481] iteration 6010 : loss : 224.843201, loss_ce: 0.027781, loss_kd: 1121.737305
[16:33:31.094] iteration 6020 : loss : 246.711273, loss_ce: 0.016032, loss_kd: 1231.096802
[16:33:36.717] iteration 6030 : loss : 226.204712, loss_ce: 0.014924, loss_kd: 1128.585693
[16:33:42.342] iteration 6040 : loss : 296.974304, loss_ce: 0.022404, loss_kd: 1482.446289
[16:33:47.970] iteration 6050 : loss : 204.885406, loss_ce: 0.017409, loss_kd: 1022.054321
[16:33:53.592] iteration 6060 : loss : 238.535126, loss_ce: 0.029186, loss_kd: 1190.201904
[16:33:59.227] iteration 6070 : loss : 213.421295, loss_ce: 0.019331, loss_kd: 1064.661987
[16:34:04.850] iteration 6080 : loss : 223.258774, loss_ce: 0.015243, loss_kd: 1113.827393
[16:34:10.487] iteration 6090 : loss : 205.601242, loss_ce: 0.031491, loss_kd: 1025.550659
[16:34:16.108] iteration 6100 : loss : 224.468063, loss_ce: 0.020578, loss_kd: 1119.950806
[16:34:21.750] iteration 6110 : loss : 240.153137, loss_ce: 0.023938, loss_kd: 1198.319458
[16:34:27.375] iteration 6120 : loss : 215.098831, loss_ce: 0.011783, loss_kd: 1073.075195
[16:34:33.010] iteration 6130 : loss : 200.016937, loss_ce: 0.011507, loss_kd: 997.687744
[16:34:38.620] iteration 6140 : loss : 295.135986, loss_ce: 0.013743, loss_kd: 1473.238770
[16:34:44.255] iteration 6150 : loss : 166.555267, loss_ce: 0.017881, loss_kd: 830.354248
[16:34:49.884] iteration 6160 : loss : 250.568390, loss_ce: 0.014486, loss_kd: 1250.283813
[16:34:55.530] iteration 6170 : loss : 200.167938, loss_ce: 0.029171, loss_kd: 998.421875
[16:35:01.160] iteration 6180 : loss : 266.859406, loss_ce: 0.016419, loss_kd: 1331.871704
[16:35:06.789] iteration 6190 : loss : 287.187927, loss_ce: 0.025937, loss_kd: 1433.500977
[16:35:12.424] iteration 6200 : loss : 228.236877, loss_ce: 0.017433, loss_kd: 1138.804077
[16:35:18.046] iteration 6210 : loss : 236.596207, loss_ce: 0.019766, loss_kd: 1180.565918
[16:35:23.671] iteration 6220 : loss : 224.176804, loss_ce: 0.021443, loss_kd: 1118.439331
[16:35:29.292] iteration 6230 : loss : 282.669586, loss_ce: 0.026605, loss_kd: 1410.903442
[16:35:34.914] iteration 6240 : loss : 223.986969, loss_ce: 0.028315, loss_kd: 1117.504639
[16:35:40.551] iteration 6250 : loss : 229.527374, loss_ce: 0.023881, loss_kd: 1145.211182
[16:35:56.990] iteration 6260 : loss : 235.111603, loss_ce: 0.020570, loss_kd: 1173.154785
[16:36:02.548] iteration 6270 : loss : 214.141647, loss_ce: 0.023641, loss_kd: 1068.273071
[16:36:08.106] iteration 6280 : loss : 189.275726, loss_ce: 0.025936, loss_kd: 943.925415
[16:36:13.668] iteration 6290 : loss : 332.691895, loss_ce: 0.024761, loss_kd: 1661.031494
[16:36:19.231] iteration 6300 : loss : 261.446289, loss_ce: 0.022545, loss_kd: 1304.808960
[16:36:24.821] iteration 6310 : loss : 211.963181, loss_ce: 0.014752, loss_kd: 1057.356812
[16:36:30.391] iteration 6320 : loss : 163.185455, loss_ce: 0.024854, loss_kd: 813.492676
[16:36:35.974] iteration 6330 : loss : 200.053986, loss_ce: 0.018253, loss_kd: 997.863037
[16:36:41.555] iteration 6340 : loss : 241.134232, loss_ce: 0.017103, loss_kd: 1203.258911
[16:36:47.152] iteration 6350 : loss : 266.694885, loss_ce: 0.015120, loss_kd: 1331.030762
[16:36:52.747] iteration 6360 : loss : 216.165894, loss_ce: 0.018877, loss_kd: 1078.436401
[16:36:58.348] iteration 6370 : loss : 222.330231, loss_ce: 0.019596, loss_kd: 1109.232056
[16:37:03.941] iteration 6380 : loss : 216.610352, loss_ce: 0.022846, loss_kd: 1080.639648
[16:37:09.553] iteration 6390 : loss : 233.534622, loss_ce: 0.012150, loss_kd: 1165.286621
[16:37:15.157] iteration 6400 : loss : 166.012283, loss_ce: 0.039916, loss_kd: 827.590820
[16:37:20.755] iteration 6410 : loss : 172.476471, loss_ce: 0.020910, loss_kd: 859.932861
[16:37:26.354] iteration 6420 : loss : 356.672424, loss_ce: 0.017881, loss_kd: 1780.927246
[16:37:31.966] iteration 6430 : loss : 231.776321, loss_ce: 0.018835, loss_kd: 1156.453003
[16:37:37.560] iteration 6440 : loss : 224.760590, loss_ce: 0.019839, loss_kd: 1121.384644
[16:37:43.172] iteration 6450 : loss : 253.241241, loss_ce: 0.023610, loss_kd: 1263.742676
[16:37:48.773] iteration 6460 : loss : 205.544785, loss_ce: 0.016777, loss_kd: 1025.291504
[16:37:54.397] iteration 6470 : loss : 223.489136, loss_ce: 0.012246, loss_kd: 1115.035889
[16:38:00.003] iteration 6480 : loss : 221.567810, loss_ce: 0.023551, loss_kd: 1105.360596
[16:38:05.612] iteration 6490 : loss : 226.512558, loss_ce: 0.014157, loss_kd: 1130.180908
[16:38:11.220] iteration 6500 : loss : 239.487000, loss_ce: 0.025035, loss_kd: 1194.994751
[16:38:16.836] iteration 6510 : loss : 255.907944, loss_ce: 0.031172, loss_kd: 1277.112793
[16:38:22.446] iteration 6520 : loss : 419.000885, loss_ce: 0.016070, loss_kd: 2092.605225
[16:38:28.077] iteration 6530 : loss : 170.814865, loss_ce: 0.027034, loss_kd: 851.634460
[16:38:33.697] iteration 6540 : loss : 252.430161, loss_ce: 0.040516, loss_kd: 1259.714111
[16:38:39.328] iteration 6550 : loss : 179.591064, loss_ce: 0.014166, loss_kd: 895.489502
[16:38:44.943] iteration 6560 : loss : 186.470459, loss_ce: 0.021384, loss_kd: 929.923889
[16:38:50.557] iteration 6570 : loss : 185.537094, loss_ce: 0.018680, loss_kd: 925.228760
[16:38:56.167] iteration 6580 : loss : 194.013641, loss_ce: 0.019341, loss_kd: 967.630371
[16:39:01.798] iteration 6590 : loss : 251.600357, loss_ce: 0.022937, loss_kd: 1255.584473
[16:39:07.413] iteration 6600 : loss : 236.326202, loss_ce: 0.028648, loss_kd: 1179.193115
[16:39:13.037] iteration 6610 : loss : 204.117737, loss_ce: 0.025466, loss_kd: 1018.119263
[16:39:18.656] iteration 6620 : loss : 212.095032, loss_ce: 0.027246, loss_kd: 1058.020264
[16:39:24.275] iteration 6630 : loss : 227.127884, loss_ce: 0.017388, loss_kd: 1133.187256
[16:39:29.879] iteration 6640 : loss : 204.379089, loss_ce: 0.019176, loss_kd: 1019.487549
[16:39:35.507] iteration 6650 : loss : 192.984146, loss_ce: 0.025182, loss_kd: 962.466187
[16:39:41.134] iteration 6660 : loss : 225.353088, loss_ce: 0.019594, loss_kd: 1124.343750
[16:39:46.793] iteration 6670 : loss : 181.941269, loss_ce: 0.018330, loss_kd: 907.303101
[16:39:52.413] iteration 6680 : loss : 199.053619, loss_ce: 0.020302, loss_kd: 992.847534
[16:39:58.046] iteration 6690 : loss : 232.031708, loss_ce: 0.017670, loss_kd: 1157.689819
[16:40:03.671] iteration 6700 : loss : 222.306686, loss_ce: 0.014312, loss_kd: 1109.118408
[16:40:09.298] iteration 6710 : loss : 175.103424, loss_ce: 0.012358, loss_kd: 873.083313
[16:40:14.934] iteration 6720 : loss : 218.487518, loss_ce: 0.015417, loss_kd: 1089.902222
[16:40:20.560] iteration 6730 : loss : 288.055695, loss_ce: 0.015571, loss_kd: 1437.859619
[16:40:26.164] iteration 6740 : loss : 193.423660, loss_ce: 0.022283, loss_kd: 964.684143
[16:40:31.803] iteration 6750 : loss : 189.522888, loss_ce: 0.027307, loss_kd: 945.166504
[16:40:37.419] iteration 6760 : loss : 227.599091, loss_ce: 0.027461, loss_kd: 1135.564941
[16:40:43.050] iteration 6770 : loss : 233.404221, loss_ce: 0.032957, loss_kd: 1164.538818
[16:40:48.670] iteration 6780 : loss : 195.022369, loss_ce: 0.042962, loss_kd: 972.658630
[16:40:54.290] iteration 6790 : loss : 222.213989, loss_ce: 0.023763, loss_kd: 1108.622437
[16:40:59.899] iteration 6800 : loss : 197.136108, loss_ce: 0.035129, loss_kd: 983.225403
[16:41:05.539] iteration 6810 : loss : 244.795135, loss_ce: 0.018119, loss_kd: 1221.543213
[16:41:11.156] iteration 6820 : loss : 215.388748, loss_ce: 0.022467, loss_kd: 1074.539062
[16:41:16.792] iteration 6830 : loss : 287.567047, loss_ce: 0.019246, loss_kd: 1435.364502
[16:41:22.406] iteration 6840 : loss : 262.483948, loss_ce: 0.015996, loss_kd: 1309.973755
[16:41:28.030] iteration 6850 : loss : 281.722717, loss_ce: 0.017471, loss_kd: 1406.132568
[16:41:33.671] iteration 6860 : loss : 183.561264, loss_ce: 0.034621, loss_kd: 915.373596
[16:41:39.303] iteration 6870 : loss : 243.456680, loss_ce: 0.032255, loss_kd: 1214.838501
[16:41:44.933] iteration 6880 : loss : 228.860992, loss_ce: 0.023299, loss_kd: 1141.866699
[16:41:50.560] iteration 6890 : loss : 215.828232, loss_ce: 0.023561, loss_kd: 1076.714111
[16:41:56.194] iteration 6900 : loss : 262.275635, loss_ce: 0.028002, loss_kd: 1308.784790
[16:42:01.825] iteration 6910 : loss : 261.435516, loss_ce: 0.015967, loss_kd: 1304.754028
[16:42:07.444] iteration 6920 : loss : 221.733078, loss_ce: 0.020564, loss_kd: 1106.221436
[16:42:13.074] iteration 6930 : loss : 188.265121, loss_ce: 0.023814, loss_kd: 938.903809
[16:42:18.692] iteration 6940 : loss : 166.099228, loss_ce: 0.024735, loss_kd: 828.027466
[16:42:24.394] iteration 6950 : loss : 179.744614, loss_ce: 0.024041, loss_kd: 896.293213
[16:42:30.008] iteration 6960 : loss : 241.196518, loss_ce: 0.019147, loss_kd: 1203.548584
[16:42:35.651] iteration 6970 : loss : 183.842773, loss_ce: 0.021213, loss_kd: 916.747131
[16:42:41.275] iteration 6980 : loss : 195.228333, loss_ce: 0.030489, loss_kd: 973.702026
[16:42:46.911] iteration 6990 : loss : 253.680450, loss_ce: 0.025719, loss_kd: 1265.980713
[16:42:52.534] iteration 7000 : loss : 218.233093, loss_ce: 0.018644, loss_kd: 1088.709717
[16:42:58.171] iteration 7010 : loss : 205.694916, loss_ce: 0.012249, loss_kd: 1026.006836
[16:43:03.793] iteration 7020 : loss : 292.342896, loss_ce: 0.018714, loss_kd: 1459.270874
[16:43:09.429] iteration 7030 : loss : 243.638687, loss_ce: 0.032685, loss_kd: 1215.743530
[16:43:15.063] iteration 7040 : loss : 236.455261, loss_ce: 0.027268, loss_kd: 1179.816284
[16:43:20.702] iteration 7050 : loss : 228.234283, loss_ce: 0.019465, loss_kd: 1138.739014
[16:43:26.329] iteration 7060 : loss : 224.164764, loss_ce: 0.019542, loss_kd: 1118.376221
[16:43:31.968] iteration 7070 : loss : 163.971649, loss_ce: 0.018276, loss_kd: 817.463928
[16:43:37.595] iteration 7080 : loss : 236.221848, loss_ce: 0.021857, loss_kd: 1178.675293
[16:43:43.232] iteration 7090 : loss : 250.886490, loss_ce: 0.016411, loss_kd: 1251.994507
[16:43:48.866] iteration 7100 : loss : 194.814682, loss_ce: 0.017558, loss_kd: 971.638794
[16:43:54.501] iteration 7110 : loss : 209.653870, loss_ce: 0.025005, loss_kd: 1045.791138
[16:44:00.124] iteration 7120 : loss : 210.966354, loss_ce: 0.015190, loss_kd: 1052.396118
[16:44:05.750] iteration 7130 : loss : 290.239288, loss_ce: 0.029438, loss_kd: 1448.740967
[16:44:11.387] iteration 7140 : loss : 260.582916, loss_ce: 0.013703, loss_kd: 1300.435059
[16:44:17.055] iteration 7150 : loss : 162.232010, loss_ce: 0.023695, loss_kd: 808.738220
[16:44:22.682] iteration 7160 : loss : 220.039780, loss_ce: 0.020887, loss_kd: 1097.767456
[16:44:28.323] iteration 7170 : loss : 197.086533, loss_ce: 0.015074, loss_kd: 983.006165
[16:44:33.947] iteration 7180 : loss : 221.379745, loss_ce: 0.016597, loss_kd: 1104.447510
[16:44:39.562] iteration 7190 : loss : 158.182892, loss_ce: 0.020153, loss_kd: 788.471130
[16:44:45.193] iteration 7200 : loss : 206.338348, loss_ce: 0.022211, loss_kd: 1029.269775
[16:44:50.825] iteration 7210 : loss : 213.120056, loss_ce: 0.013761, loss_kd: 1063.152344
[16:44:56.455] iteration 7220 : loss : 231.171585, loss_ce: 0.023466, loss_kd: 1153.409912
[16:45:02.083] iteration 7230 : loss : 218.536377, loss_ce: 0.030235, loss_kd: 1090.274658
[16:45:07.720] iteration 7240 : loss : 261.088287, loss_ce: 0.008815, loss_kd: 1303.048828
[16:45:13.338] iteration 7250 : loss : 207.809280, loss_ce: 0.014792, loss_kd: 1036.580566
[16:45:18.962] iteration 7260 : loss : 242.368652, loss_ce: 0.012441, loss_kd: 1209.314697
[16:45:24.593] iteration 7270 : loss : 241.255295, loss_ce: 0.021956, loss_kd: 1203.816162
[16:45:30.226] iteration 7280 : loss : 206.535812, loss_ce: 0.021791, loss_kd: 1030.252930
[16:45:35.862] iteration 7290 : loss : 200.409409, loss_ce: 0.019135, loss_kd: 999.597046
[16:45:38.403] Running TPGM constraint optimization after epoch 7
[16:50:23.224] iteration 7300 : loss : 219.886002, loss_ce: 0.021095, loss_kd: 1097.043335
[16:50:28.758] iteration 7310 : loss : 206.174377, loss_ce: 0.027664, loss_kd: 1028.443359
[16:50:34.288] iteration 7320 : loss : 211.268372, loss_ce: 0.021364, loss_kd: 1053.917603
[16:50:39.832] iteration 7330 : loss : 182.207474, loss_ce: 0.017002, loss_kd: 908.587830
[16:50:45.378] iteration 7340 : loss : 213.286880, loss_ce: 0.021474, loss_kd: 1064.028442
[16:50:50.930] iteration 7350 : loss : 212.817108, loss_ce: 0.023195, loss_kd: 1061.661133
[16:50:56.479] iteration 7360 : loss : 198.969360, loss_ce: 0.014668, loss_kd: 992.371826
[16:51:02.045] iteration 7370 : loss : 207.160934, loss_ce: 0.018302, loss_kd: 1033.377075
[16:51:07.605] iteration 7380 : loss : 232.133057, loss_ce: 0.018934, loss_kd: 1158.272705
[16:51:13.169] iteration 7390 : loss : 183.522858, loss_ce: 0.030497, loss_kd: 915.158203
[16:51:18.730] iteration 7400 : loss : 242.230637, loss_ce: 0.026233, loss_kd: 1208.733887
[16:51:24.309] iteration 7410 : loss : 220.170288, loss_ce: 0.017305, loss_kd: 1098.425049
[16:51:29.876] iteration 7420 : loss : 180.082565, loss_ce: 0.030565, loss_kd: 898.002930
[16:51:35.453] iteration 7430 : loss : 151.463577, loss_ce: 0.023780, loss_kd: 754.882874
[16:51:41.021] iteration 7440 : loss : 158.567474, loss_ce: 0.010192, loss_kd: 790.430481
[16:51:46.610] iteration 7450 : loss : 162.339981, loss_ce: 0.012662, loss_kd: 809.280518
[16:51:52.193] iteration 7460 : loss : 185.105972, loss_ce: 0.017738, loss_kd: 923.124573
[16:51:57.779] iteration 7470 : loss : 226.200485, loss_ce: 0.020129, loss_kd: 1128.551514
[16:52:03.373] iteration 7480 : loss : 219.891220, loss_ce: 0.018332, loss_kd: 1097.014771
[16:52:08.973] iteration 7490 : loss : 205.312622, loss_ce: 0.023279, loss_kd: 1024.127075
[16:52:14.566] iteration 7500 : loss : 166.803604, loss_ce: 0.017466, loss_kd: 831.604065
[16:52:20.177] iteration 7510 : loss : 226.049911, loss_ce: 0.029536, loss_kd: 1127.826904
[16:52:25.768] iteration 7520 : loss : 215.975052, loss_ce: 0.022279, loss_kd: 1077.265747
[16:52:31.372] iteration 7530 : loss : 189.948303, loss_ce: 0.016180, loss_kd: 947.361511
[16:52:36.967] iteration 7540 : loss : 251.487579, loss_ce: 0.020379, loss_kd: 1255.038574
[16:52:42.573] iteration 7550 : loss : 295.975586, loss_ce: 0.015865, loss_kd: 1477.490112
[16:52:48.165] iteration 7560 : loss : 179.241211, loss_ce: 0.014940, loss_kd: 893.806030
[16:52:53.770] iteration 7570 : loss : 210.265030, loss_ce: 0.023698, loss_kd: 1048.884888
[16:52:59.370] iteration 7580 : loss : 160.285080, loss_ce: 0.023955, loss_kd: 799.000916
[16:53:04.977] iteration 7590 : loss : 171.220093, loss_ce: 0.017007, loss_kd: 853.700562
[16:53:10.573] iteration 7600 : loss : 216.130554, loss_ce: 0.020245, loss_kd: 1078.212769
[16:53:16.177] iteration 7610 : loss : 179.529205, loss_ce: 0.017146, loss_kd: 895.189270
[16:53:21.776] iteration 7620 : loss : 228.850052, loss_ce: 0.025988, loss_kd: 1141.833374
[16:53:27.373] iteration 7630 : loss : 224.354782, loss_ce: 0.028781, loss_kd: 1119.295776
[16:53:32.973] iteration 7640 : loss : 198.772842, loss_ce: 0.024297, loss_kd: 991.403015
[16:53:38.582] iteration 7650 : loss : 240.031570, loss_ce: 0.013650, loss_kd: 1197.761719
[16:53:44.189] iteration 7660 : loss : 265.916840, loss_ce: 0.016638, loss_kd: 1327.144043
[16:53:49.797] iteration 7670 : loss : 194.752075, loss_ce: 0.020916, loss_kd: 971.338379
[16:53:55.396] iteration 7680 : loss : 186.174728, loss_ce: 0.014751, loss_kd: 928.430176
[16:54:01.024] iteration 7690 : loss : 168.581238, loss_ce: 0.017231, loss_kd: 840.467224
[16:54:06.632] iteration 7700 : loss : 154.693878, loss_ce: 0.042697, loss_kd: 770.979858
[16:54:12.248] iteration 7710 : loss : 170.233353, loss_ce: 0.023890, loss_kd: 848.717407
[16:54:17.858] iteration 7720 : loss : 174.708694, loss_ce: 0.027257, loss_kd: 871.091003
[16:54:23.490] iteration 7730 : loss : 224.050186, loss_ce: 0.016027, loss_kd: 1117.810425
[16:54:29.106] iteration 7740 : loss : 178.947647, loss_ce: 0.023146, loss_kd: 892.310669
[16:54:34.719] iteration 7750 : loss : 153.817139, loss_ce: 0.021988, loss_kd: 766.625122
[16:54:40.333] iteration 7760 : loss : 174.589600, loss_ce: 0.025100, loss_kd: 870.478210
[16:54:45.962] iteration 7770 : loss : 170.035538, loss_ce: 0.020428, loss_kd: 847.791321
[16:54:51.577] iteration 7780 : loss : 155.367020, loss_ce: 0.022610, loss_kd: 774.412109
[16:54:57.192] iteration 7790 : loss : 309.040894, loss_ce: 0.019078, loss_kd: 1542.742310
[16:55:02.812] iteration 7800 : loss : 212.191666, loss_ce: 0.018408, loss_kd: 1058.551636
[16:55:08.436] iteration 7810 : loss : 202.750549, loss_ce: 0.022711, loss_kd: 1011.318359
[16:55:14.052] iteration 7820 : loss : 160.271149, loss_ce: 0.018827, loss_kd: 798.871094
[16:55:19.692] iteration 7830 : loss : 175.402496, loss_ce: 0.023780, loss_kd: 874.614441
[16:55:25.305] iteration 7840 : loss : 218.424576, loss_ce: 0.024230, loss_kd: 1089.685303
[16:55:30.918] iteration 7850 : loss : 243.839188, loss_ce: 0.023508, loss_kd: 1216.707031
[16:55:36.544] iteration 7860 : loss : 172.986115, loss_ce: 0.020578, loss_kd: 862.483765
[16:55:42.162] iteration 7870 : loss : 232.110062, loss_ce: 0.019397, loss_kd: 1158.130249
[16:55:47.772] iteration 7880 : loss : 220.440659, loss_ce: 0.021547, loss_kd: 1099.768799
[16:55:53.395] iteration 7890 : loss : 197.674225, loss_ce: 0.016819, loss_kd: 985.909729
[16:55:59.027] iteration 7900 : loss : 211.172028, loss_ce: 0.017406, loss_kd: 1053.430420
[16:56:04.665] iteration 7910 : loss : 226.761673, loss_ce: 0.022787, loss_kd: 1131.400024
[16:56:10.291] iteration 7920 : loss : 226.007370, loss_ce: 0.018721, loss_kd: 1127.618774
[16:56:15.911] iteration 7930 : loss : 187.576614, loss_ce: 0.012773, loss_kd: 935.465820
[16:56:21.532] iteration 7940 : loss : 184.528275, loss_ce: 0.026737, loss_kd: 920.208923
[16:56:27.169] iteration 7950 : loss : 213.639877, loss_ce: 0.022164, loss_kd: 1065.742310
[16:56:32.804] iteration 7960 : loss : 246.226456, loss_ce: 0.028190, loss_kd: 1228.710938
[16:56:38.418] iteration 7970 : loss : 272.491638, loss_ce: 0.026577, loss_kd: 1360.017334
[16:56:44.039] iteration 7980 : loss : 232.923309, loss_ce: 0.023544, loss_kd: 1162.156128
[16:56:49.671] iteration 7990 : loss : 157.081833, loss_ce: 0.020648, loss_kd: 782.961670
[16:56:55.290] iteration 8000 : loss : 158.677551, loss_ce: 0.023490, loss_kd: 790.954529
[16:57:00.913] iteration 8010 : loss : 202.712357, loss_ce: 0.017518, loss_kd: 1011.136719
[16:57:06.537] iteration 8020 : loss : 191.649536, loss_ce: 0.025920, loss_kd: 955.760986
[16:57:12.160] iteration 8030 : loss : 259.604340, loss_ce: 0.020269, loss_kd: 1295.608887
[16:57:17.781] iteration 8040 : loss : 200.208176, loss_ce: 0.024092, loss_kd: 998.628906
[16:57:23.418] iteration 8050 : loss : 239.759460, loss_ce: 0.024202, loss_kd: 1196.335449
[16:57:29.028] iteration 8060 : loss : 220.953766, loss_ce: 0.020129, loss_kd: 1102.351929
[16:57:34.680] iteration 8070 : loss : 213.050110, loss_ce: 0.018370, loss_kd: 1062.817139
[16:57:40.295] iteration 8080 : loss : 226.509399, loss_ce: 0.014276, loss_kd: 1130.125854
[16:57:45.946] iteration 8090 : loss : 196.546524, loss_ce: 0.015165, loss_kd: 980.284912
[16:57:51.554] iteration 8100 : loss : 170.398346, loss_ce: 0.020900, loss_kd: 849.553711
[16:57:57.200] iteration 8110 : loss : 225.536957, loss_ce: 0.021240, loss_kd: 1125.281372
[16:58:02.819] iteration 8120 : loss : 260.076447, loss_ce: 0.028998, loss_kd: 1297.959839
[16:58:08.440] iteration 8130 : loss : 224.679565, loss_ce: 0.023296, loss_kd: 1120.931519
[16:58:14.065] iteration 8140 : loss : 191.591476, loss_ce: 0.024247, loss_kd: 955.510071
[16:58:19.691] iteration 8150 : loss : 210.846573, loss_ce: 0.017473, loss_kd: 1051.811401
[16:58:25.319] iteration 8160 : loss : 204.974289, loss_ce: 0.016502, loss_kd: 1022.435181
[16:58:30.958] iteration 8170 : loss : 168.716476, loss_ce: 0.019673, loss_kd: 841.161194
[16:58:36.589] iteration 8180 : loss : 189.238708, loss_ce: 0.011655, loss_kd: 943.801392
[16:58:42.224] iteration 8190 : loss : 183.966827, loss_ce: 0.014492, loss_kd: 917.416443
[16:58:47.853] iteration 8200 : loss : 174.085190, loss_ce: 0.014046, loss_kd: 868.015625
[16:58:53.487] iteration 8210 : loss : 249.300034, loss_ce: 0.022417, loss_kd: 1244.085205
[16:58:59.110] iteration 8220 : loss : 186.046722, loss_ce: 0.014939, loss_kd: 927.846191
[16:59:04.753] iteration 8230 : loss : 231.657349, loss_ce: 0.021925, loss_kd: 1155.840332
[16:59:10.373] iteration 8240 : loss : 198.560730, loss_ce: 0.025874, loss_kd: 990.431396
[16:59:16.010] iteration 8250 : loss : 162.859863, loss_ce: 0.015746, loss_kd: 811.886475
[16:59:21.645] iteration 8260 : loss : 195.668274, loss_ce: 0.016829, loss_kd: 975.917297
[16:59:27.299] iteration 8270 : loss : 248.260574, loss_ce: 0.016556, loss_kd: 1238.891357
[16:59:32.919] iteration 8280 : loss : 200.390381, loss_ce: 0.021248, loss_kd: 999.520630
[16:59:38.557] iteration 8290 : loss : 153.061111, loss_ce: 0.017954, loss_kd: 762.850342
[16:59:44.176] iteration 8300 : loss : 215.335678, loss_ce: 0.015633, loss_kd: 1074.238525
[16:59:49.827] iteration 8310 : loss : 209.686569, loss_ce: 0.016004, loss_kd: 1045.955078
[16:59:55.458] iteration 8320 : loss : 202.054245, loss_ce: 0.024378, loss_kd: 1007.831787
[17:00:01.098] iteration 8330 : loss : 178.677246, loss_ce: 0.020784, loss_kd: 890.950073
[17:00:18.127] iteration 8340 : loss : 163.491272, loss_ce: 0.015754, loss_kd: 814.990417
[17:00:23.687] iteration 8350 : loss : 220.676010, loss_ce: 0.011246, loss_kd: 1100.953003
[17:00:29.247] iteration 8360 : loss : 177.788315, loss_ce: 0.022206, loss_kd: 886.532471
[17:00:34.813] iteration 8370 : loss : 188.059143, loss_ce: 0.033079, loss_kd: 937.875122
[17:00:40.375] iteration 8380 : loss : 168.679382, loss_ce: 0.018983, loss_kd: 840.990662
[17:00:45.952] iteration 8390 : loss : 220.417969, loss_ce: 0.017341, loss_kd: 1099.684204
[17:00:51.530] iteration 8400 : loss : 165.109161, loss_ce: 0.016913, loss_kd: 823.082581
[17:00:57.121] iteration 8410 : loss : 275.748932, loss_ce: 0.011936, loss_kd: 1376.301636
[17:01:02.706] iteration 8420 : loss : 283.443176, loss_ce: 0.032919, loss_kd: 1414.765137
[17:01:08.316] iteration 8430 : loss : 182.382874, loss_ce: 0.014047, loss_kd: 909.479004
[17:01:13.905] iteration 8440 : loss : 192.980164, loss_ce: 0.028361, loss_kd: 962.480103
[17:01:19.510] iteration 8450 : loss : 299.107788, loss_ce: 0.024001, loss_kd: 1493.114380
[17:01:25.124] iteration 8460 : loss : 205.244873, loss_ce: 0.012967, loss_kd: 1023.803589
[17:01:30.726] iteration 8470 : loss : 207.268021, loss_ce: 0.017280, loss_kd: 1033.902954
[17:01:36.319] iteration 8480 : loss : 205.090714, loss_ce: 0.015819, loss_kd: 1023.012390
[17:01:41.936] iteration 8490 : loss : 188.853363, loss_ce: 0.018259, loss_kd: 941.832214
[17:01:47.538] iteration 8500 : loss : 195.464310, loss_ce: 0.020068, loss_kd: 974.873108
[17:01:53.167] iteration 8510 : loss : 212.186172, loss_ce: 0.015722, loss_kd: 1058.514282
[17:01:58.773] iteration 8520 : loss : 202.660645, loss_ce: 0.030514, loss_kd: 1010.890137
[17:02:04.385] iteration 8530 : loss : 171.231842, loss_ce: 0.019235, loss_kd: 853.683411
[17:02:09.989] iteration 8540 : loss : 194.309677, loss_ce: 0.020972, loss_kd: 969.085266
[17:02:15.610] iteration 8550 : loss : 215.275421, loss_ce: 0.018928, loss_kd: 1073.994507
[17:02:21.232] iteration 8560 : loss : 213.978378, loss_ce: 0.019648, loss_kd: 1067.491333
[17:02:26.851] iteration 8570 : loss : 195.485275, loss_ce: 0.014484, loss_kd: 975.006226
[17:02:32.465] iteration 8580 : loss : 196.637314, loss_ce: 0.018408, loss_kd: 980.795410
[17:02:38.090] iteration 8590 : loss : 142.260574, loss_ce: 0.022420, loss_kd: 708.849304
[17:02:43.710] iteration 8600 : loss : 203.665146, loss_ce: 0.012849, loss_kd: 1015.899719
[17:02:49.334] iteration 8610 : loss : 196.041367, loss_ce: 0.017747, loss_kd: 977.755371
[17:02:54.934] iteration 8620 : loss : 212.273712, loss_ce: 0.015557, loss_kd: 1058.961670
[17:03:00.563] iteration 8630 : loss : 169.425797, loss_ce: 0.011323, loss_kd: 844.687805
[17:03:06.184] iteration 8640 : loss : 220.655090, loss_ce: 0.028020, loss_kd: 1100.799805
[17:03:11.831] iteration 8650 : loss : 155.887955, loss_ce: 0.020561, loss_kd: 776.961975
[17:03:17.450] iteration 8660 : loss : 191.528473, loss_ce: 0.026243, loss_kd: 955.207153
[17:03:23.099] iteration 8670 : loss : 282.532990, loss_ce: 0.011860, loss_kd: 1410.183594
[17:03:28.718] iteration 8680 : loss : 291.274292, loss_ce: 0.023344, loss_kd: 1453.950195
[17:03:34.333] iteration 8690 : loss : 176.082153, loss_ce: 0.016594, loss_kd: 877.993713
[17:03:39.956] iteration 8700 : loss : 191.286011, loss_ce: 0.017411, loss_kd: 954.011719
[17:03:45.586] iteration 8710 : loss : 199.653702, loss_ce: 0.009047, loss_kd: 995.821533
[17:03:51.202] iteration 8720 : loss : 234.119202, loss_ce: 0.025488, loss_kd: 1168.165405
[17:03:56.837] iteration 8730 : loss : 209.249344, loss_ce: 0.015237, loss_kd: 1043.868286
[17:04:02.452] iteration 8740 : loss : 234.014771, loss_ce: 0.016352, loss_kd: 1167.646729
[17:04:08.088] iteration 8750 : loss : 236.313782, loss_ce: 0.024156, loss_kd: 1179.132690
[17:04:13.709] iteration 8760 : loss : 205.489700, loss_ce: 0.020496, loss_kd: 1025.011719
[17:04:19.332] iteration 8770 : loss : 273.865021, loss_ce: 0.023299, loss_kd: 1366.889160
[17:04:24.948] iteration 8780 : loss : 248.811783, loss_ce: 0.014446, loss_kd: 1241.632202
[17:04:30.583] iteration 8790 : loss : 216.488266, loss_ce: 0.028876, loss_kd: 1079.996338
[17:04:36.228] iteration 8800 : loss : 202.014328, loss_ce: 0.017763, loss_kd: 1007.707825
[17:04:41.868] iteration 8810 : loss : 160.887772, loss_ce: 0.017111, loss_kd: 802.013306
[17:04:47.497] iteration 8820 : loss : 221.510178, loss_ce: 0.016747, loss_kd: 1105.093750
[17:04:53.135] iteration 8830 : loss : 157.574921, loss_ce: 0.014863, loss_kd: 785.463135
[17:04:58.775] iteration 8840 : loss : 194.652420, loss_ce: 0.016388, loss_kd: 970.859497
[17:05:04.408] iteration 8850 : loss : 184.022217, loss_ce: 0.012674, loss_kd: 917.704590
[17:05:10.039] iteration 8860 : loss : 157.002472, loss_ce: 0.022736, loss_kd: 782.500488
[17:05:15.678] iteration 8870 : loss : 183.280258, loss_ce: 0.021663, loss_kd: 913.949890
[17:05:21.307] iteration 8880 : loss : 180.619980, loss_ce: 0.013542, loss_kd: 900.643066
[17:05:26.930] iteration 8890 : loss : 125.530144, loss_ce: 0.022590, loss_kd: 625.240723
[17:05:32.546] iteration 8900 : loss : 201.366638, loss_ce: 0.014727, loss_kd: 1004.403076
[17:05:38.181] iteration 8910 : loss : 236.904984, loss_ce: 0.011076, loss_kd: 1182.126953
[17:05:43.812] iteration 8920 : loss : 199.959045, loss_ce: 0.023667, loss_kd: 997.389893
[17:05:49.446] iteration 8930 : loss : 205.507584, loss_ce: 0.016248, loss_kd: 1025.143066
[17:05:55.073] iteration 8940 : loss : 197.589005, loss_ce: 0.015739, loss_kd: 985.561768
[17:06:00.701] iteration 8950 : loss : 169.794342, loss_ce: 0.023394, loss_kd: 846.543579
[17:06:06.316] iteration 8960 : loss : 235.354172, loss_ce: 0.019264, loss_kd: 1174.358521
[17:06:11.960] iteration 8970 : loss : 163.107834, loss_ce: 0.017710, loss_kd: 813.130554
[17:06:17.581] iteration 8980 : loss : 160.561691, loss_ce: 0.022649, loss_kd: 800.387634
[17:06:23.226] iteration 8990 : loss : 160.042892, loss_ce: 0.017581, loss_kd: 797.815979
[17:06:28.847] iteration 9000 : loss : 210.912125, loss_ce: 0.013028, loss_kd: 1052.156494
[17:06:34.493] iteration 9010 : loss : 209.024170, loss_ce: 0.012182, loss_kd: 1042.677490
[17:06:40.113] iteration 9020 : loss : 184.233353, loss_ce: 0.016095, loss_kd: 918.709595
[17:06:45.762] iteration 9030 : loss : 184.811203, loss_ce: 0.018141, loss_kd: 921.644714
[17:06:51.393] iteration 9040 : loss : 166.500977, loss_ce: 0.023983, loss_kd: 830.037964
[17:06:57.033] iteration 9050 : loss : 174.985321, loss_ce: 0.022863, loss_kd: 872.490906
[17:07:02.663] iteration 9060 : loss : 284.555023, loss_ce: 0.020365, loss_kd: 1420.356812
[17:07:08.303] iteration 9070 : loss : 281.442627, loss_ce: 0.023584, loss_kd: 1404.808838
[17:07:13.924] iteration 9080 : loss : 245.430267, loss_ce: 0.015072, loss_kd: 1224.728027
[17:07:19.569] iteration 9090 : loss : 203.001678, loss_ce: 0.020790, loss_kd: 1012.603882
[17:07:25.193] iteration 9100 : loss : 195.453110, loss_ce: 0.015970, loss_kd: 974.860596
[17:07:30.845] iteration 9110 : loss : 210.779297, loss_ce: 0.020220, loss_kd: 1051.491699
[17:07:36.491] iteration 9120 : loss : 162.544189, loss_ce: 0.014379, loss_kd: 810.324219
[17:07:42.134] iteration 9130 : loss : 205.099609, loss_ce: 0.012611, loss_kd: 1023.112793
[17:07:47.774] iteration 9140 : loss : 147.008713, loss_ce: 0.017727, loss_kd: 732.631348
[17:07:53.400] iteration 9150 : loss : 166.876099, loss_ce: 0.014500, loss_kd: 831.902100
[17:07:59.038] iteration 9160 : loss : 194.014343, loss_ce: 0.016176, loss_kd: 967.682495
[17:08:04.664] iteration 9170 : loss : 197.474808, loss_ce: 0.012549, loss_kd: 984.949158
[17:08:10.298] iteration 9180 : loss : 165.184189, loss_ce: 0.022125, loss_kd: 823.518250
[17:08:15.931] iteration 9190 : loss : 172.647156, loss_ce: 0.012147, loss_kd: 860.809021
[17:08:21.578] iteration 9200 : loss : 179.124420, loss_ce: 0.020158, loss_kd: 893.198425
[17:08:27.206] iteration 9210 : loss : 199.140930, loss_ce: 0.015698, loss_kd: 993.280518
[17:08:32.845] iteration 9220 : loss : 186.016190, loss_ce: 0.024607, loss_kd: 927.655701
[17:08:38.496] iteration 9230 : loss : 137.527969, loss_ce: 0.017252, loss_kd: 685.202576
[17:08:44.120] iteration 9240 : loss : 171.276291, loss_ce: 0.013396, loss_kd: 853.988281
[17:08:49.767] iteration 9250 : loss : 195.518555, loss_ce: 0.018035, loss_kd: 975.159546
[17:08:55.391] iteration 9260 : loss : 238.169235, loss_ce: 0.020599, loss_kd: 1188.414795
[17:09:01.036] iteration 9270 : loss : 169.340927, loss_ce: 0.023654, loss_kd: 844.237427
[17:09:06.665] iteration 9280 : loss : 182.210754, loss_ce: 0.027841, loss_kd: 908.592407
[17:09:12.307] iteration 9290 : loss : 167.376160, loss_ce: 0.027404, loss_kd: 834.449646
[17:09:17.933] iteration 9300 : loss : 149.855530, loss_ce: 0.017583, loss_kd: 746.841125
[17:09:23.576] iteration 9310 : loss : 174.562775, loss_ce: 0.019703, loss_kd: 870.401306
[17:09:29.199] iteration 9320 : loss : 202.927460, loss_ce: 0.016649, loss_kd: 1012.186523
[17:09:34.853] iteration 9330 : loss : 208.868408, loss_ce: 0.025167, loss_kd: 1041.904785
[17:09:40.490] iteration 9340 : loss : 139.779327, loss_ce: 0.017467, loss_kd: 696.436157
[17:09:46.120] iteration 9350 : loss : 194.988678, loss_ce: 0.019650, loss_kd: 972.536682
[17:09:51.767] iteration 9360 : loss : 153.463394, loss_ce: 0.017514, loss_kd: 764.892212
[17:09:57.400] iteration 9370 : loss : 196.956741, loss_ce: 0.026684, loss_kd: 982.348145
[17:10:02.233] Running TPGM constraint optimization after epoch 9
[17:14:56.557] iteration 9380 : loss : 234.975525, loss_ce: 0.027274, loss_kd: 1172.451904
[17:15:02.089] iteration 9390 : loss : 157.775223, loss_ce: 0.017298, loss_kd: 786.473999
[17:15:07.618] iteration 9400 : loss : 168.036667, loss_ce: 0.015468, loss_kd: 837.760254
[17:15:13.159] iteration 9410 : loss : 164.334930, loss_ce: 0.029877, loss_kd: 819.229065
[17:15:18.691] iteration 9420 : loss : 195.677597, loss_ce: 0.015534, loss_kd: 976.019653
[17:15:24.243] iteration 9430 : loss : 235.727264, loss_ce: 0.024957, loss_kd: 1176.197998
[17:15:29.782] iteration 9440 : loss : 195.242126, loss_ce: 0.019789, loss_kd: 973.776062
[17:15:35.340] iteration 9450 : loss : 162.770966, loss_ce: 0.019254, loss_kd: 811.422485
[17:15:40.888] iteration 9460 : loss : 144.623367, loss_ce: 0.020329, loss_kd: 720.676208
[17:15:46.461] iteration 9470 : loss : 171.650757, loss_ce: 0.017670, loss_kd: 855.782349
[17:15:52.018] iteration 9480 : loss : 191.907089, loss_ce: 0.022745, loss_kd: 957.081543
[17:15:57.588] iteration 9490 : loss : 192.114609, loss_ce: 0.033770, loss_kd: 958.082092
[17:16:03.148] iteration 9500 : loss : 187.228683, loss_ce: 0.020213, loss_kd: 933.733765
[17:16:08.730] iteration 9510 : loss : 171.364212, loss_ce: 0.018392, loss_kd: 854.431335
[17:16:14.293] iteration 9520 : loss : 278.220428, loss_ce: 0.020925, loss_kd: 1388.684204
[17:16:19.872] iteration 9530 : loss : 180.406250, loss_ce: 0.021710, loss_kd: 899.628113
[17:16:25.448] iteration 9540 : loss : 156.176193, loss_ce: 0.024381, loss_kd: 778.480408
[17:16:31.037] iteration 9550 : loss : 199.795456, loss_ce: 0.019259, loss_kd: 996.580750
[17:16:36.612] iteration 9560 : loss : 222.428345, loss_ce: 0.016288, loss_kd: 1109.683594
[17:16:42.201] iteration 9570 : loss : 148.687729, loss_ce: 0.017979, loss_kd: 741.035767
[17:16:47.780] iteration 9580 : loss : 181.584839, loss_ce: 0.028177, loss_kd: 905.479797
[17:16:53.378] iteration 9590 : loss : 179.950638, loss_ce: 0.017848, loss_kd: 897.340576
[17:16:58.968] iteration 9600 : loss : 205.881439, loss_ce: 0.016600, loss_kd: 1026.953125
[17:17:04.573] iteration 9610 : loss : 204.974640, loss_ce: 0.016038, loss_kd: 1022.466797
[17:17:10.167] iteration 9620 : loss : 188.013138, loss_ce: 0.021333, loss_kd: 937.638916
[17:17:15.764] iteration 9630 : loss : 241.348450, loss_ce: 0.009550, loss_kd: 1204.337769
[17:17:21.369] iteration 9640 : loss : 180.038483, loss_ce: 0.015835, loss_kd: 897.773499
[17:17:26.976] iteration 9650 : loss : 167.535049, loss_ce: 0.019238, loss_kd: 835.240967
[17:17:32.575] iteration 9660 : loss : 266.181396, loss_ce: 0.017193, loss_kd: 1328.489014
[17:17:38.175] iteration 9670 : loss : 171.541550, loss_ce: 0.023742, loss_kd: 855.269531
[17:17:43.773] iteration 9680 : loss : 169.560242, loss_ce: 0.009737, loss_kd: 845.419800
[17:17:49.382] iteration 9690 : loss : 169.266708, loss_ce: 0.034076, loss_kd: 843.897156
[17:17:54.972] iteration 9700 : loss : 184.564880, loss_ce: 0.012577, loss_kd: 920.383484
[17:18:00.585] iteration 9710 : loss : 161.442505, loss_ce: 0.015712, loss_kd: 804.816650
[17:18:06.190] iteration 9720 : loss : 200.214310, loss_ce: 0.021242, loss_kd: 998.638550
[17:18:11.796] iteration 9730 : loss : 231.586655, loss_ce: 0.028334, loss_kd: 1155.494507
[17:18:17.393] iteration 9740 : loss : 183.900711, loss_ce: 0.025560, loss_kd: 917.089478
[17:18:23.030] iteration 9750 : loss : 208.795853, loss_ce: 0.013674, loss_kd: 1041.545898
[17:18:28.655] iteration 9760 : loss : 164.508316, loss_ce: 0.022987, loss_kd: 820.122559
[17:18:34.272] iteration 9770 : loss : 168.034821, loss_ce: 0.024001, loss_kd: 837.747131
[17:18:39.886] iteration 9780 : loss : 141.584213, loss_ce: 0.015219, loss_kd: 705.514038
[17:18:45.500] iteration 9790 : loss : 191.014984, loss_ce: 0.013814, loss_kd: 952.618774
[17:18:51.096] iteration 9800 : loss : 212.945740, loss_ce: 0.012149, loss_kd: 1062.320679
[17:18:56.712] iteration 9810 : loss : 167.556961, loss_ce: 0.018490, loss_kd: 835.346741
[17:19:02.315] iteration 9820 : loss : 175.946198, loss_ce: 0.013177, loss_kd: 877.317749
[17:19:07.942] iteration 9830 : loss : 196.091324, loss_ce: 0.028082, loss_kd: 978.056519
[17:19:13.564] iteration 9840 : loss : 171.965134, loss_ce: 0.016417, loss_kd: 857.412598
[17:19:19.188] iteration 9850 : loss : 175.917618, loss_ce: 0.023939, loss_kd: 877.130920
[17:19:24.808] iteration 9860 : loss : 150.654617, loss_ce: 0.021173, loss_kd: 750.849182
[17:19:30.423] iteration 9870 : loss : 174.852859, loss_ce: 0.025687, loss_kd: 871.828674
[17:19:36.030] iteration 9880 : loss : 166.889679, loss_ce: 0.018257, loss_kd: 832.028687
[17:19:41.640] iteration 9890 : loss : 169.700455, loss_ce: 0.022107, loss_kd: 846.119263
[17:19:47.251] iteration 9900 : loss : 200.094818, loss_ce: 0.018478, loss_kd: 998.056702
[17:19:52.897] iteration 9910 : loss : 131.727188, loss_ce: 0.013998, loss_kd: 656.244568
[17:19:58.516] iteration 9920 : loss : 199.852539, loss_ce: 0.021165, loss_kd: 996.826660
[17:20:04.147] iteration 9930 : loss : 180.869125, loss_ce: 0.011878, loss_kd: 901.904907
[17:20:09.750] iteration 9940 : loss : 166.385880, loss_ce: 0.025318, loss_kd: 829.475220
[17:20:15.391] iteration 9950 : loss : 169.994461, loss_ce: 0.013104, loss_kd: 847.533569
[17:20:21.020] iteration 9960 : loss : 176.067535, loss_ce: 0.026602, loss_kd: 877.915527
[17:20:26.640] iteration 9970 : loss : 213.212524, loss_ce: 0.032874, loss_kd: 1063.658936
[17:20:32.250] iteration 9980 : loss : 235.529129, loss_ce: 0.018125, loss_kd: 1175.232788
[17:20:37.878] iteration 9990 : loss : 171.568268, loss_ce: 0.010420, loss_kd: 855.450317
[17:20:43.487] iteration 10000 : loss : 181.430176, loss_ce: 0.026092, loss_kd: 904.728394
[17:20:49.112] iteration 10010 : loss : 157.480560, loss_ce: 0.026158, loss_kd: 784.997314
[17:20:54.736] iteration 10020 : loss : 220.552826, loss_ce: 0.012333, loss_kd: 1100.160278
[17:21:00.365] iteration 10030 : loss : 193.797119, loss_ce: 0.012957, loss_kd: 966.595215
[17:21:05.992] iteration 10040 : loss : 163.164108, loss_ce: 0.014177, loss_kd: 813.422668
[17:21:11.624] iteration 10050 : loss : 166.140091, loss_ce: 0.014098, loss_kd: 828.309143
[17:21:17.248] iteration 10060 : loss : 174.991272, loss_ce: 0.016362, loss_kd: 872.557800
[17:21:22.885] iteration 10070 : loss : 178.035202, loss_ce: 0.029054, loss_kd: 887.699707
[17:21:28.509] iteration 10080 : loss : 197.687164, loss_ce: 0.023026, loss_kd: 985.998230
[17:21:34.148] iteration 10090 : loss : 149.840561, loss_ce: 0.018457, loss_kd: 746.792603
[17:21:39.768] iteration 10100 : loss : 156.857254, loss_ce: 0.020836, loss_kd: 781.877563
[17:21:45.412] iteration 10110 : loss : 172.513580, loss_ce: 0.021249, loss_kd: 860.136292
[17:21:51.039] iteration 10120 : loss : 185.406570, loss_ce: 0.024885, loss_kd: 924.635071
[17:21:56.673] iteration 10130 : loss : 234.337830, loss_ce: 0.025539, loss_kd: 1169.255127
[17:22:02.294] iteration 10140 : loss : 162.799942, loss_ce: 0.018070, loss_kd: 811.609375
[17:22:07.935] iteration 10150 : loss : 207.364426, loss_ce: 0.019956, loss_kd: 1034.404297
[17:22:13.559] iteration 10160 : loss : 157.918701, loss_ce: 0.019515, loss_kd: 787.166260
[17:22:19.207] iteration 10170 : loss : 192.989410, loss_ce: 0.012648, loss_kd: 962.558777
[17:22:24.824] iteration 10180 : loss : 203.758759, loss_ce: 0.014327, loss_kd: 1016.348938
[17:22:30.459] iteration 10190 : loss : 159.948914, loss_ce: 0.016790, loss_kd: 797.286194
[17:22:36.082] iteration 10200 : loss : 147.391815, loss_ce: 0.020388, loss_kd: 734.571899
[17:22:41.723] iteration 10210 : loss : 112.985001, loss_ce: 0.011094, loss_kd: 562.536865
[17:22:47.345] iteration 10220 : loss : 178.527756, loss_ce: 0.021685, loss_kd: 890.190979
[17:22:52.975] iteration 10230 : loss : 181.126617, loss_ce: 0.016852, loss_kd: 903.197266
[17:22:58.608] iteration 10240 : loss : 137.093124, loss_ce: 0.021723, loss_kd: 683.049622
[17:23:04.234] iteration 10250 : loss : 135.597183, loss_ce: 0.018805, loss_kd: 675.550781
[17:23:09.874] iteration 10260 : loss : 172.968353, loss_ce: 0.030875, loss_kd: 862.423645
[17:23:15.506] iteration 10270 : loss : 142.003845, loss_ce: 0.020442, loss_kd: 707.612366
[17:23:21.148] iteration 10280 : loss : 178.581146, loss_ce: 0.015306, loss_kd: 890.497681
[17:23:26.774] iteration 10290 : loss : 197.866623, loss_ce: 0.019932, loss_kd: 986.928589
[17:23:32.410] iteration 10300 : loss : 203.539551, loss_ce: 0.013680, loss_kd: 1015.301086
[17:23:38.042] iteration 10310 : loss : 181.166290, loss_ce: 0.014737, loss_kd: 903.439148
[17:23:43.672] iteration 10320 : loss : 221.284454, loss_ce: 0.013101, loss_kd: 1103.985718
[17:23:49.304] iteration 10330 : loss : 152.856003, loss_ce: 0.028680, loss_kd: 761.862427
[17:23:54.941] iteration 10340 : loss : 191.499649, loss_ce: 0.014198, loss_kd: 955.107971
[17:24:00.574] iteration 10350 : loss : 167.347748, loss_ce: 0.018269, loss_kd: 834.318298
[17:24:06.215] iteration 10360 : loss : 201.819092, loss_ce: 0.015452, loss_kd: 1006.680481
[17:24:11.848] iteration 10370 : loss : 203.755203, loss_ce: 0.018634, loss_kd: 1016.367188
[17:24:17.484] iteration 10380 : loss : 164.276688, loss_ce: 0.020714, loss_kd: 818.978394
[17:24:23.109] iteration 10390 : loss : 140.199768, loss_ce: 0.025633, loss_kd: 698.602478
[17:24:28.739] iteration 10400 : loss : 163.720184, loss_ce: 0.015832, loss_kd: 816.203979
[17:24:34.385] iteration 10410 : loss : 144.649673, loss_ce: 0.013946, loss_kd: 720.874756
[17:24:39.710] iteration 10420 : loss : 140.113464, loss_ce: 0.022199, loss_kd: 698.143860
[17:24:40.453] save model to ./debug_fixed_tpgm\continual_surgical_tpgm_epoch_9.pth
[17:24:56.440] iteration 10430 : loss : 137.008118, loss_ce: 0.024550, loss_kd: 682.634827
[17:25:01.995] iteration 10440 : loss : 187.090210, loss_ce: 0.025924, loss_kd: 933.051392
[17:25:07.570] iteration 10450 : loss : 225.772339, loss_ce: 0.011819, loss_kd: 1126.452881
[17:25:13.130] iteration 10460 : loss : 229.439148, loss_ce: 0.012686, loss_kd: 1144.807617
[17:25:18.711] iteration 10470 : loss : 186.438766, loss_ce: 0.018463, loss_kd: 929.737976
[17:25:24.286] iteration 10480 : loss : 300.219330, loss_ce: 0.024774, loss_kd: 1498.674927
[17:25:29.882] iteration 10490 : loss : 121.916061, loss_ce: 0.022777, loss_kd: 607.185852
[17:25:35.468] iteration 10500 : loss : 153.841385, loss_ce: 0.014657, loss_kd: 766.747070
[17:25:41.069] iteration 10510 : loss : 175.867203, loss_ce: 0.025781, loss_kd: 876.929382
[17:25:46.649] iteration 10520 : loss : 158.123886, loss_ce: 0.015800, loss_kd: 788.206421
[17:25:52.254] iteration 10530 : loss : 158.039749, loss_ce: 0.013489, loss_kd: 787.795959
[17:25:57.856] iteration 10540 : loss : 156.463928, loss_ce: 0.021866, loss_kd: 779.906921
[17:26:03.464] iteration 10550 : loss : 153.200668, loss_ce: 0.027498, loss_kd: 763.593079
[17:26:09.079] iteration 10560 : loss : 136.466766, loss_ce: 0.019646, loss_kd: 679.948242
[17:26:14.693] iteration 10570 : loss : 148.569641, loss_ce: 0.022877, loss_kd: 740.486206
[17:26:20.299] iteration 10580 : loss : 170.057358, loss_ce: 0.010506, loss_kd: 847.879028
[17:26:25.924] iteration 10590 : loss : 205.321335, loss_ce: 0.010952, loss_kd: 1024.235840
[17:26:31.541] iteration 10600 : loss : 178.661575, loss_ce: 0.022818, loss_kd: 890.879028
[17:26:37.167] iteration 10610 : loss : 154.112534, loss_ce: 0.030292, loss_kd: 768.173401
[17:26:42.775] iteration 10620 : loss : 184.463730, loss_ce: 0.020256, loss_kd: 919.886780
[17:26:48.398] iteration 10630 : loss : 116.618797, loss_ce: 0.027583, loss_kd: 580.679077
[17:26:54.017] iteration 10640 : loss : 183.597778, loss_ce: 0.016092, loss_kd: 915.655029
[17:26:59.645] iteration 10650 : loss : 218.502258, loss_ce: 0.017129, loss_kd: 1090.061768
[17:27:05.263] iteration 10660 : loss : 119.426277, loss_ce: 0.015793, loss_kd: 594.678711
[17:27:10.883] iteration 10670 : loss : 139.982239, loss_ce: 0.014033, loss_kd: 697.470093
[17:27:16.498] iteration 10680 : loss : 215.171188, loss_ce: 0.024528, loss_kd: 1073.427002
[17:27:22.117] iteration 10690 : loss : 157.916245, loss_ce: 0.014558, loss_kd: 787.169922
[17:27:27.737] iteration 10700 : loss : 134.010025, loss_ce: 0.026569, loss_kd: 667.635315
[17:27:33.376] iteration 10710 : loss : 186.603317, loss_ce: 0.012442, loss_kd: 930.612061
[17:27:39.010] iteration 10720 : loss : 165.793854, loss_ce: 0.010634, loss_kd: 826.580139
[17:27:44.645] iteration 10730 : loss : 163.585159, loss_ce: 0.015845, loss_kd: 815.480347
[17:27:50.271] iteration 10740 : loss : 170.979004, loss_ce: 0.019551, loss_kd: 852.491394
[17:27:55.904] iteration 10750 : loss : 171.866013, loss_ce: 0.014420, loss_kd: 856.936340
[17:28:01.537] iteration 10760 : loss : 270.689606, loss_ce: 0.016152, loss_kd: 1351.038208
[17:28:07.159] iteration 10770 : loss : 248.815475, loss_ce: 0.019010, loss_kd: 1241.642212
[17:28:12.790] iteration 10780 : loss : 194.709045, loss_ce: 0.015879, loss_kd: 971.091553
[17:28:18.422] iteration 10790 : loss : 166.679321, loss_ce: 0.012133, loss_kd: 830.977112
[17:28:24.046] iteration 10800 : loss : 140.924454, loss_ce: 0.016212, loss_kd: 702.170410
[17:28:29.691] iteration 10810 : loss : 154.530869, loss_ce: 0.010244, loss_kd: 770.209961
[17:28:35.328] iteration 10820 : loss : 163.617767, loss_ce: 0.013022, loss_kd: 815.606079
[17:28:40.961] iteration 10830 : loss : 208.295639, loss_ce: 0.019830, loss_kd: 1039.100952
[17:28:46.585] iteration 10840 : loss : 217.025635, loss_ce: 0.015611, loss_kd: 1082.719238
[17:28:52.221] iteration 10850 : loss : 158.111954, loss_ce: 0.013651, loss_kd: 788.196777
[17:28:57.841] iteration 10860 : loss : 153.954025, loss_ce: 0.014354, loss_kd: 767.367798
[17:29:03.483] iteration 10870 : loss : 155.424011, loss_ce: 0.016764, loss_kd: 774.694153
[17:29:09.111] iteration 10880 : loss : 162.039337, loss_ce: 0.016785, loss_kd: 807.772156
[17:29:14.749] iteration 10890 : loss : 211.809830, loss_ce: 0.016287, loss_kd: 1056.632324
[17:29:20.372] iteration 10900 : loss : 147.129105, loss_ce: 0.017491, loss_kd: 733.252625
[17:29:26.014] iteration 10910 : loss : 227.837204, loss_ce: 0.016023, loss_kd: 1136.740479
[17:29:31.632] iteration 10920 : loss : 183.053131, loss_ce: 0.015495, loss_kd: 912.860779
[17:29:37.276] iteration 10930 : loss : 142.577988, loss_ce: 0.020869, loss_kd: 710.525269
[17:29:42.888] iteration 10940 : loss : 181.597153, loss_ce: 0.016399, loss_kd: 905.545471
[17:29:48.536] iteration 10950 : loss : 158.597321, loss_ce: 0.013851, loss_kd: 790.537964
[17:29:54.163] iteration 10960 : loss : 144.759689, loss_ce: 0.014978, loss_kd: 721.349487
[17:29:59.813] iteration 10970 : loss : 189.008911, loss_ce: 0.013722, loss_kd: 942.624207
[17:30:05.428] iteration 10980 : loss : 227.671280, loss_ce: 0.011910, loss_kd: 1135.936279
[17:30:11.067] iteration 10990 : loss : 233.350067, loss_ce: 0.019727, loss_kd: 1164.363159
[17:30:16.712] iteration 11000 : loss : 195.424118, loss_ce: 0.019409, loss_kd: 974.676880
[17:30:22.363] iteration 11010 : loss : 210.304382, loss_ce: 0.008466, loss_kd: 1049.135864
[17:30:27.975] iteration 11020 : loss : 259.959045, loss_ce: 0.014996, loss_kd: 1297.386108
[17:30:33.627] iteration 11030 : loss : 176.418655, loss_ce: 0.015233, loss_kd: 879.726990
[17:30:39.247] iteration 11040 : loss : 184.436569, loss_ce: 0.010573, loss_kd: 919.792236
[17:30:44.893] iteration 11050 : loss : 133.832443, loss_ce: 0.022494, loss_kd: 666.746887
[17:30:50.527] iteration 11060 : loss : 158.560791, loss_ce: 0.025872, loss_kd: 790.368652
[17:30:56.167] iteration 11070 : loss : 208.275848, loss_ce: 0.022515, loss_kd: 1038.982788
[17:31:01.815] iteration 11080 : loss : 157.238464, loss_ce: 0.018073, loss_kd: 783.792725
[17:31:07.449] iteration 11090 : loss : 192.727310, loss_ce: 0.020177, loss_kd: 961.241211
[17:31:13.085] iteration 11100 : loss : 292.514526, loss_ce: 0.014691, loss_kd: 1460.185303
[17:31:18.728] iteration 11110 : loss : 266.187469, loss_ce: 0.011163, loss_kd: 1328.544556
[17:31:24.368] iteration 11120 : loss : 153.806427, loss_ce: 0.014692, loss_kd: 766.621094
[17:31:30.013] iteration 11130 : loss : 138.875671, loss_ce: 0.019274, loss_kd: 691.954529
[17:31:35.634] iteration 11140 : loss : 146.277283, loss_ce: 0.014489, loss_kd: 729.000671
[17:31:41.283] iteration 11150 : loss : 172.381744, loss_ce: 0.024463, loss_kd: 859.500000
[17:31:46.903] iteration 11160 : loss : 171.007751, loss_ce: 0.018005, loss_kd: 852.624268
[17:31:52.556] iteration 11170 : loss : 184.933044, loss_ce: 0.019649, loss_kd: 922.245850
[17:31:58.175] iteration 11180 : loss : 158.247681, loss_ce: 0.022333, loss_kd: 788.811157
[17:32:03.825] iteration 11190 : loss : 218.402771, loss_ce: 0.019448, loss_kd: 1089.595459
[17:32:09.445] iteration 11200 : loss : 154.860092, loss_ce: 0.020247, loss_kd: 771.895142
[17:32:15.088] iteration 11210 : loss : 140.618118, loss_ce: 0.012724, loss_kd: 700.678589
[17:32:20.716] iteration 11220 : loss : 209.803772, loss_ce: 0.027648, loss_kd: 1046.606689
[17:32:26.354] iteration 11230 : loss : 157.244461, loss_ce: 0.013413, loss_kd: 783.792847
[17:32:31.984] iteration 11240 : loss : 137.733093, loss_ce: 0.016336, loss_kd: 686.219666
[17:32:37.636] iteration 11250 : loss : 204.488007, loss_ce: 0.018650, loss_kd: 1020.039795
[17:32:43.250] iteration 11260 : loss : 231.381088, loss_ce: 0.012503, loss_kd: 1154.549316
[17:32:48.883] iteration 11270 : loss : 163.021149, loss_ce: 0.024591, loss_kd: 812.672729
[17:32:54.499] iteration 11280 : loss : 226.054413, loss_ce: 0.018766, loss_kd: 1127.861206
[17:33:00.145] iteration 11290 : loss : 164.234650, loss_ce: 0.011866, loss_kd: 818.748230
[17:33:05.773] iteration 11300 : loss : 162.826950, loss_ce: 0.023055, loss_kd: 811.721741
[17:33:11.416] iteration 11310 : loss : 200.052750, loss_ce: 0.017481, loss_kd: 997.891724
[17:33:17.042] iteration 11320 : loss : 182.793518, loss_ce: 0.019163, loss_kd: 911.554749
[17:33:22.687] iteration 11330 : loss : 168.452682, loss_ce: 0.009690, loss_kd: 839.884338
[17:33:28.314] iteration 11340 : loss : 130.815155, loss_ce: 0.012444, loss_kd: 651.684387
[17:33:33.955] iteration 11350 : loss : 222.592239, loss_ce: 0.012500, loss_kd: 1110.555542
[17:33:39.578] iteration 11360 : loss : 153.003296, loss_ce: 0.014617, loss_kd: 762.625610
[17:33:45.219] iteration 11370 : loss : 171.154602, loss_ce: 0.009093, loss_kd: 853.336548
[17:33:50.845] iteration 11380 : loss : 176.930405, loss_ce: 0.024533, loss_kd: 882.250488
[17:33:56.489] iteration 11390 : loss : 181.689056, loss_ce: 0.015520, loss_kd: 906.040833
[17:34:02.125] iteration 11400 : loss : 238.967987, loss_ce: 0.026062, loss_kd: 1192.409912
[17:34:07.775] iteration 11410 : loss : 170.574554, loss_ce: 0.013203, loss_kd: 850.524109
[17:34:13.406] iteration 11420 : loss : 260.849762, loss_ce: 0.018894, loss_kd: 1301.849854
[17:34:19.044] iteration 11430 : loss : 212.451248, loss_ce: 0.016283, loss_kd: 1059.836670
[17:34:24.674] iteration 11440 : loss : 191.164368, loss_ce: 0.018819, loss_kd: 953.418823
[17:34:30.309] iteration 11450 : loss : 199.351334, loss_ce: 0.027648, loss_kd: 994.371216
[17:34:35.934] iteration 11460 : loss : 166.067001, loss_ce: 0.014293, loss_kd: 827.979980
[17:34:37.421] Running TPGM constraint optimization after epoch 11
[17:39:25.033] iteration 11470 : loss : 171.229263, loss_ce: 0.015895, loss_kd: 853.776794
[17:39:30.562] iteration 11480 : loss : 151.410370, loss_ce: 0.019157, loss_kd: 754.632690
[17:39:36.110] iteration 11490 : loss : 167.900177, loss_ce: 0.015517, loss_kd: 837.107727
[17:39:41.650] iteration 11500 : loss : 232.851883, loss_ce: 0.018170, loss_kd: 1161.875854
[17:39:47.206] iteration 11510 : loss : 165.322327, loss_ce: 0.019042, loss_kd: 824.185669
[17:39:52.746] iteration 11520 : loss : 161.208405, loss_ce: 0.010345, loss_kd: 803.597290
[17:39:58.307] iteration 11530 : loss : 167.751968, loss_ce: 0.023435, loss_kd: 836.344666
[17:40:03.852] iteration 11540 : loss : 170.307602, loss_ce: 0.017843, loss_kd: 849.133179
[17:40:09.416] iteration 11550 : loss : 170.739151, loss_ce: 0.014394, loss_kd: 851.315796
[17:40:14.980] iteration 11560 : loss : 169.200180, loss_ce: 0.012129, loss_kd: 843.582275
[17:40:20.555] iteration 11570 : loss : 199.699356, loss_ce: 0.013779, loss_kd: 996.101318
[17:40:26.126] iteration 11580 : loss : 190.097229, loss_ce: 0.018143, loss_kd: 948.089905
[17:40:31.712] iteration 11590 : loss : 168.469559, loss_ce: 0.016501, loss_kd: 839.944153
[17:40:37.287] iteration 11600 : loss : 142.534302, loss_ce: 0.010667, loss_kd: 710.293396
[17:40:42.879] iteration 11610 : loss : 150.490250, loss_ce: 0.030617, loss_kd: 750.005798
[17:40:48.455] iteration 11620 : loss : 141.961411, loss_ce: 0.015290, loss_kd: 707.393005
[17:40:54.045] iteration 11630 : loss : 178.433899, loss_ce: 0.014982, loss_kd: 889.729492
[17:40:59.628] iteration 11640 : loss : 138.508484, loss_ce: 0.014101, loss_kd: 690.107239
[17:41:05.228] iteration 11650 : loss : 170.198837, loss_ce: 0.012009, loss_kd: 848.607483
[17:41:10.824] iteration 11660 : loss : 178.981506, loss_ce: 0.018247, loss_kd: 892.500549
[17:41:16.423] iteration 11670 : loss : 157.799911, loss_ce: 0.011015, loss_kd: 786.628113
[17:41:22.026] iteration 11680 : loss : 164.494766, loss_ce: 0.010912, loss_kd: 820.108521
[17:41:27.629] iteration 11690 : loss : 145.203796, loss_ce: 0.017344, loss_kd: 723.594971
[17:41:33.218] iteration 11700 : loss : 121.806496, loss_ce: 0.015540, loss_kd: 606.644348
[17:41:38.824] iteration 11710 : loss : 130.627563, loss_ce: 0.019818, loss_kd: 650.745911
[17:41:44.423] iteration 11720 : loss : 214.724152, loss_ce: 0.030952, loss_kd: 1071.191772
[17:41:50.027] iteration 11730 : loss : 193.266998, loss_ce: 0.012280, loss_kd: 963.947021
[17:41:55.626] iteration 11740 : loss : 140.980194, loss_ce: 0.017234, loss_kd: 702.494263
[17:42:01.228] iteration 11750 : loss : 150.294495, loss_ce: 0.029536, loss_kd: 749.071960
[17:42:06.822] iteration 11760 : loss : 119.772240, loss_ce: 0.010856, loss_kd: 596.425842
[17:42:12.430] iteration 11770 : loss : 138.662460, loss_ce: 0.021111, loss_kd: 690.900696
[17:42:18.040] iteration 11780 : loss : 202.409485, loss_ce: 0.014581, loss_kd: 1009.648193
[17:42:23.643] iteration 11790 : loss : 147.068832, loss_ce: 0.014319, loss_kd: 732.956665
[17:42:29.243] iteration 11800 : loss : 240.909515, loss_ce: 0.020505, loss_kd: 1202.160400
[17:42:34.873] iteration 11810 : loss : 172.865738, loss_ce: 0.028768, loss_kd: 861.902100
[17:42:40.479] iteration 11820 : loss : 138.276382, loss_ce: 0.018658, loss_kd: 688.952881
[17:42:46.084] iteration 11830 : loss : 165.506561, loss_ce: 0.018151, loss_kd: 825.121460
[17:42:51.682] iteration 11840 : loss : 179.128448, loss_ce: 0.010371, loss_kd: 893.262268
[17:42:57.304] iteration 11850 : loss : 147.424469, loss_ce: 0.015625, loss_kd: 734.725891
[17:43:02.917] iteration 11860 : loss : 154.982224, loss_ce: 0.022998, loss_kd: 772.491028
[17:43:08.543] iteration 11870 : loss : 185.056808, loss_ce: 0.017932, loss_kd: 922.879150
[17:43:14.153] iteration 11880 : loss : 168.310379, loss_ce: 0.017559, loss_kd: 839.162109
[17:43:19.786] iteration 11890 : loss : 176.776093, loss_ce: 0.013873, loss_kd: 881.517029
[17:43:25.405] iteration 11900 : loss : 173.981766, loss_ce: 0.017060, loss_kd: 867.450623
[17:43:31.030] iteration 11910 : loss : 140.979980, loss_ce: 0.010787, loss_kd: 702.509216
[17:43:36.656] iteration 11920 : loss : 142.565277, loss_ce: 0.008528, loss_kd: 710.416626
[17:43:42.288] iteration 11930 : loss : 140.144653, loss_ce: 0.013863, loss_kd: 698.274353
[17:43:47.913] iteration 11940 : loss : 179.558182, loss_ce: 0.013819, loss_kd: 895.382690
[17:43:53.540] iteration 11950 : loss : 144.202362, loss_ce: 0.015718, loss_kd: 718.602051
[17:43:59.144] iteration 11960 : loss : 145.616211, loss_ce: 0.019411, loss_kd: 725.668701
[17:44:04.764] iteration 11970 : loss : 201.424255, loss_ce: 0.022605, loss_kd: 1004.731079
[17:44:10.386] iteration 11980 : loss : 128.285706, loss_ce: 0.026311, loss_kd: 638.978577
[17:44:16.012] iteration 11990 : loss : 121.205879, loss_ce: 0.033061, loss_kd: 603.605347
[17:44:21.625] iteration 12000 : loss : 176.177994, loss_ce: 0.016115, loss_kd: 878.493408
[17:44:27.254] iteration 12010 : loss : 208.601578, loss_ce: 0.026647, loss_kd: 1040.580200
[17:44:32.872] iteration 12020 : loss : 159.158890, loss_ce: 0.015986, loss_kd: 793.380615
[17:44:38.509] iteration 12030 : loss : 152.992859, loss_ce: 0.016813, loss_kd: 762.586975
[17:44:44.137] iteration 12040 : loss : 156.728470, loss_ce: 0.017957, loss_kd: 781.189697
[17:44:49.775] iteration 12050 : loss : 191.022018, loss_ce: 0.012388, loss_kd: 952.686462
[17:44:55.399] iteration 12060 : loss : 172.766830, loss_ce: 0.017510, loss_kd: 861.368652
[17:45:01.037] iteration 12070 : loss : 162.846344, loss_ce: 0.025254, loss_kd: 811.821960
[17:45:06.663] iteration 12080 : loss : 179.156540, loss_ce: 0.024066, loss_kd: 893.361633
[17:45:12.301] iteration 12090 : loss : 128.971359, loss_ce: 0.019684, loss_kd: 642.441956
[17:45:17.939] iteration 12100 : loss : 169.116257, loss_ce: 0.019562, loss_kd: 843.175537
[17:45:23.580] iteration 12110 : loss : 160.156631, loss_ce: 0.022201, loss_kd: 798.341125
[17:45:29.212] iteration 12120 : loss : 175.773361, loss_ce: 0.013057, loss_kd: 876.474548
[17:45:34.839] iteration 12130 : loss : 207.234573, loss_ce: 0.013845, loss_kd: 1033.789551
[17:45:40.468] iteration 12140 : loss : 148.831024, loss_ce: 0.022928, loss_kd: 741.758850
[17:45:46.100] iteration 12150 : loss : 150.594055, loss_ce: 0.019964, loss_kd: 750.528198
[17:45:51.734] iteration 12160 : loss : 200.748688, loss_ce: 0.023350, loss_kd: 1001.330688
[17:45:57.367] iteration 12170 : loss : 200.937820, loss_ce: 0.021016, loss_kd: 1002.280640
[17:46:02.993] iteration 12180 : loss : 129.580170, loss_ce: 0.015479, loss_kd: 645.463867
[17:46:08.608] iteration 12190 : loss : 164.910202, loss_ce: 0.027253, loss_kd: 822.128479
[17:46:14.222] iteration 12200 : loss : 130.422989, loss_ce: 0.026392, loss_kd: 649.707825
[17:46:19.871] iteration 12210 : loss : 126.396393, loss_ce: 0.014793, loss_kd: 629.552307
[17:46:25.499] iteration 12220 : loss : 137.817581, loss_ce: 0.008200, loss_kd: 686.676025
[17:46:31.136] iteration 12230 : loss : 212.172226, loss_ce: 0.013888, loss_kd: 1058.430176
[17:46:36.749] iteration 12240 : loss : 153.413437, loss_ce: 0.023818, loss_kd: 764.663391
[17:46:42.367] iteration 12250 : loss : 192.356583, loss_ce: 0.014646, loss_kd: 959.369141
[17:46:47.994] iteration 12260 : loss : 162.767334, loss_ce: 0.013760, loss_kd: 811.419922
[17:46:53.630] iteration 12270 : loss : 183.406464, loss_ce: 0.016441, loss_kd: 914.615173
[17:46:59.267] iteration 12280 : loss : 156.198059, loss_ce: 0.017871, loss_kd: 778.570068
[17:47:04.901] iteration 12290 : loss : 163.056000, loss_ce: 0.020964, loss_kd: 812.846924
[17:47:10.534] iteration 12300 : loss : 182.604233, loss_ce: 0.010949, loss_kd: 910.598633
[17:47:16.164] iteration 12310 : loss : 167.215927, loss_ce: 0.016105, loss_kd: 833.661377
[17:47:21.794] iteration 12320 : loss : 135.737106, loss_ce: 0.023710, loss_kd: 676.278381
[17:47:27.426] iteration 12330 : loss : 155.695038, loss_ce: 0.011532, loss_kd: 776.068604
[17:47:33.061] iteration 12340 : loss : 202.168350, loss_ce: 0.018099, loss_kd: 1008.419800
[17:47:38.696] iteration 12350 : loss : 220.742462, loss_ce: 0.011214, loss_kd: 1101.256470
[17:47:44.329] iteration 12360 : loss : 158.984421, loss_ce: 0.017328, loss_kd: 792.524048
[17:47:49.959] iteration 12370 : loss : 156.409164, loss_ce: 0.020443, loss_kd: 779.630920
[17:47:55.583] iteration 12380 : loss : 199.662979, loss_ce: 0.013249, loss_kd: 995.914185
[17:48:01.221] iteration 12390 : loss : 144.415756, loss_ce: 0.013942, loss_kd: 719.683594
[17:48:06.861] iteration 12400 : loss : 121.249931, loss_ce: 0.021109, loss_kd: 603.828125
[17:48:12.495] iteration 12410 : loss : 143.585190, loss_ce: 0.017095, loss_kd: 715.533142
[17:48:18.120] iteration 12420 : loss : 128.262131, loss_ce: 0.012216, loss_kd: 638.914307
[17:48:23.751] iteration 12430 : loss : 172.618057, loss_ce: 0.022731, loss_kd: 860.686768
[17:48:29.391] iteration 12440 : loss : 205.631531, loss_ce: 0.026994, loss_kd: 1025.767578
[17:48:35.029] iteration 12450 : loss : 187.187531, loss_ce: 0.007312, loss_kd: 933.556274
[17:48:40.639] iteration 12460 : loss : 135.900360, loss_ce: 0.011133, loss_kd: 677.072693
[17:48:46.272] iteration 12470 : loss : 179.250122, loss_ce: 0.012535, loss_kd: 893.803711
[17:48:51.901] iteration 12480 : loss : 169.155273, loss_ce: 0.020115, loss_kd: 843.330872
[17:48:57.536] iteration 12490 : loss : 135.170715, loss_ce: 0.016442, loss_kd: 673.466064
[17:49:03.153] iteration 12500 : loss : 147.046249, loss_ce: 0.013705, loss_kd: 732.846497
[17:49:19.558] iteration 12510 : loss : 192.796722, loss_ce: 0.017860, loss_kd: 961.616150
[17:49:25.111] iteration 12520 : loss : 158.493622, loss_ce: 0.020123, loss_kd: 790.064453
[17:49:30.685] iteration 12530 : loss : 178.812653, loss_ce: 0.019864, loss_kd: 891.643860
[17:49:36.245] iteration 12540 : loss : 189.994705, loss_ce: 0.010911, loss_kd: 947.566162
[17:49:41.821] iteration 12550 : loss : 177.498627, loss_ce: 0.018142, loss_kd: 885.108704
[17:49:47.397] iteration 12560 : loss : 161.400635, loss_ce: 0.018300, loss_kd: 804.611328
[17:49:52.991] iteration 12570 : loss : 137.648529, loss_ce: 0.013756, loss_kd: 685.825256
[17:49:58.571] iteration 12580 : loss : 220.539368, loss_ce: 0.018542, loss_kd: 1100.273193
[17:50:04.163] iteration 12590 : loss : 153.536896, loss_ce: 0.014096, loss_kd: 765.330078
[17:50:09.747] iteration 12600 : loss : 113.790001, loss_ce: 0.026428, loss_kd: 566.549744
[17:50:15.342] iteration 12610 : loss : 159.303207, loss_ce: 0.021833, loss_kd: 794.124878
[17:50:20.939] iteration 12620 : loss : 139.982040, loss_ce: 0.016636, loss_kd: 697.468811
[17:50:26.546] iteration 12630 : loss : 136.579712, loss_ce: 0.026016, loss_kd: 680.511108
[17:50:32.135] iteration 12640 : loss : 128.031326, loss_ce: 0.016910, loss_kd: 637.770020
[17:50:37.739] iteration 12650 : loss : 185.662964, loss_ce: 0.007740, loss_kd: 925.923584
[17:50:43.337] iteration 12660 : loss : 134.824768, loss_ce: 0.013064, loss_kd: 671.728271
[17:50:48.950] iteration 12670 : loss : 180.435837, loss_ce: 0.012152, loss_kd: 899.816650
[17:50:54.551] iteration 12680 : loss : 176.471100, loss_ce: 0.017738, loss_kd: 879.911560
[17:51:00.162] iteration 12690 : loss : 132.556320, loss_ce: 0.018186, loss_kd: 660.354126
[17:51:05.763] iteration 12700 : loss : 191.165924, loss_ce: 0.018296, loss_kd: 953.420593
[17:51:11.400] iteration 12710 : loss : 148.989410, loss_ce: 0.015479, loss_kd: 742.542480
[17:51:17.010] iteration 12720 : loss : 191.105774, loss_ce: 0.022369, loss_kd: 953.159424
[17:51:22.623] iteration 12730 : loss : 135.490402, loss_ce: 0.017263, loss_kd: 675.097778
[17:51:28.232] iteration 12740 : loss : 164.358810, loss_ce: 0.014126, loss_kd: 819.407410
[17:51:33.859] iteration 12750 : loss : 190.354965, loss_ce: 0.014430, loss_kd: 949.408264
[17:51:39.464] iteration 12760 : loss : 213.542542, loss_ce: 0.014932, loss_kd: 1065.317993
[17:51:45.085] iteration 12770 : loss : 170.525070, loss_ce: 0.013245, loss_kd: 850.250488
[17:51:50.698] iteration 12780 : loss : 129.617523, loss_ce: 0.018016, loss_kd: 645.667358
[17:51:56.327] iteration 12790 : loss : 118.254906, loss_ce: 0.020295, loss_kd: 588.872803
[17:52:01.941] iteration 12800 : loss : 197.922760, loss_ce: 0.016256, loss_kd: 987.218872
[17:52:07.576] iteration 12810 : loss : 222.831223, loss_ce: 0.015766, loss_kd: 1111.743042
[17:52:13.194] iteration 12820 : loss : 147.913651, loss_ce: 0.014733, loss_kd: 737.142639
[17:52:18.823] iteration 12830 : loss : 204.591492, loss_ce: 0.018945, loss_kd: 1020.561340
[17:52:24.445] iteration 12840 : loss : 166.244492, loss_ce: 0.018161, loss_kd: 828.796326
[17:52:30.080] iteration 12850 : loss : 206.914001, loss_ce: 0.020416, loss_kd: 1032.142944
[17:52:35.714] iteration 12860 : loss : 135.326904, loss_ce: 0.016909, loss_kd: 674.253052
[17:52:41.350] iteration 12870 : loss : 193.150635, loss_ce: 0.015173, loss_kd: 963.336914
[17:52:46.965] iteration 12880 : loss : 134.656509, loss_ce: 0.017066, loss_kd: 670.880676
[17:52:52.598] iteration 12890 : loss : 179.790466, loss_ce: 0.012903, loss_kd: 896.536072
[17:52:58.213] iteration 12900 : loss : 130.534515, loss_ce: 0.016381, loss_kd: 650.257690
[17:53:03.858] iteration 12910 : loss : 131.077881, loss_ce: 0.033079, loss_kd: 652.951111
[17:53:09.475] iteration 12920 : loss : 160.512894, loss_ce: 0.014858, loss_kd: 800.159546
[17:53:15.121] iteration 12930 : loss : 140.999878, loss_ce: 0.021486, loss_kd: 702.616089
[17:53:20.742] iteration 12940 : loss : 186.900436, loss_ce: 0.014421, loss_kd: 932.075439
[17:53:26.376] iteration 12950 : loss : 169.285400, loss_ce: 0.021570, loss_kd: 844.016541
[17:53:32.000] iteration 12960 : loss : 159.060196, loss_ce: 0.012724, loss_kd: 792.907837
[17:53:37.639] iteration 12970 : loss : 150.938705, loss_ce: 0.022097, loss_kd: 752.235657
[17:53:43.269] iteration 12980 : loss : 154.946793, loss_ce: 0.014885, loss_kd: 772.374084
[17:53:48.917] iteration 12990 : loss : 125.968872, loss_ce: 0.018806, loss_kd: 627.444214
[17:53:54.528] iteration 13000 : loss : 161.118042, loss_ce: 0.015493, loss_kd: 803.181396
[17:54:00.146] iteration 13010 : loss : 188.884460, loss_ce: 0.015772, loss_kd: 942.039185
[17:54:05.765] iteration 13020 : loss : 176.534515, loss_ce: 0.018379, loss_kd: 880.266113
[17:54:11.409] iteration 13030 : loss : 161.557053, loss_ce: 0.017595, loss_kd: 805.350403
[17:54:17.036] iteration 13040 : loss : 171.110367, loss_ce: 0.020630, loss_kd: 853.173401
[17:54:22.671] iteration 13050 : loss : 151.038361, loss_ce: 0.018380, loss_kd: 752.804504
[17:54:28.295] iteration 13060 : loss : 142.557938, loss_ce: 0.018174, loss_kd: 710.324097
[17:54:33.938] iteration 13070 : loss : 143.370071, loss_ce: 0.016592, loss_kd: 714.431458
[17:54:39.563] iteration 13080 : loss : 144.884232, loss_ce: 0.018099, loss_kd: 722.024353
[17:54:45.199] iteration 13090 : loss : 123.426903, loss_ce: 0.015805, loss_kd: 614.729858
[17:54:50.824] iteration 13100 : loss : 222.727875, loss_ce: 0.016626, loss_kd: 1111.208618
[17:54:56.463] iteration 13110 : loss : 149.475082, loss_ce: 0.011666, loss_kd: 744.982483
[17:55:02.088] iteration 13120 : loss : 139.328140, loss_ce: 0.013918, loss_kd: 694.239746
[17:55:07.733] iteration 13130 : loss : 142.712997, loss_ce: 0.015432, loss_kd: 711.170410
[17:55:13.348] iteration 13140 : loss : 176.139481, loss_ce: 0.009688, loss_kd: 878.310730
[17:55:18.983] iteration 13150 : loss : 169.250610, loss_ce: 0.019141, loss_kd: 843.831970
[17:55:24.606] iteration 13160 : loss : 160.090454, loss_ce: 0.015501, loss_kd: 798.022522
[17:55:30.249] iteration 13170 : loss : 140.182022, loss_ce: 0.024169, loss_kd: 698.502686
[17:55:35.867] iteration 13180 : loss : 201.769714, loss_ce: 0.017891, loss_kd: 1006.444092
[17:55:41.522] iteration 13190 : loss : 151.014252, loss_ce: 0.020799, loss_kd: 752.577637
[17:55:47.149] iteration 13200 : loss : 144.128922, loss_ce: 0.013330, loss_kd: 718.233154
[17:55:52.797] iteration 13210 : loss : 154.157684, loss_ce: 0.020328, loss_kd: 768.392578
[17:55:58.415] iteration 13220 : loss : 144.364166, loss_ce: 0.012365, loss_kd: 719.421448
[17:56:04.065] iteration 13230 : loss : 130.578323, loss_ce: 0.023022, loss_kd: 650.458801
[17:56:09.682] iteration 13240 : loss : 173.557465, loss_ce: 0.015812, loss_kd: 865.398010
[17:56:15.327] iteration 13250 : loss : 135.450577, loss_ce: 0.018784, loss_kd: 674.853149
[17:56:20.947] iteration 13260 : loss : 153.862762, loss_ce: 0.019615, loss_kd: 766.875488
[17:56:26.601] iteration 13270 : loss : 230.499344, loss_ce: 0.016031, loss_kd: 1150.102295
[17:56:32.226] iteration 13280 : loss : 166.734390, loss_ce: 0.011521, loss_kd: 831.253906
[17:56:37.864] iteration 13290 : loss : 164.516922, loss_ce: 0.012563, loss_kd: 820.195374
[17:56:43.504] iteration 13300 : loss : 154.355392, loss_ce: 0.014074, loss_kd: 769.357239
[17:56:49.138] iteration 13310 : loss : 156.808578, loss_ce: 0.017053, loss_kd: 781.637268
[17:56:54.760] iteration 13320 : loss : 117.644966, loss_ce: 0.020657, loss_kd: 585.828491
[17:57:00.392] iteration 13330 : loss : 138.758453, loss_ce: 0.019368, loss_kd: 691.416809
[17:57:06.014] iteration 13340 : loss : 158.183777, loss_ce: 0.019182, loss_kd: 788.480164
[17:57:11.672] iteration 13350 : loss : 189.329041, loss_ce: 0.016730, loss_kd: 944.241272
[17:57:17.316] iteration 13360 : loss : 185.406403, loss_ce: 0.015722, loss_kd: 924.619507
[17:57:22.949] iteration 13370 : loss : 149.603821, loss_ce: 0.012167, loss_kd: 745.608887
[17:57:28.581] iteration 13380 : loss : 135.086670, loss_ce: 0.023822, loss_kd: 672.991272
[17:57:34.220] iteration 13390 : loss : 152.780441, loss_ce: 0.009946, loss_kd: 761.528870
[17:57:39.850] iteration 13400 : loss : 196.073196, loss_ce: 0.010876, loss_kd: 977.977112
[17:57:45.499] iteration 13410 : loss : 139.149994, loss_ce: 0.012919, loss_kd: 693.354858
[17:57:51.138] iteration 13420 : loss : 221.743103, loss_ce: 0.024346, loss_kd: 1106.291504
[17:57:56.781] iteration 13430 : loss : 147.597122, loss_ce: 0.013407, loss_kd: 735.594421
[17:58:02.399] iteration 13440 : loss : 217.621780, loss_ce: 0.015674, loss_kd: 1085.678345
[17:58:08.052] iteration 13450 : loss : 144.819183, loss_ce: 0.021382, loss_kd: 721.711182
[17:58:13.686] iteration 13460 : loss : 175.197174, loss_ce: 0.012962, loss_kd: 873.580811
[17:58:19.326] iteration 13470 : loss : 198.029083, loss_ce: 0.012624, loss_kd: 987.768677
[17:58:24.949] iteration 13480 : loss : 172.964615, loss_ce: 0.015912, loss_kd: 862.433105
[17:58:30.606] iteration 13490 : loss : 132.163239, loss_ce: 0.015001, loss_kd: 658.417847
[17:58:36.219] iteration 13500 : loss : 124.094986, loss_ce: 0.013820, loss_kd: 618.034546
[17:58:41.860] iteration 13510 : loss : 98.679848, loss_ce: 0.013808, loss_kd: 490.981110
[17:58:47.484] iteration 13520 : loss : 161.165131, loss_ce: 0.012944, loss_kd: 803.384583
[17:58:53.128] iteration 13530 : loss : 141.381912, loss_ce: 0.029586, loss_kd: 704.475830
[17:58:58.752] iteration 13540 : loss : 137.798141, loss_ce: 0.017405, loss_kd: 686.576843
[17:59:02.484] Running TPGM constraint optimization after epoch 13
[18:03:57.973] iteration 13550 : loss : 127.422920, loss_ce: 0.014204, loss_kd: 634.668335
[18:04:03.499] iteration 13560 : loss : 120.857338, loss_ce: 0.009395, loss_kd: 601.885986
[18:04:09.041] iteration 13570 : loss : 199.801102, loss_ce: 0.015957, loss_kd: 996.615112
[18:04:14.571] iteration 13580 : loss : 178.904800, loss_ce: 0.023243, loss_kd: 892.135864
[18:04:20.116] iteration 13590 : loss : 172.894318, loss_ce: 0.015372, loss_kd: 862.080750
[18:04:25.660] iteration 13600 : loss : 137.494843, loss_ce: 0.015138, loss_kd: 685.093262
[18:04:31.219] iteration 13610 : loss : 144.697800, loss_ce: 0.015368, loss_kd: 721.039490
[18:04:36.762] iteration 13620 : loss : 126.300461, loss_ce: 0.010166, loss_kd: 629.080566
[18:04:42.326] iteration 13630 : loss : 165.874603, loss_ce: 0.025492, loss_kd: 826.923767
[18:04:47.884] iteration 13640 : loss : 179.384155, loss_ce: 0.012681, loss_kd: 894.517273
[18:04:53.449] iteration 13650 : loss : 221.146301, loss_ce: 0.020002, loss_kd: 1103.335205
[18:04:59.012] iteration 13660 : loss : 172.868942, loss_ce: 0.017709, loss_kd: 861.958618
[18:05:04.592] iteration 13670 : loss : 166.072830, loss_ce: 0.011107, loss_kd: 827.963867
[18:05:10.159] iteration 13680 : loss : 125.824387, loss_ce: 0.019429, loss_kd: 626.699219
[18:05:15.745] iteration 13690 : loss : 106.104202, loss_ce: 0.010184, loss_kd: 528.107727
[18:05:21.322] iteration 13700 : loss : 143.062668, loss_ce: 0.016862, loss_kd: 712.888977
[18:05:26.915] iteration 13710 : loss : 139.214600, loss_ce: 0.017461, loss_kd: 693.698486
[18:05:32.484] iteration 13720 : loss : 150.225037, loss_ce: 0.021809, loss_kd: 748.695923
[18:05:38.074] iteration 13730 : loss : 168.798050, loss_ce: 0.025259, loss_kd: 841.605591
[18:05:43.661] iteration 13740 : loss : 147.155670, loss_ce: 0.018201, loss_kd: 733.364014
[18:05:49.262] iteration 13750 : loss : 145.068390, loss_ce: 0.016214, loss_kd: 722.926270
[18:05:54.858] iteration 13760 : loss : 156.220383, loss_ce: 0.018095, loss_kd: 778.708313
[18:06:00.458] iteration 13770 : loss : 158.471375, loss_ce: 0.020057, loss_kd: 789.967285
[18:06:06.055] iteration 13780 : loss : 127.157623, loss_ce: 0.014926, loss_kd: 633.377075
[18:06:11.660] iteration 13790 : loss : 164.647507, loss_ce: 0.017493, loss_kd: 820.828796
[18:06:17.264] iteration 13800 : loss : 132.486496, loss_ce: 0.019941, loss_kd: 659.988831
[18:06:22.867] iteration 13810 : loss : 174.168610, loss_ce: 0.012670, loss_kd: 868.453003
[18:06:28.466] iteration 13820 : loss : 153.964432, loss_ce: 0.017321, loss_kd: 767.374329
[18:06:34.064] iteration 13830 : loss : 165.454636, loss_ce: 0.013761, loss_kd: 824.882263
[18:06:39.670] iteration 13840 : loss : 183.183746, loss_ce: 0.008014, loss_kd: 913.525269
[18:06:45.275] iteration 13850 : loss : 162.082840, loss_ce: 0.025085, loss_kd: 807.960815
[18:06:50.872] iteration 13860 : loss : 149.000946, loss_ce: 0.018806, loss_kd: 742.556274
[18:06:56.494] iteration 13870 : loss : 176.935669, loss_ce: 0.022529, loss_kd: 882.268921
[18:07:02.090] iteration 13880 : loss : 158.665161, loss_ce: 0.011779, loss_kd: 790.900940
[18:07:07.720] iteration 13890 : loss : 174.565842, loss_ce: 0.019825, loss_kd: 870.419434
[18:07:13.327] iteration 13900 : loss : 110.500961, loss_ce: 0.013447, loss_kd: 550.120117
[18:07:18.948] iteration 13910 : loss : 157.430557, loss_ce: 0.015167, loss_kd: 784.752075
[18:07:24.551] iteration 13920 : loss : 170.958145, loss_ce: 0.006642, loss_kd: 852.352966
[18:07:30.183] iteration 13930 : loss : 153.074310, loss_ce: 0.025615, loss_kd: 762.960693
[18:07:35.794] iteration 13940 : loss : 211.601913, loss_ce: 0.014732, loss_kd: 1055.636230
[18:07:41.415] iteration 13950 : loss : 221.022568, loss_ce: 0.011793, loss_kd: 1102.711914
[18:07:47.029] iteration 13960 : loss : 151.003616, loss_ce: 0.018803, loss_kd: 752.607849
[18:07:52.657] iteration 13970 : loss : 128.312637, loss_ce: 0.016636, loss_kd: 639.156738
[18:07:58.278] iteration 13980 : loss : 184.484268, loss_ce: 0.017279, loss_kd: 920.009766
[18:08:03.917] iteration 13990 : loss : 144.033249, loss_ce: 0.014178, loss_kd: 717.756836
[18:08:09.528] iteration 14000 : loss : 142.671509, loss_ce: 0.026656, loss_kd: 710.961182
[18:08:15.148] iteration 14010 : loss : 145.358704, loss_ce: 0.013919, loss_kd: 724.425415
[18:08:20.766] iteration 14020 : loss : 147.225754, loss_ce: 0.012981, loss_kd: 733.732971
[18:08:26.389] iteration 14030 : loss : 173.249680, loss_ce: 0.013073, loss_kd: 863.826660
[18:08:32.011] iteration 14040 : loss : 158.770569, loss_ce: 0.010643, loss_kd: 791.468506
[18:08:37.653] iteration 14050 : loss : 165.572876, loss_ce: 0.017577, loss_kd: 825.454407
[18:08:43.258] iteration 14060 : loss : 117.464844, loss_ce: 0.011573, loss_kd: 584.951782
[18:08:48.878] iteration 14070 : loss : 118.590988, loss_ce: 0.019362, loss_kd: 590.495911
[18:08:54.511] iteration 14080 : loss : 158.334366, loss_ce: 0.018067, loss_kd: 789.236389
[18:09:00.130] iteration 14090 : loss : 158.465820, loss_ce: 0.010968, loss_kd: 789.895691
[18:09:05.744] iteration 14100 : loss : 134.573120, loss_ce: 0.021005, loss_kd: 670.470093
[18:09:11.392] iteration 14110 : loss : 127.820206, loss_ce: 0.016626, loss_kd: 636.684937
[18:09:16.986] iteration 14120 : loss : 256.082123, loss_ce: 0.010829, loss_kd: 1278.013428
[18:09:22.604] iteration 14130 : loss : 194.510147, loss_ce: 0.015234, loss_kd: 970.183594
[18:09:28.235] iteration 14140 : loss : 147.201584, loss_ce: 0.012333, loss_kd: 733.627075
[18:09:33.864] iteration 14150 : loss : 148.801697, loss_ce: 0.014636, loss_kd: 741.660767
[18:09:39.488] iteration 14160 : loss : 117.333832, loss_ce: 0.019463, loss_kd: 584.277649
[18:09:45.126] iteration 14170 : loss : 137.862106, loss_ce: 0.016615, loss_kd: 686.923889
[18:09:50.741] iteration 14180 : loss : 129.116180, loss_ce: 0.017231, loss_kd: 643.191467
[18:09:56.378] iteration 14190 : loss : 132.980072, loss_ce: 0.020977, loss_kd: 662.489624
[18:10:02.002] iteration 14200 : loss : 136.802521, loss_ce: 0.015486, loss_kd: 681.632568
[18:10:07.648] iteration 14210 : loss : 129.495651, loss_ce: 0.014307, loss_kd: 645.089722
[18:10:13.257] iteration 14220 : loss : 147.881439, loss_ce: 0.013342, loss_kd: 736.978821
[18:10:18.899] iteration 14230 : loss : 119.537704, loss_ce: 0.013446, loss_kd: 595.279053
[18:10:24.523] iteration 14240 : loss : 136.420456, loss_ce: 0.014696, loss_kd: 679.719788
[18:10:30.167] iteration 14250 : loss : 112.850891, loss_ce: 0.016238, loss_kd: 561.821716
[18:10:35.787] iteration 14260 : loss : 127.715599, loss_ce: 0.019957, loss_kd: 636.166077
[18:10:41.431] iteration 14270 : loss : 149.135300, loss_ce: 0.016305, loss_kd: 743.270142
[18:10:47.055] iteration 14280 : loss : 188.255524, loss_ce: 0.021162, loss_kd: 938.879761
[18:10:52.686] iteration 14290 : loss : 161.275375, loss_ce: 0.013688, loss_kd: 803.980347
[18:10:58.313] iteration 14300 : loss : 164.292770, loss_ce: 0.019003, loss_kd: 819.089111
[18:11:03.951] iteration 14310 : loss : 217.408951, loss_ce: 0.010944, loss_kd: 1084.653687
[18:11:09.583] iteration 14320 : loss : 186.253876, loss_ce: 0.016719, loss_kd: 928.884644
[18:11:15.219] iteration 14330 : loss : 142.671539, loss_ce: 0.009840, loss_kd: 710.977356
[18:11:20.843] iteration 14340 : loss : 161.774918, loss_ce: 0.008432, loss_kd: 806.517212
[18:11:26.483] iteration 14350 : loss : 147.759369, loss_ce: 0.013407, loss_kd: 736.425232
[18:11:32.117] iteration 14360 : loss : 129.601288, loss_ce: 0.012064, loss_kd: 645.563232
[18:11:37.748] iteration 14370 : loss : 160.698105, loss_ce: 0.015945, loss_kd: 801.096436
[18:11:43.378] iteration 14380 : loss : 168.424377, loss_ce: 0.010942, loss_kd: 839.730652
[18:11:49.002] iteration 14390 : loss : 125.697250, loss_ce: 0.021703, loss_kd: 626.071838
[18:11:54.656] iteration 14400 : loss : 123.426460, loss_ce: 0.011119, loss_kd: 614.756592
[18:12:00.308] iteration 14410 : loss : 134.130173, loss_ce: 0.015496, loss_kd: 668.254883
[18:12:05.941] iteration 14420 : loss : 129.322357, loss_ce: 0.016131, loss_kd: 644.199463
[18:12:11.582] iteration 14430 : loss : 138.501678, loss_ce: 0.024020, loss_kd: 690.095093
[18:12:17.197] iteration 14440 : loss : 146.070969, loss_ce: 0.014825, loss_kd: 727.936157
[18:12:22.841] iteration 14450 : loss : 129.400497, loss_ce: 0.011377, loss_kd: 644.602966
[18:12:28.456] iteration 14460 : loss : 135.358353, loss_ce: 0.015361, loss_kd: 674.393738
[18:12:34.094] iteration 14470 : loss : 138.179062, loss_ce: 0.016072, loss_kd: 688.498413
[18:12:39.726] iteration 14480 : loss : 166.627274, loss_ce: 0.022501, loss_kd: 830.690613
[18:12:45.373] iteration 14490 : loss : 122.221207, loss_ce: 0.018510, loss_kd: 608.680176
[18:12:50.986] iteration 14500 : loss : 172.702301, loss_ce: 0.019019, loss_kd: 861.125610
[18:12:56.637] iteration 14510 : loss : 171.422577, loss_ce: 0.015117, loss_kd: 854.722717
[18:13:02.263] iteration 14520 : loss : 146.738434, loss_ce: 0.015845, loss_kd: 731.315247
[18:13:07.908] iteration 14530 : loss : 182.140488, loss_ce: 0.014428, loss_kd: 908.276062
[18:13:13.519] iteration 14540 : loss : 143.227097, loss_ce: 0.018203, loss_kd: 713.731628
[18:13:19.165] iteration 14550 : loss : 148.304031, loss_ce: 0.014965, loss_kd: 739.076416
[18:13:24.784] iteration 14560 : loss : 166.179031, loss_ce: 0.017012, loss_kd: 828.499146
[18:13:30.432] iteration 14570 : loss : 140.339661, loss_ce: 0.013255, loss_kd: 699.315613
[18:13:36.057] iteration 14580 : loss : 160.832718, loss_ce: 0.022359, loss_kd: 801.725281
[18:13:52.481] iteration 14590 : loss : 132.397598, loss_ce: 0.021817, loss_kd: 659.592834
[18:13:58.027] iteration 14600 : loss : 143.064606, loss_ce: 0.016138, loss_kd: 712.929199
[18:14:03.598] iteration 14610 : loss : 165.583267, loss_ce: 0.014608, loss_kd: 825.492310
[18:14:09.162] iteration 14620 : loss : 148.743835, loss_ce: 0.025119, loss_kd: 741.288025
[18:14:14.731] iteration 14630 : loss : 138.109436, loss_ce: 0.014787, loss_kd: 688.180847
[18:14:20.304] iteration 14640 : loss : 188.955811, loss_ce: 0.023451, loss_kd: 942.360962
[18:14:25.883] iteration 14650 : loss : 163.354187, loss_ce: 0.013419, loss_kd: 814.368896
[18:14:31.463] iteration 14660 : loss : 129.480804, loss_ce: 0.018090, loss_kd: 645.028870
[18:14:37.049] iteration 14670 : loss : 95.694092, loss_ce: 0.015572, loss_kd: 476.073181
[18:14:42.634] iteration 14680 : loss : 144.559906, loss_ce: 0.015851, loss_kd: 720.353882
[18:14:48.238] iteration 14690 : loss : 141.620987, loss_ce: 0.019417, loss_kd: 705.696045
[18:14:53.835] iteration 14700 : loss : 122.390335, loss_ce: 0.034328, loss_kd: 609.521240
[18:14:59.438] iteration 14710 : loss : 122.667641, loss_ce: 0.014869, loss_kd: 610.957153
[18:15:05.041] iteration 14720 : loss : 210.732773, loss_ce: 0.014001, loss_kd: 1051.282593
[18:15:10.649] iteration 14730 : loss : 169.640289, loss_ce: 0.021227, loss_kd: 845.781006
[18:15:16.250] iteration 14740 : loss : 128.749237, loss_ce: 0.020885, loss_kd: 641.368286
[18:15:21.860] iteration 14750 : loss : 137.719269, loss_ce: 0.024907, loss_kd: 686.201660
[18:15:27.465] iteration 14760 : loss : 144.951355, loss_ce: 0.015309, loss_kd: 722.381714
[18:15:33.073] iteration 14770 : loss : 154.891663, loss_ce: 0.017821, loss_kd: 772.042236
[18:15:38.689] iteration 14780 : loss : 138.755783, loss_ce: 0.017964, loss_kd: 691.406494
[18:15:44.316] iteration 14790 : loss : 138.207230, loss_ce: 0.022544, loss_kd: 688.644165
[18:15:49.920] iteration 14800 : loss : 166.249664, loss_ce: 0.017385, loss_kd: 828.854492
[18:15:55.547] iteration 14810 : loss : 179.261002, loss_ce: 0.013816, loss_kd: 893.889648
[18:16:01.166] iteration 14820 : loss : 179.227844, loss_ce: 0.016507, loss_kd: 893.723877
[18:16:06.780] iteration 14830 : loss : 151.438385, loss_ce: 0.021284, loss_kd: 754.762878
[18:16:12.387] iteration 14840 : loss : 147.523636, loss_ce: 0.008488, loss_kd: 735.221313
[18:16:18.012] iteration 14850 : loss : 153.707199, loss_ce: 0.014320, loss_kd: 766.103455
[18:16:23.637] iteration 14860 : loss : 105.711685, loss_ce: 0.016226, loss_kd: 526.143616
[18:16:29.256] iteration 14870 : loss : 174.056595, loss_ce: 0.015486, loss_kd: 867.887695
[18:16:34.866] iteration 14880 : loss : 129.145844, loss_ce: 0.025139, loss_kd: 643.314392
[18:16:40.494] iteration 14890 : loss : 125.789246, loss_ce: 0.009206, loss_kd: 626.565796
[18:16:46.105] iteration 14900 : loss : 142.067688, loss_ce: 0.030809, loss_kd: 707.909119
[18:16:51.731] iteration 14910 : loss : 204.095764, loss_ce: 0.010169, loss_kd: 1018.056152
[18:16:57.337] iteration 14920 : loss : 138.873657, loss_ce: 0.016206, loss_kd: 691.984314
[18:17:02.974] iteration 14930 : loss : 166.805237, loss_ce: 0.018830, loss_kd: 831.619385
[18:17:08.586] iteration 14940 : loss : 150.879913, loss_ce: 0.021728, loss_kd: 751.990845
[18:17:14.230] iteration 14950 : loss : 134.346130, loss_ce: 0.023005, loss_kd: 669.325012
[18:17:19.846] iteration 14960 : loss : 152.335922, loss_ce: 0.013468, loss_kd: 759.263062
[18:17:25.476] iteration 14970 : loss : 192.018600, loss_ce: 0.023018, loss_kd: 957.675476
[18:17:31.113] iteration 14980 : loss : 139.666702, loss_ce: 0.021413, loss_kd: 695.917542
[18:17:36.752] iteration 14990 : loss : 143.720261, loss_ce: 0.014615, loss_kd: 716.209106
[18:17:42.374] iteration 15000 : loss : 146.661652, loss_ce: 0.012450, loss_kd: 730.869019
[18:17:48.007] iteration 15010 : loss : 229.863052, loss_ce: 0.012570, loss_kd: 1146.939819
[18:17:53.640] iteration 15020 : loss : 177.277847, loss_ce: 0.019884, loss_kd: 883.977539
[18:17:59.267] iteration 15030 : loss : 149.985016, loss_ce: 0.012434, loss_kd: 747.534302
[18:18:04.905] iteration 15040 : loss : 134.544830, loss_ce: 0.030901, loss_kd: 670.310608
[18:18:10.523] iteration 15050 : loss : 117.224289, loss_ce: 0.014625, loss_kd: 583.730530
[18:18:16.141] iteration 15060 : loss : 134.362595, loss_ce: 0.022700, loss_kd: 669.384155
[18:18:21.775] iteration 15070 : loss : 123.498024, loss_ce: 0.020567, loss_kd: 615.086914
[18:18:27.390] iteration 15080 : loss : 138.762146, loss_ce: 0.025979, loss_kd: 691.386475
[18:18:33.031] iteration 15090 : loss : 131.503326, loss_ce: 0.016991, loss_kd: 655.117065
[18:18:38.641] iteration 15100 : loss : 164.552002, loss_ce: 0.020976, loss_kd: 820.395935
[18:18:44.298] iteration 15110 : loss : 172.910477, loss_ce: 0.015486, loss_kd: 862.176147
[18:18:49.913] iteration 15120 : loss : 138.826065, loss_ce: 0.011019, loss_kd: 691.756287
[18:18:55.568] iteration 15130 : loss : 140.072006, loss_ce: 0.017237, loss_kd: 697.955933
[18:19:01.186] iteration 15140 : loss : 131.145813, loss_ce: 0.010723, loss_kd: 653.302368
[18:19:06.826] iteration 15150 : loss : 181.319931, loss_ce: 0.018753, loss_kd: 904.181335
[18:19:12.440] iteration 15160 : loss : 128.198044, loss_ce: 0.013690, loss_kd: 638.590393
[18:19:18.087] iteration 15170 : loss : 146.025482, loss_ce: 0.026497, loss_kd: 727.718933
[18:19:23.699] iteration 15180 : loss : 157.159729, loss_ce: 0.026010, loss_kd: 783.407837
[18:19:29.333] iteration 15190 : loss : 166.103363, loss_ce: 0.017138, loss_kd: 828.092712
[18:19:34.971] iteration 15200 : loss : 243.922897, loss_ce: 0.012839, loss_kd: 1217.209351
[18:19:40.628] iteration 15210 : loss : 129.370270, loss_ce: 0.022129, loss_kd: 644.467773
[18:19:46.253] iteration 15220 : loss : 142.294479, loss_ce: 0.025235, loss_kd: 709.088257
[18:19:51.894] iteration 15230 : loss : 113.242203, loss_ce: 0.012384, loss_kd: 563.749268
[18:19:57.515] iteration 15240 : loss : 124.513680, loss_ce: 0.011708, loss_kd: 620.195129
[18:20:03.155] iteration 15250 : loss : 169.004166, loss_ce: 0.014038, loss_kd: 842.643860
[18:20:08.778] iteration 15260 : loss : 151.509598, loss_ce: 0.012702, loss_kd: 755.141113
[18:20:14.413] iteration 15270 : loss : 136.563446, loss_ce: 0.015003, loss_kd: 680.442017
[18:20:20.041] iteration 15280 : loss : 172.710281, loss_ce: 0.022685, loss_kd: 861.128845
[18:20:25.681] iteration 15290 : loss : 151.912598, loss_ce: 0.019041, loss_kd: 757.173340
[18:20:31.309] iteration 15300 : loss : 151.186874, loss_ce: 0.018880, loss_kd: 753.541931
[18:20:36.942] iteration 15310 : loss : 129.808304, loss_ce: 0.019204, loss_kd: 646.665100
[18:20:42.564] iteration 15320 : loss : 122.756210, loss_ce: 0.022384, loss_kd: 611.341980
[18:20:48.204] iteration 15330 : loss : 218.097778, loss_ce: 0.024186, loss_kd: 1088.110596
[18:20:53.828] iteration 15340 : loss : 190.437332, loss_ce: 0.020616, loss_kd: 949.777222
[18:20:59.456] iteration 15350 : loss : 186.950607, loss_ce: 0.015004, loss_kd: 932.387268
[18:21:05.098] iteration 15360 : loss : 166.440201, loss_ce: 0.012822, loss_kd: 829.837891
[18:21:10.733] iteration 15370 : loss : 141.055008, loss_ce: 0.016640, loss_kd: 702.878662
[18:21:16.375] iteration 15380 : loss : 125.251984, loss_ce: 0.012728, loss_kd: 623.866882
[18:21:22.005] iteration 15390 : loss : 164.410889, loss_ce: 0.014873, loss_kd: 819.622375
[18:21:27.639] iteration 15400 : loss : 141.938187, loss_ce: 0.015087, loss_kd: 707.240906
[18:21:33.272] iteration 15410 : loss : 143.362076, loss_ce: 0.017923, loss_kd: 714.442383
[18:21:38.907] iteration 15420 : loss : 117.536575, loss_ce: 0.010858, loss_kd: 585.301453
[18:21:44.533] iteration 15430 : loss : 120.237183, loss_ce: 0.019868, loss_kd: 598.759399
[18:21:50.173] iteration 15440 : loss : 126.634918, loss_ce: 0.016340, loss_kd: 630.779602
[18:21:55.794] iteration 15450 : loss : 139.806351, loss_ce: 0.022682, loss_kd: 696.625000
[18:22:01.435] iteration 15460 : loss : 128.615845, loss_ce: 0.015825, loss_kd: 640.662415
[18:22:07.063] iteration 15470 : loss : 155.450760, loss_ce: 0.028611, loss_kd: 774.846802
[18:22:12.700] iteration 15480 : loss : 116.534874, loss_ce: 0.016986, loss_kd: 580.292297
[18:22:18.327] iteration 15490 : loss : 145.529663, loss_ce: 0.015992, loss_kd: 725.231140
[18:22:23.960] iteration 15500 : loss : 175.001312, loss_ce: 0.025608, loss_kd: 872.586670
[18:22:29.597] iteration 15510 : loss : 191.406281, loss_ce: 0.010120, loss_kd: 954.651245
[18:22:35.239] iteration 15520 : loss : 150.106689, loss_ce: 0.014085, loss_kd: 748.143677
[18:22:40.881] iteration 15530 : loss : 133.813782, loss_ce: 0.014163, loss_kd: 666.641418
[18:22:46.513] iteration 15540 : loss : 158.551651, loss_ce: 0.029490, loss_kd: 790.357178
[18:22:52.171] iteration 15550 : loss : 168.392838, loss_ce: 0.011702, loss_kd: 839.602783
[18:22:57.796] iteration 15560 : loss : 189.678879, loss_ce: 0.016923, loss_kd: 946.007812
[18:23:03.434] iteration 15570 : loss : 179.853226, loss_ce: 0.012074, loss_kd: 896.886047
[18:23:09.061] iteration 15580 : loss : 166.707138, loss_ce: 0.013867, loss_kd: 831.113770
[18:23:14.719] iteration 15590 : loss : 164.980865, loss_ce: 0.017445, loss_kd: 822.504517
[18:23:20.359] iteration 15600 : loss : 162.349808, loss_ce: 0.021890, loss_kd: 809.373535
[18:23:25.995] iteration 15610 : loss : 171.877884, loss_ce: 0.012978, loss_kd: 857.004333
[18:23:31.630] iteration 15620 : loss : 148.616165, loss_ce: 0.010147, loss_kd: 740.737244
[18:23:36.967] iteration 15630 : loss : 101.231110, loss_ce: 0.023651, loss_kd: 503.731476
[18:23:37.783] save model to ./debug_fixed_tpgm\continual_surgical_tpgm_epoch_14.pth
[18:23:37.784] Applying final TPGM projection
[18:23:37.950] save final model to ./debug_fixed_tpgm\continual_surgical_tpgm_final.pth
[21:24:50.712] Namespace(root_path='./datasets/kits23/train_npz', dataset='kits23', list_dir='./lists/kits23', num_classes_old=9, num_classes_new=4, output_dir='./debug_fixed_tpgm', max_iterations=10000, max_epochs=15, batch_size=32, n_gpu=1, deterministic=1, base_lr=0.001, img_size=224, seed=1234, cfg='configs/finetune.yaml', pretrained_path='./pretrain/epoch_149.pth', data_fraction=0.35, kd_temperature=3.0, kd_weight=0.2, freeze_old_classes=False, auto_tune='none', gradient_batches=5, tpgm_norm_mode='l2', tpgm_lr=0.05, tpgm_iters=500, tpgm_exclude=[], tpgm_frequency=2, tpgm_start_epoch=2, disable_tpgm=False, tpgm_data_fraction=0.3, opts=None, zip=False, cache_mode='part', resume=None, accumulation_steps=None, use_checkpoint=False, amp_opt_level='O1', tag=None, eval=False, throughput=False)
[21:24:50.734] Using 33327/95221 samples (35.0%) for continual learning
[21:24:50.734] Old classes: 9, New classes: 4, Total: 12
[21:24:50.734] TPGM enabled: True
[21:24:50.734] Surgical fine-tuning method: none
[21:28:07.711] Combined Continual Learning + Surgical + TPGM Configuration:
[21:28:07.711] KD Temperature: 3.0
[21:28:07.712] KD Weight: 0.2
[21:28:07.712] Auto-tune method: none
[21:28:07.712] TPGM start epoch: 2
[21:28:07.712] TPGM frequency: 2
[21:28:07.712] 1042 iterations per epoch. 15630 max iterations 
[21:28:26.204] iteration 10 : loss : 5603.246582, loss_ce: 0.254506, loss_kd: 28013.501953
[21:28:31.701] iteration 20 : loss : 3771.561279, loss_ce: 0.232940, loss_kd: 18854.687500
[21:28:37.263] iteration 30 : loss : 4068.643311, loss_ce: 0.170892, loss_kd: 20340.373047
[21:28:42.775] iteration 40 : loss : 2952.815674, loss_ce: 0.147216, loss_kd: 14761.041016
[21:28:48.310] iteration 50 : loss : 1991.151123, loss_ce: 0.134721, loss_kd: 9952.947266
[21:28:53.840] iteration 60 : loss : 1787.323975, loss_ce: 0.171531, loss_kd: 8933.642578
[21:28:59.375] iteration 70 : loss : 1302.562500, loss_ce: 0.168004, loss_kd: 6509.942871
[21:29:04.900] iteration 80 : loss : 1267.604736, loss_ce: 0.093403, loss_kd: 6335.222168
[21:29:10.436] iteration 90 : loss : 1514.672241, loss_ce: 0.126000, loss_kd: 7570.385254
[21:29:15.967] iteration 100 : loss : 1292.782593, loss_ce: 0.098314, loss_kd: 6461.148926
[21:29:21.511] iteration 110 : loss : 1334.174072, loss_ce: 0.080514, loss_kd: 6667.932617
[21:29:27.041] iteration 120 : loss : 1364.823608, loss_ce: 0.078627, loss_kd: 6821.250000
[21:29:32.589] iteration 130 : loss : 1067.468506, loss_ce: 0.098510, loss_kd: 5334.640625
[21:29:38.121] iteration 140 : loss : 1271.808838, loss_ce: 0.058937, loss_kd: 6356.400391
[21:29:43.668] iteration 150 : loss : 1064.039795, loss_ce: 0.085945, loss_kd: 5317.400391
[21:29:49.204] iteration 160 : loss : 1198.357788, loss_ce: 0.024793, loss_kd: 5989.071289
[21:29:54.761] iteration 170 : loss : 911.944824, loss_ce: 0.026217, loss_kd: 4557.009766
[21:30:00.303] iteration 180 : loss : 1339.675537, loss_ce: 0.018147, loss_kd: 6695.767090
[21:30:05.857] iteration 190 : loss : 909.561035, loss_ce: 0.043075, loss_kd: 4545.091309
[21:30:11.429] iteration 200 : loss : 862.236206, loss_ce: 0.034092, loss_kd: 4308.442383
[21:30:16.991] iteration 210 : loss : 838.607788, loss_ce: 0.025415, loss_kd: 4190.500000
[21:30:22.532] iteration 220 : loss : 907.366760, loss_ce: 0.021083, loss_kd: 4534.179199
[21:30:28.092] iteration 230 : loss : 1259.537231, loss_ce: 0.018248, loss_kd: 6295.015137
[21:30:33.645] iteration 240 : loss : 662.233398, loss_ce: 0.017866, loss_kd: 3308.486084
[21:30:39.211] iteration 250 : loss : 664.609619, loss_ce: 0.021476, loss_kd: 3320.434082
[21:30:44.766] iteration 260 : loss : 1170.447998, loss_ce: 0.030219, loss_kd: 5849.553711
[21:30:50.335] iteration 270 : loss : 840.907898, loss_ce: 0.012443, loss_kd: 4202.014160
[21:30:55.891] iteration 280 : loss : 951.925598, loss_ce: 0.027856, loss_kd: 4757.088379
[21:31:01.459] iteration 290 : loss : 781.685608, loss_ce: 0.009956, loss_kd: 3905.769775
[21:31:07.017] iteration 300 : loss : 727.529602, loss_ce: 0.010693, loss_kd: 3635.146484
[21:31:12.590] iteration 310 : loss : 841.190918, loss_ce: 0.022380, loss_kd: 4203.367676
[21:31:18.154] iteration 320 : loss : 1059.872925, loss_ce: 0.016011, loss_kd: 5296.823730
[21:31:23.724] iteration 330 : loss : 832.491272, loss_ce: 0.019374, loss_kd: 4159.865234
[21:31:29.281] iteration 340 : loss : 807.053101, loss_ce: 0.015402, loss_kd: 4032.727295
[21:31:34.857] iteration 350 : loss : 780.537109, loss_ce: 0.027872, loss_kd: 3900.122070
[21:31:40.427] iteration 360 : loss : 651.616821, loss_ce: 0.025221, loss_kd: 3255.549561
[21:31:46.006] iteration 370 : loss : 691.620728, loss_ce: 0.018099, loss_kd: 3455.562744
[21:31:51.562] iteration 380 : loss : 653.950623, loss_ce: 0.022522, loss_kd: 3267.224121
[21:31:57.130] iteration 390 : loss : 864.127869, loss_ce: 0.010945, loss_kd: 4318.078125
[21:32:02.689] iteration 400 : loss : 968.035828, loss_ce: 0.016071, loss_kd: 4837.653809
[21:32:08.262] iteration 410 : loss : 944.567200, loss_ce: 0.024826, loss_kd: 4720.268066
[21:32:13.830] iteration 420 : loss : 811.525940, loss_ce: 0.022086, loss_kd: 4055.094971
[21:32:19.403] iteration 430 : loss : 663.257751, loss_ce: 0.013856, loss_kd: 3313.819824
[21:32:24.970] iteration 440 : loss : 881.240173, loss_ce: 0.019214, loss_kd: 4403.725586
[21:32:30.547] iteration 450 : loss : 422.091400, loss_ce: 0.015780, loss_kd: 2107.873047
[21:32:36.122] iteration 460 : loss : 673.163757, loss_ce: 0.022679, loss_kd: 3363.295166
[21:32:41.704] iteration 470 : loss : 725.383789, loss_ce: 0.021429, loss_kd: 3624.394531
[21:32:47.274] iteration 480 : loss : 928.828247, loss_ce: 0.028458, loss_kd: 4641.640137
[21:32:52.860] iteration 490 : loss : 719.796387, loss_ce: 0.021234, loss_kd: 3596.501953
[21:32:58.437] iteration 500 : loss : 633.446045, loss_ce: 0.022232, loss_kd: 3164.729980
[21:33:04.047] iteration 510 : loss : 632.843079, loss_ce: 0.032295, loss_kd: 3161.754395
[21:33:09.626] iteration 520 : loss : 595.767456, loss_ce: 0.027955, loss_kd: 2976.213379
[21:33:15.244] iteration 530 : loss : 698.667603, loss_ce: 0.015485, loss_kd: 3490.791504
[21:33:20.826] iteration 540 : loss : 670.178711, loss_ce: 0.020205, loss_kd: 3348.348145
[21:33:26.421] iteration 550 : loss : 810.671631, loss_ce: 0.027695, loss_kd: 4050.761230
[21:33:32.019] iteration 560 : loss : 917.016113, loss_ce: 0.017088, loss_kd: 4582.431641
[21:33:37.610] iteration 570 : loss : 715.640076, loss_ce: 0.030183, loss_kd: 3575.730469
[21:33:43.194] iteration 580 : loss : 491.049988, loss_ce: 0.027736, loss_kd: 2452.772217
[21:33:48.787] iteration 590 : loss : 593.401489, loss_ce: 0.011959, loss_kd: 2964.468262
[21:33:54.384] iteration 600 : loss : 845.662842, loss_ce: 0.026428, loss_kd: 4225.774902
[21:33:59.986] iteration 610 : loss : 553.627136, loss_ce: 0.026654, loss_kd: 2765.651611
[21:34:05.579] iteration 620 : loss : 750.811279, loss_ce: 0.013163, loss_kd: 3751.528564
[21:34:11.181] iteration 630 : loss : 601.464478, loss_ce: 0.029541, loss_kd: 3004.751953
[21:34:16.771] iteration 640 : loss : 570.588257, loss_ce: 0.034777, loss_kd: 2850.468262
[21:34:22.373] iteration 650 : loss : 471.446289, loss_ce: 0.032394, loss_kd: 2354.735352
[21:34:27.974] iteration 660 : loss : 811.087646, loss_ce: 0.028226, loss_kd: 4052.979980
[21:34:33.570] iteration 670 : loss : 629.304749, loss_ce: 0.022235, loss_kd: 3144.053223
[21:34:39.166] iteration 680 : loss : 449.536713, loss_ce: 0.022644, loss_kd: 2245.185303
[21:34:44.773] iteration 690 : loss : 711.032776, loss_ce: 0.021610, loss_kd: 3552.645020
[21:34:50.364] iteration 700 : loss : 544.096558, loss_ce: 0.020175, loss_kd: 2717.778076
[21:34:55.966] iteration 710 : loss : 675.687744, loss_ce: 0.029739, loss_kd: 3375.739990
[21:35:01.568] iteration 720 : loss : 639.881836, loss_ce: 0.019859, loss_kd: 3196.955566
[21:35:07.180] iteration 730 : loss : 694.106384, loss_ce: 0.038939, loss_kd: 3467.986084
[21:35:12.779] iteration 740 : loss : 532.615906, loss_ce: 0.025773, loss_kd: 2660.572754
[21:35:18.372] iteration 750 : loss : 526.581787, loss_ce: 0.022426, loss_kd: 2630.363770
[21:35:23.963] iteration 760 : loss : 536.041443, loss_ce: 0.028603, loss_kd: 2677.488525
[21:35:29.572] iteration 770 : loss : 603.981323, loss_ce: 0.034181, loss_kd: 3017.374756
[21:35:35.169] iteration 780 : loss : 571.653442, loss_ce: 0.033517, loss_kd: 2855.755615
[21:35:40.771] iteration 790 : loss : 561.791809, loss_ce: 0.017171, loss_kd: 2806.466309
[21:35:46.372] iteration 800 : loss : 632.052185, loss_ce: 0.033404, loss_kd: 3157.659180
[21:35:51.989] iteration 810 : loss : 610.029785, loss_ce: 0.024912, loss_kd: 3047.596680
[21:35:57.593] iteration 820 : loss : 548.138855, loss_ce: 0.022109, loss_kd: 2738.201172
[21:36:03.207] iteration 830 : loss : 590.406189, loss_ce: 0.027461, loss_kd: 2949.470947
[21:36:08.813] iteration 840 : loss : 589.569702, loss_ce: 0.020586, loss_kd: 2945.408447
[21:36:14.428] iteration 850 : loss : 655.125549, loss_ce: 0.030032, loss_kd: 3273.090332
[21:36:20.030] iteration 860 : loss : 563.401611, loss_ce: 0.028497, loss_kd: 2814.505615
[21:36:25.638] iteration 870 : loss : 488.075439, loss_ce: 0.020553, loss_kd: 2437.838135
[21:36:31.238] iteration 880 : loss : 504.083862, loss_ce: 0.039870, loss_kd: 2517.945068
[21:36:36.851] iteration 890 : loss : 574.257141, loss_ce: 0.023527, loss_kd: 2868.891602
[21:36:42.451] iteration 900 : loss : 497.358063, loss_ce: 0.027568, loss_kd: 2484.281250
[21:36:48.077] iteration 910 : loss : 536.385315, loss_ce: 0.017047, loss_kd: 2679.456299
[21:36:53.680] iteration 920 : loss : 338.363556, loss_ce: 0.015665, loss_kd: 1689.363281
[21:36:59.302] iteration 930 : loss : 736.323181, loss_ce: 0.020876, loss_kd: 3679.110840
[21:37:04.905] iteration 940 : loss : 710.547852, loss_ce: 0.018924, loss_kd: 3550.205078
[21:37:10.512] iteration 950 : loss : 505.806335, loss_ce: 0.018870, loss_kd: 2526.468994
[21:37:16.112] iteration 960 : loss : 787.021179, loss_ce: 0.033119, loss_kd: 3932.521973
[21:37:21.744] iteration 970 : loss : 527.841797, loss_ce: 0.022381, loss_kd: 2636.681641
[21:37:27.349] iteration 980 : loss : 692.956299, loss_ce: 0.028852, loss_kd: 3462.200439
[21:37:32.965] iteration 990 : loss : 644.787903, loss_ce: 0.016232, loss_kd: 3221.438477
[21:37:38.573] iteration 1000 : loss : 604.016968, loss_ce: 0.024738, loss_kd: 3017.575684
[21:37:44.202] iteration 1010 : loss : 535.560425, loss_ce: 0.029125, loss_kd: 2675.306396
[21:37:49.812] iteration 1020 : loss : 857.874207, loss_ce: 0.028383, loss_kd: 4286.823242
[21:37:55.431] iteration 1030 : loss : 419.971313, loss_ce: 0.030411, loss_kd: 2097.342041
[21:38:01.035] iteration 1040 : loss : 510.111664, loss_ce: 0.024631, loss_kd: 2548.098389
[21:38:20.169] iteration 1050 : loss : 604.208130, loss_ce: 0.031268, loss_kd: 3018.574951
[21:38:25.727] iteration 1060 : loss : 778.500977, loss_ce: 0.024588, loss_kd: 3889.997559
[21:38:31.296] iteration 1070 : loss : 484.426147, loss_ce: 0.019849, loss_kd: 2419.558594
[21:38:36.856] iteration 1080 : loss : 548.512512, loss_ce: 0.023943, loss_kd: 2740.003906
[21:38:42.435] iteration 1090 : loss : 513.487427, loss_ce: 0.021785, loss_kd: 2564.961182
[21:38:48.012] iteration 1100 : loss : 530.111877, loss_ce: 0.018497, loss_kd: 2647.977539
[21:38:53.606] iteration 1110 : loss : 471.621429, loss_ce: 0.030881, loss_kd: 2355.472168
[21:38:59.192] iteration 1120 : loss : 491.240753, loss_ce: 0.021194, loss_kd: 2453.753174
[21:39:04.788] iteration 1130 : loss : 348.463593, loss_ce: 0.023061, loss_kd: 1739.806641
[21:39:10.374] iteration 1140 : loss : 631.862366, loss_ce: 0.026132, loss_kd: 3156.745850
[21:39:15.970] iteration 1150 : loss : 644.849365, loss_ce: 0.021220, loss_kd: 3221.764893
[21:39:21.554] iteration 1160 : loss : 443.577850, loss_ce: 0.030504, loss_kd: 2215.247803
[21:39:27.156] iteration 1170 : loss : 477.413788, loss_ce: 0.020185, loss_kd: 2384.539307
[21:39:32.748] iteration 1180 : loss : 506.986969, loss_ce: 0.015251, loss_kd: 2532.473389
[21:39:38.350] iteration 1190 : loss : 490.429504, loss_ce: 0.048287, loss_kd: 2449.601074
[21:39:43.939] iteration 1200 : loss : 342.092926, loss_ce: 0.028196, loss_kd: 1707.869507
[21:39:49.555] iteration 1210 : loss : 497.460449, loss_ce: 0.016250, loss_kd: 2484.843506
[21:39:55.145] iteration 1220 : loss : 393.458954, loss_ce: 0.015624, loss_kd: 1964.794434
[21:40:00.756] iteration 1230 : loss : 428.603790, loss_ce: 0.024001, loss_kd: 2140.561523
[21:40:06.350] iteration 1240 : loss : 564.190979, loss_ce: 0.024084, loss_kd: 2818.407227
[21:40:11.960] iteration 1250 : loss : 494.045410, loss_ce: 0.020527, loss_kd: 2467.707764
[21:40:17.561] iteration 1260 : loss : 556.114319, loss_ce: 0.022404, loss_kd: 2778.077637
[21:40:23.169] iteration 1270 : loss : 384.523010, loss_ce: 0.024911, loss_kd: 1920.116577
[21:40:28.769] iteration 1280 : loss : 433.749603, loss_ce: 0.016720, loss_kd: 2166.325439
[21:40:34.388] iteration 1290 : loss : 417.445251, loss_ce: 0.032865, loss_kd: 2084.737061
[21:40:39.990] iteration 1300 : loss : 413.774811, loss_ce: 0.047014, loss_kd: 2066.350586
[21:40:45.610] iteration 1310 : loss : 514.781372, loss_ce: 0.023068, loss_kd: 2571.440430
[21:40:51.211] iteration 1320 : loss : 447.091614, loss_ce: 0.034175, loss_kd: 2232.953857
[21:40:56.822] iteration 1330 : loss : 432.729645, loss_ce: 0.047628, loss_kd: 2161.130615
[21:41:02.419] iteration 1340 : loss : 376.431824, loss_ce: 0.022259, loss_kd: 1879.587891
[21:41:08.039] iteration 1350 : loss : 455.403992, loss_ce: 0.023753, loss_kd: 2274.542236
[21:41:13.654] iteration 1360 : loss : 537.364685, loss_ce: 0.020404, loss_kd: 2684.359131
[21:41:19.269] iteration 1370 : loss : 368.443970, loss_ce: 0.034516, loss_kd: 1839.690552
[21:41:24.875] iteration 1380 : loss : 514.151794, loss_ce: 0.042840, loss_kd: 2568.231689
[21:41:30.491] iteration 1390 : loss : 516.841553, loss_ce: 0.029354, loss_kd: 2581.729980
[21:41:36.101] iteration 1400 : loss : 405.827393, loss_ce: 0.028390, loss_kd: 2026.627319
[21:41:41.723] iteration 1410 : loss : 524.392151, loss_ce: 0.031713, loss_kd: 2619.441162
[21:41:47.348] iteration 1420 : loss : 482.771210, loss_ce: 0.024489, loss_kd: 2411.343018
[21:41:53.046] iteration 1430 : loss : 504.759918, loss_ce: 0.022448, loss_kd: 2521.354248
[21:41:58.656] iteration 1440 : loss : 385.324799, loss_ce: 0.027105, loss_kd: 1924.122192
[21:42:04.333] iteration 1450 : loss : 466.957825, loss_ce: 0.025626, loss_kd: 2332.318604
[21:42:09.952] iteration 1460 : loss : 552.677612, loss_ce: 0.026244, loss_kd: 2760.923096
[21:42:15.583] iteration 1470 : loss : 370.644836, loss_ce: 0.021228, loss_kd: 1850.775269
[21:42:21.194] iteration 1480 : loss : 526.798767, loss_ce: 0.021954, loss_kd: 2631.487793
[21:42:26.827] iteration 1490 : loss : 428.257965, loss_ce: 0.021414, loss_kd: 2138.802490
[21:42:32.444] iteration 1500 : loss : 461.760803, loss_ce: 0.017611, loss_kd: 2306.339844
[21:42:38.073] iteration 1510 : loss : 426.832520, loss_ce: 0.022111, loss_kd: 2131.659424
[21:42:43.687] iteration 1520 : loss : 579.424744, loss_ce: 0.020088, loss_kd: 2894.646973
[21:42:49.312] iteration 1530 : loss : 528.093872, loss_ce: 0.028560, loss_kd: 2638.023926
[21:42:54.920] iteration 1540 : loss : 495.351959, loss_ce: 0.027215, loss_kd: 2474.262695
[21:43:00.541] iteration 1550 : loss : 509.217987, loss_ce: 0.034129, loss_kd: 2543.616943
[21:43:06.146] iteration 1560 : loss : 348.585022, loss_ce: 0.035758, loss_kd: 1740.406860
[21:43:11.777] iteration 1570 : loss : 368.672424, loss_ce: 0.048283, loss_kd: 1840.852905
[21:43:17.390] iteration 1580 : loss : 398.050934, loss_ce: 0.022321, loss_kd: 1987.775146
[21:43:23.027] iteration 1590 : loss : 416.575897, loss_ce: 0.045027, loss_kd: 2080.344482
[21:43:28.648] iteration 1600 : loss : 436.223755, loss_ce: 0.022158, loss_kd: 2178.642090
[21:43:34.283] iteration 1610 : loss : 442.286591, loss_ce: 0.026606, loss_kd: 2208.996582
[21:43:39.900] iteration 1620 : loss : 428.112335, loss_ce: 0.024216, loss_kd: 2138.035889
[21:43:45.539] iteration 1630 : loss : 409.572571, loss_ce: 0.026426, loss_kd: 2045.369751
[21:43:51.148] iteration 1640 : loss : 340.226685, loss_ce: 0.022119, loss_kd: 1698.613281
[21:43:56.779] iteration 1650 : loss : 358.440613, loss_ce: 0.037144, loss_kd: 1789.731201
[21:44:02.393] iteration 1660 : loss : 366.158081, loss_ce: 0.041421, loss_kd: 1828.312622
[21:44:08.017] iteration 1670 : loss : 381.430267, loss_ce: 0.028209, loss_kd: 1904.654541
[21:44:13.635] iteration 1680 : loss : 544.299744, loss_ce: 0.020670, loss_kd: 2719.028809
[21:44:19.259] iteration 1690 : loss : 357.743225, loss_ce: 0.029658, loss_kd: 1786.240723
[21:44:24.874] iteration 1700 : loss : 498.387482, loss_ce: 0.021050, loss_kd: 2489.457031
[21:44:30.509] iteration 1710 : loss : 440.045288, loss_ce: 0.026716, loss_kd: 2197.692627
[21:44:36.129] iteration 1720 : loss : 506.716095, loss_ce: 0.032874, loss_kd: 2531.108887
[21:44:41.756] iteration 1730 : loss : 389.167999, loss_ce: 0.028297, loss_kd: 1943.343018
[21:44:47.371] iteration 1740 : loss : 355.520050, loss_ce: 0.033310, loss_kd: 1775.110718
[21:44:52.997] iteration 1750 : loss : 372.898224, loss_ce: 0.022696, loss_kd: 1862.008179
[21:44:58.630] iteration 1760 : loss : 389.826782, loss_ce: 0.020973, loss_kd: 1946.631226
[21:45:04.251] iteration 1770 : loss : 328.743835, loss_ce: 0.036311, loss_kd: 1641.251587
[21:45:09.869] iteration 1780 : loss : 399.308258, loss_ce: 0.028138, loss_kd: 1994.095581
[21:45:15.513] iteration 1790 : loss : 357.483002, loss_ce: 0.027985, loss_kd: 1784.910522
[21:45:21.133] iteration 1800 : loss : 579.185852, loss_ce: 0.015196, loss_kd: 2893.465332
[21:45:26.770] iteration 1810 : loss : 422.548737, loss_ce: 0.023086, loss_kd: 2110.244141
[21:45:32.378] iteration 1820 : loss : 368.599060, loss_ce: 0.037577, loss_kd: 1840.504517
[21:45:38.001] iteration 1830 : loss : 478.753479, loss_ce: 0.035302, loss_kd: 2391.289551
[21:45:43.630] iteration 1840 : loss : 440.377014, loss_ce: 0.019438, loss_kd: 2199.386230
[21:45:49.256] iteration 1850 : loss : 630.547363, loss_ce: 0.032629, loss_kd: 3150.247803
[21:45:54.886] iteration 1860 : loss : 351.304504, loss_ce: 0.024862, loss_kd: 1754.074829
[21:46:00.518] iteration 1870 : loss : 316.821167, loss_ce: 0.023544, loss_kd: 1581.629272
[21:46:06.148] iteration 1880 : loss : 332.385590, loss_ce: 0.024590, loss_kd: 1659.418457
[21:46:11.775] iteration 1890 : loss : 372.364166, loss_ce: 0.032653, loss_kd: 1859.317871
[21:46:17.393] iteration 1900 : loss : 482.177490, loss_ce: 0.021841, loss_kd: 2408.408691
[21:46:23.034] iteration 1910 : loss : 383.470306, loss_ce: 0.017676, loss_kd: 1914.889893
[21:46:28.656] iteration 1920 : loss : 431.782898, loss_ce: 0.033838, loss_kd: 2156.274658
[21:46:34.290] iteration 1930 : loss : 434.508850, loss_ce: 0.017143, loss_kd: 2170.001465
[21:46:39.908] iteration 1940 : loss : 433.788940, loss_ce: 0.028862, loss_kd: 2166.494385
[21:46:45.540] iteration 1950 : loss : 366.464508, loss_ce: 0.018821, loss_kd: 1829.881714
[21:46:51.166] iteration 1960 : loss : 325.693970, loss_ce: 0.020245, loss_kd: 1626.002075
[21:46:56.795] iteration 1970 : loss : 389.073029, loss_ce: 0.026010, loss_kd: 1942.861816
[21:47:02.418] iteration 1980 : loss : 261.802063, loss_ce: 0.024479, loss_kd: 1306.529785
[21:47:08.047] iteration 1990 : loss : 535.938538, loss_ce: 0.025241, loss_kd: 2677.206543
[21:47:13.662] iteration 2000 : loss : 274.664490, loss_ce: 0.022196, loss_kd: 1370.815552
[21:47:19.304] iteration 2010 : loss : 388.619629, loss_ce: 0.029377, loss_kd: 1940.623047
[21:47:24.926] iteration 2020 : loss : 558.179688, loss_ce: 0.041641, loss_kd: 2788.414062
[21:47:30.560] iteration 2030 : loss : 465.760742, loss_ce: 0.019132, loss_kd: 2326.336426
[21:47:36.172] iteration 2040 : loss : 369.265930, loss_ce: 0.019686, loss_kd: 1843.881348
[21:47:41.815] iteration 2050 : loss : 524.398254, loss_ce: 0.014466, loss_kd: 2619.498291
[21:47:47.437] iteration 2060 : loss : 418.735107, loss_ce: 0.027946, loss_kd: 2091.143066
[21:47:53.064] iteration 2070 : loss : 409.059235, loss_ce: 0.028103, loss_kd: 2042.813965
[21:47:58.683] iteration 2080 : loss : 415.010651, loss_ce: 0.024541, loss_kd: 2072.569824
[21:48:17.104] iteration 2090 : loss : 413.071228, loss_ce: 0.027364, loss_kd: 2062.926514
[21:48:22.674] iteration 2100 : loss : 306.851440, loss_ce: 0.023028, loss_kd: 1531.789673
[21:48:28.259] iteration 2110 : loss : 432.231995, loss_ce: 0.025528, loss_kd: 2158.688721
[21:48:33.834] iteration 2120 : loss : 338.008636, loss_ce: 0.025268, loss_kd: 1687.545654
[21:48:39.426] iteration 2130 : loss : 422.915588, loss_ce: 0.028524, loss_kd: 2112.135010
[21:48:45.005] iteration 2140 : loss : 368.759735, loss_ce: 0.024011, loss_kd: 1841.334473
[21:48:50.599] iteration 2150 : loss : 363.815552, loss_ce: 0.024330, loss_kd: 1816.482544
[21:48:56.184] iteration 2160 : loss : 403.526031, loss_ce: 0.027524, loss_kd: 2015.151001
[21:49:01.788] iteration 2170 : loss : 442.202942, loss_ce: 0.018330, loss_kd: 2208.578613
[21:49:07.381] iteration 2180 : loss : 314.028137, loss_ce: 0.039184, loss_kd: 1567.702881
[21:49:12.991] iteration 2190 : loss : 360.140289, loss_ce: 0.025968, loss_kd: 1798.265259
[21:49:18.591] iteration 2200 : loss : 269.501160, loss_ce: 0.028089, loss_kd: 1345.010742
[21:49:24.205] iteration 2210 : loss : 354.480133, loss_ce: 0.033735, loss_kd: 1769.943481
[21:49:29.810] iteration 2220 : loss : 363.848145, loss_ce: 0.029720, loss_kd: 1816.799805
[21:49:35.431] iteration 2230 : loss : 287.372070, loss_ce: 0.015803, loss_kd: 1434.397705
[21:49:41.038] iteration 2240 : loss : 325.869843, loss_ce: 0.017775, loss_kd: 1626.848145
[21:49:46.675] iteration 2250 : loss : 364.587402, loss_ce: 0.019077, loss_kd: 1820.481201
[21:49:52.274] iteration 2260 : loss : 383.819427, loss_ce: 0.027940, loss_kd: 1916.604248
[21:49:57.894] iteration 2270 : loss : 361.376160, loss_ce: 0.022122, loss_kd: 1804.418457
[21:50:03.497] iteration 2280 : loss : 379.884979, loss_ce: 0.026971, loss_kd: 1896.967529
[21:50:09.124] iteration 2290 : loss : 372.783600, loss_ce: 0.023141, loss_kd: 1861.413086
[21:50:14.738] iteration 2300 : loss : 335.020020, loss_ce: 0.031731, loss_kd: 1672.594604
[21:50:20.366] iteration 2310 : loss : 298.088959, loss_ce: 0.036095, loss_kd: 1487.980469
[21:50:25.970] iteration 2320 : loss : 474.562927, loss_ce: 0.016870, loss_kd: 2370.398682
[21:50:31.596] iteration 2330 : loss : 427.048584, loss_ce: 0.027282, loss_kd: 2132.787598
[21:50:37.204] iteration 2340 : loss : 407.305298, loss_ce: 0.019140, loss_kd: 2034.083740
[21:50:42.828] iteration 2350 : loss : 357.659851, loss_ce: 0.019018, loss_kd: 1785.879272
[21:50:48.444] iteration 2360 : loss : 290.342407, loss_ce: 0.028180, loss_kd: 1449.239014
[21:50:54.068] iteration 2370 : loss : 263.727142, loss_ce: 0.026959, loss_kd: 1316.189819
[21:50:59.690] iteration 2380 : loss : 413.097351, loss_ce: 0.022244, loss_kd: 2063.058350
[21:51:05.318] iteration 2390 : loss : 470.806427, loss_ce: 0.022173, loss_kd: 2351.553711
[21:51:10.938] iteration 2400 : loss : 372.877991, loss_ce: 0.024682, loss_kd: 1861.917847
[21:51:16.575] iteration 2410 : loss : 511.579773, loss_ce: 0.027609, loss_kd: 2555.461182
[21:51:22.197] iteration 2420 : loss : 363.137604, loss_ce: 0.034165, loss_kd: 1813.170044
[21:51:27.829] iteration 2430 : loss : 277.320404, loss_ce: 0.027722, loss_kd: 1384.125488
[21:51:33.449] iteration 2440 : loss : 369.441803, loss_ce: 0.017348, loss_kd: 1844.774414
[21:51:39.067] iteration 2450 : loss : 359.393646, loss_ce: 0.024209, loss_kd: 1794.484375
[21:51:44.694] iteration 2460 : loss : 335.848785, loss_ce: 0.020473, loss_kd: 1676.785889
[21:51:50.328] iteration 2470 : loss : 345.022583, loss_ce: 0.016782, loss_kd: 1722.635376
[21:51:55.948] iteration 2480 : loss : 328.363983, loss_ce: 0.025792, loss_kd: 1639.320801
[21:52:01.588] iteration 2490 : loss : 373.755768, loss_ce: 0.054733, loss_kd: 1866.240479
[21:52:07.211] iteration 2500 : loss : 324.749329, loss_ce: 0.026185, loss_kd: 1621.262939
[21:52:12.855] iteration 2510 : loss : 284.925781, loss_ce: 0.026926, loss_kd: 1422.171631
[21:52:18.482] iteration 2520 : loss : 437.552032, loss_ce: 0.022934, loss_kd: 2185.286621
[21:52:24.119] iteration 2530 : loss : 421.226898, loss_ce: 0.021714, loss_kd: 2103.688477
[21:52:29.744] iteration 2540 : loss : 330.485107, loss_ce: 0.029556, loss_kd: 1649.946411
[21:52:35.381] iteration 2550 : loss : 372.759918, loss_ce: 0.034760, loss_kd: 1861.284668
[21:52:41.006] iteration 2560 : loss : 294.326141, loss_ce: 0.022762, loss_kd: 1469.199219
[21:52:46.648] iteration 2570 : loss : 280.531158, loss_ce: 0.028838, loss_kd: 1400.217773
[21:52:52.264] iteration 2580 : loss : 376.142792, loss_ce: 0.025651, loss_kd: 1878.233643
[21:52:57.900] iteration 2590 : loss : 427.601501, loss_ce: 0.025781, loss_kd: 2135.573730
[21:53:03.533] iteration 2600 : loss : 439.313782, loss_ce: 0.034389, loss_kd: 2194.084229
[21:53:09.179] iteration 2610 : loss : 312.076660, loss_ce: 0.019751, loss_kd: 1557.893188
[21:53:14.803] iteration 2620 : loss : 296.353851, loss_ce: 0.032840, loss_kd: 1479.306030
[21:53:20.436] iteration 2630 : loss : 345.007111, loss_ce: 0.028926, loss_kd: 1722.562622
[21:53:26.052] iteration 2640 : loss : 310.084198, loss_ce: 0.026662, loss_kd: 1547.917603
[21:53:31.679] iteration 2650 : loss : 336.584381, loss_ce: 0.025086, loss_kd: 1680.431396
[21:53:37.284] iteration 2660 : loss : 312.668274, loss_ce: 0.020393, loss_kd: 1560.902100
[21:53:42.904] iteration 2670 : loss : 283.965118, loss_ce: 0.024390, loss_kd: 1417.356079
[21:53:48.501] iteration 2680 : loss : 360.721405, loss_ce: 0.018436, loss_kd: 1801.103516
[21:53:54.131] iteration 2690 : loss : 351.999207, loss_ce: 0.022435, loss_kd: 1757.547974
[21:53:59.720] iteration 2700 : loss : 415.016968, loss_ce: 0.022309, loss_kd: 2072.643311
[21:54:05.327] iteration 2710 : loss : 411.699005, loss_ce: 0.026812, loss_kd: 2056.027344
[21:54:10.919] iteration 2720 : loss : 322.534363, loss_ce: 0.014774, loss_kd: 1610.192505
[21:54:16.526] iteration 2730 : loss : 289.072784, loss_ce: 0.031444, loss_kd: 1442.888916
[21:54:22.123] iteration 2740 : loss : 272.428955, loss_ce: 0.025165, loss_kd: 1359.631470
[21:54:27.724] iteration 2750 : loss : 326.571594, loss_ce: 0.031682, loss_kd: 1630.375366
[21:54:33.322] iteration 2760 : loss : 374.060181, loss_ce: 0.033359, loss_kd: 1867.805786
[21:54:38.931] iteration 2770 : loss : 336.704193, loss_ce: 0.036404, loss_kd: 1680.978882
[21:54:44.533] iteration 2780 : loss : 358.099213, loss_ce: 0.023689, loss_kd: 1788.022461
[21:54:50.143] iteration 2790 : loss : 340.067688, loss_ce: 0.033416, loss_kd: 1697.845581
[21:54:55.743] iteration 2800 : loss : 356.049377, loss_ce: 0.023516, loss_kd: 1777.810913
[21:55:01.357] iteration 2810 : loss : 236.362686, loss_ce: 0.032267, loss_kd: 1179.307129
[21:55:06.962] iteration 2820 : loss : 317.391083, loss_ce: 0.032077, loss_kd: 1584.478516
[21:55:12.563] iteration 2830 : loss : 267.908173, loss_ce: 0.026830, loss_kd: 1337.066406
[21:55:18.158] iteration 2840 : loss : 352.256500, loss_ce: 0.025257, loss_kd: 1758.816650
[21:55:23.770] iteration 2850 : loss : 341.074158, loss_ce: 0.016930, loss_kd: 1702.770264
[21:55:29.368] iteration 2860 : loss : 290.970398, loss_ce: 0.026788, loss_kd: 1452.366455
[21:55:34.981] iteration 2870 : loss : 301.105347, loss_ce: 0.021603, loss_kd: 1502.993774
[21:55:40.579] iteration 2880 : loss : 299.039825, loss_ce: 0.021018, loss_kd: 1492.729126
[21:55:46.210] iteration 2890 : loss : 288.683777, loss_ce: 0.024243, loss_kd: 1440.957520
[21:55:51.813] iteration 2900 : loss : 259.210236, loss_ce: 0.027644, loss_kd: 1293.603271
[21:55:57.424] iteration 2910 : loss : 397.928955, loss_ce: 0.041518, loss_kd: 1987.160889
[21:56:03.024] iteration 2920 : loss : 359.299347, loss_ce: 0.030307, loss_kd: 1793.983643
[21:56:08.633] iteration 2930 : loss : 328.913147, loss_ce: 0.027899, loss_kd: 1642.088257
[21:56:14.237] iteration 2940 : loss : 397.996735, loss_ce: 0.024235, loss_kd: 1987.528687
[21:56:19.854] iteration 2950 : loss : 356.225586, loss_ce: 0.019004, loss_kd: 1778.673584
[21:56:25.470] iteration 2960 : loss : 240.767426, loss_ce: 0.027152, loss_kd: 1201.387817
[21:56:31.085] iteration 2970 : loss : 265.993256, loss_ce: 0.016558, loss_kd: 1327.526001
[21:56:36.702] iteration 2980 : loss : 371.746002, loss_ce: 0.018185, loss_kd: 1856.275513
[21:56:42.329] iteration 2990 : loss : 274.481750, loss_ce: 0.020130, loss_kd: 1369.966309
[21:56:47.935] iteration 3000 : loss : 266.895782, loss_ce: 0.027014, loss_kd: 1332.019897
[21:56:53.562] iteration 3010 : loss : 326.742523, loss_ce: 0.014695, loss_kd: 1631.287109
[21:56:59.155] iteration 3020 : loss : 423.567688, loss_ce: 0.024677, loss_kd: 2115.368408
[21:57:04.767] iteration 3030 : loss : 342.560333, loss_ce: 0.030797, loss_kd: 1710.386353
[21:57:10.367] iteration 3040 : loss : 329.728943, loss_ce: 0.015735, loss_kd: 1646.210938
[21:57:15.994] iteration 3050 : loss : 339.793488, loss_ce: 0.021463, loss_kd: 1696.476807
[21:57:21.601] iteration 3060 : loss : 381.680481, loss_ce: 0.024613, loss_kd: 1905.928223
[21:57:27.213] iteration 3070 : loss : 353.536926, loss_ce: 0.020575, loss_kd: 1765.237061
[21:57:32.818] iteration 3080 : loss : 277.952576, loss_ce: 0.026001, loss_kd: 1387.251343
[21:57:38.427] iteration 3090 : loss : 324.048340, loss_ce: 0.019736, loss_kd: 1617.754639
[21:57:44.030] iteration 3100 : loss : 276.535950, loss_ce: 0.015850, loss_kd: 1380.082764
[21:57:49.653] iteration 3110 : loss : 290.511230, loss_ce: 0.027987, loss_kd: 1450.074951
[21:57:55.264] iteration 3120 : loss : 263.983276, loss_ce: 0.025090, loss_kd: 1317.439575
[21:57:58.977] Running TPGM constraint optimization after epoch 3
[22:40:55.522] Namespace(root_path='./datasets/kits23/train_npz', dataset='kits23', list_dir='./lists/kits23', num_classes_old=9, num_classes_new=4, output_dir='./debug_fixed_tpgm', max_iterations=10000, max_epochs=15, batch_size=32, n_gpu=1, deterministic=1, base_lr=0.001, img_size=224, seed=1234, cfg='configs/finetune.yaml', pretrained_path='./pretrain/epoch_149.pth', data_fraction=0.35, kd_temperature=3.0, kd_weight=0.2, freeze_old_classes=False, auto_tune='none', gradient_batches=5, tpgm_norm_mode='l2', tpgm_lr=0.05, tpgm_iters=500, tpgm_exclude=[], tpgm_frequency=2, tpgm_start_epoch=2, disable_tpgm=False, tpgm_data_fraction=0.3, opts=None, zip=False, cache_mode='part', resume=None, accumulation_steps=None, use_checkpoint=False, amp_opt_level='O1', tag=None, eval=False, throughput=False)
[22:40:55.539] Using 33327/95221 samples (35.0%) for continual learning
[22:40:55.540] Old classes: 9, New classes: 4, Total: 12
[22:40:55.540] TPGM enabled: True
[22:40:55.540] Surgical fine-tuning method: none
[22:43:09.319] Combined Continual Learning + Surgical + TPGM Configuration:
[22:43:09.319] KD Temperature: 3.0
[22:43:09.319] KD Weight: 0.2
[22:43:09.319] Auto-tune method: none
[22:43:09.319] TPGM start epoch: 2
[22:43:09.319] TPGM frequency: 2
[22:43:09.320] 1042 iterations per epoch. 15630 max iterations 
[22:43:25.809] iteration 10 : loss : 5603.246582, loss_ce: 0.254506, loss_kd: 28013.501953
[22:43:31.285] iteration 20 : loss : 3771.561279, loss_ce: 0.232940, loss_kd: 18854.687500
[22:43:36.787] iteration 30 : loss : 4068.643311, loss_ce: 0.170892, loss_kd: 20340.373047
[22:43:42.280] iteration 40 : loss : 2952.815674, loss_ce: 0.147216, loss_kd: 14761.041016
[22:43:47.792] iteration 50 : loss : 1991.151123, loss_ce: 0.134721, loss_kd: 9952.947266
[22:43:53.289] iteration 60 : loss : 1787.323975, loss_ce: 0.171531, loss_kd: 8933.642578
[22:43:58.808] iteration 70 : loss : 1302.562500, loss_ce: 0.168004, loss_kd: 6509.942871
[22:44:04.310] iteration 80 : loss : 1267.604736, loss_ce: 0.093403, loss_kd: 6335.222168
[22:44:09.829] iteration 90 : loss : 1514.672241, loss_ce: 0.126000, loss_kd: 7570.385254
[22:44:15.337] iteration 100 : loss : 1292.782593, loss_ce: 0.098314, loss_kd: 6461.148926
[22:44:20.861] iteration 110 : loss : 1334.174072, loss_ce: 0.080514, loss_kd: 6667.932617
[22:44:26.371] iteration 120 : loss : 1364.823608, loss_ce: 0.078627, loss_kd: 6821.250000
[22:44:31.894] iteration 130 : loss : 1067.468506, loss_ce: 0.098510, loss_kd: 5334.640625
[22:44:37.407] iteration 140 : loss : 1271.808838, loss_ce: 0.058937, loss_kd: 6356.400391
[22:44:42.935] iteration 150 : loss : 1064.039795, loss_ce: 0.085945, loss_kd: 5317.400391
[22:44:48.449] iteration 160 : loss : 1198.357788, loss_ce: 0.024793, loss_kd: 5989.071289
[22:44:53.979] iteration 170 : loss : 911.944824, loss_ce: 0.026217, loss_kd: 4557.009766
[22:44:59.502] iteration 180 : loss : 1339.675537, loss_ce: 0.018147, loss_kd: 6695.767090
[22:45:05.034] iteration 190 : loss : 909.561035, loss_ce: 0.043075, loss_kd: 4545.091309
[22:45:10.556] iteration 200 : loss : 862.236206, loss_ce: 0.034092, loss_kd: 4308.442383
[22:45:16.111] iteration 210 : loss : 838.607788, loss_ce: 0.025415, loss_kd: 4190.500000
[22:45:21.638] iteration 220 : loss : 907.366760, loss_ce: 0.021083, loss_kd: 4534.179199
[22:45:27.173] iteration 230 : loss : 1259.537231, loss_ce: 0.018248, loss_kd: 6295.015137
[22:45:32.701] iteration 240 : loss : 662.233398, loss_ce: 0.017866, loss_kd: 3308.486084
[22:45:38.238] iteration 250 : loss : 664.609619, loss_ce: 0.021476, loss_kd: 3320.434082
[22:45:43.775] iteration 260 : loss : 1170.447998, loss_ce: 0.030219, loss_kd: 5849.553711
[22:45:49.309] iteration 270 : loss : 840.907898, loss_ce: 0.012443, loss_kd: 4202.014160
[22:45:54.840] iteration 280 : loss : 951.925598, loss_ce: 0.027856, loss_kd: 4757.088379
[22:46:00.379] iteration 290 : loss : 781.685608, loss_ce: 0.009956, loss_kd: 3905.769775
[22:46:05.910] iteration 300 : loss : 727.529602, loss_ce: 0.010693, loss_kd: 3635.146484
[22:46:11.453] iteration 310 : loss : 841.190918, loss_ce: 0.022380, loss_kd: 4203.367676
[22:46:16.985] iteration 320 : loss : 1059.872925, loss_ce: 0.016011, loss_kd: 5296.823730
[22:46:22.531] iteration 330 : loss : 832.491272, loss_ce: 0.019374, loss_kd: 4159.865234
[22:46:28.062] iteration 340 : loss : 807.053101, loss_ce: 0.015402, loss_kd: 4032.727295
[22:46:33.608] iteration 350 : loss : 780.537109, loss_ce: 0.027872, loss_kd: 3900.122070
[22:46:39.140] iteration 360 : loss : 651.616821, loss_ce: 0.025221, loss_kd: 3255.549561
[22:46:44.688] iteration 370 : loss : 691.620728, loss_ce: 0.018099, loss_kd: 3455.562744
[22:46:50.226] iteration 380 : loss : 653.950623, loss_ce: 0.022522, loss_kd: 3267.224121
[22:46:55.776] iteration 390 : loss : 864.127869, loss_ce: 0.010945, loss_kd: 4318.078125
[22:47:01.317] iteration 400 : loss : 968.035828, loss_ce: 0.016071, loss_kd: 4837.653809
[22:47:06.871] iteration 410 : loss : 944.567200, loss_ce: 0.024826, loss_kd: 4720.268066
[22:47:12.413] iteration 420 : loss : 811.525940, loss_ce: 0.022086, loss_kd: 4055.094971
[22:47:17.961] iteration 430 : loss : 663.257751, loss_ce: 0.013856, loss_kd: 3313.819824
[22:47:23.503] iteration 440 : loss : 881.240173, loss_ce: 0.019214, loss_kd: 4403.725586
[22:47:29.056] iteration 450 : loss : 422.091400, loss_ce: 0.015780, loss_kd: 2107.873047
[22:47:34.606] iteration 460 : loss : 673.163757, loss_ce: 0.022679, loss_kd: 3363.295166
[22:47:40.166] iteration 470 : loss : 725.383789, loss_ce: 0.021429, loss_kd: 3624.394531
[22:47:45.716] iteration 480 : loss : 928.828247, loss_ce: 0.028458, loss_kd: 4641.640137
[22:47:51.277] iteration 490 : loss : 719.796387, loss_ce: 0.021234, loss_kd: 3596.501953
[22:47:56.830] iteration 500 : loss : 633.446045, loss_ce: 0.022232, loss_kd: 3164.729980
[22:48:02.393] iteration 510 : loss : 632.843079, loss_ce: 0.032295, loss_kd: 3161.754395
[22:48:07.947] iteration 520 : loss : 595.767456, loss_ce: 0.027955, loss_kd: 2976.213379
[22:48:13.511] iteration 530 : loss : 698.667603, loss_ce: 0.015485, loss_kd: 3490.791504
[22:48:19.064] iteration 540 : loss : 670.178711, loss_ce: 0.020205, loss_kd: 3348.348145
[22:48:24.626] iteration 550 : loss : 810.671631, loss_ce: 0.027695, loss_kd: 4050.761230
[22:48:30.176] iteration 560 : loss : 917.016113, loss_ce: 0.017088, loss_kd: 4582.431641
[22:48:35.745] iteration 570 : loss : 715.640076, loss_ce: 0.030183, loss_kd: 3575.730469
[22:48:41.304] iteration 580 : loss : 491.049988, loss_ce: 0.027736, loss_kd: 2452.772217
[22:48:46.870] iteration 590 : loss : 593.401489, loss_ce: 0.011959, loss_kd: 2964.468262
[22:48:52.426] iteration 600 : loss : 845.662842, loss_ce: 0.026428, loss_kd: 4225.774902
[22:48:58.005] iteration 610 : loss : 553.627136, loss_ce: 0.026654, loss_kd: 2765.651611
[22:49:03.560] iteration 620 : loss : 750.811279, loss_ce: 0.013163, loss_kd: 3751.528564
[22:49:09.134] iteration 630 : loss : 601.464478, loss_ce: 0.029541, loss_kd: 3004.751953
[22:49:14.693] iteration 640 : loss : 570.588257, loss_ce: 0.034777, loss_kd: 2850.468262
[22:49:20.269] iteration 650 : loss : 471.444580, loss_ce: 0.032394, loss_kd: 2354.726807
[22:49:25.830] iteration 660 : loss : 810.971436, loss_ce: 0.028226, loss_kd: 4052.398926
[22:49:31.413] iteration 670 : loss : 630.151428, loss_ce: 0.022252, loss_kd: 3148.287109
[22:49:36.978] iteration 680 : loss : 448.959534, loss_ce: 0.022635, loss_kd: 2242.299316
[22:49:42.546] iteration 690 : loss : 715.113708, loss_ce: 0.021614, loss_kd: 3573.048828
[22:49:48.120] iteration 700 : loss : 540.378723, loss_ce: 0.020225, loss_kd: 2699.189209
[22:49:53.705] iteration 710 : loss : 677.738220, loss_ce: 0.029769, loss_kd: 3385.991699
[22:49:59.272] iteration 720 : loss : 553.281189, loss_ce: 0.019385, loss_kd: 2763.961426
[22:50:04.856] iteration 730 : loss : 597.116821, loss_ce: 0.037015, loss_kd: 2982.999023
[22:50:10.429] iteration 740 : loss : 589.917969, loss_ce: 0.026228, loss_kd: 2947.052246
[22:50:16.008] iteration 750 : loss : 607.645081, loss_ce: 0.021878, loss_kd: 3035.619141
[22:50:21.579] iteration 760 : loss : 523.329773, loss_ce: 0.028501, loss_kd: 2614.074219
[22:50:27.167] iteration 770 : loss : 732.533875, loss_ce: 0.036970, loss_kd: 3660.084229
[22:50:32.740] iteration 780 : loss : 518.706116, loss_ce: 0.037605, loss_kd: 2590.997070
[22:50:38.319] iteration 790 : loss : 472.770782, loss_ce: 0.019434, loss_kd: 2361.310547
[22:50:43.899] iteration 800 : loss : 518.716614, loss_ce: 0.031088, loss_kd: 2591.013916
[22:50:49.484] iteration 810 : loss : 529.578857, loss_ce: 0.023652, loss_kd: 2645.343506
[22:50:55.057] iteration 820 : loss : 536.733215, loss_ce: 0.022853, loss_kd: 2681.133301
[22:51:00.636] iteration 830 : loss : 545.586182, loss_ce: 0.029555, loss_kd: 2725.345215
[22:51:06.215] iteration 840 : loss : 730.117737, loss_ce: 0.019717, loss_kd: 3648.161133
[22:51:11.797] iteration 850 : loss : 602.747864, loss_ce: 0.028322, loss_kd: 3011.194580
[22:51:17.369] iteration 860 : loss : 587.726318, loss_ce: 0.024217, loss_kd: 2936.092285
[22:51:22.959] iteration 870 : loss : 559.723999, loss_ce: 0.019123, loss_kd: 2796.086426
[22:51:28.537] iteration 880 : loss : 530.819092, loss_ce: 0.043063, loss_kd: 2651.593750
[22:51:34.130] iteration 890 : loss : 590.279480, loss_ce: 0.025004, loss_kd: 2948.943604
[22:51:39.709] iteration 900 : loss : 525.875183, loss_ce: 0.029106, loss_kd: 2626.772217
[22:51:45.296] iteration 910 : loss : 669.447021, loss_ce: 0.017432, loss_kd: 3344.675293
[22:51:50.876] iteration 920 : loss : 526.968445, loss_ce: 0.018192, loss_kd: 2632.396729
[22:51:56.473] iteration 930 : loss : 483.590118, loss_ce: 0.018961, loss_kd: 2415.432129
[22:52:02.050] iteration 940 : loss : 643.184692, loss_ce: 0.016985, loss_kd: 3213.396484
[22:52:07.639] iteration 950 : loss : 465.270508, loss_ce: 0.015039, loss_kd: 2323.806885
[22:52:13.219] iteration 960 : loss : 786.288574, loss_ce: 0.035995, loss_kd: 3928.852295
[22:52:18.812] iteration 970 : loss : 460.026459, loss_ce: 0.022931, loss_kd: 2297.620850
[22:52:24.395] iteration 980 : loss : 674.324524, loss_ce: 0.033469, loss_kd: 3369.018311
[22:52:29.992] iteration 990 : loss : 561.415466, loss_ce: 0.018788, loss_kd: 2804.605225
[22:52:35.571] iteration 1000 : loss : 632.238647, loss_ce: 0.022472, loss_kd: 3158.618652
[22:52:41.178] iteration 1010 : loss : 654.934326, loss_ce: 0.026498, loss_kd: 3272.172607
[22:52:46.760] iteration 1020 : loss : 532.188171, loss_ce: 0.026594, loss_kd: 2658.283203
[22:52:52.353] iteration 1030 : loss : 355.863525, loss_ce: 0.033174, loss_kd: 1776.802612
[22:52:57.935] iteration 1040 : loss : 482.975372, loss_ce: 0.030357, loss_kd: 2412.361328
[22:53:14.800] iteration 1050 : loss : 605.820862, loss_ce: 0.029804, loss_kd: 3026.658203
[22:53:20.334] iteration 1060 : loss : 528.135864, loss_ce: 0.029806, loss_kd: 2638.117920
[22:53:25.881] iteration 1070 : loss : 531.985352, loss_ce: 0.020099, loss_kd: 2657.460693
[22:53:31.424] iteration 1080 : loss : 420.659668, loss_ce: 0.023339, loss_kd: 2100.781006
[22:53:36.983] iteration 1090 : loss : 585.202271, loss_ce: 0.022461, loss_kd: 2923.491211
[22:53:42.532] iteration 1100 : loss : 470.252991, loss_ce: 0.016868, loss_kd: 2348.691650
[22:53:48.096] iteration 1110 : loss : 483.174896, loss_ce: 0.031301, loss_kd: 2413.391113
[22:53:53.657] iteration 1120 : loss : 499.346405, loss_ce: 0.019628, loss_kd: 2494.221191
[22:53:59.222] iteration 1130 : loss : 420.051636, loss_ce: 0.024218, loss_kd: 2097.712891
[22:54:04.791] iteration 1140 : loss : 462.496887, loss_ce: 0.023142, loss_kd: 2309.928223
[22:54:10.361] iteration 1150 : loss : 373.214325, loss_ce: 0.020556, loss_kd: 1863.571289
[22:54:15.934] iteration 1160 : loss : 442.647461, loss_ce: 0.025199, loss_kd: 2210.733154
[22:54:21.514] iteration 1170 : loss : 503.018097, loss_ce: 0.020874, loss_kd: 2512.591797
[22:54:27.087] iteration 1180 : loss : 517.540527, loss_ce: 0.017530, loss_kd: 2585.227295
[22:54:32.669] iteration 1190 : loss : 442.879669, loss_ce: 0.044257, loss_kd: 2211.861816
[22:54:38.237] iteration 1200 : loss : 448.500824, loss_ce: 0.028794, loss_kd: 2239.950439
[22:54:43.826] iteration 1210 : loss : 520.328125, loss_ce: 0.018862, loss_kd: 2599.167969
[22:54:49.402] iteration 1220 : loss : 428.976013, loss_ce: 0.014836, loss_kd: 2142.423584
[22:54:54.989] iteration 1230 : loss : 419.006622, loss_ce: 0.022606, loss_kd: 2092.482910
[22:55:00.570] iteration 1240 : loss : 505.450989, loss_ce: 0.028205, loss_kd: 2524.761475
[22:55:06.159] iteration 1250 : loss : 578.273071, loss_ce: 0.021508, loss_kd: 2888.856934
[22:55:11.745] iteration 1260 : loss : 416.979980, loss_ce: 0.017057, loss_kd: 2082.440918
[22:55:17.331] iteration 1270 : loss : 377.997559, loss_ce: 0.026345, loss_kd: 1887.499634
[22:55:22.916] iteration 1280 : loss : 553.580933, loss_ce: 0.020231, loss_kd: 2765.456055
[22:55:28.509] iteration 1290 : loss : 416.527924, loss_ce: 0.036563, loss_kd: 2080.152100
[22:55:34.097] iteration 1300 : loss : 462.006195, loss_ce: 0.041697, loss_kd: 2307.486328
[22:55:39.701] iteration 1310 : loss : 480.637695, loss_ce: 0.023209, loss_kd: 2400.715088
[22:55:45.285] iteration 1320 : loss : 550.632629, loss_ce: 0.035399, loss_kd: 2750.676758
[22:55:50.892] iteration 1330 : loss : 574.100708, loss_ce: 0.039965, loss_kd: 2867.973145
[22:55:56.494] iteration 1340 : loss : 382.319214, loss_ce: 0.019666, loss_kd: 1909.078003
[22:56:02.097] iteration 1350 : loss : 419.540619, loss_ce: 0.024297, loss_kd: 2095.182129
[22:56:07.689] iteration 1360 : loss : 439.786255, loss_ce: 0.021767, loss_kd: 2196.461182
[22:56:13.292] iteration 1370 : loss : 340.409332, loss_ce: 0.034221, loss_kd: 1699.508179
[22:56:18.880] iteration 1380 : loss : 452.239227, loss_ce: 0.044283, loss_kd: 2258.675049
[22:56:24.484] iteration 1390 : loss : 467.852875, loss_ce: 0.029171, loss_kd: 2336.795410
[22:56:30.067] iteration 1400 : loss : 378.511383, loss_ce: 0.029315, loss_kd: 1890.043091
[22:56:35.678] iteration 1410 : loss : 476.325348, loss_ce: 0.034293, loss_kd: 2379.105225
[22:56:41.274] iteration 1420 : loss : 459.456879, loss_ce: 0.020891, loss_kd: 2294.806152
[22:56:46.888] iteration 1430 : loss : 438.874542, loss_ce: 0.023302, loss_kd: 2191.937744
[22:56:52.484] iteration 1440 : loss : 649.703003, loss_ce: 0.029681, loss_kd: 3246.013184
[22:56:58.090] iteration 1450 : loss : 413.340668, loss_ce: 0.026715, loss_kd: 2064.203369
[22:57:03.700] iteration 1460 : loss : 477.710785, loss_ce: 0.025622, loss_kd: 2386.078369
[22:57:09.305] iteration 1470 : loss : 392.143616, loss_ce: 0.021514, loss_kd: 1958.276367
[22:57:14.892] iteration 1480 : loss : 569.011108, loss_ce: 0.022226, loss_kd: 2842.538818
[22:57:20.497] iteration 1490 : loss : 466.431763, loss_ce: 0.022617, loss_kd: 2329.672363
[22:57:26.092] iteration 1500 : loss : 464.115479, loss_ce: 0.017304, loss_kd: 2318.108643
[22:57:31.704] iteration 1510 : loss : 429.854919, loss_ce: 0.025336, loss_kd: 2146.761719
[22:57:37.296] iteration 1520 : loss : 685.158752, loss_ce: 0.021040, loss_kd: 3423.332031
[22:57:42.911] iteration 1530 : loss : 356.701843, loss_ce: 0.027609, loss_kd: 1781.053223
[22:57:48.508] iteration 1540 : loss : 385.135620, loss_ce: 0.027023, loss_kd: 1923.143188
[22:57:54.109] iteration 1550 : loss : 410.990784, loss_ce: 0.039078, loss_kd: 2052.464111
[22:57:59.705] iteration 1560 : loss : 319.561737, loss_ce: 0.037351, loss_kd: 1595.263184
[22:58:05.321] iteration 1570 : loss : 375.539825, loss_ce: 0.047302, loss_kd: 1875.186768
[22:58:10.928] iteration 1580 : loss : 446.119324, loss_ce: 0.021189, loss_kd: 2228.143311
[22:58:16.536] iteration 1590 : loss : 465.553162, loss_ce: 0.049010, loss_kd: 2325.225830
[22:58:22.131] iteration 1600 : loss : 457.359894, loss_ce: 0.022070, loss_kd: 2284.340576
[22:58:27.743] iteration 1610 : loss : 402.029755, loss_ce: 0.024992, loss_kd: 2007.707275
[22:58:33.333] iteration 1620 : loss : 446.604187, loss_ce: 0.022765, loss_kd: 2230.492432
[22:58:38.940] iteration 1630 : loss : 454.720093, loss_ce: 0.026663, loss_kd: 2271.102539
[22:58:44.539] iteration 1640 : loss : 460.840271, loss_ce: 0.020733, loss_kd: 2301.686768
[22:58:50.155] iteration 1650 : loss : 407.091492, loss_ce: 0.036279, loss_kd: 2032.993652
[22:58:55.750] iteration 1660 : loss : 463.429352, loss_ce: 0.037607, loss_kd: 2314.678955
[22:59:01.358] iteration 1670 : loss : 319.550690, loss_ce: 0.030716, loss_kd: 1595.264893
[22:59:06.956] iteration 1680 : loss : 423.066772, loss_ce: 0.021226, loss_kd: 2112.844971
[22:59:12.561] iteration 1690 : loss : 381.279999, loss_ce: 0.029827, loss_kd: 1903.915039
[22:59:18.155] iteration 1700 : loss : 457.425293, loss_ce: 0.020923, loss_kd: 2284.638672
[22:59:23.781] iteration 1710 : loss : 485.483765, loss_ce: 0.026018, loss_kd: 2424.919434
[22:59:29.390] iteration 1720 : loss : 555.826660, loss_ce: 0.027735, loss_kd: 2776.666992
[22:59:34.997] iteration 1730 : loss : 396.057129, loss_ce: 0.025031, loss_kd: 1977.789917
[22:59:40.594] iteration 1740 : loss : 348.604034, loss_ce: 0.030197, loss_kd: 1740.541992
[22:59:46.215] iteration 1750 : loss : 427.497437, loss_ce: 0.021251, loss_kd: 2134.994629
[22:59:51.816] iteration 1760 : loss : 416.075165, loss_ce: 0.020226, loss_kd: 2077.783691
[22:59:57.434] iteration 1770 : loss : 333.295654, loss_ce: 0.038934, loss_kd: 1664.004272
[23:00:03.040] iteration 1780 : loss : 437.321442, loss_ce: 0.027279, loss_kd: 2184.152588
[23:00:08.649] iteration 1790 : loss : 370.456329, loss_ce: 0.023940, loss_kd: 1849.797119
[23:00:14.247] iteration 1800 : loss : 453.369781, loss_ce: 0.016191, loss_kd: 2264.365967
[23:00:19.850] iteration 1810 : loss : 432.880371, loss_ce: 0.019805, loss_kd: 2161.893311
[23:00:25.449] iteration 1820 : loss : 326.429810, loss_ce: 0.036755, loss_kd: 1629.650879
[23:00:31.061] iteration 1830 : loss : 429.007904, loss_ce: 0.032995, loss_kd: 2142.550781
[23:00:36.667] iteration 1840 : loss : 427.956604, loss_ce: 0.018484, loss_kd: 2137.313965
[23:00:42.264] iteration 1850 : loss : 430.221558, loss_ce: 0.027826, loss_kd: 2148.618652
[23:00:47.865] iteration 1860 : loss : 317.173004, loss_ce: 0.026982, loss_kd: 1583.411621
[23:00:53.484] iteration 1870 : loss : 395.547821, loss_ce: 0.023779, loss_kd: 1975.272705
[23:00:59.098] iteration 1880 : loss : 367.414734, loss_ce: 0.023025, loss_kd: 1834.573730
[23:01:04.711] iteration 1890 : loss : 396.288818, loss_ce: 0.029682, loss_kd: 1978.964355
[23:01:10.307] iteration 1900 : loss : 363.117065, loss_ce: 0.025033, loss_kd: 1813.103149
[23:01:15.925] iteration 1910 : loss : 339.305298, loss_ce: 0.018813, loss_kd: 1694.066650
[23:01:21.523] iteration 1920 : loss : 406.349701, loss_ce: 0.036093, loss_kd: 2029.202026
[23:01:27.128] iteration 1930 : loss : 390.329834, loss_ce: 0.014829, loss_kd: 1949.127563
[23:01:32.750] iteration 1940 : loss : 437.379120, loss_ce: 0.031161, loss_kd: 2184.346680
[23:01:38.363] iteration 1950 : loss : 405.647369, loss_ce: 0.020016, loss_kd: 2025.795898
[23:01:43.981] iteration 1960 : loss : 315.078033, loss_ce: 0.019850, loss_kd: 1572.903564
[23:01:49.591] iteration 1970 : loss : 399.750183, loss_ce: 0.026745, loss_kd: 1996.245728
[23:01:55.206] iteration 1980 : loss : 368.566101, loss_ce: 0.024850, loss_kd: 1840.356079
[23:02:00.831] iteration 1990 : loss : 483.961945, loss_ce: 0.025329, loss_kd: 2417.314453
[23:02:06.436] iteration 2000 : loss : 408.198517, loss_ce: 0.023026, loss_kd: 2038.498657
[23:02:12.056] iteration 2010 : loss : 352.315826, loss_ce: 0.028818, loss_kd: 1759.114990
[23:02:17.661] iteration 2020 : loss : 378.914246, loss_ce: 0.045535, loss_kd: 1892.065063
[23:02:23.285] iteration 2030 : loss : 436.055847, loss_ce: 0.021809, loss_kd: 2177.800537
[23:02:28.893] iteration 2040 : loss : 309.516174, loss_ce: 0.018625, loss_kd: 1545.127686
[23:02:34.501] iteration 2050 : loss : 335.193542, loss_ce: 0.018192, loss_kd: 1673.445068
[23:02:40.108] iteration 2060 : loss : 434.976074, loss_ce: 0.030141, loss_kd: 2172.326416
[23:02:45.714] iteration 2070 : loss : 417.109894, loss_ce: 0.031512, loss_kd: 2083.039307
[23:02:51.315] iteration 2080 : loss : 517.561523, loss_ce: 0.024885, loss_kd: 2585.319824
[23:03:08.117] iteration 2090 : loss : 391.291260, loss_ce: 0.025859, loss_kd: 1954.029419
[23:03:13.660] iteration 2100 : loss : 384.828857, loss_ce: 0.022636, loss_kd: 1921.674438
[23:03:19.223] iteration 2110 : loss : 446.820038, loss_ce: 0.025765, loss_kd: 2231.624023
[23:03:24.777] iteration 2120 : loss : 416.781464, loss_ce: 0.020786, loss_kd: 2081.431396
[23:03:30.346] iteration 2130 : loss : 417.427917, loss_ce: 0.027454, loss_kd: 2084.694336
[23:03:35.910] iteration 2140 : loss : 446.465027, loss_ce: 0.024925, loss_kd: 2229.864502
[23:03:41.480] iteration 2150 : loss : 327.630676, loss_ce: 0.022961, loss_kd: 1635.585938
[23:03:47.050] iteration 2160 : loss : 394.389862, loss_ce: 0.024663, loss_kd: 1969.470215
[23:03:52.627] iteration 2170 : loss : 414.784607, loss_ce: 0.019606, loss_kd: 2071.493652
[23:03:58.196] iteration 2180 : loss : 403.828064, loss_ce: 0.041115, loss_kd: 2016.688965
[23:04:03.784] iteration 2190 : loss : 319.843536, loss_ce: 0.027149, loss_kd: 1596.790771
[23:04:09.363] iteration 2200 : loss : 324.664917, loss_ce: 0.025633, loss_kd: 1620.827515
[23:04:14.965] iteration 2210 : loss : 460.185089, loss_ce: 0.036367, loss_kd: 2298.455322
[23:04:20.550] iteration 2220 : loss : 262.980255, loss_ce: 0.030081, loss_kd: 1312.454834
[23:04:26.153] iteration 2230 : loss : 274.684204, loss_ce: 0.015263, loss_kd: 1370.958862
[23:04:31.746] iteration 2240 : loss : 366.796631, loss_ce: 0.016251, loss_kd: 1831.502075
[23:04:37.349] iteration 2250 : loss : 346.057404, loss_ce: 0.016811, loss_kd: 1727.849121
[23:04:42.947] iteration 2260 : loss : 316.680206, loss_ce: 0.029256, loss_kd: 1580.914551
[23:04:48.550] iteration 2270 : loss : 289.571075, loss_ce: 0.020359, loss_kd: 1445.384644
[23:04:54.146] iteration 2280 : loss : 386.150177, loss_ce: 0.025209, loss_kd: 1928.283447
[23:04:59.759] iteration 2290 : loss : 356.559692, loss_ce: 0.020331, loss_kd: 1780.317871
[23:05:05.349] iteration 2300 : loss : 349.437286, loss_ce: 0.031354, loss_kd: 1744.693726
[23:05:10.951] iteration 2310 : loss : 335.070984, loss_ce: 0.037116, loss_kd: 1672.883667
[23:05:16.551] iteration 2320 : loss : 448.919281, loss_ce: 0.016644, loss_kd: 2242.195557
[23:05:22.158] iteration 2330 : loss : 422.576630, loss_ce: 0.024934, loss_kd: 2110.421631
[23:05:27.747] iteration 2340 : loss : 381.448883, loss_ce: 0.021540, loss_kd: 1904.802856
[23:05:33.352] iteration 2350 : loss : 376.933563, loss_ce: 0.019068, loss_kd: 1882.234009
[23:05:38.956] iteration 2360 : loss : 236.321976, loss_ce: 0.028076, loss_kd: 1179.143555
[23:05:44.553] iteration 2370 : loss : 340.733887, loss_ce: 0.028398, loss_kd: 1701.210449
[23:05:50.152] iteration 2380 : loss : 509.494568, loss_ce: 0.019756, loss_kd: 2545.045410
[23:05:55.765] iteration 2390 : loss : 545.183167, loss_ce: 0.022165, loss_kd: 2723.454346
[23:06:01.369] iteration 2400 : loss : 374.537323, loss_ce: 0.021946, loss_kd: 1870.220215
[23:06:06.978] iteration 2410 : loss : 424.980194, loss_ce: 0.025755, loss_kd: 2122.461914
[23:06:12.584] iteration 2420 : loss : 316.641083, loss_ce: 0.033740, loss_kd: 1580.686035
[23:06:18.202] iteration 2430 : loss : 349.765289, loss_ce: 0.027871, loss_kd: 1746.339844
[23:06:23.805] iteration 2440 : loss : 378.279877, loss_ce: 0.019626, loss_kd: 1888.964844
[23:06:29.418] iteration 2450 : loss : 412.745880, loss_ce: 0.025588, loss_kd: 2061.239746
[23:06:35.009] iteration 2460 : loss : 348.404358, loss_ce: 0.021887, loss_kd: 1739.557373
[23:06:40.622] iteration 2470 : loss : 352.078308, loss_ce: 0.018613, loss_kd: 1757.910278
[23:06:46.231] iteration 2480 : loss : 428.825867, loss_ce: 0.025206, loss_kd: 2141.642578
[23:06:51.855] iteration 2490 : loss : 418.352356, loss_ce: 0.055046, loss_kd: 2089.210938
[23:06:57.463] iteration 2500 : loss : 335.455811, loss_ce: 0.022499, loss_kd: 1674.812134
[23:07:03.066] iteration 2510 : loss : 312.368378, loss_ce: 0.027503, loss_kd: 1559.383667
[23:07:08.664] iteration 2520 : loss : 440.505920, loss_ce: 0.024259, loss_kd: 2200.064209
[23:07:14.277] iteration 2530 : loss : 338.510681, loss_ce: 0.019904, loss_kd: 1690.116455
[23:07:19.879] iteration 2540 : loss : 290.290100, loss_ce: 0.027855, loss_kd: 1448.963013
[23:07:25.489] iteration 2550 : loss : 351.134155, loss_ce: 0.032327, loss_kd: 1753.157593
[23:07:31.093] iteration 2560 : loss : 358.174072, loss_ce: 0.021364, loss_kd: 1788.446411
[23:07:36.724] iteration 2570 : loss : 231.288971, loss_ce: 0.028112, loss_kd: 1154.004883
[23:07:42.337] iteration 2580 : loss : 374.290314, loss_ce: 0.024936, loss_kd: 1868.968628
[23:07:47.957] iteration 2590 : loss : 419.207123, loss_ce: 0.023790, loss_kd: 2093.590576
[23:07:53.573] iteration 2600 : loss : 389.618042, loss_ce: 0.032097, loss_kd: 1945.556519
[23:07:59.197] iteration 2610 : loss : 315.848145, loss_ce: 0.021893, loss_kd: 1576.747070
[23:08:04.793] iteration 2620 : loss : 262.442383, loss_ce: 0.033109, loss_kd: 1309.748535
[23:08:10.413] iteration 2630 : loss : 367.531647, loss_ce: 0.029703, loss_kd: 1835.168091
[23:08:16.017] iteration 2640 : loss : 294.975677, loss_ce: 0.023679, loss_kd: 1472.378906
[23:08:21.648] iteration 2650 : loss : 324.077301, loss_ce: 0.023430, loss_kd: 1617.902466
[23:08:27.257] iteration 2660 : loss : 310.057678, loss_ce: 0.019493, loss_kd: 1547.820190
[23:08:32.881] iteration 2670 : loss : 261.675110, loss_ce: 0.023876, loss_kd: 1305.903320
[23:08:38.495] iteration 2680 : loss : 406.234253, loss_ce: 0.019663, loss_kd: 2028.676514
[23:08:44.111] iteration 2690 : loss : 399.920166, loss_ce: 0.020066, loss_kd: 1997.158447
[23:08:49.736] iteration 2700 : loss : 302.953217, loss_ce: 0.022171, loss_kd: 1512.321289
[23:08:55.350] iteration 2710 : loss : 288.373352, loss_ce: 0.029481, loss_kd: 1439.383423
[23:09:00.978] iteration 2720 : loss : 372.496216, loss_ce: 0.014747, loss_kd: 1860.005127
[23:09:06.586] iteration 2730 : loss : 296.147736, loss_ce: 0.030009, loss_kd: 1478.271606
[23:09:12.190] iteration 2740 : loss : 330.276154, loss_ce: 0.023593, loss_kd: 1648.880005
[23:09:17.811] iteration 2750 : loss : 302.699585, loss_ce: 0.032871, loss_kd: 1511.013184
[23:09:23.429] iteration 2760 : loss : 374.216217, loss_ce: 0.034848, loss_kd: 1868.584351
[23:09:29.054] iteration 2770 : loss : 334.637085, loss_ce: 0.032809, loss_kd: 1670.666992
[23:09:34.647] iteration 2780 : loss : 317.855591, loss_ce: 0.024103, loss_kd: 1586.799561
[23:09:40.264] iteration 2790 : loss : 344.413696, loss_ce: 0.031109, loss_kd: 1719.590576
[23:09:45.869] iteration 2800 : loss : 277.533203, loss_ce: 0.023213, loss_kd: 1385.208984
[23:09:51.500] iteration 2810 : loss : 314.347198, loss_ce: 0.031695, loss_kd: 1569.221924
[23:09:57.117] iteration 2820 : loss : 414.083069, loss_ce: 0.028702, loss_kd: 2067.935547
[23:10:02.731] iteration 2830 : loss : 283.904907, loss_ce: 0.026278, loss_kd: 1417.041138
[23:10:08.349] iteration 2840 : loss : 375.626373, loss_ce: 0.024312, loss_kd: 1875.672119
[23:10:13.970] iteration 2850 : loss : 364.997131, loss_ce: 0.016099, loss_kd: 1822.449951
[23:10:19.571] iteration 2860 : loss : 339.154449, loss_ce: 0.028728, loss_kd: 1693.296021
[23:10:25.199] iteration 2870 : loss : 344.269623, loss_ce: 0.020187, loss_kd: 1718.829468
[23:10:30.815] iteration 2880 : loss : 269.687714, loss_ce: 0.024330, loss_kd: 1345.955078
[23:10:36.443] iteration 2890 : loss : 308.700165, loss_ce: 0.022657, loss_kd: 1541.041138
[23:10:42.054] iteration 2900 : loss : 336.261993, loss_ce: 0.024710, loss_kd: 1678.829712
[23:10:47.685] iteration 2910 : loss : 357.347687, loss_ce: 0.043249, loss_kd: 1784.261475
[23:10:53.298] iteration 2920 : loss : 390.227966, loss_ce: 0.026123, loss_kd: 1948.635742
[23:10:58.911] iteration 2930 : loss : 337.405823, loss_ce: 0.025657, loss_kd: 1684.561768
[23:11:04.519] iteration 2940 : loss : 314.164032, loss_ce: 0.022311, loss_kd: 1568.356934
[23:11:10.146] iteration 2950 : loss : 369.408417, loss_ce: 0.019641, loss_kd: 1844.575684
[23:11:15.758] iteration 2960 : loss : 221.041992, loss_ce: 0.025868, loss_kd: 1102.756958
[23:11:21.379] iteration 2970 : loss : 282.817169, loss_ce: 0.016400, loss_kd: 1411.619019
[23:11:26.985] iteration 2980 : loss : 397.014191, loss_ce: 0.016368, loss_kd: 1982.624390
[23:11:32.616] iteration 2990 : loss : 297.349243, loss_ce: 0.019170, loss_kd: 1484.295532
[23:11:38.227] iteration 3000 : loss : 309.054382, loss_ce: 0.026331, loss_kd: 1542.811890
[23:11:43.853] iteration 3010 : loss : 348.173859, loss_ce: 0.016944, loss_kd: 1738.455078
[23:11:49.462] iteration 3020 : loss : 372.865112, loss_ce: 0.024927, loss_kd: 1861.841064
[23:11:55.093] iteration 3030 : loss : 317.202606, loss_ce: 0.028738, loss_kd: 1583.584717
[23:12:00.695] iteration 3040 : loss : 280.901215, loss_ce: 0.016258, loss_kd: 1402.054565
[23:12:06.315] iteration 3050 : loss : 276.475464, loss_ce: 0.021021, loss_kd: 1379.881958
[23:12:11.918] iteration 3060 : loss : 387.319031, loss_ce: 0.024057, loss_kd: 1934.144897
[23:12:17.550] iteration 3070 : loss : 314.831024, loss_ce: 0.019063, loss_kd: 1571.703125
[23:12:23.160] iteration 3080 : loss : 244.209229, loss_ce: 0.024579, loss_kd: 1218.538452
[23:12:28.777] iteration 3090 : loss : 356.280029, loss_ce: 0.020586, loss_kd: 1778.904053
[23:12:34.376] iteration 3100 : loss : 287.646942, loss_ce: 0.016114, loss_kd: 1435.747314
[23:12:40.009] iteration 3110 : loss : 280.329224, loss_ce: 0.029246, loss_kd: 1399.058716
[23:12:45.614] iteration 3120 : loss : 230.347092, loss_ce: 0.024010, loss_kd: 1149.266479
[23:12:49.341] Running TPGM constraint optimization after epoch 3
[23:17:34.570] iteration 3130 : loss : 252.920959, loss_ce: 0.020783, loss_kd: 1262.128052
[23:17:40.095] iteration 3140 : loss : 287.129456, loss_ce: 0.014683, loss_kd: 1433.137939
[23:17:45.637] iteration 3150 : loss : 290.026703, loss_ce: 0.036942, loss_kd: 1447.623291
[23:17:51.171] iteration 3160 : loss : 355.226074, loss_ce: 0.039979, loss_kd: 1773.682617
[23:17:56.717] iteration 3170 : loss : 316.615967, loss_ce: 0.027225, loss_kd: 1580.633057
[23:18:02.249] iteration 3180 : loss : 359.937256, loss_ce: 0.022307, loss_kd: 1797.223022
[23:18:07.798] iteration 3190 : loss : 333.794006, loss_ce: 0.020844, loss_kd: 1666.478516
[23:18:13.342] iteration 3200 : loss : 263.811096, loss_ce: 0.017380, loss_kd: 1316.572021
[23:18:18.901] iteration 3210 : loss : 267.907837, loss_ce: 0.037336, loss_kd: 1337.070801
[23:18:24.459] iteration 3220 : loss : 270.678375, loss_ce: 0.021952, loss_kd: 1350.898804
[23:18:30.025] iteration 3230 : loss : 287.831390, loss_ce: 0.033911, loss_kd: 1436.682617
[23:18:35.577] iteration 3240 : loss : 324.096863, loss_ce: 0.025543, loss_kd: 1618.022095
[23:18:41.150] iteration 3250 : loss : 310.347443, loss_ce: 0.016726, loss_kd: 1549.289429
[23:18:46.710] iteration 3260 : loss : 343.466858, loss_ce: 0.021894, loss_kd: 1714.871582
[23:18:52.287] iteration 3270 : loss : 321.340332, loss_ce: 0.014754, loss_kd: 1604.233154
[23:18:57.855] iteration 3280 : loss : 309.489624, loss_ce: 0.027118, loss_kd: 1544.970093
[23:19:03.434] iteration 3290 : loss : 305.999695, loss_ce: 0.024660, loss_kd: 1527.494751
[23:19:09.008] iteration 3300 : loss : 355.641144, loss_ce: 0.027403, loss_kd: 1775.732300
[23:19:14.597] iteration 3310 : loss : 309.061798, loss_ce: 0.032100, loss_kd: 1542.872070
[23:19:20.173] iteration 3320 : loss : 275.042389, loss_ce: 0.019693, loss_kd: 1372.746094
[23:19:25.758] iteration 3330 : loss : 335.214355, loss_ce: 0.022137, loss_kd: 1673.588013
[23:19:31.337] iteration 3340 : loss : 291.517120, loss_ce: 0.026241, loss_kd: 1455.119385
[23:19:36.932] iteration 3350 : loss : 336.539520, loss_ce: 0.031051, loss_kd: 1680.246582
[23:19:42.519] iteration 3360 : loss : 276.269165, loss_ce: 0.019837, loss_kd: 1378.909668
[23:19:48.113] iteration 3370 : loss : 270.999268, loss_ce: 0.024431, loss_kd: 1352.540771
[23:19:53.695] iteration 3380 : loss : 351.466888, loss_ce: 0.027988, loss_kd: 1754.861328
[23:19:59.286] iteration 3390 : loss : 338.466583, loss_ce: 0.022379, loss_kd: 1689.843750
[23:20:04.870] iteration 3400 : loss : 297.965424, loss_ce: 0.017400, loss_kd: 1487.367798
[23:20:10.465] iteration 3410 : loss : 284.229095, loss_ce: 0.021226, loss_kd: 1418.702393
[23:20:16.058] iteration 3420 : loss : 327.216766, loss_ce: 0.012976, loss_kd: 1633.620850
[23:20:21.663] iteration 3430 : loss : 367.980835, loss_ce: 0.033882, loss_kd: 1837.407349
[23:20:27.256] iteration 3440 : loss : 249.437134, loss_ce: 0.018830, loss_kd: 1244.685913
[23:20:32.857] iteration 3450 : loss : 210.142593, loss_ce: 0.030099, loss_kd: 1048.258057
[23:20:38.452] iteration 3460 : loss : 288.693115, loss_ce: 0.019358, loss_kd: 1441.020996
[23:20:44.051] iteration 3470 : loss : 242.866409, loss_ce: 0.034856, loss_kd: 1211.851562
[23:20:49.648] iteration 3480 : loss : 265.832001, loss_ce: 0.025267, loss_kd: 1326.673950
[23:20:55.253] iteration 3490 : loss : 378.457214, loss_ce: 0.019556, loss_kd: 1889.831055
[23:21:00.843] iteration 3500 : loss : 292.838867, loss_ce: 0.011280, loss_kd: 1461.702026
[23:21:06.452] iteration 3510 : loss : 307.000793, loss_ce: 0.032437, loss_kd: 1532.538330
[23:21:12.044] iteration 3520 : loss : 344.610321, loss_ce: 0.016508, loss_kd: 1720.645752
[23:21:17.643] iteration 3530 : loss : 411.595306, loss_ce: 0.023323, loss_kd: 2055.533203
[23:21:23.249] iteration 3540 : loss : 316.166656, loss_ce: 0.030572, loss_kd: 1578.347412
[23:21:28.865] iteration 3550 : loss : 304.573914, loss_ce: 0.024125, loss_kd: 1520.376221
[23:21:34.467] iteration 3560 : loss : 328.168823, loss_ce: 0.027341, loss_kd: 1638.358154
[23:21:40.073] iteration 3570 : loss : 259.652832, loss_ce: 0.022761, loss_kd: 1295.812134
[23:21:45.669] iteration 3580 : loss : 255.432892, loss_ce: 0.037597, loss_kd: 1274.688965
[23:21:51.286] iteration 3590 : loss : 243.748047, loss_ce: 0.029889, loss_kd: 1216.313843
[23:21:56.902] iteration 3600 : loss : 274.845184, loss_ce: 0.023237, loss_kd: 1371.699829
[23:22:02.517] iteration 3610 : loss : 338.889862, loss_ce: 0.021175, loss_kd: 1691.978882
[23:22:08.129] iteration 3620 : loss : 278.168762, loss_ce: 0.020188, loss_kd: 1388.396362
[23:22:13.755] iteration 3630 : loss : 262.874939, loss_ce: 0.023096, loss_kd: 1311.926270
[23:22:19.368] iteration 3640 : loss : 269.445404, loss_ce: 0.015166, loss_kd: 1344.790649
[23:22:24.985] iteration 3650 : loss : 266.727539, loss_ce: 0.021557, loss_kd: 1331.152954
[23:22:30.581] iteration 3660 : loss : 329.306274, loss_ce: 0.030248, loss_kd: 1644.058716
[23:22:36.197] iteration 3670 : loss : 225.558792, loss_ce: 0.014544, loss_kd: 1125.320312
[23:22:41.801] iteration 3680 : loss : 227.769394, loss_ce: 0.030731, loss_kd: 1136.392334
[23:22:47.432] iteration 3690 : loss : 312.164917, loss_ce: 0.018060, loss_kd: 1558.344360
[23:22:53.034] iteration 3700 : loss : 310.658600, loss_ce: 0.016786, loss_kd: 1550.850830
[23:22:58.650] iteration 3710 : loss : 285.954559, loss_ce: 0.032956, loss_kd: 1427.333496
[23:23:04.251] iteration 3720 : loss : 374.052155, loss_ce: 0.024443, loss_kd: 1867.817505
[23:23:09.858] iteration 3730 : loss : 231.650864, loss_ce: 0.024095, loss_kd: 1155.807007
[23:23:15.457] iteration 3740 : loss : 299.463501, loss_ce: 0.023092, loss_kd: 1494.752197
[23:23:21.077] iteration 3750 : loss : 316.613007, loss_ce: 0.020238, loss_kd: 1580.626099
[23:23:26.675] iteration 3760 : loss : 265.738434, loss_ce: 0.022907, loss_kd: 1326.239014
[23:23:32.285] iteration 3770 : loss : 304.032318, loss_ce: 0.022811, loss_kd: 1517.720581
[23:23:37.887] iteration 3780 : loss : 297.782227, loss_ce: 0.019430, loss_kd: 1486.462280
[23:23:43.501] iteration 3790 : loss : 323.847015, loss_ce: 0.019088, loss_kd: 1616.788696
[23:23:49.101] iteration 3800 : loss : 338.312012, loss_ce: 0.016070, loss_kd: 1689.077881
[23:23:54.711] iteration 3810 : loss : 235.883514, loss_ce: 0.022003, loss_kd: 1176.938965
[23:24:00.324] iteration 3820 : loss : 275.538971, loss_ce: 0.025062, loss_kd: 1375.223755
[23:24:05.951] iteration 3830 : loss : 274.421936, loss_ce: 0.026895, loss_kd: 1369.614014
[23:24:11.552] iteration 3840 : loss : 218.336517, loss_ce: 0.030535, loss_kd: 1089.234131
[23:24:17.166] iteration 3850 : loss : 329.322357, loss_ce: 0.027813, loss_kd: 1644.125244
[23:24:22.762] iteration 3860 : loss : 310.272491, loss_ce: 0.035611, loss_kd: 1548.897461
[23:24:28.368] iteration 3870 : loss : 318.581360, loss_ce: 0.020969, loss_kd: 1590.463013
[23:24:33.963] iteration 3880 : loss : 360.774689, loss_ce: 0.031747, loss_kd: 1801.413208
[23:24:39.570] iteration 3890 : loss : 251.856964, loss_ce: 0.022556, loss_kd: 1256.817627
[23:24:45.190] iteration 3900 : loss : 303.630890, loss_ce: 0.021387, loss_kd: 1515.733521
[23:24:50.803] iteration 3910 : loss : 246.927124, loss_ce: 0.018966, loss_kd: 1232.172852
[23:24:56.402] iteration 3920 : loss : 334.549774, loss_ce: 0.012946, loss_kd: 1670.362427
[23:25:01.999] iteration 3930 : loss : 254.626587, loss_ce: 0.020982, loss_kd: 1270.692139
[23:25:07.594] iteration 3940 : loss : 249.729721, loss_ce: 0.019689, loss_kd: 1246.168457
[23:25:13.194] iteration 3950 : loss : 290.407501, loss_ce: 0.020481, loss_kd: 1449.579346
[23:25:18.788] iteration 3960 : loss : 348.707397, loss_ce: 0.017387, loss_kd: 1741.082520
[23:25:24.392] iteration 3970 : loss : 228.795197, loss_ce: 0.027050, loss_kd: 1141.547363
[23:25:29.983] iteration 3980 : loss : 219.243835, loss_ce: 0.015658, loss_kd: 1093.755005
[23:25:35.582] iteration 3990 : loss : 284.437622, loss_ce: 0.026734, loss_kd: 1419.719971
[23:25:41.176] iteration 4000 : loss : 262.686188, loss_ce: 0.024396, loss_kd: 1310.963501
[23:25:46.783] iteration 4010 : loss : 257.152496, loss_ce: 0.032971, loss_kd: 1283.308838
[23:25:52.372] iteration 4020 : loss : 229.584106, loss_ce: 0.028183, loss_kd: 1145.442017
[23:25:57.978] iteration 4030 : loss : 234.436859, loss_ce: 0.012857, loss_kd: 1169.760376
[23:26:03.569] iteration 4040 : loss : 266.953857, loss_ce: 0.023956, loss_kd: 1332.308838
[23:26:09.168] iteration 4050 : loss : 374.059937, loss_ce: 0.030320, loss_kd: 1867.600220
[23:26:14.763] iteration 4060 : loss : 374.879669, loss_ce: 0.036487, loss_kd: 1871.899292
[23:26:20.361] iteration 4070 : loss : 258.754120, loss_ce: 0.028724, loss_kd: 1291.293701
[23:26:25.953] iteration 4080 : loss : 251.438553, loss_ce: 0.028281, loss_kd: 1254.750488
[23:26:31.556] iteration 4090 : loss : 281.206146, loss_ce: 0.021924, loss_kd: 1403.550903
[23:26:37.142] iteration 4100 : loss : 266.031677, loss_ce: 0.023221, loss_kd: 1327.736450
[23:26:42.740] iteration 4110 : loss : 293.886383, loss_ce: 0.020603, loss_kd: 1466.936279
[23:26:48.326] iteration 4120 : loss : 270.263824, loss_ce: 0.026003, loss_kd: 1348.863770
[23:26:53.917] iteration 4130 : loss : 210.158630, loss_ce: 0.020634, loss_kd: 1048.312500
[23:26:59.506] iteration 4140 : loss : 250.600632, loss_ce: 0.026401, loss_kd: 1250.535522
[23:27:05.102] iteration 4150 : loss : 221.489517, loss_ce: 0.022103, loss_kd: 1104.995117
[23:27:10.683] iteration 4160 : loss : 253.090225, loss_ce: 0.023765, loss_kd: 1262.982788
[23:27:28.878] iteration 4170 : loss : 375.351044, loss_ce: 0.034630, loss_kd: 1874.290771
[23:27:34.414] iteration 4180 : loss : 281.428955, loss_ce: 0.021803, loss_kd: 1404.712769
[23:27:39.971] iteration 4190 : loss : 486.873993, loss_ce: 0.018404, loss_kd: 2431.900146
[23:27:45.509] iteration 4200 : loss : 257.790100, loss_ce: 0.031951, loss_kd: 1286.492188
[23:27:51.065] iteration 4210 : loss : 281.139679, loss_ce: 0.023115, loss_kd: 1403.292114
[23:27:56.608] iteration 4220 : loss : 374.067383, loss_ce: 0.028995, loss_kd: 1867.862305
[23:28:02.165] iteration 4230 : loss : 231.876114, loss_ce: 0.024168, loss_kd: 1156.922363
[23:28:07.712] iteration 4240 : loss : 200.252762, loss_ce: 0.026213, loss_kd: 998.830933
[23:28:13.275] iteration 4250 : loss : 196.997986, loss_ce: 0.023221, loss_kd: 982.535461
[23:28:18.830] iteration 4260 : loss : 269.866058, loss_ce: 0.020700, loss_kd: 1346.828003
[23:28:24.392] iteration 4270 : loss : 226.016144, loss_ce: 0.026750, loss_kd: 1127.599365
[23:28:29.948] iteration 4280 : loss : 302.758759, loss_ce: 0.041766, loss_kd: 1511.284180
[23:28:35.513] iteration 4290 : loss : 201.024094, loss_ce: 0.026105, loss_kd: 1002.685364
[23:28:41.070] iteration 4300 : loss : 263.174896, loss_ce: 0.019235, loss_kd: 1313.452148
[23:28:46.647] iteration 4310 : loss : 276.165802, loss_ce: 0.028458, loss_kd: 1378.340332
[23:28:52.210] iteration 4320 : loss : 259.373840, loss_ce: 0.024445, loss_kd: 1294.437256
[23:28:57.785] iteration 4330 : loss : 280.077393, loss_ce: 0.031706, loss_kd: 1397.938477
[23:29:03.345] iteration 4340 : loss : 326.779968, loss_ce: 0.023013, loss_kd: 1631.477173
[23:29:08.924] iteration 4350 : loss : 270.908356, loss_ce: 0.024671, loss_kd: 1352.045654
[23:29:14.483] iteration 4360 : loss : 226.077621, loss_ce: 0.022667, loss_kd: 1127.966675
[23:29:20.063] iteration 4370 : loss : 320.949768, loss_ce: 0.033725, loss_kd: 1602.277954
[23:29:25.628] iteration 4380 : loss : 235.344284, loss_ce: 0.020016, loss_kd: 1174.277588
[23:29:31.198] iteration 4390 : loss : 254.073776, loss_ce: 0.024348, loss_kd: 1267.873779
[23:29:36.759] iteration 4400 : loss : 263.353088, loss_ce: 0.019410, loss_kd: 1314.313354
[23:29:42.340] iteration 4410 : loss : 323.496735, loss_ce: 0.029716, loss_kd: 1614.986084
[23:29:47.906] iteration 4420 : loss : 285.905396, loss_ce: 0.013522, loss_kd: 1427.099121
[23:29:53.483] iteration 4430 : loss : 323.589142, loss_ce: 0.016120, loss_kd: 1615.488647
[23:29:59.051] iteration 4440 : loss : 283.860474, loss_ce: 0.022109, loss_kd: 1416.832153
[23:30:04.643] iteration 4450 : loss : 250.402222, loss_ce: 0.023954, loss_kd: 1249.557129
[23:30:10.211] iteration 4460 : loss : 221.965820, loss_ce: 0.028598, loss_kd: 1107.371582
[23:30:15.786] iteration 4470 : loss : 280.808319, loss_ce: 0.013588, loss_kd: 1401.613403
[23:30:21.357] iteration 4480 : loss : 217.520340, loss_ce: 0.040272, loss_kd: 1085.125366
[23:30:26.945] iteration 4490 : loss : 274.229462, loss_ce: 0.017717, loss_kd: 1368.672363
[23:30:32.514] iteration 4500 : loss : 229.550858, loss_ce: 0.021188, loss_kd: 1145.303589
[23:30:38.102] iteration 4510 : loss : 294.262238, loss_ce: 0.020211, loss_kd: 1468.836060
[23:30:43.672] iteration 4520 : loss : 293.499115, loss_ce: 0.028274, loss_kd: 1465.027344
[23:30:49.254] iteration 4530 : loss : 299.884094, loss_ce: 0.034943, loss_kd: 1496.959961
[23:30:54.826] iteration 4540 : loss : 383.173035, loss_ce: 0.015891, loss_kd: 1913.417236
[23:31:00.410] iteration 4550 : loss : 247.921082, loss_ce: 0.031160, loss_kd: 1237.141479
[23:31:05.984] iteration 4560 : loss : 219.640717, loss_ce: 0.026660, loss_kd: 1095.722778
[23:31:11.576] iteration 4570 : loss : 229.507019, loss_ce: 0.022205, loss_kd: 1145.090210
[23:31:17.140] iteration 4580 : loss : 264.309387, loss_ce: 0.017989, loss_kd: 1319.071289
[23:31:22.725] iteration 4590 : loss : 248.634842, loss_ce: 0.016484, loss_kd: 1240.769287
[23:31:28.285] iteration 4600 : loss : 235.318146, loss_ce: 0.017520, loss_kd: 1174.009644
[23:31:33.873] iteration 4610 : loss : 234.190445, loss_ce: 0.018091, loss_kd: 1168.504395
[23:31:39.445] iteration 4620 : loss : 276.788086, loss_ce: 0.040817, loss_kd: 1381.495605
[23:31:45.026] iteration 4630 : loss : 288.351379, loss_ce: 0.021812, loss_kd: 1439.288818
[23:31:50.602] iteration 4640 : loss : 242.333420, loss_ce: 0.029204, loss_kd: 1209.198730
[23:31:56.187] iteration 4650 : loss : 194.913559, loss_ce: 0.023292, loss_kd: 972.121338
[23:32:01.762] iteration 4660 : loss : 226.479309, loss_ce: 0.031849, loss_kd: 1129.933105
[23:32:07.346] iteration 4670 : loss : 262.570496, loss_ce: 0.024221, loss_kd: 1310.399414
[23:32:12.912] iteration 4680 : loss : 232.210114, loss_ce: 0.029045, loss_kd: 1158.621704
[23:32:18.499] iteration 4690 : loss : 232.956146, loss_ce: 0.023157, loss_kd: 1162.342407
[23:32:24.065] iteration 4700 : loss : 208.242554, loss_ce: 0.016109, loss_kd: 1038.780518
[23:32:29.645] iteration 4710 : loss : 244.297836, loss_ce: 0.029250, loss_kd: 1218.999146
[23:32:35.212] iteration 4720 : loss : 290.795135, loss_ce: 0.018426, loss_kd: 1451.501831
[23:32:40.789] iteration 4730 : loss : 282.116730, loss_ce: 0.032228, loss_kd: 1408.110718
[23:32:46.357] iteration 4740 : loss : 193.024567, loss_ce: 0.020266, loss_kd: 962.663818
[23:32:51.944] iteration 4750 : loss : 211.480194, loss_ce: 0.033847, loss_kd: 1054.930054
[23:32:57.518] iteration 4760 : loss : 300.996399, loss_ce: 0.041315, loss_kd: 1502.545044
[23:33:03.101] iteration 4770 : loss : 331.298615, loss_ce: 0.022719, loss_kd: 1654.053223
[23:33:08.679] iteration 4780 : loss : 267.990204, loss_ce: 0.016420, loss_kd: 1337.524902
[23:33:14.260] iteration 4790 : loss : 358.827057, loss_ce: 0.033650, loss_kd: 1791.658691
[23:33:19.827] iteration 4800 : loss : 199.492569, loss_ce: 0.040427, loss_kd: 994.995361
[23:33:25.411] iteration 4810 : loss : 229.790939, loss_ce: 0.018633, loss_kd: 1146.461670
[23:33:30.986] iteration 4820 : loss : 288.222900, loss_ce: 0.017396, loss_kd: 1438.691772
[23:33:36.571] iteration 4830 : loss : 275.565094, loss_ce: 0.018791, loss_kd: 1375.397461
[23:33:42.167] iteration 4840 : loss : 289.595673, loss_ce: 0.020604, loss_kd: 1445.517456
[23:33:47.752] iteration 4850 : loss : 281.087280, loss_ce: 0.021173, loss_kd: 1403.017578
[23:33:53.325] iteration 4860 : loss : 302.087585, loss_ce: 0.030580, loss_kd: 1507.965576
[23:33:58.916] iteration 4870 : loss : 259.716492, loss_ce: 0.031969, loss_kd: 1296.117310
[23:34:04.488] iteration 4880 : loss : 235.733566, loss_ce: 0.021415, loss_kd: 1176.242310
[23:34:10.071] iteration 4890 : loss : 214.344879, loss_ce: 0.022327, loss_kd: 1069.293823
[23:34:15.648] iteration 4900 : loss : 223.585068, loss_ce: 0.027551, loss_kd: 1115.407593
[23:34:21.235] iteration 4910 : loss : 203.550674, loss_ce: 0.029124, loss_kd: 1015.174255
[23:34:26.805] iteration 4920 : loss : 201.582565, loss_ce: 0.031977, loss_kd: 1005.453796
[23:34:32.386] iteration 4930 : loss : 238.265930, loss_ce: 0.022070, loss_kd: 1188.887451
[23:34:37.956] iteration 4940 : loss : 269.170715, loss_ce: 0.027701, loss_kd: 1343.407104
[23:34:43.528] iteration 4950 : loss : 210.436020, loss_ce: 0.025462, loss_kd: 1049.737793
[23:34:49.111] iteration 4960 : loss : 316.927216, loss_ce: 0.015570, loss_kd: 1582.198608
[23:34:54.696] iteration 4970 : loss : 290.749634, loss_ce: 0.019770, loss_kd: 1451.258423
[23:35:00.269] iteration 4980 : loss : 244.213913, loss_ce: 0.019723, loss_kd: 1218.602051
[23:35:05.850] iteration 4990 : loss : 236.401047, loss_ce: 0.029752, loss_kd: 1179.547485
[23:35:11.423] iteration 5000 : loss : 263.606110, loss_ce: 0.017563, loss_kd: 1315.575684
[23:35:17.003] iteration 5010 : loss : 233.927933, loss_ce: 0.028804, loss_kd: 1167.167603
[23:35:22.574] iteration 5020 : loss : 282.570343, loss_ce: 0.020563, loss_kd: 1410.408081
[23:35:28.157] iteration 5030 : loss : 367.458618, loss_ce: 0.026805, loss_kd: 1834.831543
[23:35:33.739] iteration 5040 : loss : 345.176697, loss_ce: 0.022804, loss_kd: 1723.436523
[23:35:39.318] iteration 5050 : loss : 349.049072, loss_ce: 0.045367, loss_kd: 1742.754883
[23:35:44.888] iteration 5060 : loss : 186.970917, loss_ce: 0.024225, loss_kd: 932.420532
[23:35:50.470] iteration 5070 : loss : 242.256790, loss_ce: 0.016150, loss_kd: 1208.866333
[23:35:56.029] iteration 5080 : loss : 284.626617, loss_ce: 0.029776, loss_kd: 1420.688232
[23:36:01.608] iteration 5090 : loss : 289.991028, loss_ce: 0.016645, loss_kd: 1447.527588
[23:36:07.174] iteration 5100 : loss : 269.256897, loss_ce: 0.017615, loss_kd: 1343.832031
[23:36:12.767] iteration 5110 : loss : 258.760864, loss_ce: 0.021143, loss_kd: 1291.334106
[23:36:18.339] iteration 5120 : loss : 181.268661, loss_ce: 0.032789, loss_kd: 903.892456
[23:36:23.925] iteration 5130 : loss : 324.959686, loss_ce: 0.019876, loss_kd: 1622.384766
[23:36:29.495] iteration 5140 : loss : 221.075546, loss_ce: 0.023244, loss_kd: 1102.926392
[23:36:35.071] iteration 5150 : loss : 254.086838, loss_ce: 0.016788, loss_kd: 1267.997559
[23:36:40.643] iteration 5160 : loss : 293.150604, loss_ce: 0.019300, loss_kd: 1463.311890
[23:36:46.231] iteration 5170 : loss : 214.774658, loss_ce: 0.030136, loss_kd: 1071.402466
[23:36:51.800] iteration 5180 : loss : 244.878891, loss_ce: 0.030838, loss_kd: 1221.967773
[23:36:57.379] iteration 5190 : loss : 237.204163, loss_ce: 0.017871, loss_kd: 1183.595947
[23:37:02.950] iteration 5200 : loss : 216.802933, loss_ce: 0.021382, loss_kd: 1081.583374
[23:37:08.238] iteration 5210 : loss : 274.874878, loss_ce: 0.026621, loss_kd: 1371.900391
[23:37:09.037] save model to ./debug_fixed_tpgm\continual_surgical_tpgm_epoch_4.pth
[23:37:09.040] Running TPGM constraint optimization after epoch 5
[23:42:17.403] iteration 5220 : loss : 216.927948, loss_ce: 0.026178, loss_kd: 1082.179199
[23:42:22.928] iteration 5230 : loss : 298.987122, loss_ce: 0.029297, loss_kd: 1492.410278
[23:42:28.446] iteration 5240 : loss : 290.792633, loss_ce: 0.017078, loss_kd: 1451.488647
[23:42:33.987] iteration 5250 : loss : 281.301208, loss_ce: 0.019218, loss_kd: 1404.090332
[23:42:39.516] iteration 5260 : loss : 230.682358, loss_ce: 0.025703, loss_kd: 1150.958374
[23:42:45.059] iteration 5270 : loss : 227.076431, loss_ce: 0.027419, loss_kd: 1132.935547
[23:42:50.588] iteration 5280 : loss : 202.095505, loss_ce: 0.031274, loss_kd: 1008.035095
[23:42:56.130] iteration 5290 : loss : 215.415894, loss_ce: 0.016679, loss_kd: 1074.593628
[23:43:01.661] iteration 5300 : loss : 239.776199, loss_ce: 0.029778, loss_kd: 1196.467285
[23:43:07.205] iteration 5310 : loss : 244.984665, loss_ce: 0.018072, loss_kd: 1222.495850
[23:43:12.739] iteration 5320 : loss : 266.914032, loss_ce: 0.021130, loss_kd: 1332.121704
[23:43:18.290] iteration 5330 : loss : 253.194855, loss_ce: 0.025904, loss_kd: 1263.525879
[23:43:23.827] iteration 5340 : loss : 218.755875, loss_ce: 0.034974, loss_kd: 1091.354248
[23:43:29.377] iteration 5350 : loss : 189.461151, loss_ce: 0.024352, loss_kd: 944.880737
[23:43:34.918] iteration 5360 : loss : 200.816986, loss_ce: 0.034817, loss_kd: 1001.648560
[23:43:40.477] iteration 5370 : loss : 273.235992, loss_ce: 0.013751, loss_kd: 1363.722290
[23:43:46.017] iteration 5380 : loss : 234.838196, loss_ce: 0.014639, loss_kd: 1171.787842
[23:43:51.577] iteration 5390 : loss : 242.964111, loss_ce: 0.029323, loss_kd: 1212.352783
[23:43:57.125] iteration 5400 : loss : 243.804703, loss_ce: 0.035956, loss_kd: 1216.601440
[23:44:02.686] iteration 5410 : loss : 288.271454, loss_ce: 0.025670, loss_kd: 1438.888916
[23:44:08.239] iteration 5420 : loss : 227.660858, loss_ce: 0.029296, loss_kd: 1135.861084
[23:44:13.802] iteration 5430 : loss : 256.032745, loss_ce: 0.019447, loss_kd: 1277.801392
[23:44:19.355] iteration 5440 : loss : 249.907486, loss_ce: 0.017196, loss_kd: 1247.075806
[23:44:24.918] iteration 5450 : loss : 177.738831, loss_ce: 0.017131, loss_kd: 886.230591
[23:44:30.484] iteration 5460 : loss : 294.055786, loss_ce: 0.015333, loss_kd: 1467.823120
[23:44:36.056] iteration 5470 : loss : 328.536133, loss_ce: 0.032002, loss_kd: 1640.225464
[23:44:41.618] iteration 5480 : loss : 259.749573, loss_ce: 0.016240, loss_kd: 1296.296997
[23:44:47.185] iteration 5490 : loss : 234.482300, loss_ce: 0.034852, loss_kd: 1169.970581
[23:44:52.745] iteration 5500 : loss : 218.652039, loss_ce: 0.017498, loss_kd: 1090.827881
[23:44:58.318] iteration 5510 : loss : 222.477020, loss_ce: 0.014744, loss_kd: 1109.950073
[23:45:03.875] iteration 5520 : loss : 266.689240, loss_ce: 0.017863, loss_kd: 1330.972778
[23:45:09.454] iteration 5530 : loss : 258.464966, loss_ce: 0.024943, loss_kd: 1289.883301
[23:45:15.014] iteration 5540 : loss : 249.928711, loss_ce: 0.019235, loss_kd: 1247.226196
[23:45:20.587] iteration 5550 : loss : 225.462082, loss_ce: 0.018994, loss_kd: 1124.873535
[23:45:26.159] iteration 5560 : loss : 276.860931, loss_ce: 0.025942, loss_kd: 1381.833130
[23:45:31.737] iteration 5570 : loss : 271.002014, loss_ce: 0.019382, loss_kd: 1352.553345
[23:45:37.314] iteration 5580 : loss : 218.757874, loss_ce: 0.013879, loss_kd: 1091.307861
[23:45:42.899] iteration 5590 : loss : 159.426849, loss_ce: 0.018392, loss_kd: 794.700439
[23:45:48.470] iteration 5600 : loss : 260.028137, loss_ce: 0.012680, loss_kd: 1297.676270
[23:45:54.051] iteration 5610 : loss : 248.585938, loss_ce: 0.016914, loss_kd: 1240.445679
[23:45:59.625] iteration 5620 : loss : 301.704987, loss_ce: 0.022460, loss_kd: 1506.120605
[23:46:05.208] iteration 5630 : loss : 316.219391, loss_ce: 0.019651, loss_kd: 1578.667480
[23:46:10.780] iteration 5640 : loss : 240.419037, loss_ce: 0.017895, loss_kd: 1199.694946
[23:46:16.364] iteration 5650 : loss : 198.959854, loss_ce: 0.016922, loss_kd: 992.373047
[23:46:21.938] iteration 5660 : loss : 164.394562, loss_ce: 0.016411, loss_kd: 819.528992
[23:46:27.522] iteration 5670 : loss : 233.789688, loss_ce: 0.022444, loss_kd: 1166.506348
[23:46:33.096] iteration 5680 : loss : 206.354889, loss_ce: 0.018877, loss_kd: 1029.315308
[23:46:38.679] iteration 5690 : loss : 212.592529, loss_ce: 0.027607, loss_kd: 1060.532959
[23:46:44.252] iteration 5700 : loss : 251.272766, loss_ce: 0.015162, loss_kd: 1253.914429
[23:46:49.838] iteration 5710 : loss : 234.003845, loss_ce: 0.018099, loss_kd: 1167.582031
[23:46:55.408] iteration 5720 : loss : 232.206497, loss_ce: 0.026853, loss_kd: 1158.626465
[23:47:00.988] iteration 5730 : loss : 205.461868, loss_ce: 0.021182, loss_kd: 1024.821533
[23:47:06.557] iteration 5740 : loss : 243.381134, loss_ce: 0.013429, loss_kd: 1214.481689
[23:47:12.142] iteration 5750 : loss : 262.111481, loss_ce: 0.016022, loss_kd: 1308.075928
[23:47:17.725] iteration 5760 : loss : 334.462433, loss_ce: 0.020205, loss_kd: 1669.859863
[23:47:23.311] iteration 5770 : loss : 212.575928, loss_ce: 0.013284, loss_kd: 1060.436523
[23:47:28.879] iteration 5780 : loss : 293.792358, loss_ce: 0.034523, loss_kd: 1466.505859
[23:47:34.463] iteration 5790 : loss : 231.453644, loss_ce: 0.020625, loss_kd: 1154.809448
[23:47:40.032] iteration 5800 : loss : 289.534760, loss_ce: 0.012770, loss_kd: 1445.249023
[23:47:45.620] iteration 5810 : loss : 268.588165, loss_ce: 0.024827, loss_kd: 1340.483887
[23:47:51.193] iteration 5820 : loss : 218.847473, loss_ce: 0.018928, loss_kd: 1091.853882
[23:47:56.788] iteration 5830 : loss : 268.099152, loss_ce: 0.012861, loss_kd: 1338.064697
[23:48:02.364] iteration 5840 : loss : 209.814560, loss_ce: 0.025160, loss_kd: 1046.606445
[23:48:07.948] iteration 5850 : loss : 251.507706, loss_ce: 0.024636, loss_kd: 1255.061279
[23:48:13.520] iteration 5860 : loss : 227.106598, loss_ce: 0.023459, loss_kd: 1133.015137
[23:48:19.108] iteration 5870 : loss : 233.629547, loss_ce: 0.021004, loss_kd: 1165.717163
[23:48:24.677] iteration 5880 : loss : 198.444031, loss_ce: 0.022561, loss_kd: 989.798401
[23:48:30.253] iteration 5890 : loss : 218.966049, loss_ce: 0.016722, loss_kd: 1092.409180
[23:48:35.835] iteration 5900 : loss : 333.068726, loss_ce: 0.018988, loss_kd: 1662.929077
[23:48:41.424] iteration 5910 : loss : 252.150604, loss_ce: 0.023166, loss_kd: 1258.247070
[23:48:46.987] iteration 5920 : loss : 240.610519, loss_ce: 0.023250, loss_kd: 1200.591309
[23:48:52.571] iteration 5930 : loss : 293.651520, loss_ce: 0.018863, loss_kd: 1465.858765
[23:48:58.146] iteration 5940 : loss : 240.344055, loss_ce: 0.032252, loss_kd: 1199.253540
[23:49:03.731] iteration 5950 : loss : 278.789154, loss_ce: 0.026628, loss_kd: 1391.488281
[23:49:09.297] iteration 5960 : loss : 295.361328, loss_ce: 0.020904, loss_kd: 1474.344727
[23:49:14.884] iteration 5970 : loss : 273.320312, loss_ce: 0.022528, loss_kd: 1364.145996
[23:49:20.462] iteration 5980 : loss : 282.270020, loss_ce: 0.021797, loss_kd: 1408.882202
[23:49:26.048] iteration 5990 : loss : 229.222061, loss_ce: 0.025008, loss_kd: 1143.662109
[23:49:31.616] iteration 6000 : loss : 226.587143, loss_ce: 0.017720, loss_kd: 1130.500244
[23:49:37.201] iteration 6010 : loss : 198.847290, loss_ce: 0.027925, loss_kd: 991.772766
[23:49:42.768] iteration 6020 : loss : 216.639740, loss_ce: 0.015711, loss_kd: 1080.736572
[23:49:48.345] iteration 6030 : loss : 275.847687, loss_ce: 0.016194, loss_kd: 1376.793701
[23:49:53.926] iteration 6040 : loss : 279.346008, loss_ce: 0.022052, loss_kd: 1394.304810
[23:49:59.509] iteration 6050 : loss : 204.759995, loss_ce: 0.017553, loss_kd: 1021.419861
[23:50:05.084] iteration 6060 : loss : 203.346527, loss_ce: 0.028110, loss_kd: 1014.262085
[23:50:10.670] iteration 6070 : loss : 267.911377, loss_ce: 0.018139, loss_kd: 1337.113770
[23:50:16.249] iteration 6080 : loss : 214.598816, loss_ce: 0.014790, loss_kd: 1070.541748
[23:50:21.839] iteration 6090 : loss : 195.077240, loss_ce: 0.031971, loss_kd: 972.925049
[23:50:27.407] iteration 6100 : loss : 291.361877, loss_ce: 0.021038, loss_kd: 1454.413940
[23:50:32.995] iteration 6110 : loss : 280.589661, loss_ce: 0.021373, loss_kd: 1400.507202
[23:50:38.575] iteration 6120 : loss : 309.768616, loss_ce: 0.012122, loss_kd: 1546.415771
[23:50:44.160] iteration 6130 : loss : 182.139511, loss_ce: 0.012726, loss_kd: 908.292114
[23:50:49.728] iteration 6140 : loss : 230.084595, loss_ce: 0.013158, loss_kd: 1147.969727
[23:50:55.311] iteration 6150 : loss : 181.450760, loss_ce: 0.017575, loss_kd: 904.839355
[23:51:00.894] iteration 6160 : loss : 241.251755, loss_ce: 0.013680, loss_kd: 1203.775146
[23:51:06.479] iteration 6170 : loss : 189.170792, loss_ce: 0.026523, loss_kd: 943.442078
[23:51:12.048] iteration 6180 : loss : 284.366943, loss_ce: 0.015472, loss_kd: 1419.410645
[23:51:17.633] iteration 6190 : loss : 272.442108, loss_ce: 0.026520, loss_kd: 1359.776001
[23:51:23.201] iteration 6200 : loss : 231.472000, loss_ce: 0.017588, loss_kd: 1154.979004
[23:51:28.780] iteration 6210 : loss : 226.520721, loss_ce: 0.021433, loss_kd: 1130.184204
[23:51:34.351] iteration 6220 : loss : 242.045441, loss_ce: 0.017994, loss_kd: 1207.791870
[23:51:39.943] iteration 6230 : loss : 308.197510, loss_ce: 0.027689, loss_kd: 1538.541748
[23:51:45.512] iteration 6240 : loss : 176.690033, loss_ce: 0.028542, loss_kd: 880.999268
[23:51:51.088] iteration 6250 : loss : 221.108932, loss_ce: 0.022231, loss_kd: 1103.120850
[23:52:08.969] iteration 6260 : loss : 282.031982, loss_ce: 0.022380, loss_kd: 1407.762817
[23:52:14.517] iteration 6270 : loss : 196.234680, loss_ce: 0.024035, loss_kd: 978.731567
[23:52:20.049] iteration 6280 : loss : 192.439728, loss_ce: 0.025833, loss_kd: 959.750488
[23:52:25.599] iteration 6290 : loss : 242.175980, loss_ce: 0.025898, loss_kd: 1208.447266
[23:52:31.141] iteration 6300 : loss : 231.955612, loss_ce: 0.022454, loss_kd: 1157.346680
[23:52:36.701] iteration 6310 : loss : 240.777420, loss_ce: 0.014558, loss_kd: 1201.418823
[23:52:42.251] iteration 6320 : loss : 194.285461, loss_ce: 0.024907, loss_kd: 968.990417
[23:52:47.816] iteration 6330 : loss : 333.638336, loss_ce: 0.017217, loss_kd: 1665.786377
[23:52:53.371] iteration 6340 : loss : 187.996552, loss_ce: 0.017837, loss_kd: 937.574585
[23:52:58.936] iteration 6350 : loss : 245.602570, loss_ce: 0.016080, loss_kd: 1225.571167
[23:53:04.494] iteration 6360 : loss : 170.741409, loss_ce: 0.019515, loss_kd: 851.306274
[23:53:10.069] iteration 6370 : loss : 202.755753, loss_ce: 0.020480, loss_kd: 1011.350159
[23:53:15.627] iteration 6380 : loss : 246.108643, loss_ce: 0.023102, loss_kd: 1228.122803
[23:53:21.198] iteration 6390 : loss : 202.689697, loss_ce: 0.011414, loss_kd: 1011.059143
[23:53:26.758] iteration 6400 : loss : 212.924271, loss_ce: 0.039358, loss_kd: 1062.165649
[23:53:32.335] iteration 6410 : loss : 203.495804, loss_ce: 0.023178, loss_kd: 1015.018188
[23:53:37.895] iteration 6420 : loss : 229.128754, loss_ce: 0.018030, loss_kd: 1143.194702
[23:53:43.469] iteration 6430 : loss : 187.461319, loss_ce: 0.017025, loss_kd: 934.885742
[23:53:49.037] iteration 6440 : loss : 257.622589, loss_ce: 0.019219, loss_kd: 1285.699463
[23:53:54.610] iteration 6450 : loss : 234.012817, loss_ce: 0.024231, loss_kd: 1167.599854
[23:54:00.173] iteration 6460 : loss : 210.003311, loss_ce: 0.014968, loss_kd: 1047.597412
[23:54:05.746] iteration 6470 : loss : 182.347137, loss_ce: 0.012562, loss_kd: 909.330261
[23:54:11.306] iteration 6480 : loss : 205.440277, loss_ce: 0.022218, loss_kd: 1024.734619
[23:54:16.879] iteration 6490 : loss : 195.550507, loss_ce: 0.014516, loss_kd: 975.361938
[23:54:22.442] iteration 6500 : loss : 209.906647, loss_ce: 0.023232, loss_kd: 1047.091064
[23:54:28.025] iteration 6510 : loss : 204.669235, loss_ce: 0.032021, loss_kd: 1020.920898
[23:54:33.584] iteration 6520 : loss : 225.782501, loss_ce: 0.015706, loss_kd: 1126.503296
[23:54:39.164] iteration 6530 : loss : 186.684067, loss_ce: 0.026693, loss_kd: 930.973999
[23:54:44.730] iteration 6540 : loss : 235.438522, loss_ce: 0.041401, loss_kd: 1174.755737
[23:54:50.311] iteration 6550 : loss : 169.259048, loss_ce: 0.015953, loss_kd: 843.827454
[23:54:55.879] iteration 6560 : loss : 225.019836, loss_ce: 0.021362, loss_kd: 1122.668823
[23:55:01.463] iteration 6570 : loss : 204.671082, loss_ce: 0.018603, loss_kd: 1020.903503
[23:55:07.031] iteration 6580 : loss : 208.049026, loss_ce: 0.020075, loss_kd: 1037.814331
[23:55:12.618] iteration 6590 : loss : 270.877625, loss_ce: 0.023367, loss_kd: 1351.972046
[23:55:18.191] iteration 6600 : loss : 276.857910, loss_ce: 0.029687, loss_kd: 1381.854858
[23:55:23.782] iteration 6610 : loss : 199.318817, loss_ce: 0.024317, loss_kd: 994.136597
[23:55:29.354] iteration 6620 : loss : 205.395203, loss_ce: 0.028186, loss_kd: 1024.519775
[23:55:34.940] iteration 6630 : loss : 237.782639, loss_ce: 0.015139, loss_kd: 1186.478516
[23:55:40.521] iteration 6640 : loss : 225.944855, loss_ce: 0.019071, loss_kd: 1127.317627
[23:55:46.105] iteration 6650 : loss : 193.130814, loss_ce: 0.024225, loss_kd: 963.194824
[23:55:51.679] iteration 6660 : loss : 258.746887, loss_ce: 0.017364, loss_kd: 1291.322388
[23:55:57.269] iteration 6670 : loss : 175.108231, loss_ce: 0.017319, loss_kd: 873.140198
[23:56:02.851] iteration 6680 : loss : 210.845871, loss_ce: 0.019251, loss_kd: 1051.818726
[23:56:08.449] iteration 6690 : loss : 224.929703, loss_ce: 0.016122, loss_kd: 1122.183594
[23:56:14.026] iteration 6700 : loss : 318.053802, loss_ce: 0.014325, loss_kd: 1587.848267
[23:56:19.616] iteration 6710 : loss : 190.683960, loss_ce: 0.012492, loss_kd: 950.990173
[23:56:25.195] iteration 6720 : loss : 206.544098, loss_ce: 0.015972, loss_kd: 1030.236572
[23:56:30.785] iteration 6730 : loss : 298.733765, loss_ce: 0.015789, loss_kd: 1491.248535
[23:56:36.374] iteration 6740 : loss : 180.218735, loss_ce: 0.022604, loss_kd: 898.638245
[23:56:41.971] iteration 6750 : loss : 271.856262, loss_ce: 0.027287, loss_kd: 1356.835938
[23:56:47.565] iteration 6760 : loss : 213.473419, loss_ce: 0.025175, loss_kd: 1064.951538
[23:56:53.163] iteration 6770 : loss : 263.993439, loss_ce: 0.031547, loss_kd: 1317.490112
[23:56:58.747] iteration 6780 : loss : 202.465637, loss_ce: 0.041776, loss_kd: 1009.885132
[23:57:04.340] iteration 6790 : loss : 244.642807, loss_ce: 0.022258, loss_kd: 1220.763428
[23:57:09.920] iteration 6800 : loss : 209.208603, loss_ce: 0.032994, loss_kd: 1043.592529
[23:57:15.527] iteration 6810 : loss : 261.242401, loss_ce: 0.018229, loss_kd: 1303.780029
[23:57:21.112] iteration 6820 : loss : 235.797653, loss_ce: 0.021396, loss_kd: 1176.580444
[23:57:26.706] iteration 6830 : loss : 283.453644, loss_ce: 0.018152, loss_kd: 1414.797729
[23:57:32.299] iteration 6840 : loss : 284.395782, loss_ce: 0.017260, loss_kd: 1419.534180
[23:57:37.899] iteration 6850 : loss : 272.100494, loss_ce: 0.016632, loss_kd: 1358.013916
[23:57:43.495] iteration 6860 : loss : 178.360275, loss_ce: 0.032072, loss_kd: 889.372253
[23:57:49.095] iteration 6870 : loss : 248.702026, loss_ce: 0.031663, loss_kd: 1241.054810
[23:57:54.684] iteration 6880 : loss : 212.075760, loss_ce: 0.025678, loss_kd: 1057.939209
[23:58:00.289] iteration 6890 : loss : 231.785828, loss_ce: 0.023712, loss_kd: 1156.513916
[23:58:05.882] iteration 6900 : loss : 200.567230, loss_ce: 0.024807, loss_kd: 1000.260071
[23:58:11.490] iteration 6910 : loss : 215.696121, loss_ce: 0.015620, loss_kd: 1076.070312
[23:58:17.085] iteration 6920 : loss : 180.908752, loss_ce: 0.019890, loss_kd: 902.102905
[23:58:22.684] iteration 6930 : loss : 189.929672, loss_ce: 0.024528, loss_kd: 947.240845
[23:58:28.288] iteration 6940 : loss : 184.285187, loss_ce: 0.023983, loss_kd: 918.949646
[23:58:33.888] iteration 6950 : loss : 227.014862, loss_ce: 0.023920, loss_kd: 1132.639404
[23:58:39.483] iteration 6960 : loss : 207.494339, loss_ce: 0.017960, loss_kd: 1035.050903
[23:58:45.089] iteration 6970 : loss : 228.726303, loss_ce: 0.020812, loss_kd: 1141.178711
[23:58:50.685] iteration 6980 : loss : 256.034760, loss_ce: 0.036073, loss_kd: 1277.716797
[23:58:56.287] iteration 6990 : loss : 211.718323, loss_ce: 0.025832, loss_kd: 1056.174194
[23:59:01.885] iteration 7000 : loss : 178.270081, loss_ce: 0.017735, loss_kd: 888.908325
[23:59:07.481] iteration 7010 : loss : 202.250900, loss_ce: 0.011697, loss_kd: 1008.799072
[23:59:13.085] iteration 7020 : loss : 281.696472, loss_ce: 0.017123, loss_kd: 1406.038818
[23:59:18.691] iteration 7030 : loss : 228.024170, loss_ce: 0.031517, loss_kd: 1137.671143
[23:59:24.293] iteration 7040 : loss : 232.160278, loss_ce: 0.031184, loss_kd: 1158.323730
[23:59:29.901] iteration 7050 : loss : 298.159943, loss_ce: 0.018018, loss_kd: 1488.366211
[23:59:35.496] iteration 7060 : loss : 289.612274, loss_ce: 0.020496, loss_kd: 1445.618042
[23:59:41.100] iteration 7070 : loss : 153.910873, loss_ce: 0.017362, loss_kd: 767.156494
[23:59:46.694] iteration 7080 : loss : 204.628311, loss_ce: 0.021551, loss_kd: 1020.702515
[23:59:52.297] iteration 7090 : loss : 230.207962, loss_ce: 0.016295, loss_kd: 1148.596924
[23:59:57.891] iteration 7100 : loss : 198.334900, loss_ce: 0.016905, loss_kd: 989.250610
[00:00:03.487] iteration 7110 : loss : 224.601791, loss_ce: 0.024540, loss_kd: 1120.435913
[00:00:09.073] iteration 7120 : loss : 247.105515, loss_ce: 0.014556, loss_kd: 1233.084717
[00:00:14.682] iteration 7130 : loss : 262.840820, loss_ce: 0.028126, loss_kd: 1311.752319
[00:00:20.280] iteration 7140 : loss : 213.770752, loss_ce: 0.013580, loss_kd: 1066.363647
[00:00:25.912] iteration 7150 : loss : 132.989319, loss_ce: 0.024932, loss_kd: 662.526672
[00:00:31.504] iteration 7160 : loss : 195.757446, loss_ce: 0.016618, loss_kd: 976.361816
[00:00:37.112] iteration 7170 : loss : 186.090820, loss_ce: 0.016151, loss_kd: 928.023743
[00:00:42.694] iteration 7180 : loss : 185.615356, loss_ce: 0.017859, loss_kd: 925.633545
[00:00:48.290] iteration 7190 : loss : 192.018082, loss_ce: 0.021722, loss_kd: 957.642944
[00:00:53.870] iteration 7200 : loss : 196.443176, loss_ce: 0.021409, loss_kd: 979.800110
[00:00:59.462] iteration 7210 : loss : 204.627228, loss_ce: 0.013611, loss_kd: 1020.696899
[00:01:05.042] iteration 7220 : loss : 287.341156, loss_ce: 0.022595, loss_kd: 1434.257324
[00:01:10.633] iteration 7230 : loss : 214.453110, loss_ce: 0.033736, loss_kd: 1069.844604
[00:01:16.223] iteration 7240 : loss : 250.733810, loss_ce: 0.010270, loss_kd: 1251.268433
[00:01:21.814] iteration 7250 : loss : 236.086761, loss_ce: 0.015252, loss_kd: 1177.970581
[00:01:27.400] iteration 7260 : loss : 192.088821, loss_ce: 0.013473, loss_kd: 957.952332
[00:01:32.996] iteration 7270 : loss : 237.355545, loss_ce: 0.022638, loss_kd: 1184.302002
[00:01:38.575] iteration 7280 : loss : 222.363388, loss_ce: 0.021181, loss_kd: 1109.391602
[00:01:44.166] iteration 7290 : loss : 229.451187, loss_ce: 0.017765, loss_kd: 1144.812256
[00:01:46.761] Running TPGM constraint optimization after epoch 7
[00:06:35.774] iteration 7300 : loss : 228.053802, loss_ce: 0.021114, loss_kd: 1137.882202
[00:06:41.312] iteration 7310 : loss : 279.385742, loss_ce: 0.031489, loss_kd: 1394.485718
[00:06:46.839] iteration 7320 : loss : 219.335571, loss_ce: 0.021734, loss_kd: 1094.243286
[00:06:52.380] iteration 7330 : loss : 190.931595, loss_ce: 0.016852, loss_kd: 952.213867
[00:06:57.911] iteration 7340 : loss : 199.022141, loss_ce: 0.022784, loss_kd: 992.698059
[00:07:03.455] iteration 7350 : loss : 190.216370, loss_ce: 0.022692, loss_kd: 948.654541
[00:07:08.995] iteration 7360 : loss : 158.357437, loss_ce: 0.013793, loss_kd: 789.319458
[00:07:14.540] iteration 7370 : loss : 223.481033, loss_ce: 0.020062, loss_kd: 1114.955566
[00:07:20.083] iteration 7380 : loss : 242.292419, loss_ce: 0.018946, loss_kd: 1209.075928
[00:07:25.642] iteration 7390 : loss : 175.409607, loss_ce: 0.031484, loss_kd: 874.612244
[00:07:31.191] iteration 7400 : loss : 189.432693, loss_ce: 0.025535, loss_kd: 944.749146
[00:07:36.752] iteration 7410 : loss : 185.765259, loss_ce: 0.017775, loss_kd: 926.402100
[00:07:42.302] iteration 7420 : loss : 198.832916, loss_ce: 0.030896, loss_kd: 991.740112
[00:07:47.871] iteration 7430 : loss : 137.363266, loss_ce: 0.023540, loss_kd: 684.383240
[00:07:53.425] iteration 7440 : loss : 170.337692, loss_ce: 0.010270, loss_kd: 849.281067
[00:07:58.995] iteration 7450 : loss : 179.995041, loss_ce: 0.014779, loss_kd: 897.550293
[00:08:04.560] iteration 7460 : loss : 180.072159, loss_ce: 0.016636, loss_kd: 897.954224
[00:08:10.126] iteration 7470 : loss : 248.164459, loss_ce: 0.017834, loss_kd: 1238.376953
[00:08:15.682] iteration 7480 : loss : 176.054276, loss_ce: 0.021195, loss_kd: 877.819275
[00:08:21.259] iteration 7490 : loss : 200.420059, loss_ce: 0.023147, loss_kd: 999.664551
[00:08:26.827] iteration 7500 : loss : 197.054077, loss_ce: 0.018662, loss_kd: 982.851135
[00:08:32.411] iteration 7510 : loss : 200.999710, loss_ce: 0.027232, loss_kd: 1002.581970
[00:08:37.980] iteration 7520 : loss : 269.113831, loss_ce: 0.022729, loss_kd: 1342.935791
[00:08:43.553] iteration 7530 : loss : 213.482574, loss_ce: 0.017134, loss_kd: 1065.033203
[00:08:49.131] iteration 7540 : loss : 351.278015, loss_ce: 0.020696, loss_kd: 1753.992188
[00:08:54.717] iteration 7550 : loss : 252.341629, loss_ce: 0.016890, loss_kd: 1259.306396
[00:09:00.295] iteration 7560 : loss : 209.961426, loss_ce: 0.016952, loss_kd: 1047.409302
[00:09:05.880] iteration 7570 : loss : 154.245605, loss_ce: 0.023588, loss_kd: 768.783020
[00:09:11.464] iteration 7580 : loss : 151.140182, loss_ce: 0.026127, loss_kd: 753.223206
[00:09:17.056] iteration 7590 : loss : 189.435425, loss_ce: 0.017135, loss_kd: 944.772827
[00:09:22.652] iteration 7600 : loss : 193.961563, loss_ce: 0.020057, loss_kd: 967.365417
[00:09:28.248] iteration 7610 : loss : 223.750259, loss_ce: 0.015873, loss_kd: 1116.314331
[00:09:33.848] iteration 7620 : loss : 212.212219, loss_ce: 0.023730, loss_kd: 1058.651001
[00:09:39.452] iteration 7630 : loss : 234.340179, loss_ce: 0.025423, loss_kd: 1169.234619
[00:09:45.047] iteration 7640 : loss : 229.889816, loss_ce: 0.024514, loss_kd: 1146.989502
[00:09:50.649] iteration 7650 : loss : 267.452820, loss_ce: 0.013531, loss_kd: 1334.834595
[00:09:56.247] iteration 7660 : loss : 217.097580, loss_ce: 0.016810, loss_kd: 1083.048584
[00:10:01.851] iteration 7670 : loss : 207.538559, loss_ce: 0.017904, loss_kd: 1035.270630
[00:10:07.451] iteration 7680 : loss : 168.032806, loss_ce: 0.014792, loss_kd: 837.726746
[00:10:13.056] iteration 7690 : loss : 185.438065, loss_ce: 0.018982, loss_kd: 924.752197
[00:10:18.650] iteration 7700 : loss : 161.502289, loss_ce: 0.041865, loss_kd: 805.022949
[00:10:24.253] iteration 7710 : loss : 199.747269, loss_ce: 0.021722, loss_kd: 996.293823
[00:10:29.848] iteration 7720 : loss : 148.511581, loss_ce: 0.025462, loss_kd: 740.119263
[00:10:35.455] iteration 7730 : loss : 210.830597, loss_ce: 0.016048, loss_kd: 1051.722534
[00:10:41.044] iteration 7740 : loss : 192.646210, loss_ce: 0.022979, loss_kd: 960.803223
[00:10:46.655] iteration 7750 : loss : 174.371658, loss_ce: 0.022865, loss_kd: 869.400146
[00:10:52.254] iteration 7760 : loss : 172.459229, loss_ce: 0.023755, loss_kd: 859.832947
[00:10:57.854] iteration 7770 : loss : 187.706970, loss_ce: 0.022613, loss_kd: 936.142334
[00:11:03.452] iteration 7780 : loss : 140.934616, loss_ce: 0.022067, loss_kd: 702.244751
[00:11:09.065] iteration 7790 : loss : 218.462006, loss_ce: 0.019521, loss_kd: 1089.872437
[00:11:14.664] iteration 7800 : loss : 242.090851, loss_ce: 0.017019, loss_kd: 1208.052979
[00:11:20.290] iteration 7810 : loss : 187.597702, loss_ce: 0.022113, loss_kd: 935.558105
[00:11:25.898] iteration 7820 : loss : 170.352325, loss_ce: 0.018442, loss_kd: 849.297974
[00:11:31.516] iteration 7830 : loss : 192.861649, loss_ce: 0.024218, loss_kd: 961.900879
[00:11:37.121] iteration 7840 : loss : 200.257660, loss_ce: 0.025129, loss_kd: 998.850037
[00:11:42.738] iteration 7850 : loss : 274.401917, loss_ce: 0.021962, loss_kd: 1369.524536
[00:11:48.349] iteration 7860 : loss : 204.566422, loss_ce: 0.018695, loss_kd: 1020.396484
[00:11:53.967] iteration 7870 : loss : 195.818588, loss_ce: 0.019576, loss_kd: 976.672058
[00:11:59.573] iteration 7880 : loss : 205.778473, loss_ce: 0.020596, loss_kd: 1026.458130
[00:12:05.187] iteration 7890 : loss : 222.409027, loss_ce: 0.016501, loss_kd: 1109.589844
[00:12:10.810] iteration 7900 : loss : 201.783752, loss_ce: 0.017117, loss_kd: 1006.499390
[00:12:16.430] iteration 7910 : loss : 211.004364, loss_ce: 0.023269, loss_kd: 1052.597534
[00:12:22.033] iteration 7920 : loss : 175.465240, loss_ce: 0.019004, loss_kd: 874.907288
[00:12:27.641] iteration 7930 : loss : 168.819122, loss_ce: 0.013034, loss_kd: 841.667664
[00:12:33.253] iteration 7940 : loss : 203.111649, loss_ce: 0.025446, loss_kd: 1013.130859
[00:12:38.881] iteration 7950 : loss : 211.171585, loss_ce: 0.022340, loss_kd: 1053.410889
[00:12:44.501] iteration 7960 : loss : 212.973801, loss_ce: 0.028060, loss_kd: 1062.437378
[00:12:50.117] iteration 7970 : loss : 285.643036, loss_ce: 0.024307, loss_kd: 1425.778442
[00:12:55.740] iteration 7980 : loss : 179.436630, loss_ce: 0.025991, loss_kd: 894.717224
[00:13:01.359] iteration 7990 : loss : 199.914612, loss_ce: 0.019996, loss_kd: 997.123718
[00:13:06.973] iteration 8000 : loss : 189.959503, loss_ce: 0.024861, loss_kd: 947.361572
[00:13:12.593] iteration 8010 : loss : 218.339828, loss_ce: 0.017159, loss_kd: 1089.276978
[00:13:18.220] iteration 8020 : loss : 216.607803, loss_ce: 0.025096, loss_kd: 1080.551758
[00:13:23.850] iteration 8030 : loss : 171.495148, loss_ce: 0.020424, loss_kd: 855.062622
[00:13:29.481] iteration 8040 : loss : 205.237808, loss_ce: 0.023867, loss_kd: 1023.776367
[00:13:35.104] iteration 8050 : loss : 238.714630, loss_ce: 0.024529, loss_kd: 1191.109863
[00:13:40.722] iteration 8060 : loss : 232.571045, loss_ce: 0.020370, loss_kd: 1160.436401
[00:13:46.357] iteration 8070 : loss : 195.056671, loss_ce: 0.018354, loss_kd: 972.852539
[00:13:51.982] iteration 8080 : loss : 207.640961, loss_ce: 0.014172, loss_kd: 1035.783691
[00:13:57.613] iteration 8090 : loss : 211.382721, loss_ce: 0.016559, loss_kd: 1054.466919
[00:14:03.215] iteration 8100 : loss : 162.707047, loss_ce: 0.020580, loss_kd: 811.091858
[00:14:08.845] iteration 8110 : loss : 170.998077, loss_ce: 0.022215, loss_kd: 852.582458
[00:14:14.461] iteration 8120 : loss : 229.555511, loss_ce: 0.026825, loss_kd: 1145.364624
[00:14:20.098] iteration 8130 : loss : 206.221924, loss_ce: 0.023561, loss_kd: 1028.638062
[00:14:25.706] iteration 8140 : loss : 181.758621, loss_ce: 0.022568, loss_kd: 906.343933
[00:14:31.346] iteration 8150 : loss : 233.864426, loss_ce: 0.015828, loss_kd: 1166.905762
[00:14:36.971] iteration 8160 : loss : 193.078110, loss_ce: 0.016002, loss_kd: 962.955383
[00:14:42.603] iteration 8170 : loss : 204.077667, loss_ce: 0.020232, loss_kd: 1017.970947
[00:14:48.221] iteration 8180 : loss : 168.173248, loss_ce: 0.011369, loss_kd: 838.473694
[00:14:53.850] iteration 8190 : loss : 222.244751, loss_ce: 0.015301, loss_kd: 1108.802002
[00:14:59.467] iteration 8200 : loss : 219.222794, loss_ce: 0.013375, loss_kd: 1093.706299
[00:15:05.104] iteration 8210 : loss : 280.376770, loss_ce: 0.023188, loss_kd: 1399.462158
[00:15:10.733] iteration 8220 : loss : 218.193970, loss_ce: 0.013220, loss_kd: 1088.588257
[00:15:16.355] iteration 8230 : loss : 240.215042, loss_ce: 0.021380, loss_kd: 1198.620605
[00:15:21.978] iteration 8240 : loss : 184.234329, loss_ce: 0.026633, loss_kd: 918.798950
[00:15:27.612] iteration 8250 : loss : 179.083771, loss_ce: 0.014254, loss_kd: 893.012451
[00:15:33.223] iteration 8260 : loss : 165.364273, loss_ce: 0.016519, loss_kd: 824.404053
[00:15:38.850] iteration 8270 : loss : 225.287323, loss_ce: 0.015958, loss_kd: 1124.025146
[00:15:44.474] iteration 8280 : loss : 189.179672, loss_ce: 0.019618, loss_kd: 943.475525
[00:15:50.109] iteration 8290 : loss : 152.903214, loss_ce: 0.017198, loss_kd: 762.057007
[00:15:55.735] iteration 8300 : loss : 191.821152, loss_ce: 0.015560, loss_kd: 956.660156
[00:16:01.368] iteration 8310 : loss : 242.573044, loss_ce: 0.016375, loss_kd: 1210.380615
[00:16:06.999] iteration 8320 : loss : 203.235413, loss_ce: 0.025099, loss_kd: 1013.749573
[00:16:12.635] iteration 8330 : loss : 179.863754, loss_ce: 0.020049, loss_kd: 896.889282
[00:16:29.511] iteration 8340 : loss : 185.426971, loss_ce: 0.016359, loss_kd: 924.677856
[00:16:35.073] iteration 8350 : loss : 205.146362, loss_ce: 0.011184, loss_kd: 1023.302795
[00:16:40.634] iteration 8360 : loss : 226.374466, loss_ce: 0.022171, loss_kd: 1129.459839
[00:16:46.200] iteration 8370 : loss : 211.627655, loss_ce: 0.032020, loss_kd: 1055.718140
[00:16:51.761] iteration 8380 : loss : 182.202255, loss_ce: 0.019553, loss_kd: 908.597351
[00:16:57.341] iteration 8390 : loss : 215.483215, loss_ce: 0.018012, loss_kd: 1075.008789
[00:17:02.908] iteration 8400 : loss : 176.677811, loss_ce: 0.017820, loss_kd: 880.929016
[00:17:08.501] iteration 8410 : loss : 239.977356, loss_ce: 0.011326, loss_kd: 1197.436768
[00:17:14.092] iteration 8420 : loss : 188.133286, loss_ce: 0.030001, loss_kd: 938.236084
[00:17:19.683] iteration 8430 : loss : 179.121613, loss_ce: 0.014197, loss_kd: 893.180359
[00:17:25.289] iteration 8440 : loss : 205.688492, loss_ce: 0.027026, loss_kd: 1026.022217
[00:17:30.896] iteration 8450 : loss : 253.716034, loss_ce: 0.023582, loss_kd: 1266.163086
[00:17:36.490] iteration 8460 : loss : 212.746811, loss_ce: 0.013576, loss_kd: 1061.309204
[00:17:42.098] iteration 8470 : loss : 205.140778, loss_ce: 0.018693, loss_kd: 1023.261169
[00:17:47.691] iteration 8480 : loss : 166.884644, loss_ce: 0.013732, loss_kd: 831.985168
[00:17:53.304] iteration 8490 : loss : 181.692963, loss_ce: 0.017359, loss_kd: 906.034424
[00:17:58.904] iteration 8500 : loss : 199.826462, loss_ce: 0.020876, loss_kd: 996.681458
[00:18:04.515] iteration 8510 : loss : 214.480530, loss_ce: 0.020517, loss_kd: 1069.981567
[00:18:10.123] iteration 8520 : loss : 195.050995, loss_ce: 0.029183, loss_kd: 972.827942
[00:18:15.750] iteration 8530 : loss : 145.096405, loss_ce: 0.019715, loss_kd: 723.033386
[00:18:21.380] iteration 8540 : loss : 205.470230, loss_ce: 0.021461, loss_kd: 1024.888306
[00:18:26.994] iteration 8550 : loss : 177.600647, loss_ce: 0.019135, loss_kd: 885.613953
[00:18:32.618] iteration 8560 : loss : 206.113174, loss_ce: 0.018840, loss_kd: 1028.161255
[00:18:38.235] iteration 8570 : loss : 199.219910, loss_ce: 0.015129, loss_kd: 993.684143
[00:18:43.842] iteration 8580 : loss : 210.042831, loss_ce: 0.018884, loss_kd: 1047.816406
[00:18:49.462] iteration 8590 : loss : 155.681198, loss_ce: 0.023649, loss_kd: 775.925842
[00:18:55.077] iteration 8600 : loss : 193.026398, loss_ce: 0.013220, loss_kd: 962.685669
[00:19:00.711] iteration 8610 : loss : 198.070465, loss_ce: 0.020517, loss_kd: 987.888794
[00:19:06.323] iteration 8620 : loss : 249.302429, loss_ce: 0.015798, loss_kd: 1244.103760
[00:19:11.970] iteration 8630 : loss : 230.418793, loss_ce: 0.012289, loss_kd: 1149.666626
[00:19:17.579] iteration 8640 : loss : 272.674347, loss_ce: 0.025730, loss_kd: 1360.897217
[00:19:23.218] iteration 8650 : loss : 141.884903, loss_ce: 0.021411, loss_kd: 706.939697
[00:19:28.841] iteration 8660 : loss : 169.665146, loss_ce: 0.025248, loss_kd: 845.885986
[00:19:34.472] iteration 8670 : loss : 282.432281, loss_ce: 0.011802, loss_kd: 1409.708862
[00:19:40.095] iteration 8680 : loss : 214.816727, loss_ce: 0.024934, loss_kd: 1071.636353
[00:19:45.710] iteration 8690 : loss : 185.312424, loss_ce: 0.017569, loss_kd: 924.148621
[00:19:51.314] iteration 8700 : loss : 174.391144, loss_ce: 0.016455, loss_kd: 869.534790
[00:19:56.942] iteration 8710 : loss : 231.120331, loss_ce: 0.010068, loss_kd: 1153.151611
[00:20:02.558] iteration 8720 : loss : 207.668793, loss_ce: 0.025592, loss_kd: 1035.916138
[00:20:08.182] iteration 8730 : loss : 204.648117, loss_ce: 0.014916, loss_kd: 1020.858948
[00:20:13.788] iteration 8740 : loss : 259.639099, loss_ce: 0.015058, loss_kd: 1295.765625
[00:20:19.418] iteration 8750 : loss : 243.478256, loss_ce: 0.024023, loss_kd: 1214.954712
[00:20:25.024] iteration 8760 : loss : 173.397751, loss_ce: 0.019979, loss_kd: 864.547546
[00:20:30.646] iteration 8770 : loss : 250.464218, loss_ce: 0.024305, loss_kd: 1249.880859
[00:20:36.259] iteration 8780 : loss : 148.966461, loss_ce: 0.013788, loss_kd: 742.421265
[00:20:41.878] iteration 8790 : loss : 244.739960, loss_ce: 0.030675, loss_kd: 1221.251221
[00:20:47.488] iteration 8800 : loss : 255.360962, loss_ce: 0.018549, loss_kd: 1274.451416
[00:20:53.107] iteration 8810 : loss : 195.817490, loss_ce: 0.016445, loss_kd: 976.662048
[00:20:58.708] iteration 8820 : loss : 246.592056, loss_ce: 0.017449, loss_kd: 1230.515991
[00:21:04.335] iteration 8830 : loss : 178.149078, loss_ce: 0.014343, loss_kd: 888.350037
[00:21:09.935] iteration 8840 : loss : 226.190079, loss_ce: 0.017138, loss_kd: 1128.530762
[00:21:15.550] iteration 8850 : loss : 230.490250, loss_ce: 0.014431, loss_kd: 1150.047729
[00:21:21.144] iteration 8860 : loss : 165.954056, loss_ce: 0.021668, loss_kd: 827.248779
[00:21:26.751] iteration 8870 : loss : 380.304504, loss_ce: 0.018772, loss_kd: 1899.077759
[00:21:32.343] iteration 8880 : loss : 172.347092, loss_ce: 0.013555, loss_kd: 859.274536
[00:21:37.955] iteration 8890 : loss : 136.747452, loss_ce: 0.024677, loss_kd: 681.312500
[00:21:43.553] iteration 8900 : loss : 191.491501, loss_ce: 0.017979, loss_kd: 955.015137
[00:21:49.162] iteration 8910 : loss : 262.833008, loss_ce: 0.011193, loss_kd: 1311.751953
[00:21:54.757] iteration 8920 : loss : 199.343323, loss_ce: 0.024721, loss_kd: 994.301636
[00:22:00.356] iteration 8930 : loss : 230.076309, loss_ce: 0.015938, loss_kd: 1147.983521
[00:22:05.946] iteration 8940 : loss : 164.752396, loss_ce: 0.018503, loss_kd: 821.367615
[00:22:11.558] iteration 8950 : loss : 144.817902, loss_ce: 0.024079, loss_kd: 721.656189
[00:22:17.146] iteration 8960 : loss : 164.365494, loss_ce: 0.016894, loss_kd: 819.422119
[00:22:22.742] iteration 8970 : loss : 191.789597, loss_ce: 0.017983, loss_kd: 956.523438
[00:22:28.330] iteration 8980 : loss : 191.268738, loss_ce: 0.021766, loss_kd: 953.926208
[00:22:33.929] iteration 8990 : loss : 155.943481, loss_ce: 0.017433, loss_kd: 777.317200
[00:22:39.515] iteration 9000 : loss : 212.216644, loss_ce: 0.013273, loss_kd: 1058.679077
[00:22:45.106] iteration 9010 : loss : 193.591293, loss_ce: 0.011817, loss_kd: 965.505798
[00:22:50.695] iteration 9020 : loss : 199.145447, loss_ce: 0.016010, loss_kd: 993.271667
[00:22:56.295] iteration 9030 : loss : 215.720291, loss_ce: 0.017061, loss_kd: 1076.189697
[00:23:01.880] iteration 9040 : loss : 179.599777, loss_ce: 0.021894, loss_kd: 895.544373
[00:23:07.481] iteration 9050 : loss : 141.348663, loss_ce: 0.022721, loss_kd: 704.296692
[00:23:13.064] iteration 9060 : loss : 210.775055, loss_ce: 0.019772, loss_kd: 1051.441162
[00:23:18.652] iteration 9070 : loss : 246.630615, loss_ce: 0.023917, loss_kd: 1230.725586
[00:23:24.231] iteration 9080 : loss : 212.461777, loss_ce: 0.014556, loss_kd: 1059.887695
[00:23:29.824] iteration 9090 : loss : 198.216324, loss_ce: 0.022115, loss_kd: 988.677002
[00:23:35.411] iteration 9100 : loss : 160.834702, loss_ce: 0.015155, loss_kd: 801.769287
[00:23:41.011] iteration 9110 : loss : 184.219849, loss_ce: 0.021958, loss_kd: 918.697876
[00:23:46.609] iteration 9120 : loss : 154.893570, loss_ce: 0.014442, loss_kd: 772.075317
[00:23:52.207] iteration 9130 : loss : 207.505157, loss_ce: 0.012525, loss_kd: 1035.144897
[00:23:57.801] iteration 9140 : loss : 164.940552, loss_ce: 0.018599, loss_kd: 822.296326
[00:24:03.404] iteration 9150 : loss : 181.134109, loss_ce: 0.014560, loss_kd: 903.193298
[00:24:08.991] iteration 9160 : loss : 213.295975, loss_ce: 0.018877, loss_kd: 1064.079102
[00:24:14.598] iteration 9170 : loss : 221.615250, loss_ce: 0.013008, loss_kd: 1105.658447
[00:24:20.193] iteration 9180 : loss : 181.687531, loss_ce: 0.020822, loss_kd: 906.033508
[00:24:25.798] iteration 9190 : loss : 157.677338, loss_ce: 0.011905, loss_kd: 785.964355
[00:24:31.395] iteration 9200 : loss : 218.696289, loss_ce: 0.017995, loss_kd: 1091.075195
[00:24:37.009] iteration 9210 : loss : 183.758148, loss_ce: 0.015664, loss_kd: 916.365295
[00:24:42.601] iteration 9220 : loss : 187.024765, loss_ce: 0.026059, loss_kd: 932.695984
[00:24:48.201] iteration 9230 : loss : 146.240387, loss_ce: 0.016269, loss_kd: 728.769958
[00:24:53.795] iteration 9240 : loss : 162.781479, loss_ce: 0.012654, loss_kd: 811.521118
[00:24:59.401] iteration 9250 : loss : 172.179871, loss_ce: 0.017338, loss_kd: 858.472717
[00:25:04.998] iteration 9260 : loss : 232.118256, loss_ce: 0.019918, loss_kd: 1158.157959
[00:25:10.605] iteration 9270 : loss : 185.885544, loss_ce: 0.022888, loss_kd: 926.974609
[00:25:16.204] iteration 9280 : loss : 163.655884, loss_ce: 0.028334, loss_kd: 815.820984
[00:25:21.804] iteration 9290 : loss : 147.492477, loss_ce: 0.025989, loss_kd: 735.038635
[00:25:27.399] iteration 9300 : loss : 178.984879, loss_ce: 0.017260, loss_kd: 892.496765
[00:25:33.005] iteration 9310 : loss : 288.269165, loss_ce: 0.020598, loss_kd: 1438.924561
[00:25:38.597] iteration 9320 : loss : 198.574265, loss_ce: 0.017121, loss_kd: 990.417908
[00:25:44.200] iteration 9330 : loss : 175.375549, loss_ce: 0.026757, loss_kd: 874.427002
[00:25:49.796] iteration 9340 : loss : 147.567215, loss_ce: 0.016583, loss_kd: 735.379333
[00:25:55.399] iteration 9350 : loss : 217.182816, loss_ce: 0.017309, loss_kd: 1083.515625
[00:26:00.989] iteration 9360 : loss : 172.011612, loss_ce: 0.017772, loss_kd: 857.630737
[00:26:06.589] iteration 9370 : loss : 157.619003, loss_ce: 0.028676, loss_kd: 785.658813
[00:26:11.437] Running TPGM constraint optimization after epoch 9
[00:31:09.318] iteration 9380 : loss : 212.634796, loss_ce: 0.029853, loss_kd: 1060.740234
[00:31:14.843] iteration 9390 : loss : 158.661789, loss_ce: 0.016552, loss_kd: 790.907104
[00:31:20.365] iteration 9400 : loss : 148.757126, loss_ce: 0.015451, loss_kd: 741.349731
[00:31:25.906] iteration 9410 : loss : 166.802383, loss_ce: 0.029812, loss_kd: 831.559814
[00:31:31.434] iteration 9420 : loss : 192.180084, loss_ce: 0.016525, loss_kd: 958.514526
[00:31:36.982] iteration 9430 : loss : 226.241867, loss_ce: 0.023358, loss_kd: 1128.766968
[00:31:42.517] iteration 9440 : loss : 163.913101, loss_ce: 0.019104, loss_kd: 817.135071
[00:31:48.067] iteration 9450 : loss : 164.609482, loss_ce: 0.020758, loss_kd: 820.627930
[00:31:53.603] iteration 9460 : loss : 155.090622, loss_ce: 0.019679, loss_kd: 773.018005
[00:31:59.159] iteration 9470 : loss : 173.124649, loss_ce: 0.017902, loss_kd: 863.156189
[00:32:04.704] iteration 9480 : loss : 178.783264, loss_ce: 0.024623, loss_kd: 891.460449
[00:32:10.267] iteration 9490 : loss : 188.978348, loss_ce: 0.032736, loss_kd: 942.389404
[00:32:15.818] iteration 9500 : loss : 157.901581, loss_ce: 0.017694, loss_kd: 787.110229
[00:32:21.388] iteration 9510 : loss : 178.643509, loss_ce: 0.016507, loss_kd: 890.819580
[00:32:26.949] iteration 9520 : loss : 321.729279, loss_ce: 0.020536, loss_kd: 1606.178711
[00:32:32.518] iteration 9530 : loss : 159.867813, loss_ce: 0.025262, loss_kd: 796.924316
[00:32:38.078] iteration 9540 : loss : 156.954544, loss_ce: 0.029083, loss_kd: 782.382141
[00:32:43.652] iteration 9550 : loss : 199.469589, loss_ce: 0.018090, loss_kd: 994.944946
[00:32:49.225] iteration 9560 : loss : 192.549255, loss_ce: 0.016600, loss_kd: 960.307373
[00:32:54.811] iteration 9570 : loss : 184.329193, loss_ce: 0.018169, loss_kd: 919.250488
[00:33:00.377] iteration 9580 : loss : 165.101028, loss_ce: 0.028003, loss_kd: 823.077759
[00:33:05.958] iteration 9590 : loss : 223.127441, loss_ce: 0.017490, loss_kd: 1113.222046
[00:33:11.543] iteration 9600 : loss : 191.618561, loss_ce: 0.017911, loss_kd: 955.650330
[00:33:17.141] iteration 9610 : loss : 169.989700, loss_ce: 0.016271, loss_kd: 847.548523
[00:33:22.724] iteration 9620 : loss : 151.204880, loss_ce: 0.019626, loss_kd: 753.601868
[00:33:28.320] iteration 9630 : loss : 254.010223, loss_ce: 0.010430, loss_kd: 1267.655762
[00:33:33.904] iteration 9640 : loss : 177.306610, loss_ce: 0.014226, loss_kd: 884.112488
[00:33:39.501] iteration 9650 : loss : 165.992249, loss_ce: 0.018986, loss_kd: 827.534424
[00:33:45.103] iteration 9660 : loss : 186.133942, loss_ce: 0.017047, loss_kd: 928.256287
[00:33:50.703] iteration 9670 : loss : 153.064667, loss_ce: 0.026978, loss_kd: 762.880859
[00:33:56.300] iteration 9680 : loss : 168.100952, loss_ce: 0.009605, loss_kd: 838.123901
[00:34:01.899] iteration 9690 : loss : 191.868332, loss_ce: 0.030795, loss_kd: 956.909180
[00:34:07.488] iteration 9700 : loss : 229.405365, loss_ce: 0.012819, loss_kd: 1144.593140
[00:34:13.102] iteration 9710 : loss : 151.987030, loss_ce: 0.014970, loss_kd: 757.531006
[00:34:18.691] iteration 9720 : loss : 208.181137, loss_ce: 0.024175, loss_kd: 1038.466919
[00:34:24.299] iteration 9730 : loss : 207.347092, loss_ce: 0.026876, loss_kd: 1034.305298
[00:34:29.899] iteration 9740 : loss : 200.330627, loss_ce: 0.027238, loss_kd: 999.238403
[00:34:35.506] iteration 9750 : loss : 227.198471, loss_ce: 0.014222, loss_kd: 1133.554077
[00:34:41.105] iteration 9760 : loss : 183.645859, loss_ce: 0.024793, loss_kd: 915.805908
[00:34:46.728] iteration 9770 : loss : 161.068146, loss_ce: 0.023582, loss_kd: 802.916992
[00:34:52.331] iteration 9780 : loss : 169.596924, loss_ce: 0.016551, loss_kd: 845.578003
[00:34:57.936] iteration 9790 : loss : 168.230194, loss_ce: 0.013898, loss_kd: 838.701111
[00:35:03.537] iteration 9800 : loss : 149.516464, loss_ce: 0.012688, loss_kd: 745.183105
[00:35:09.160] iteration 9810 : loss : 195.075760, loss_ce: 0.019120, loss_kd: 972.944885
[00:35:14.764] iteration 9820 : loss : 200.311142, loss_ce: 0.013827, loss_kd: 999.137085
[00:35:20.389] iteration 9830 : loss : 173.054047, loss_ce: 0.026052, loss_kd: 862.873169
[00:35:26.008] iteration 9840 : loss : 186.394302, loss_ce: 0.015453, loss_kd: 929.559082
[00:35:31.625] iteration 9850 : loss : 182.683289, loss_ce: 0.022476, loss_kd: 910.974121
[00:35:37.225] iteration 9860 : loss : 168.266403, loss_ce: 0.019963, loss_kd: 838.914917
[00:35:42.848] iteration 9870 : loss : 190.691513, loss_ce: 0.026799, loss_kd: 951.017639
[00:35:48.456] iteration 9880 : loss : 193.097046, loss_ce: 0.018910, loss_kd: 963.072510
[00:35:54.072] iteration 9890 : loss : 278.561859, loss_ce: 0.022165, loss_kd: 1390.418701
[00:35:59.678] iteration 9900 : loss : 187.506531, loss_ce: 0.017413, loss_kd: 935.116272
[00:36:05.294] iteration 9910 : loss : 157.051346, loss_ce: 0.013244, loss_kd: 782.873840
[00:36:10.913] iteration 9920 : loss : 275.130127, loss_ce: 0.020684, loss_kd: 1373.206299
[00:36:16.531] iteration 9930 : loss : 193.753662, loss_ce: 0.012102, loss_kd: 966.328613
[00:36:22.144] iteration 9940 : loss : 158.207718, loss_ce: 0.025448, loss_kd: 788.587280
[00:36:27.779] iteration 9950 : loss : 204.731781, loss_ce: 0.012628, loss_kd: 1021.249756
[00:36:33.396] iteration 9960 : loss : 188.197418, loss_ce: 0.025659, loss_kd: 938.558716
[00:36:39.009] iteration 9970 : loss : 245.011612, loss_ce: 0.031874, loss_kd: 1222.648193
[00:36:44.627] iteration 9980 : loss : 172.002289, loss_ce: 0.019159, loss_kd: 857.591003
[00:36:50.261] iteration 9990 : loss : 149.533447, loss_ce: 0.010877, loss_kd: 745.273621
[00:36:55.870] iteration 10000 : loss : 178.063812, loss_ce: 0.025646, loss_kd: 887.908264
[00:37:01.511] iteration 10010 : loss : 157.892944, loss_ce: 0.026981, loss_kd: 787.060181
[00:37:07.122] iteration 10020 : loss : 186.172256, loss_ce: 0.012375, loss_kd: 928.321106
[00:37:12.752] iteration 10030 : loss : 166.081314, loss_ce: 0.014435, loss_kd: 828.000610
[00:37:18.370] iteration 10040 : loss : 197.138916, loss_ce: 0.013177, loss_kd: 983.304688
[00:37:23.995] iteration 10050 : loss : 175.839066, loss_ce: 0.014837, loss_kd: 876.788452
[00:37:29.617] iteration 10060 : loss : 197.016830, loss_ce: 0.017330, loss_kd: 982.679382
[00:37:35.250] iteration 10070 : loss : 185.790253, loss_ce: 0.028754, loss_kd: 926.487610
[00:37:40.865] iteration 10080 : loss : 245.462067, loss_ce: 0.021767, loss_kd: 1224.861328
[00:37:46.487] iteration 10090 : loss : 192.951355, loss_ce: 0.018067, loss_kd: 962.349487
[00:37:52.115] iteration 10100 : loss : 175.872925, loss_ce: 0.021863, loss_kd: 876.954163
[00:37:57.748] iteration 10110 : loss : 156.095261, loss_ce: 0.023923, loss_kd: 778.025452
[00:38:03.376] iteration 10120 : loss : 172.111130, loss_ce: 0.028186, loss_kd: 858.145874
[00:38:09.008] iteration 10130 : loss : 208.033707, loss_ce: 0.022176, loss_kd: 1037.724121
[00:38:14.638] iteration 10140 : loss : 213.181747, loss_ce: 0.018261, loss_kd: 1063.521851
[00:38:20.264] iteration 10150 : loss : 262.735199, loss_ce: 0.019537, loss_kd: 1311.260376
[00:38:25.878] iteration 10160 : loss : 158.684219, loss_ce: 0.020676, loss_kd: 790.995361
[00:38:31.516] iteration 10170 : loss : 148.798431, loss_ce: 0.013745, loss_kd: 741.599243
[00:38:37.125] iteration 10180 : loss : 175.195847, loss_ce: 0.012929, loss_kd: 873.539612
[00:38:42.754] iteration 10190 : loss : 185.828232, loss_ce: 0.015937, loss_kd: 926.685608
[00:38:48.377] iteration 10200 : loss : 121.759392, loss_ce: 0.020589, loss_kd: 606.403198
[00:38:54.017] iteration 10210 : loss : 159.189087, loss_ce: 0.010857, loss_kd: 793.546265
[00:38:59.650] iteration 10220 : loss : 141.596710, loss_ce: 0.022662, loss_kd: 705.533447
[00:39:05.283] iteration 10230 : loss : 213.430634, loss_ce: 0.015937, loss_kd: 1064.725464
[00:39:10.909] iteration 10240 : loss : 163.116287, loss_ce: 0.022229, loss_kd: 813.161194
[00:39:16.551] iteration 10250 : loss : 150.792221, loss_ce: 0.020449, loss_kd: 751.512207
[00:39:22.176] iteration 10260 : loss : 175.877686, loss_ce: 0.031982, loss_kd: 876.953003
[00:39:27.805] iteration 10270 : loss : 139.063004, loss_ce: 0.018473, loss_kd: 692.910889
[00:39:33.436] iteration 10280 : loss : 191.695145, loss_ce: 0.013569, loss_kd: 956.067261
[00:39:39.070] iteration 10290 : loss : 211.055908, loss_ce: 0.019147, loss_kd: 1052.880371
[00:39:44.703] iteration 10300 : loss : 196.370071, loss_ce: 0.014809, loss_kd: 979.446533
[00:39:50.339] iteration 10310 : loss : 195.256073, loss_ce: 0.014902, loss_kd: 973.880310
[00:39:55.967] iteration 10320 : loss : 197.423523, loss_ce: 0.014394, loss_kd: 984.684387
[00:40:01.588] iteration 10330 : loss : 146.711700, loss_ce: 0.032982, loss_kd: 731.137329
[00:40:07.214] iteration 10340 : loss : 203.811478, loss_ce: 0.013485, loss_kd: 1016.672607
[00:40:12.845] iteration 10350 : loss : 160.257446, loss_ce: 0.017968, loss_kd: 798.859680
[00:40:18.469] iteration 10360 : loss : 207.112686, loss_ce: 0.016062, loss_kd: 1033.145630
[00:40:24.113] iteration 10370 : loss : 167.353073, loss_ce: 0.019179, loss_kd: 834.349731
[00:40:29.727] iteration 10380 : loss : 181.715805, loss_ce: 0.022679, loss_kd: 906.167175
[00:40:35.352] iteration 10390 : loss : 166.225769, loss_ce: 0.029276, loss_kd: 828.714050
[00:40:40.977] iteration 10400 : loss : 156.249954, loss_ce: 0.016569, loss_kd: 778.854004
[00:40:46.613] iteration 10410 : loss : 136.467346, loss_ce: 0.014231, loss_kd: 679.956848
[00:40:51.934] iteration 10420 : loss : 139.565857, loss_ce: 0.022008, loss_kd: 695.415161
[00:40:52.702] save model to ./debug_fixed_tpgm\continual_surgical_tpgm_epoch_9.pth
[00:41:09.380] iteration 10430 : loss : 209.500565, loss_ce: 0.024479, loss_kd: 1045.079590
[00:41:14.930] iteration 10440 : loss : 192.489594, loss_ce: 0.023438, loss_kd: 960.047729
[00:41:20.496] iteration 10450 : loss : 220.929596, loss_ce: 0.011959, loss_kd: 1102.227051
[00:41:26.059] iteration 10460 : loss : 184.940323, loss_ce: 0.014648, loss_kd: 922.294189
[00:41:31.636] iteration 10470 : loss : 158.431305, loss_ce: 0.018581, loss_kd: 789.702637
[00:41:37.214] iteration 10480 : loss : 200.903549, loss_ce: 0.024698, loss_kd: 1002.097900
[00:41:42.800] iteration 10490 : loss : 155.694672, loss_ce: 0.022981, loss_kd: 776.072449
[00:41:48.382] iteration 10500 : loss : 183.701797, loss_ce: 0.016325, loss_kd: 916.045776
[00:41:53.977] iteration 10510 : loss : 158.330475, loss_ce: 0.026645, loss_kd: 789.237488
[00:41:59.558] iteration 10520 : loss : 158.324585, loss_ce: 0.016306, loss_kd: 789.201904
[00:42:05.152] iteration 10530 : loss : 139.822021, loss_ce: 0.012852, loss_kd: 696.706055
[00:42:10.743] iteration 10540 : loss : 171.776871, loss_ce: 0.021637, loss_kd: 856.474182
[00:42:16.354] iteration 10550 : loss : 177.294388, loss_ce: 0.026072, loss_kd: 884.068298
[00:42:21.954] iteration 10560 : loss : 145.010483, loss_ce: 0.020091, loss_kd: 722.661743
[00:42:27.558] iteration 10570 : loss : 152.548279, loss_ce: 0.023005, loss_kd: 760.382996
[00:42:33.153] iteration 10580 : loss : 147.226044, loss_ce: 0.010132, loss_kd: 733.722290
[00:42:38.780] iteration 10590 : loss : 162.328201, loss_ce: 0.011762, loss_kd: 809.251709
[00:42:44.372] iteration 10600 : loss : 197.253845, loss_ce: 0.026521, loss_kd: 983.827332
[00:42:49.988] iteration 10610 : loss : 143.591827, loss_ce: 0.030893, loss_kd: 715.562500
[00:42:55.593] iteration 10620 : loss : 140.452133, loss_ce: 0.019683, loss_kd: 699.831787
[00:43:01.201] iteration 10630 : loss : 132.923798, loss_ce: 0.029292, loss_kd: 662.200256
[00:43:06.804] iteration 10640 : loss : 182.095566, loss_ce: 0.018132, loss_kd: 908.132263
[00:43:12.414] iteration 10650 : loss : 184.264404, loss_ce: 0.016304, loss_kd: 918.862549
[00:43:18.014] iteration 10660 : loss : 141.227570, loss_ce: 0.019000, loss_kd: 703.675964
[00:43:23.616] iteration 10670 : loss : 194.391586, loss_ce: 0.012841, loss_kd: 969.509277
[00:43:29.205] iteration 10680 : loss : 228.726898, loss_ce: 0.026240, loss_kd: 1141.204346
[00:43:34.810] iteration 10690 : loss : 166.614090, loss_ce: 0.014185, loss_kd: 830.671143
[00:43:40.405] iteration 10700 : loss : 156.733292, loss_ce: 0.026352, loss_kd: 781.247681
[00:43:46.017] iteration 10710 : loss : 179.004059, loss_ce: 0.013720, loss_kd: 892.611816
[00:43:51.613] iteration 10720 : loss : 154.290848, loss_ce: 0.010625, loss_kd: 769.065796
[00:43:57.217] iteration 10730 : loss : 203.017853, loss_ce: 0.015850, loss_kd: 1012.644470
[00:44:02.811] iteration 10740 : loss : 205.762451, loss_ce: 0.020422, loss_kd: 1026.418823
[00:44:08.411] iteration 10750 : loss : 204.082626, loss_ce: 0.015021, loss_kd: 1018.012878
[00:44:14.002] iteration 10760 : loss : 206.790344, loss_ce: 0.015693, loss_kd: 1031.548340
[00:44:19.602] iteration 10770 : loss : 202.513611, loss_ce: 0.018858, loss_kd: 1010.132080
[00:44:25.200] iteration 10780 : loss : 170.753113, loss_ce: 0.018381, loss_kd: 851.302856
[00:44:30.803] iteration 10790 : loss : 171.365997, loss_ce: 0.012737, loss_kd: 854.412720
[00:44:36.395] iteration 10800 : loss : 130.213669, loss_ce: 0.015870, loss_kd: 648.630615
[00:44:42.001] iteration 10810 : loss : 158.119202, loss_ce: 0.010415, loss_kd: 788.145325
[00:44:47.588] iteration 10820 : loss : 173.646469, loss_ce: 0.013233, loss_kd: 865.768188
[00:44:53.186] iteration 10830 : loss : 246.762192, loss_ce: 0.022016, loss_kd: 1231.430908
[00:44:58.769] iteration 10840 : loss : 230.190170, loss_ce: 0.015532, loss_kd: 1148.540161
[00:45:04.366] iteration 10850 : loss : 137.912582, loss_ce: 0.013042, loss_kd: 687.196045
[00:45:09.955] iteration 10860 : loss : 187.869583, loss_ce: 0.014752, loss_kd: 936.942505
[00:45:15.554] iteration 10870 : loss : 169.545944, loss_ce: 0.018674, loss_kd: 845.294678
[00:45:21.144] iteration 10880 : loss : 162.033508, loss_ce: 0.018357, loss_kd: 807.734680
[00:45:26.747] iteration 10890 : loss : 187.135834, loss_ce: 0.016176, loss_kd: 933.267944
[00:45:32.338] iteration 10900 : loss : 177.767395, loss_ce: 0.016157, loss_kd: 886.440552
[00:45:37.938] iteration 10910 : loss : 165.529312, loss_ce: 0.016020, loss_kd: 825.214478
[00:45:43.531] iteration 10920 : loss : 179.897705, loss_ce: 0.015166, loss_kd: 897.085693
[00:45:49.134] iteration 10930 : loss : 140.663208, loss_ce: 0.020844, loss_kd: 700.951660
[00:45:54.724] iteration 10940 : loss : 164.899841, loss_ce: 0.018141, loss_kd: 822.047668
[00:46:00.324] iteration 10950 : loss : 184.420929, loss_ce: 0.015070, loss_kd: 919.695862
[00:46:05.912] iteration 10960 : loss : 247.817886, loss_ce: 0.013929, loss_kd: 1236.635986
[00:46:11.506] iteration 10970 : loss : 201.180237, loss_ce: 0.014082, loss_kd: 1003.477966
[00:46:17.087] iteration 10980 : loss : 191.815292, loss_ce: 0.012962, loss_kd: 956.653076
[00:46:22.681] iteration 10990 : loss : 249.017868, loss_ce: 0.022004, loss_kd: 1242.686523
[00:46:28.265] iteration 11000 : loss : 202.769257, loss_ce: 0.019621, loss_kd: 1011.397705
[00:46:33.865] iteration 11010 : loss : 182.568665, loss_ce: 0.008783, loss_kd: 910.451172
[00:46:39.450] iteration 11020 : loss : 186.998093, loss_ce: 0.015435, loss_kd: 932.581909
[00:46:45.049] iteration 11030 : loss : 187.729507, loss_ce: 0.014803, loss_kd: 936.273315
[00:46:50.638] iteration 11040 : loss : 148.941864, loss_ce: 0.012890, loss_kd: 742.307373
[00:46:56.233] iteration 11050 : loss : 150.826889, loss_ce: 0.022106, loss_kd: 751.718201
[00:47:01.814] iteration 11060 : loss : 169.825623, loss_ce: 0.025804, loss_kd: 846.693054
[00:47:07.408] iteration 11070 : loss : 202.404663, loss_ce: 0.021258, loss_kd: 1009.622803
[00:47:12.991] iteration 11080 : loss : 146.442505, loss_ce: 0.019461, loss_kd: 729.802612
[00:47:18.584] iteration 11090 : loss : 192.923355, loss_ce: 0.020903, loss_kd: 962.228516
[00:47:24.172] iteration 11100 : loss : 167.111160, loss_ce: 0.014605, loss_kd: 833.171265
[00:47:29.771] iteration 11110 : loss : 193.416321, loss_ce: 0.011679, loss_kd: 964.695374
[00:47:35.365] iteration 11120 : loss : 180.904480, loss_ce: 0.014380, loss_kd: 902.108948
[00:47:40.963] iteration 11130 : loss : 169.839371, loss_ce: 0.019182, loss_kd: 846.775269
[00:47:46.555] iteration 11140 : loss : 158.261658, loss_ce: 0.015035, loss_kd: 788.923889
[00:47:52.159] iteration 11150 : loss : 171.667252, loss_ce: 0.025344, loss_kd: 855.929688
[00:47:57.755] iteration 11160 : loss : 179.117462, loss_ce: 0.017451, loss_kd: 893.170898
[00:48:03.351] iteration 11170 : loss : 186.823334, loss_ce: 0.019249, loss_kd: 931.703064
[00:48:08.943] iteration 11180 : loss : 164.468460, loss_ce: 0.020959, loss_kd: 819.910339
[00:48:14.542] iteration 11190 : loss : 171.299393, loss_ce: 0.020793, loss_kd: 854.068604
[00:48:20.123] iteration 11200 : loss : 167.853409, loss_ce: 0.021255, loss_kd: 836.844849
[00:48:25.723] iteration 11210 : loss : 150.593506, loss_ce: 0.013735, loss_kd: 750.556458
[00:48:31.302] iteration 11220 : loss : 155.613922, loss_ce: 0.027495, loss_kd: 775.659973
[00:48:36.895] iteration 11230 : loss : 163.863892, loss_ce: 0.013218, loss_kd: 816.887939
[00:48:42.481] iteration 11240 : loss : 167.646271, loss_ce: 0.015547, loss_kd: 835.794617
[00:48:48.074] iteration 11250 : loss : 236.427689, loss_ce: 0.016939, loss_kd: 1179.741943
[00:48:53.655] iteration 11260 : loss : 199.868240, loss_ce: 0.013723, loss_kd: 996.987427
[00:48:59.243] iteration 11270 : loss : 164.912323, loss_ce: 0.024780, loss_kd: 822.131104
[00:49:04.825] iteration 11280 : loss : 192.928131, loss_ce: 0.016704, loss_kd: 962.229004
[00:49:10.415] iteration 11290 : loss : 120.888885, loss_ce: 0.013449, loss_kd: 602.019165
[00:49:15.992] iteration 11300 : loss : 178.725891, loss_ce: 0.024633, loss_kd: 891.212769
[00:49:21.588] iteration 11310 : loss : 193.842850, loss_ce: 0.018693, loss_kd: 966.843750
[00:49:27.172] iteration 11320 : loss : 135.293198, loss_ce: 0.021841, loss_kd: 674.039429
[00:49:32.764] iteration 11330 : loss : 166.734009, loss_ce: 0.010509, loss_kd: 831.281006
[00:49:38.333] iteration 11340 : loss : 145.365875, loss_ce: 0.012754, loss_kd: 724.421570
[00:49:43.930] iteration 11350 : loss : 247.831085, loss_ce: 0.011838, loss_kd: 1236.752441
[00:49:49.509] iteration 11360 : loss : 154.306824, loss_ce: 0.017114, loss_kd: 769.137268
[00:49:55.092] iteration 11370 : loss : 217.492569, loss_ce: 0.010105, loss_kd: 1085.021606
[00:50:00.671] iteration 11380 : loss : 211.463547, loss_ce: 0.023681, loss_kd: 1054.913330
[00:50:06.259] iteration 11390 : loss : 189.007004, loss_ce: 0.018526, loss_kd: 942.619019
[00:50:11.840] iteration 11400 : loss : 225.866776, loss_ce: 0.024497, loss_kd: 1126.895020
[00:50:17.437] iteration 11410 : loss : 145.924103, loss_ce: 0.013904, loss_kd: 727.268677
[00:50:23.014] iteration 11420 : loss : 179.117477, loss_ce: 0.017557, loss_kd: 893.192810
[00:50:28.603] iteration 11430 : loss : 191.856857, loss_ce: 0.019830, loss_kd: 956.865906
[00:50:34.179] iteration 11440 : loss : 182.777740, loss_ce: 0.018867, loss_kd: 911.480286
[00:50:39.766] iteration 11450 : loss : 178.681427, loss_ce: 0.025458, loss_kd: 891.010315
[00:50:45.348] iteration 11460 : loss : 136.488770, loss_ce: 0.014509, loss_kd: 680.095032
[00:50:46.892] Running TPGM constraint optimization after epoch 11
[00:55:43.008] iteration 11470 : loss : 207.358154, loss_ce: 0.017627, loss_kd: 1034.418701
[00:55:48.529] iteration 11480 : loss : 139.088455, loss_ce: 0.018821, loss_kd: 693.030029
[00:55:54.065] iteration 11490 : loss : 121.936966, loss_ce: 0.018005, loss_kd: 607.287598
[00:55:59.592] iteration 11500 : loss : 250.088379, loss_ce: 0.020461, loss_kd: 1248.050781
[00:56:05.133] iteration 11510 : loss : 139.215576, loss_ce: 0.018443, loss_kd: 693.652466
[00:56:10.670] iteration 11520 : loss : 170.654449, loss_ce: 0.011509, loss_kd: 850.815369
[00:56:16.216] iteration 11530 : loss : 171.803726, loss_ce: 0.023038, loss_kd: 856.598083
[00:56:21.772] iteration 11540 : loss : 174.781891, loss_ce: 0.016738, loss_kd: 871.512512
[00:56:27.320] iteration 11550 : loss : 197.905014, loss_ce: 0.013771, loss_kd: 987.155457
[00:56:32.859] iteration 11560 : loss : 180.286057, loss_ce: 0.013087, loss_kd: 899.011414
[00:56:38.407] iteration 11570 : loss : 155.639023, loss_ce: 0.014162, loss_kd: 775.802429
[00:56:43.948] iteration 11580 : loss : 144.469177, loss_ce: 0.017697, loss_kd: 719.951294
[00:56:49.497] iteration 11590 : loss : 158.224030, loss_ce: 0.016981, loss_kd: 788.727539
[00:56:55.037] iteration 11600 : loss : 156.835175, loss_ce: 0.010855, loss_kd: 781.794739
[00:57:00.593] iteration 11610 : loss : 203.219147, loss_ce: 0.033335, loss_kd: 1013.643799
[00:57:06.136] iteration 11620 : loss : 178.283737, loss_ce: 0.016792, loss_kd: 889.005127
[00:57:11.703] iteration 11630 : loss : 256.409088, loss_ce: 0.014560, loss_kd: 1279.617676
[00:57:17.248] iteration 11640 : loss : 160.876892, loss_ce: 0.013776, loss_kd: 801.960144
[00:57:22.811] iteration 11650 : loss : 171.768127, loss_ce: 0.012388, loss_kd: 856.456848
[00:57:28.363] iteration 11660 : loss : 185.148788, loss_ce: 0.017443, loss_kd: 923.336609
[00:57:33.930] iteration 11670 : loss : 164.961487, loss_ce: 0.010724, loss_kd: 822.440796
[00:57:39.481] iteration 11680 : loss : 136.546387, loss_ce: 0.011112, loss_kd: 680.354065
[00:57:45.042] iteration 11690 : loss : 160.841873, loss_ce: 0.017333, loss_kd: 801.789307
[00:57:50.594] iteration 11700 : loss : 144.761841, loss_ce: 0.014333, loss_kd: 721.425903
[00:57:56.160] iteration 11710 : loss : 126.892548, loss_ce: 0.019329, loss_kd: 632.071533
[00:58:01.715] iteration 11720 : loss : 248.892960, loss_ce: 0.031650, loss_kd: 1242.035522
[00:58:07.317] iteration 11730 : loss : 243.622223, loss_ce: 0.013959, loss_kd: 1215.718018
[00:58:12.873] iteration 11740 : loss : 191.094849, loss_ce: 0.019854, loss_kd: 953.083984
[00:58:18.444] iteration 11750 : loss : 149.544510, loss_ce: 0.029010, loss_kd: 745.325195
[00:58:24.008] iteration 11760 : loss : 114.834686, loss_ce: 0.011432, loss_kd: 571.736938
[00:58:29.584] iteration 11770 : loss : 99.993355, loss_ce: 0.020427, loss_kd: 497.553223
[00:58:35.143] iteration 11780 : loss : 186.821747, loss_ce: 0.013686, loss_kd: 931.700317
[00:58:40.724] iteration 11790 : loss : 147.253494, loss_ce: 0.015620, loss_kd: 733.884033
[00:58:46.290] iteration 11800 : loss : 235.531998, loss_ce: 0.021390, loss_kd: 1175.270752
[00:58:51.875] iteration 11810 : loss : 168.165741, loss_ce: 0.024247, loss_kd: 838.401672
[00:58:57.445] iteration 11820 : loss : 174.605194, loss_ce: 0.020128, loss_kd: 870.598511
[00:59:03.020] iteration 11830 : loss : 201.358963, loss_ce: 0.020977, loss_kd: 1004.358521
[00:59:08.587] iteration 11840 : loss : 194.594559, loss_ce: 0.010520, loss_kd: 970.597290
[00:59:14.171] iteration 11850 : loss : 139.863495, loss_ce: 0.013818, loss_kd: 696.926941
[00:59:19.746] iteration 11860 : loss : 171.017426, loss_ce: 0.024566, loss_kd: 852.653259
[00:59:25.324] iteration 11870 : loss : 236.100510, loss_ce: 0.018415, loss_kd: 1178.096680
[00:59:30.898] iteration 11880 : loss : 169.888016, loss_ce: 0.016892, loss_kd: 847.048706
[00:59:36.488] iteration 11890 : loss : 143.673141, loss_ce: 0.013300, loss_kd: 716.006104
[00:59:42.062] iteration 11900 : loss : 162.372818, loss_ce: 0.016464, loss_kd: 809.395264
[00:59:47.647] iteration 11910 : loss : 138.876343, loss_ce: 0.011537, loss_kd: 691.993652
[00:59:53.228] iteration 11920 : loss : 183.430908, loss_ce: 0.008657, loss_kd: 914.742554
[00:59:58.818] iteration 11930 : loss : 163.858002, loss_ce: 0.013829, loss_kd: 816.840515
[01:00:04.390] iteration 11940 : loss : 215.712448, loss_ce: 0.013044, loss_kd: 1076.153809
[01:00:09.980] iteration 11950 : loss : 136.891663, loss_ce: 0.016236, loss_kd: 682.049194
[01:00:15.557] iteration 11960 : loss : 136.302246, loss_ce: 0.018674, loss_kd: 679.093994
[01:00:21.148] iteration 11970 : loss : 177.390396, loss_ce: 0.024943, loss_kd: 884.543457
[01:00:26.728] iteration 11980 : loss : 174.774368, loss_ce: 0.026464, loss_kd: 871.425903
[01:00:32.316] iteration 11990 : loss : 133.216934, loss_ce: 0.030745, loss_kd: 663.668030
[01:00:37.895] iteration 12000 : loss : 164.207016, loss_ce: 0.016229, loss_kd: 818.639648
[01:00:43.493] iteration 12010 : loss : 240.822601, loss_ce: 0.026216, loss_kd: 1201.687744
[01:00:49.073] iteration 12020 : loss : 168.455444, loss_ce: 0.016637, loss_kd: 839.859863
[01:00:54.673] iteration 12030 : loss : 142.728409, loss_ce: 0.017583, loss_kd: 711.260315
[01:01:00.259] iteration 12040 : loss : 132.440613, loss_ce: 0.017661, loss_kd: 659.750366
[01:01:05.861] iteration 12050 : loss : 148.475906, loss_ce: 0.012608, loss_kd: 739.953125
[01:01:11.450] iteration 12060 : loss : 204.015823, loss_ce: 0.014932, loss_kd: 1017.625671
[01:01:17.051] iteration 12070 : loss : 177.046188, loss_ce: 0.024307, loss_kd: 882.824219
[01:01:22.634] iteration 12080 : loss : 152.462601, loss_ce: 0.022970, loss_kd: 759.898071
[01:01:28.225] iteration 12090 : loss : 136.607864, loss_ce: 0.018285, loss_kd: 680.623779
[01:01:33.817] iteration 12100 : loss : 194.498734, loss_ce: 0.018867, loss_kd: 970.081604
[01:01:39.415] iteration 12110 : loss : 163.578949, loss_ce: 0.022358, loss_kd: 815.442383
[01:01:44.999] iteration 12120 : loss : 165.224838, loss_ce: 0.012989, loss_kd: 823.734497
[01:01:50.592] iteration 12130 : loss : 163.454071, loss_ce: 0.013899, loss_kd: 814.890991
[01:01:56.178] iteration 12140 : loss : 154.437912, loss_ce: 0.022324, loss_kd: 769.794678
[01:02:01.777] iteration 12150 : loss : 158.954269, loss_ce: 0.019258, loss_kd: 792.327576
[01:02:07.381] iteration 12160 : loss : 145.537918, loss_ce: 0.023297, loss_kd: 725.261353
[01:02:12.974] iteration 12170 : loss : 168.368088, loss_ce: 0.020072, loss_kd: 839.436035
[01:02:18.569] iteration 12180 : loss : 146.835983, loss_ce: 0.013912, loss_kd: 731.757996
[01:02:24.169] iteration 12190 : loss : 171.803162, loss_ce: 0.028080, loss_kd: 856.588501
[01:02:29.754] iteration 12200 : loss : 121.473984, loss_ce: 0.026268, loss_kd: 604.962708
[01:02:35.360] iteration 12210 : loss : 155.658569, loss_ce: 0.013954, loss_kd: 775.868591
[01:02:40.935] iteration 12220 : loss : 145.161911, loss_ce: 0.008530, loss_kd: 723.393188
[01:02:46.528] iteration 12230 : loss : 175.372070, loss_ce: 0.015812, loss_kd: 874.425293
[01:02:52.112] iteration 12240 : loss : 162.251907, loss_ce: 0.025643, loss_kd: 808.851746
[01:02:57.726] iteration 12250 : loss : 153.631851, loss_ce: 0.014743, loss_kd: 765.742004
[01:03:03.310] iteration 12260 : loss : 154.460297, loss_ce: 0.012581, loss_kd: 769.888794
[01:03:08.906] iteration 12270 : loss : 182.383698, loss_ce: 0.018352, loss_kd: 909.496460
[01:03:14.501] iteration 12280 : loss : 173.761368, loss_ce: 0.018092, loss_kd: 866.409180
[01:03:20.097] iteration 12290 : loss : 142.249252, loss_ce: 0.020472, loss_kd: 708.825195
[01:03:25.693] iteration 12300 : loss : 193.757904, loss_ce: 0.011274, loss_kd: 966.366882
[01:03:31.289] iteration 12310 : loss : 200.758438, loss_ce: 0.015365, loss_kd: 1001.363220
[01:03:36.881] iteration 12320 : loss : 120.009521, loss_ce: 0.022088, loss_kd: 597.642334
[01:03:42.486] iteration 12330 : loss : 157.614105, loss_ce: 0.011239, loss_kd: 785.665344
[01:03:48.074] iteration 12340 : loss : 181.462723, loss_ce: 0.018950, loss_kd: 904.896179
[01:03:53.682] iteration 12350 : loss : 213.063446, loss_ce: 0.011219, loss_kd: 1062.875000
[01:03:59.276] iteration 12360 : loss : 152.240845, loss_ce: 0.017265, loss_kd: 758.822754
[01:04:04.876] iteration 12370 : loss : 137.086151, loss_ce: 0.016470, loss_kd: 683.018433
[01:04:10.471] iteration 12380 : loss : 156.523773, loss_ce: 0.012523, loss_kd: 780.212219
[01:04:16.077] iteration 12390 : loss : 205.000336, loss_ce: 0.015093, loss_kd: 1022.603088
[01:04:21.663] iteration 12400 : loss : 146.312943, loss_ce: 0.021343, loss_kd: 729.140198
[01:04:27.266] iteration 12410 : loss : 159.853821, loss_ce: 0.017744, loss_kd: 796.861328
[01:04:32.859] iteration 12420 : loss : 116.453285, loss_ce: 0.012719, loss_kd: 579.870605
[01:04:38.457] iteration 12430 : loss : 161.587814, loss_ce: 0.021795, loss_kd: 805.530762
[01:04:44.050] iteration 12440 : loss : 215.800369, loss_ce: 0.026911, loss_kd: 1076.610718
[01:04:49.650] iteration 12450 : loss : 194.905640, loss_ce: 0.008685, loss_kd: 972.136108
[01:04:55.249] iteration 12460 : loss : 126.583977, loss_ce: 0.011132, loss_kd: 630.495239
[01:05:00.855] iteration 12470 : loss : 186.313644, loss_ce: 0.011820, loss_kd: 929.127869
[01:05:06.444] iteration 12480 : loss : 180.161819, loss_ce: 0.019235, loss_kd: 898.367432
[01:05:12.042] iteration 12490 : loss : 202.409470, loss_ce: 0.015816, loss_kd: 1009.643738
[01:05:17.641] iteration 12500 : loss : 190.714752, loss_ce: 0.013574, loss_kd: 951.189819
[01:05:35.101] iteration 12510 : loss : 172.494095, loss_ce: 0.016378, loss_kd: 860.100830
[01:05:40.635] iteration 12520 : loss : 168.858765, loss_ce: 0.021642, loss_kd: 841.880981
[01:05:46.188] iteration 12530 : loss : 145.554260, loss_ce: 0.017965, loss_kd: 725.356934
[01:05:51.728] iteration 12540 : loss : 165.791687, loss_ce: 0.012309, loss_kd: 826.557739
[01:05:57.278] iteration 12550 : loss : 152.543152, loss_ce: 0.018886, loss_kd: 760.330261
[01:06:02.827] iteration 12560 : loss : 139.932144, loss_ce: 0.019879, loss_kd: 697.267334
[01:06:08.386] iteration 12570 : loss : 149.203415, loss_ce: 0.013099, loss_kd: 743.599915
[01:06:13.942] iteration 12580 : loss : 161.648117, loss_ce: 0.016783, loss_kd: 805.814026
[01:06:19.510] iteration 12590 : loss : 191.115295, loss_ce: 0.014944, loss_kd: 953.215576
[01:06:25.072] iteration 12600 : loss : 110.824051, loss_ce: 0.026734, loss_kd: 551.712463
[01:06:30.644] iteration 12610 : loss : 147.226639, loss_ce: 0.023620, loss_kd: 733.735657
[01:06:36.219] iteration 12620 : loss : 163.679626, loss_ce: 0.017098, loss_kd: 815.965332
[01:06:41.802] iteration 12630 : loss : 145.130676, loss_ce: 0.025812, loss_kd: 723.263367
[01:06:47.395] iteration 12640 : loss : 112.417381, loss_ce: 0.017756, loss_kd: 559.696533
[01:06:52.976] iteration 12650 : loss : 126.179916, loss_ce: 0.007992, loss_kd: 628.504028
[01:06:58.556] iteration 12660 : loss : 184.666718, loss_ce: 0.014392, loss_kd: 920.934570
[01:07:04.150] iteration 12670 : loss : 168.024078, loss_ce: 0.012796, loss_kd: 837.754211
[01:07:09.732] iteration 12680 : loss : 188.896408, loss_ce: 0.019058, loss_kd: 942.023254
[01:07:15.322] iteration 12690 : loss : 127.935829, loss_ce: 0.017443, loss_kd: 637.256287
[01:07:20.909] iteration 12700 : loss : 216.599335, loss_ce: 0.018540, loss_kd: 1080.575439
[01:07:26.502] iteration 12710 : loss : 173.200394, loss_ce: 0.015666, loss_kd: 863.623840
[01:07:32.081] iteration 12720 : loss : 190.778976, loss_ce: 0.022419, loss_kd: 951.517517
[01:07:37.685] iteration 12730 : loss : 165.799316, loss_ce: 0.018804, loss_kd: 826.629150
[01:07:43.281] iteration 12740 : loss : 195.007370, loss_ce: 0.013149, loss_kd: 972.652954
[01:07:48.884] iteration 12750 : loss : 169.228775, loss_ce: 0.015282, loss_kd: 843.775330
[01:07:54.478] iteration 12760 : loss : 200.248383, loss_ce: 0.014925, loss_kd: 998.840454
[01:08:00.078] iteration 12770 : loss : 165.886719, loss_ce: 0.013056, loss_kd: 827.057373
[01:08:05.678] iteration 12780 : loss : 147.592453, loss_ce: 0.018515, loss_kd: 735.536255
[01:08:11.283] iteration 12790 : loss : 142.668182, loss_ce: 0.021064, loss_kd: 710.923157
[01:08:16.876] iteration 12800 : loss : 211.901474, loss_ce: 0.016233, loss_kd: 1057.108521
[01:08:22.483] iteration 12810 : loss : 334.386414, loss_ce: 0.013613, loss_kd: 1669.521729
[01:08:28.079] iteration 12820 : loss : 230.793625, loss_ce: 0.013490, loss_kd: 1151.548340
[01:08:33.680] iteration 12830 : loss : 217.145599, loss_ce: 0.017047, loss_kd: 1083.329956
[01:08:39.279] iteration 12840 : loss : 141.522675, loss_ce: 0.019332, loss_kd: 705.188416
[01:08:44.887] iteration 12850 : loss : 155.268051, loss_ce: 0.023103, loss_kd: 773.907837
[01:08:50.503] iteration 12860 : loss : 127.229034, loss_ce: 0.015813, loss_kd: 633.773193
[01:08:56.125] iteration 12870 : loss : 176.531296, loss_ce: 0.014747, loss_kd: 880.243774
[01:09:01.729] iteration 12880 : loss : 158.788483, loss_ce: 0.017261, loss_kd: 791.538208
[01:09:07.338] iteration 12890 : loss : 150.719391, loss_ce: 0.011782, loss_kd: 751.191956
[01:09:12.937] iteration 12900 : loss : 143.655197, loss_ce: 0.014458, loss_kd: 715.853333
[01:09:18.549] iteration 12910 : loss : 124.007851, loss_ce: 0.036442, loss_kd: 617.578979
[01:09:24.155] iteration 12920 : loss : 142.897293, loss_ce: 0.016358, loss_kd: 712.069214
[01:09:29.775] iteration 12930 : loss : 183.344849, loss_ce: 0.020670, loss_kd: 914.340332
[01:09:35.382] iteration 12940 : loss : 153.300995, loss_ce: 0.014821, loss_kd: 764.082092
[01:09:41.013] iteration 12950 : loss : 157.467545, loss_ce: 0.019317, loss_kd: 784.934875
[01:09:46.616] iteration 12960 : loss : 144.858276, loss_ce: 0.013069, loss_kd: 721.893372
[01:09:52.225] iteration 12970 : loss : 159.285767, loss_ce: 0.023070, loss_kd: 793.973022
[01:09:57.828] iteration 12980 : loss : 133.705063, loss_ce: 0.015668, loss_kd: 666.160278
[01:10:03.454] iteration 12990 : loss : 109.036514, loss_ce: 0.018646, loss_kd: 542.783203
[01:10:09.071] iteration 13000 : loss : 173.086945, loss_ce: 0.016375, loss_kd: 863.023499
[01:10:14.686] iteration 13010 : loss : 203.825867, loss_ce: 0.016617, loss_kd: 1016.745789
[01:10:20.290] iteration 13020 : loss : 189.398590, loss_ce: 0.019164, loss_kd: 944.588074
[01:10:25.918] iteration 13030 : loss : 126.302979, loss_ce: 0.017945, loss_kd: 629.064636
[01:10:31.520] iteration 13040 : loss : 159.626266, loss_ce: 0.021669, loss_kd: 795.758667
[01:10:37.133] iteration 13050 : loss : 160.316330, loss_ce: 0.019628, loss_kd: 799.181030
[01:10:42.745] iteration 13060 : loss : 145.485245, loss_ce: 0.019080, loss_kd: 724.957458
[01:10:48.420] iteration 13070 : loss : 209.370209, loss_ce: 0.015242, loss_kd: 1044.430664
[01:10:54.042] iteration 13080 : loss : 121.078537, loss_ce: 0.018995, loss_kd: 602.995117
[01:10:59.659] iteration 13090 : loss : 123.542801, loss_ce: 0.016542, loss_kd: 615.308716
[01:11:05.267] iteration 13100 : loss : 161.749771, loss_ce: 0.016233, loss_kd: 806.319458
[01:11:10.898] iteration 13110 : loss : 165.813675, loss_ce: 0.012331, loss_kd: 826.678772
[01:11:16.517] iteration 13120 : loss : 166.568726, loss_ce: 0.014293, loss_kd: 830.431519
[01:11:22.138] iteration 13130 : loss : 187.417526, loss_ce: 0.016153, loss_kd: 934.688049
[01:11:27.745] iteration 13140 : loss : 192.135178, loss_ce: 0.009702, loss_kd: 958.283630
[01:11:33.376] iteration 13150 : loss : 181.935989, loss_ce: 0.019880, loss_kd: 907.258118
[01:11:38.984] iteration 13160 : loss : 194.914932, loss_ce: 0.015776, loss_kd: 972.140198
[01:11:44.609] iteration 13170 : loss : 152.178757, loss_ce: 0.023341, loss_kd: 758.487183
[01:11:50.216] iteration 13180 : loss : 175.667801, loss_ce: 0.017224, loss_kd: 875.942566
[01:11:55.844] iteration 13190 : loss : 201.012024, loss_ce: 0.021554, loss_kd: 1002.616821
[01:12:01.455] iteration 13200 : loss : 151.533478, loss_ce: 0.014369, loss_kd: 755.243042
[01:12:07.078] iteration 13210 : loss : 184.069565, loss_ce: 0.019177, loss_kd: 917.957031
[01:12:12.692] iteration 13220 : loss : 164.720810, loss_ce: 0.012333, loss_kd: 821.197083
[01:12:18.317] iteration 13230 : loss : 169.914932, loss_ce: 0.022760, loss_kd: 847.135315
[01:12:23.925] iteration 13240 : loss : 157.844162, loss_ce: 0.016439, loss_kd: 786.829834
[01:12:29.549] iteration 13250 : loss : 118.810989, loss_ce: 0.018467, loss_kd: 591.644470
[01:12:35.177] iteration 13260 : loss : 188.797104, loss_ce: 0.019952, loss_kd: 941.545959
[01:12:40.804] iteration 13270 : loss : 202.783707, loss_ce: 0.015584, loss_kd: 1011.516174
[01:12:46.428] iteration 13280 : loss : 141.516693, loss_ce: 0.012516, loss_kd: 705.174622
[01:12:52.049] iteration 13290 : loss : 164.751373, loss_ce: 0.011713, loss_kd: 821.366943
[01:12:57.666] iteration 13300 : loss : 149.758636, loss_ce: 0.013786, loss_kd: 746.388245
[01:13:03.307] iteration 13310 : loss : 155.996399, loss_ce: 0.017260, loss_kd: 777.569458
[01:13:08.919] iteration 13320 : loss : 122.151718, loss_ce: 0.019902, loss_kd: 608.372498
[01:13:14.547] iteration 13330 : loss : 161.568329, loss_ce: 0.019800, loss_kd: 805.467163
[01:13:20.172] iteration 13340 : loss : 165.862579, loss_ce: 0.018825, loss_kd: 826.872070
[01:13:25.808] iteration 13350 : loss : 203.244568, loss_ce: 0.015697, loss_kd: 1013.818726
[01:13:31.435] iteration 13360 : loss : 167.697647, loss_ce: 0.016527, loss_kd: 836.082275
[01:13:37.057] iteration 13370 : loss : 167.763855, loss_ce: 0.012548, loss_kd: 836.408386
[01:13:42.670] iteration 13380 : loss : 130.509262, loss_ce: 0.023153, loss_kd: 650.110596
[01:13:48.311] iteration 13390 : loss : 127.075584, loss_ce: 0.009579, loss_kd: 633.007629
[01:13:53.932] iteration 13400 : loss : 145.724045, loss_ce: 0.011636, loss_kd: 726.226135
[01:13:59.572] iteration 13410 : loss : 160.461624, loss_ce: 0.013487, loss_kd: 799.909668
[01:14:05.190] iteration 13420 : loss : 180.595108, loss_ce: 0.021313, loss_kd: 900.549866
[01:14:10.823] iteration 13430 : loss : 155.872116, loss_ce: 0.013280, loss_kd: 776.973022
[01:14:16.452] iteration 13440 : loss : 175.513107, loss_ce: 0.014640, loss_kd: 875.138428
[01:14:22.080] iteration 13450 : loss : 149.746201, loss_ce: 0.022780, loss_kd: 746.343079
[01:14:27.703] iteration 13460 : loss : 136.270615, loss_ce: 0.014115, loss_kd: 678.956848
[01:14:33.344] iteration 13470 : loss : 176.091461, loss_ce: 0.012514, loss_kd: 878.064575
[01:14:38.980] iteration 13480 : loss : 205.874252, loss_ce: 0.017076, loss_kd: 1026.974854
[01:14:44.615] iteration 13490 : loss : 183.027359, loss_ce: 0.015123, loss_kd: 912.739380
[01:14:50.235] iteration 13500 : loss : 145.026047, loss_ce: 0.012317, loss_kd: 722.706360
[01:14:55.856] iteration 13510 : loss : 142.562546, loss_ce: 0.013527, loss_kd: 710.400024
[01:15:01.460] iteration 13520 : loss : 165.976501, loss_ce: 0.013004, loss_kd: 827.435791
[01:15:07.102] iteration 13530 : loss : 123.849388, loss_ce: 0.026276, loss_kd: 616.825623
[01:15:12.719] iteration 13540 : loss : 128.996506, loss_ce: 0.017964, loss_kd: 642.563538
[01:15:16.513] Running TPGM constraint optimization after epoch 13
[01:20:13.330] iteration 13550 : loss : 125.255356, loss_ce: 0.014831, loss_kd: 623.828552
[01:20:18.853] iteration 13560 : loss : 153.560776, loss_ce: 0.008701, loss_kd: 765.406860
[01:20:24.392] iteration 13570 : loss : 210.956406, loss_ce: 0.016281, loss_kd: 1052.394043
[01:20:29.921] iteration 13580 : loss : 204.320679, loss_ce: 0.022811, loss_kd: 1019.217407
[01:20:35.465] iteration 13590 : loss : 143.046341, loss_ce: 0.016063, loss_kd: 712.847961
[01:20:41.003] iteration 13600 : loss : 158.493958, loss_ce: 0.014064, loss_kd: 790.085327
[01:20:46.557] iteration 13610 : loss : 196.252304, loss_ce: 0.015455, loss_kd: 978.819641
[01:20:52.104] iteration 13620 : loss : 157.893265, loss_ce: 0.010076, loss_kd: 787.039856
[01:20:57.663] iteration 13630 : loss : 190.585571, loss_ce: 0.025137, loss_kd: 950.510559
[01:21:03.230] iteration 13640 : loss : 193.939636, loss_ce: 0.011174, loss_kd: 967.302002
[01:21:08.798] iteration 13650 : loss : 199.504257, loss_ce: 0.019749, loss_kd: 995.129395
[01:21:14.355] iteration 13660 : loss : 208.929214, loss_ce: 0.019821, loss_kd: 1042.258667
[01:21:19.922] iteration 13670 : loss : 154.135269, loss_ce: 0.011919, loss_kd: 768.272461
[01:21:25.480] iteration 13680 : loss : 123.536926, loss_ce: 0.020516, loss_kd: 615.255432
[01:21:31.056] iteration 13690 : loss : 116.726540, loss_ce: 0.009564, loss_kd: 581.217285
[01:21:36.624] iteration 13700 : loss : 145.175064, loss_ce: 0.015916, loss_kd: 723.455627
[01:21:42.205] iteration 13710 : loss : 166.366348, loss_ce: 0.017095, loss_kd: 829.449219
[01:21:47.782] iteration 13720 : loss : 119.548820, loss_ce: 0.020441, loss_kd: 595.312866
[01:21:53.376] iteration 13730 : loss : 166.601013, loss_ce: 0.025518, loss_kd: 830.618164
[01:21:58.948] iteration 13740 : loss : 142.486847, loss_ce: 0.016792, loss_kd: 710.015869
[01:22:04.535] iteration 13750 : loss : 155.550552, loss_ce: 0.016770, loss_kd: 775.337646
[01:22:10.108] iteration 13760 : loss : 130.784760, loss_ce: 0.017659, loss_kd: 651.533875
[01:22:15.705] iteration 13770 : loss : 169.975403, loss_ce: 0.019503, loss_kd: 847.485413
[01:22:21.291] iteration 13780 : loss : 133.551285, loss_ce: 0.016488, loss_kd: 665.342896
[01:22:26.889] iteration 13790 : loss : 153.455368, loss_ce: 0.016708, loss_kd: 764.862610
[01:22:32.484] iteration 13800 : loss : 182.599823, loss_ce: 0.020006, loss_kd: 910.556946
[01:22:38.090] iteration 13810 : loss : 191.832932, loss_ce: 0.011949, loss_kd: 956.778503
[01:22:43.689] iteration 13820 : loss : 141.436005, loss_ce: 0.016726, loss_kd: 704.730103
[01:22:49.290] iteration 13830 : loss : 145.608292, loss_ce: 0.013890, loss_kd: 725.650146
[01:22:54.888] iteration 13840 : loss : 166.673447, loss_ce: 0.008308, loss_kd: 830.978027
[01:23:00.494] iteration 13850 : loss : 147.514023, loss_ce: 0.026170, loss_kd: 735.118835
[01:23:06.091] iteration 13860 : loss : 144.420990, loss_ce: 0.019731, loss_kd: 719.644958
[01:23:11.693] iteration 13870 : loss : 163.207611, loss_ce: 0.020136, loss_kd: 813.632202
[01:23:17.291] iteration 13880 : loss : 142.746323, loss_ce: 0.010979, loss_kd: 711.314087
[01:23:22.897] iteration 13890 : loss : 154.346161, loss_ce: 0.020231, loss_kd: 769.310669
[01:23:28.496] iteration 13900 : loss : 131.055374, loss_ce: 0.013083, loss_kd: 652.889038
[01:23:34.097] iteration 13910 : loss : 132.477646, loss_ce: 0.015138, loss_kd: 659.987793
[01:23:39.698] iteration 13920 : loss : 181.008148, loss_ce: 0.006273, loss_kd: 902.602234
[01:23:45.319] iteration 13930 : loss : 176.959167, loss_ce: 0.023321, loss_kd: 882.388000
[01:23:50.919] iteration 13940 : loss : 147.895081, loss_ce: 0.013896, loss_kd: 737.102295
[01:23:56.544] iteration 13950 : loss : 231.880264, loss_ce: 0.011635, loss_kd: 1157.000854
[01:24:02.161] iteration 13960 : loss : 144.101212, loss_ce: 0.019060, loss_kd: 718.097595
[01:24:07.798] iteration 13970 : loss : 122.868729, loss_ce: 0.016158, loss_kd: 611.940002
[01:24:13.422] iteration 13980 : loss : 149.231735, loss_ce: 0.016942, loss_kd: 743.751587
[01:24:19.046] iteration 13990 : loss : 144.134171, loss_ce: 0.014933, loss_kd: 718.264709
[01:24:24.651] iteration 14000 : loss : 150.629837, loss_ce: 0.025432, loss_kd: 750.740906
[01:24:30.287] iteration 14010 : loss : 157.387222, loss_ce: 0.014835, loss_kd: 784.566650
[01:24:35.905] iteration 14020 : loss : 135.196228, loss_ce: 0.012491, loss_kd: 673.583374
[01:24:41.546] iteration 14030 : loss : 168.014893, loss_ce: 0.014122, loss_kd: 837.646484
[01:24:47.164] iteration 14040 : loss : 161.358139, loss_ce: 0.010546, loss_kd: 804.401733
[01:24:52.810] iteration 14050 : loss : 183.999832, loss_ce: 0.017983, loss_kd: 917.585388
[01:24:58.426] iteration 14060 : loss : 127.671371, loss_ce: 0.011755, loss_kd: 635.983826
[01:25:04.067] iteration 14070 : loss : 112.765305, loss_ce: 0.021603, loss_kd: 561.315063
[01:25:09.698] iteration 14080 : loss : 162.348160, loss_ce: 0.015842, loss_kd: 809.314026
[01:25:15.320] iteration 14090 : loss : 125.983917, loss_ce: 0.010740, loss_kd: 627.496216
[01:25:20.945] iteration 14100 : loss : 134.681717, loss_ce: 0.022636, loss_kd: 671.010803
[01:25:26.581] iteration 14110 : loss : 138.612488, loss_ce: 0.016890, loss_kd: 690.645752
[01:25:32.205] iteration 14120 : loss : 182.677216, loss_ce: 0.009620, loss_kd: 910.990295
[01:25:37.836] iteration 14130 : loss : 149.454361, loss_ce: 0.018694, loss_kd: 744.893555
[01:25:43.463] iteration 14140 : loss : 157.257401, loss_ce: 0.013903, loss_kd: 783.889954
[01:25:49.099] iteration 14150 : loss : 117.958725, loss_ce: 0.013966, loss_kd: 587.433350
[01:25:54.732] iteration 14160 : loss : 114.212883, loss_ce: 0.018800, loss_kd: 568.667542
[01:26:00.356] iteration 14170 : loss : 258.159485, loss_ce: 0.018790, loss_kd: 1288.395142
[01:26:05.966] iteration 14180 : loss : 123.575333, loss_ce: 0.016434, loss_kd: 615.493286
[01:26:11.603] iteration 14190 : loss : 144.157486, loss_ce: 0.022147, loss_kd: 718.382202
[01:26:17.234] iteration 14200 : loss : 154.163376, loss_ce: 0.015064, loss_kd: 768.436768
[01:26:22.874] iteration 14210 : loss : 134.296982, loss_ce: 0.013628, loss_kd: 669.097900
[01:26:28.490] iteration 14220 : loss : 165.325089, loss_ce: 0.013032, loss_kd: 824.196045
[01:26:34.118] iteration 14230 : loss : 117.688927, loss_ce: 0.013320, loss_kd: 586.033264
[01:26:39.739] iteration 14240 : loss : 137.413391, loss_ce: 0.015705, loss_kd: 684.667114
[01:26:45.373] iteration 14250 : loss : 121.561272, loss_ce: 0.015761, loss_kd: 605.376526
[01:26:50.999] iteration 14260 : loss : 125.773857, loss_ce: 0.020910, loss_kd: 626.451538
[01:26:56.620] iteration 14270 : loss : 152.753922, loss_ce: 0.018465, loss_kd: 761.351868
[01:27:02.236] iteration 14280 : loss : 150.931305, loss_ce: 0.021342, loss_kd: 752.260010
[01:27:07.874] iteration 14290 : loss : 176.158905, loss_ce: 0.014153, loss_kd: 878.394897
[01:27:13.504] iteration 14300 : loss : 163.504730, loss_ce: 0.018687, loss_kd: 815.149536
[01:27:19.152] iteration 14310 : loss : 195.053802, loss_ce: 0.013142, loss_kd: 972.871887
[01:27:24.754] iteration 14320 : loss : 173.627838, loss_ce: 0.016307, loss_kd: 865.746582
[01:27:30.378] iteration 14330 : loss : 162.335770, loss_ce: 0.009943, loss_kd: 809.293152
[01:27:35.996] iteration 14340 : loss : 125.281639, loss_ce: 0.008774, loss_kd: 624.051086
[01:27:41.632] iteration 14350 : loss : 115.847809, loss_ce: 0.014215, loss_kd: 576.864197
[01:27:47.253] iteration 14360 : loss : 143.371841, loss_ce: 0.010776, loss_kd: 714.417236
[01:27:52.887] iteration 14370 : loss : 132.713882, loss_ce: 0.016637, loss_kd: 661.172363
[01:27:58.503] iteration 14380 : loss : 174.218994, loss_ce: 0.010110, loss_kd: 868.686279
[01:28:04.152] iteration 14390 : loss : 126.337494, loss_ce: 0.022376, loss_kd: 629.272583
[01:28:09.774] iteration 14400 : loss : 147.406494, loss_ce: 0.011281, loss_kd: 734.655273
[01:28:15.421] iteration 14410 : loss : 148.788910, loss_ce: 0.016800, loss_kd: 741.551208
[01:28:21.041] iteration 14420 : loss : 133.884583, loss_ce: 0.017972, loss_kd: 667.004883
[01:28:26.685] iteration 14430 : loss : 129.497162, loss_ce: 0.027489, loss_kd: 645.062073
[01:28:32.320] iteration 14440 : loss : 137.713898, loss_ce: 0.013686, loss_kd: 686.154968
[01:28:37.954] iteration 14450 : loss : 174.700150, loss_ce: 0.010709, loss_kd: 871.091492
[01:28:43.564] iteration 14460 : loss : 135.336517, loss_ce: 0.016362, loss_kd: 674.282043
[01:28:49.211] iteration 14470 : loss : 148.475876, loss_ce: 0.015674, loss_kd: 739.985596
[01:28:54.826] iteration 14480 : loss : 178.810303, loss_ce: 0.022567, loss_kd: 891.604919
[01:29:00.456] iteration 14490 : loss : 104.453400, loss_ce: 0.017875, loss_kd: 519.840332
[01:29:06.084] iteration 14500 : loss : 186.641159, loss_ce: 0.022280, loss_kd: 930.806396
[01:29:11.735] iteration 14510 : loss : 171.047684, loss_ce: 0.015556, loss_kd: 852.847778
[01:29:17.363] iteration 14520 : loss : 166.581177, loss_ce: 0.017422, loss_kd: 830.526428
[01:29:23.017] iteration 14530 : loss : 156.107422, loss_ce: 0.014880, loss_kd: 778.106201
[01:29:28.624] iteration 14540 : loss : 138.616302, loss_ce: 0.018645, loss_kd: 690.672546
[01:29:34.277] iteration 14550 : loss : 123.463364, loss_ce: 0.017261, loss_kd: 614.869812
[01:29:39.896] iteration 14560 : loss : 146.240173, loss_ce: 0.018649, loss_kd: 728.798279
[01:29:45.561] iteration 14570 : loss : 139.001480, loss_ce: 0.013412, loss_kd: 692.618164
[01:29:51.185] iteration 14580 : loss : 172.546951, loss_ce: 0.025201, loss_kd: 860.309509
[01:30:08.053] iteration 14590 : loss : 137.690979, loss_ce: 0.020846, loss_kd: 686.066345
[01:30:13.599] iteration 14600 : loss : 170.538956, loss_ce: 0.017247, loss_kd: 850.300415
[01:30:19.172] iteration 14610 : loss : 135.493591, loss_ce: 0.014297, loss_kd: 675.045654
[01:30:24.738] iteration 14620 : loss : 162.267090, loss_ce: 0.026615, loss_kd: 808.900391
[01:30:30.313] iteration 14630 : loss : 142.630463, loss_ce: 0.015697, loss_kd: 710.777100
[01:30:35.881] iteration 14640 : loss : 191.961319, loss_ce: 0.023500, loss_kd: 957.383911
[01:30:41.466] iteration 14650 : loss : 117.103783, loss_ce: 0.016132, loss_kd: 583.107422
[01:30:47.046] iteration 14660 : loss : 135.887863, loss_ce: 0.018491, loss_kd: 677.056213
[01:30:52.679] iteration 14670 : loss : 106.494293, loss_ce: 0.015934, loss_kd: 530.077393
[01:30:58.263] iteration 14680 : loss : 136.142929, loss_ce: 0.015328, loss_kd: 678.269409
[01:31:03.857] iteration 14690 : loss : 134.145782, loss_ce: 0.020782, loss_kd: 668.314453
[01:31:09.450] iteration 14700 : loss : 189.733032, loss_ce: 0.032144, loss_kd: 946.238831
[01:31:15.058] iteration 14710 : loss : 113.079010, loss_ce: 0.015573, loss_kd: 563.015320
[01:31:20.646] iteration 14720 : loss : 190.278442, loss_ce: 0.014989, loss_kd: 949.010742
[01:31:26.255] iteration 14730 : loss : 160.257935, loss_ce: 0.020199, loss_kd: 798.873596
[01:31:31.852] iteration 14740 : loss : 170.293228, loss_ce: 0.020890, loss_kd: 849.083801
[01:31:37.466] iteration 14750 : loss : 154.010162, loss_ce: 0.024271, loss_kd: 767.654724
[01:31:43.072] iteration 14760 : loss : 142.995544, loss_ce: 0.015953, loss_kd: 712.593567
[01:31:48.698] iteration 14770 : loss : 138.786896, loss_ce: 0.018074, loss_kd: 691.515320
[01:31:54.304] iteration 14780 : loss : 152.439713, loss_ce: 0.016833, loss_kd: 759.829712
[01:31:59.921] iteration 14790 : loss : 119.793694, loss_ce: 0.023791, loss_kd: 596.570801
[01:32:05.536] iteration 14800 : loss : 179.215958, loss_ce: 0.016714, loss_kd: 893.699280
[01:32:11.154] iteration 14810 : loss : 139.942719, loss_ce: 0.015042, loss_kd: 697.295532
[01:32:16.772] iteration 14820 : loss : 168.504059, loss_ce: 0.013563, loss_kd: 840.116394
[01:32:22.392] iteration 14830 : loss : 164.059021, loss_ce: 0.021649, loss_kd: 817.870728
[01:32:28.008] iteration 14840 : loss : 137.892487, loss_ce: 0.008844, loss_kd: 687.070557
[01:32:33.635] iteration 14850 : loss : 171.117996, loss_ce: 0.012732, loss_kd: 853.153809
[01:32:39.237] iteration 14860 : loss : 123.041733, loss_ce: 0.015470, loss_kd: 612.794861
[01:32:44.871] iteration 14870 : loss : 154.572815, loss_ce: 0.015253, loss_kd: 770.457581
[01:32:50.487] iteration 14880 : loss : 127.125092, loss_ce: 0.023736, loss_kd: 633.207397
[01:32:56.110] iteration 14890 : loss : 144.551773, loss_ce: 0.009926, loss_kd: 720.383057
[01:33:01.748] iteration 14900 : loss : 148.716599, loss_ce: 0.030712, loss_kd: 741.157593
[01:33:07.365] iteration 14910 : loss : 175.541611, loss_ce: 0.010354, loss_kd: 875.283813
[01:33:12.976] iteration 14920 : loss : 148.137161, loss_ce: 0.014331, loss_kd: 738.297180
[01:33:18.596] iteration 14930 : loss : 211.109589, loss_ce: 0.018270, loss_kd: 1053.144775
[01:33:24.223] iteration 14940 : loss : 165.497681, loss_ce: 0.019471, loss_kd: 825.092834
[01:33:29.851] iteration 14950 : loss : 123.154503, loss_ce: 0.021449, loss_kd: 613.379456
[01:33:35.483] iteration 14960 : loss : 171.660767, loss_ce: 0.014181, loss_kd: 855.887573
[01:33:41.111] iteration 14970 : loss : 171.381805, loss_ce: 0.021939, loss_kd: 854.489746
[01:33:46.750] iteration 14980 : loss : 131.930939, loss_ce: 0.019268, loss_kd: 657.241577
[01:33:52.375] iteration 14990 : loss : 133.086395, loss_ce: 0.013708, loss_kd: 663.041626
[01:33:57.996] iteration 15000 : loss : 150.291641, loss_ce: 0.012666, loss_kd: 749.023132
[01:34:03.759] iteration 15010 : loss : 147.241547, loss_ce: 0.012914, loss_kd: 733.826111
[01:34:09.380] iteration 15020 : loss : 115.400993, loss_ce: 0.017753, loss_kd: 574.585938
[01:34:15.012] iteration 15030 : loss : 174.209946, loss_ce: 0.012426, loss_kd: 868.660522
[01:34:20.643] iteration 15040 : loss : 164.952057, loss_ce: 0.028259, loss_kd: 822.352966
[01:34:26.277] iteration 15050 : loss : 155.927460, loss_ce: 0.014362, loss_kd: 777.244385
[01:34:31.902] iteration 15060 : loss : 149.081299, loss_ce: 0.021928, loss_kd: 742.980530
[01:34:37.541] iteration 15070 : loss : 127.976654, loss_ce: 0.020114, loss_kd: 637.471252
[01:34:43.166] iteration 15080 : loss : 119.282684, loss_ce: 0.026375, loss_kd: 593.991272
[01:34:48.812] iteration 15090 : loss : 155.504715, loss_ce: 0.015231, loss_kd: 775.118530
[01:34:54.449] iteration 15100 : loss : 126.012947, loss_ce: 0.020314, loss_kd: 627.705627
[01:35:00.103] iteration 15110 : loss : 155.731812, loss_ce: 0.017394, loss_kd: 776.277466
[01:35:05.727] iteration 15120 : loss : 102.154099, loss_ce: 0.011444, loss_kd: 508.396301
[01:35:11.374] iteration 15130 : loss : 120.446083, loss_ce: 0.018044, loss_kd: 599.829956
[01:35:17.004] iteration 15140 : loss : 137.896805, loss_ce: 0.010722, loss_kd: 687.056152
[01:35:22.652] iteration 15150 : loss : 140.339981, loss_ce: 0.018367, loss_kd: 699.285950
[01:35:28.281] iteration 15160 : loss : 125.281830, loss_ce: 0.013413, loss_kd: 624.010132
[01:35:33.958] iteration 15170 : loss : 125.450317, loss_ce: 0.024838, loss_kd: 624.844055
[01:35:39.584] iteration 15180 : loss : 145.004044, loss_ce: 0.026251, loss_kd: 722.629517
[01:35:45.249] iteration 15190 : loss : 158.222748, loss_ce: 0.016082, loss_kd: 788.714844
[01:35:50.895] iteration 15200 : loss : 184.877213, loss_ce: 0.010554, loss_kd: 921.990356
[01:35:56.533] iteration 15210 : loss : 164.760162, loss_ce: 0.022768, loss_kd: 821.419312
[01:36:02.171] iteration 15220 : loss : 176.719147, loss_ce: 0.024951, loss_kd: 881.206360
[01:36:07.799] iteration 15230 : loss : 187.602982, loss_ce: 0.011902, loss_kd: 935.575256
[01:36:13.443] iteration 15240 : loss : 114.705215, loss_ce: 0.012150, loss_kd: 571.149292
[01:36:19.079] iteration 15250 : loss : 169.603912, loss_ce: 0.014628, loss_kd: 845.637390
[01:36:24.716] iteration 15260 : loss : 138.415085, loss_ce: 0.012941, loss_kd: 689.669189
[01:36:30.342] iteration 15270 : loss : 134.643097, loss_ce: 0.013754, loss_kd: 670.848938
[01:36:35.977] iteration 15280 : loss : 145.352768, loss_ce: 0.021363, loss_kd: 724.351257
[01:36:41.612] iteration 15290 : loss : 118.876450, loss_ce: 0.020371, loss_kd: 591.982910
[01:36:47.242] iteration 15300 : loss : 135.582092, loss_ce: 0.018493, loss_kd: 675.517334
[01:36:52.885] iteration 15310 : loss : 143.356552, loss_ce: 0.019828, loss_kd: 714.400757
[01:36:58.513] iteration 15320 : loss : 133.475555, loss_ce: 0.022927, loss_kd: 664.926880
[01:37:04.137] iteration 15330 : loss : 163.929474, loss_ce: 0.024207, loss_kd: 817.276672
[01:37:09.767] iteration 15340 : loss : 145.978241, loss_ce: 0.020822, loss_kd: 727.477539
[01:37:15.407] iteration 15350 : loss : 127.998161, loss_ce: 0.014173, loss_kd: 637.627380
[01:37:21.041] iteration 15360 : loss : 211.953522, loss_ce: 0.014140, loss_kd: 1057.399292
[01:37:26.679] iteration 15370 : loss : 167.076965, loss_ce: 0.017547, loss_kd: 832.989380
[01:37:32.316] iteration 15380 : loss : 111.501030, loss_ce: 0.012887, loss_kd: 555.105774
[01:37:37.964] iteration 15390 : loss : 144.984390, loss_ce: 0.012930, loss_kd: 722.502258
[01:37:43.598] iteration 15400 : loss : 146.631256, loss_ce: 0.014310, loss_kd: 730.702026
[01:37:49.242] iteration 15410 : loss : 126.851501, loss_ce: 0.019109, loss_kd: 631.883789
[01:37:54.874] iteration 15420 : loss : 109.733055, loss_ce: 0.010801, loss_kd: 546.277771
[01:38:00.524] iteration 15430 : loss : 132.768951, loss_ce: 0.019044, loss_kd: 661.422180
[01:38:06.141] iteration 15440 : loss : 132.633911, loss_ce: 0.015571, loss_kd: 660.771667
[01:38:11.777] iteration 15450 : loss : 143.343521, loss_ce: 0.022495, loss_kd: 714.308838
[01:38:17.408] iteration 15460 : loss : 112.110016, loss_ce: 0.017338, loss_kd: 558.136414
[01:38:23.057] iteration 15470 : loss : 153.650208, loss_ce: 0.025650, loss_kd: 765.849243
[01:38:28.683] iteration 15480 : loss : 107.779236, loss_ce: 0.016629, loss_kd: 536.524902
[01:38:34.318] iteration 15490 : loss : 123.746216, loss_ce: 0.016153, loss_kd: 616.310059
[01:38:39.948] iteration 15500 : loss : 167.816406, loss_ce: 0.026645, loss_kd: 836.662842
[01:38:45.591] iteration 15510 : loss : 151.660873, loss_ce: 0.010552, loss_kd: 755.919800
[01:38:51.234] iteration 15520 : loss : 136.980011, loss_ce: 0.015082, loss_kd: 682.516357
[01:38:56.866] iteration 15530 : loss : 124.067352, loss_ce: 0.013825, loss_kd: 617.908997
[01:39:02.503] iteration 15540 : loss : 122.915123, loss_ce: 0.029718, loss_kd: 612.177734
[01:39:08.143] iteration 15550 : loss : 153.909897, loss_ce: 0.011914, loss_kd: 767.190674
[01:39:13.783] iteration 15560 : loss : 158.692841, loss_ce: 0.019186, loss_kd: 791.070984
[01:39:19.411] iteration 15570 : loss : 156.698318, loss_ce: 0.012629, loss_kd: 781.104980
[01:39:25.045] iteration 15580 : loss : 184.901855, loss_ce: 0.013626, loss_kd: 922.085449
[01:39:30.672] iteration 15590 : loss : 132.905014, loss_ce: 0.017690, loss_kd: 662.136841
[01:39:36.312] iteration 15600 : loss : 135.955582, loss_ce: 0.021097, loss_kd: 677.402527
[01:39:41.964] iteration 15610 : loss : 119.626099, loss_ce: 0.015413, loss_kd: 595.740295
[01:39:47.594] iteration 15620 : loss : 131.673615, loss_ce: 0.011496, loss_kd: 656.012329
[01:39:52.957] iteration 15630 : loss : 91.629143, loss_ce: 0.022802, loss_kd: 455.716949
[01:39:53.740] save model to ./debug_fixed_tpgm\continual_surgical_tpgm_epoch_14.pth
[01:39:53.741] Applying final TPGM projection
[01:39:53.925] save final model to ./debug_fixed_tpgm\continual_surgical_tpgm_final.pth
[17:37:36.961] Namespace(root_path='./datasets/kits23/train_npz', dataset='kits23', list_dir='./lists/kits23', stage=1, num_classes_old=9, num_classes_new=4, num_classes_lits17=3, output_dir='./debug_fixed_tpgm', max_iterations=10000, max_epochs=15, batch_size=32, n_gpu=1, deterministic=1, base_lr=0.001, img_size=224, seed=1234, cfg='configs/finetune.yaml', pretrained_path='./pretrain/epoch_149.pth', data_fraction=0.35, kd_temperature=3.0, kd_weight=0.2, freeze_old_classes=False, auto_tune='none', gradient_batches=5, tpgm_norm_mode='l2', tpgm_lr=0.05, tpgm_iters=500, tpgm_exclude=[], tpgm_frequency=2, tpgm_start_epoch=2, disable_tpgm=False, tpgm_data_fraction=0.3, opts=None, zip=False, cache_mode='part', resume=None, accumulation_steps=None, use_checkpoint=False, amp_opt_level='O1', tag=None, eval=False, throughput=False)
[17:37:36.980] Stage 1: Using 33327/95221 samples (35.0%) for continual learning
[17:37:36.980] Old classes: 9, New classes: 4, Total: 12
[17:37:36.980] Dataset: kits23
[17:37:36.980] TPGM enabled: True
[17:37:36.980] Surgical fine-tuning method: none
[17:40:42.542] Combined Continual Learning Stage 1 + Surgical + TPGM Configuration:
[17:40:42.542] KD Temperature: 3.0
[17:40:42.542] KD Weight: 0.2
[17:40:42.542] Auto-tune method: none
[17:40:42.542] TPGM start epoch: 2
[17:40:42.542] TPGM frequency: 2
[17:40:42.542] 1042 iterations per epoch. 15630 max iterations 
[17:40:58.605] iteration 10 : loss : 5603.246582, loss_ce: 0.254506, loss_kd: 28013.501953
[17:41:04.075] iteration 20 : loss : 3771.561279, loss_ce: 0.232940, loss_kd: 18854.687500
[17:41:09.606] iteration 30 : loss : 4068.643311, loss_ce: 0.170892, loss_kd: 20340.373047
[17:41:15.095] iteration 40 : loss : 2952.815674, loss_ce: 0.147216, loss_kd: 14761.041016
[17:41:20.605] iteration 50 : loss : 1991.151123, loss_ce: 0.134721, loss_kd: 9952.947266
[17:41:26.106] iteration 60 : loss : 1787.323975, loss_ce: 0.171531, loss_kd: 8933.642578
[17:41:31.618] iteration 70 : loss : 1302.562500, loss_ce: 0.168004, loss_kd: 6509.942871
[17:41:37.125] iteration 80 : loss : 1267.604736, loss_ce: 0.093403, loss_kd: 6335.222168
[17:41:42.639] iteration 90 : loss : 1514.672241, loss_ce: 0.126000, loss_kd: 7570.385254
[17:41:48.145] iteration 100 : loss : 1292.782593, loss_ce: 0.098314, loss_kd: 6461.148926
[17:41:53.670] iteration 110 : loss : 1334.174072, loss_ce: 0.080514, loss_kd: 6667.932617
[17:41:59.180] iteration 120 : loss : 1364.823608, loss_ce: 0.078627, loss_kd: 6821.250000
[17:42:04.704] iteration 130 : loss : 1067.468506, loss_ce: 0.098510, loss_kd: 5334.640625
[17:42:10.219] iteration 140 : loss : 1271.808838, loss_ce: 0.058937, loss_kd: 6356.400391
[17:42:15.745] iteration 150 : loss : 1064.039795, loss_ce: 0.085945, loss_kd: 5317.400391
[17:42:21.265] iteration 160 : loss : 1198.357788, loss_ce: 0.024793, loss_kd: 5989.071289
[17:42:26.793] iteration 170 : loss : 911.944824, loss_ce: 0.026217, loss_kd: 4557.009766
[17:42:32.312] iteration 180 : loss : 1339.675537, loss_ce: 0.018147, loss_kd: 6695.767090
[17:42:37.845] iteration 190 : loss : 909.561035, loss_ce: 0.043075, loss_kd: 4545.091309
[17:42:43.381] iteration 200 : loss : 862.236206, loss_ce: 0.034092, loss_kd: 4308.442383
[17:42:48.920] iteration 210 : loss : 838.607788, loss_ce: 0.025415, loss_kd: 4190.500000
[17:42:54.445] iteration 220 : loss : 907.366760, loss_ce: 0.021083, loss_kd: 4534.179199
[17:42:59.983] iteration 230 : loss : 1259.537231, loss_ce: 0.018248, loss_kd: 6295.015137
[17:43:05.510] iteration 240 : loss : 662.233398, loss_ce: 0.017866, loss_kd: 3308.486084
[17:43:11.047] iteration 250 : loss : 664.609619, loss_ce: 0.021476, loss_kd: 3320.434082
[17:43:16.577] iteration 260 : loss : 1170.447998, loss_ce: 0.030219, loss_kd: 5849.553711
[17:43:22.121] iteration 270 : loss : 840.907898, loss_ce: 0.012443, loss_kd: 4202.014160
[17:43:27.655] iteration 280 : loss : 951.925598, loss_ce: 0.027856, loss_kd: 4757.088379
[17:43:33.197] iteration 290 : loss : 781.685608, loss_ce: 0.009956, loss_kd: 3905.769775
[17:43:38.732] iteration 300 : loss : 727.529602, loss_ce: 0.010693, loss_kd: 3635.146484
[17:43:44.278] iteration 310 : loss : 841.190918, loss_ce: 0.022380, loss_kd: 4203.367676
[17:43:49.818] iteration 320 : loss : 1059.872925, loss_ce: 0.016011, loss_kd: 5296.823730
[17:43:55.368] iteration 330 : loss : 832.491272, loss_ce: 0.019374, loss_kd: 4159.865234
[17:44:00.907] iteration 340 : loss : 807.053101, loss_ce: 0.015402, loss_kd: 4032.727295
[17:44:06.462] iteration 350 : loss : 780.537109, loss_ce: 0.027872, loss_kd: 3900.122070
[17:44:12.003] iteration 360 : loss : 651.616821, loss_ce: 0.025221, loss_kd: 3255.549561
[17:44:17.559] iteration 370 : loss : 691.620728, loss_ce: 0.018099, loss_kd: 3455.562744
[17:44:23.110] iteration 380 : loss : 653.950623, loss_ce: 0.022522, loss_kd: 3267.224121
[17:44:28.667] iteration 390 : loss : 864.127869, loss_ce: 0.010945, loss_kd: 4318.078125
[17:44:34.213] iteration 400 : loss : 968.035828, loss_ce: 0.016071, loss_kd: 4837.653809
[17:44:39.778] iteration 410 : loss : 944.567200, loss_ce: 0.024826, loss_kd: 4720.268066
[17:44:45.324] iteration 420 : loss : 811.525940, loss_ce: 0.022086, loss_kd: 4055.094971
[17:44:50.886] iteration 430 : loss : 663.257751, loss_ce: 0.013856, loss_kd: 3313.819824
[17:44:56.440] iteration 440 : loss : 881.238892, loss_ce: 0.019214, loss_kd: 4403.719238
[17:45:02.007] iteration 450 : loss : 422.082550, loss_ce: 0.015780, loss_kd: 2107.828857
[17:45:07.564] iteration 460 : loss : 673.168945, loss_ce: 0.022680, loss_kd: 3363.321045
[17:45:13.130] iteration 470 : loss : 727.203003, loss_ce: 0.021419, loss_kd: 3633.490234
[17:45:18.688] iteration 480 : loss : 978.198792, loss_ce: 0.028162, loss_kd: 4888.484375
[17:45:24.258] iteration 490 : loss : 654.228882, loss_ce: 0.020488, loss_kd: 3268.660156
[17:45:29.817] iteration 500 : loss : 907.575745, loss_ce: 0.021416, loss_kd: 4535.348145
[17:45:35.389] iteration 510 : loss : 603.172241, loss_ce: 0.029870, loss_kd: 3013.331543
[17:45:40.955] iteration 520 : loss : 612.006226, loss_ce: 0.028098, loss_kd: 3057.391357
[17:45:46.528] iteration 530 : loss : 616.900574, loss_ce: 0.016522, loss_kd: 3081.918213
[17:45:52.096] iteration 540 : loss : 730.196167, loss_ce: 0.020933, loss_kd: 3648.421143
[17:45:57.670] iteration 550 : loss : 610.540161, loss_ce: 0.024975, loss_kd: 3050.058838
[17:46:03.241] iteration 560 : loss : 795.854614, loss_ce: 0.017605, loss_kd: 3976.620850
[17:46:08.826] iteration 570 : loss : 726.178589, loss_ce: 0.031140, loss_kd: 3628.345215
[17:46:14.393] iteration 580 : loss : 541.403015, loss_ce: 0.031228, loss_kd: 2704.522949
[17:46:19.973] iteration 590 : loss : 636.621460, loss_ce: 0.011887, loss_kd: 3180.607178
[17:46:25.555] iteration 600 : loss : 707.603699, loss_ce: 0.025396, loss_kd: 3535.484375
[17:46:31.154] iteration 610 : loss : 566.814392, loss_ce: 0.022972, loss_kd: 2831.598633
[17:46:36.727] iteration 620 : loss : 713.867310, loss_ce: 0.013352, loss_kd: 3566.801025
[17:46:42.309] iteration 630 : loss : 615.889221, loss_ce: 0.036140, loss_kd: 3076.806396
[17:46:47.890] iteration 640 : loss : 636.030884, loss_ce: 0.031943, loss_kd: 3177.594727
[17:46:53.480] iteration 650 : loss : 474.344604, loss_ce: 0.027798, loss_kd: 2369.208984
[17:46:59.055] iteration 660 : loss : 817.460022, loss_ce: 0.029017, loss_kd: 4084.842773
[17:47:04.645] iteration 670 : loss : 665.871399, loss_ce: 0.020711, loss_kd: 3326.755859
[17:47:10.223] iteration 680 : loss : 496.952911, loss_ce: 0.026483, loss_kd: 2482.235107
[17:47:15.812] iteration 690 : loss : 735.796448, loss_ce: 0.021305, loss_kd: 3676.508301
[17:47:21.401] iteration 700 : loss : 548.486572, loss_ce: 0.023823, loss_kd: 2739.705566
[17:47:27.003] iteration 710 : loss : 560.184814, loss_ce: 0.025484, loss_kd: 2798.234619
[17:47:32.591] iteration 720 : loss : 678.425476, loss_ce: 0.020215, loss_kd: 3389.692871
[17:47:38.188] iteration 730 : loss : 726.635193, loss_ce: 0.039528, loss_kd: 3630.632080
[17:47:43.778] iteration 740 : loss : 573.273865, loss_ce: 0.026745, loss_kd: 2863.835205
[17:47:49.368] iteration 750 : loss : 548.391846, loss_ce: 0.022649, loss_kd: 2739.364746
[17:47:54.954] iteration 760 : loss : 585.330200, loss_ce: 0.028936, loss_kd: 2924.132080
[17:48:00.544] iteration 770 : loss : 632.493042, loss_ce: 0.035183, loss_kd: 3159.918945
[17:48:06.140] iteration 780 : loss : 663.047485, loss_ce: 0.035218, loss_kd: 3312.714844
[17:48:11.743] iteration 790 : loss : 555.878540, loss_ce: 0.020923, loss_kd: 2776.894775
[17:48:17.332] iteration 800 : loss : 611.025574, loss_ce: 0.035615, loss_kd: 3052.573730
[17:48:22.944] iteration 810 : loss : 544.123596, loss_ce: 0.025724, loss_kd: 2717.962158
[17:48:28.541] iteration 820 : loss : 676.998413, loss_ce: 0.021262, loss_kd: 3382.443359
[17:48:34.138] iteration 830 : loss : 823.431335, loss_ce: 0.029360, loss_kd: 4114.600586
[17:48:39.732] iteration 840 : loss : 754.425415, loss_ce: 0.018729, loss_kd: 3769.695801
[17:48:45.335] iteration 850 : loss : 694.665039, loss_ce: 0.029190, loss_kd: 3470.804932
[17:48:50.929] iteration 860 : loss : 577.355347, loss_ce: 0.029280, loss_kd: 2884.297363
[17:48:56.533] iteration 870 : loss : 488.280548, loss_ce: 0.018591, loss_kd: 2438.854004
[17:49:02.129] iteration 880 : loss : 453.204712, loss_ce: 0.041447, loss_kd: 2263.524414
[17:49:07.730] iteration 890 : loss : 542.730591, loss_ce: 0.023775, loss_kd: 2711.212891
[17:49:13.328] iteration 900 : loss : 554.802002, loss_ce: 0.027715, loss_kd: 2771.436523
[17:49:18.934] iteration 910 : loss : 414.624573, loss_ce: 0.020012, loss_kd: 2070.623047
[17:49:24.522] iteration 920 : loss : 392.816193, loss_ce: 0.016763, loss_kd: 1961.615479
[17:49:30.123] iteration 930 : loss : 530.256592, loss_ce: 0.021477, loss_kd: 2648.739746
[17:49:35.722] iteration 940 : loss : 500.105347, loss_ce: 0.022128, loss_kd: 2498.031250
[17:49:41.335] iteration 950 : loss : 589.617615, loss_ce: 0.019337, loss_kd: 2945.494385
[17:49:46.924] iteration 960 : loss : 799.554993, loss_ce: 0.037545, loss_kd: 3995.150146
[17:49:52.526] iteration 970 : loss : 620.583435, loss_ce: 0.022257, loss_kd: 3100.341797
[17:49:58.131] iteration 980 : loss : 583.164001, loss_ce: 0.031464, loss_kd: 2913.263916
[17:50:03.734] iteration 990 : loss : 540.022400, loss_ce: 0.019766, loss_kd: 2697.648438
[17:50:09.330] iteration 1000 : loss : 648.267822, loss_ce: 0.024472, loss_kd: 3238.757324
[17:50:14.947] iteration 1010 : loss : 633.328796, loss_ce: 0.026203, loss_kd: 3164.161865
[17:50:20.551] iteration 1020 : loss : 661.091675, loss_ce: 0.024497, loss_kd: 3302.800293
[17:50:26.170] iteration 1030 : loss : 370.661133, loss_ce: 0.031420, loss_kd: 1850.821411
[17:50:31.769] iteration 1040 : loss : 515.209534, loss_ce: 0.024679, loss_kd: 2573.578369
[17:50:47.734] iteration 1050 : loss : 534.357849, loss_ce: 0.031777, loss_kd: 2669.313232
[17:50:53.280] iteration 1060 : loss : 558.171997, loss_ce: 0.028920, loss_kd: 2788.288330
[17:50:58.840] iteration 1070 : loss : 459.596588, loss_ce: 0.019846, loss_kd: 2295.418457
[17:51:04.395] iteration 1080 : loss : 366.173309, loss_ce: 0.024151, loss_kd: 1828.342651
[17:51:09.965] iteration 1090 : loss : 485.633850, loss_ce: 0.026836, loss_kd: 2425.708252
[17:51:15.528] iteration 1100 : loss : 586.554260, loss_ce: 0.016677, loss_kd: 2930.193359
[17:51:21.104] iteration 1110 : loss : 457.327911, loss_ce: 0.031790, loss_kd: 2284.031494
[17:51:26.678] iteration 1120 : loss : 565.887024, loss_ce: 0.020341, loss_kd: 2826.890137
[17:51:32.262] iteration 1130 : loss : 356.718994, loss_ce: 0.023567, loss_kd: 1781.102417
[17:51:37.830] iteration 1140 : loss : 469.007477, loss_ce: 0.023519, loss_kd: 2342.427979
[17:51:43.418] iteration 1150 : loss : 362.717407, loss_ce: 0.020171, loss_kd: 1811.100464
[17:51:49.005] iteration 1160 : loss : 416.572266, loss_ce: 0.026810, loss_kd: 2080.310547
[17:51:54.608] iteration 1170 : loss : 628.881775, loss_ce: 0.020574, loss_kd: 3141.880615
[17:52:00.206] iteration 1180 : loss : 497.582886, loss_ce: 0.016145, loss_kd: 2485.478027
[17:52:05.809] iteration 1190 : loss : 396.685120, loss_ce: 0.048397, loss_kd: 1980.886963
[17:52:11.400] iteration 1200 : loss : 398.921600, loss_ce: 0.028851, loss_kd: 1992.054443
[17:52:17.018] iteration 1210 : loss : 497.585510, loss_ce: 0.018496, loss_kd: 2485.418945
[17:52:22.618] iteration 1220 : loss : 356.340942, loss_ce: 0.015950, loss_kd: 1779.220703
[17:52:28.215] iteration 1230 : loss : 483.266174, loss_ce: 0.024927, loss_kd: 2413.863525
[17:52:33.817] iteration 1240 : loss : 536.875549, loss_ce: 0.025590, loss_kd: 2681.887451
[17:52:39.428] iteration 1250 : loss : 483.601318, loss_ce: 0.026364, loss_kd: 2415.488770
[17:52:45.034] iteration 1260 : loss : 441.367279, loss_ce: 0.021346, loss_kd: 2204.349121
[17:52:50.636] iteration 1270 : loss : 442.489227, loss_ce: 0.025879, loss_kd: 2209.955322
[17:52:56.241] iteration 1280 : loss : 431.037445, loss_ce: 0.018521, loss_kd: 2152.660400
[17:53:01.867] iteration 1290 : loss : 338.115021, loss_ce: 0.032658, loss_kd: 1688.091797
[17:53:07.476] iteration 1300 : loss : 365.726501, loss_ce: 0.044657, loss_kd: 1826.114746
[17:53:13.088] iteration 1310 : loss : 494.736664, loss_ce: 0.026788, loss_kd: 2471.207031
[17:53:18.680] iteration 1320 : loss : 521.105469, loss_ce: 0.037118, loss_kd: 2603.031006
[17:53:24.293] iteration 1330 : loss : 577.198547, loss_ce: 0.042311, loss_kd: 2883.476807
[17:53:29.897] iteration 1340 : loss : 464.155731, loss_ce: 0.022103, loss_kd: 2318.266113
[17:53:35.521] iteration 1350 : loss : 478.252563, loss_ce: 0.024618, loss_kd: 2388.783936
[17:53:41.140] iteration 1360 : loss : 432.582336, loss_ce: 0.022050, loss_kd: 2160.447266
[17:53:46.776] iteration 1370 : loss : 271.145325, loss_ce: 0.032844, loss_kd: 1353.167114
[17:53:52.396] iteration 1380 : loss : 452.500946, loss_ce: 0.041882, loss_kd: 2260.003418
[17:53:58.020] iteration 1390 : loss : 406.257019, loss_ce: 0.026473, loss_kd: 2028.822266
[17:54:03.635] iteration 1400 : loss : 467.975769, loss_ce: 0.029897, loss_kd: 2337.356689
[17:54:09.275] iteration 1410 : loss : 687.557800, loss_ce: 0.038354, loss_kd: 3435.278076
[17:54:14.886] iteration 1420 : loss : 420.212830, loss_ce: 0.021674, loss_kd: 2098.571777
[17:54:20.524] iteration 1430 : loss : 504.961639, loss_ce: 0.021256, loss_kd: 2522.378418
[17:54:26.135] iteration 1440 : loss : 533.008911, loss_ce: 0.030542, loss_kd: 2662.541992
[17:54:31.783] iteration 1450 : loss : 474.680328, loss_ce: 0.028859, loss_kd: 2370.896973
[17:54:37.404] iteration 1460 : loss : 544.158875, loss_ce: 0.026301, loss_kd: 2718.327881
[17:54:43.040] iteration 1470 : loss : 416.485352, loss_ce: 0.022903, loss_kd: 2079.955566
[17:54:48.672] iteration 1480 : loss : 459.209076, loss_ce: 0.022367, loss_kd: 2293.515625
[17:54:54.291] iteration 1490 : loss : 464.140930, loss_ce: 0.022181, loss_kd: 2318.213379
[17:54:59.900] iteration 1500 : loss : 404.729065, loss_ce: 0.017922, loss_kd: 2021.166138
[17:55:05.542] iteration 1510 : loss : 358.461761, loss_ce: 0.024058, loss_kd: 1789.796387
[17:55:11.152] iteration 1520 : loss : 420.145233, loss_ce: 0.020236, loss_kd: 2098.254150
[17:55:16.791] iteration 1530 : loss : 408.153259, loss_ce: 0.028925, loss_kd: 2038.305298
[17:55:22.402] iteration 1540 : loss : 366.806122, loss_ce: 0.026876, loss_kd: 1831.541260
[17:55:28.040] iteration 1550 : loss : 342.881561, loss_ce: 0.033917, loss_kd: 1711.945923
[17:55:33.675] iteration 1560 : loss : 337.532318, loss_ce: 0.036545, loss_kd: 1685.158813
[17:55:39.297] iteration 1570 : loss : 489.738007, loss_ce: 0.045636, loss_kd: 2446.203125
[17:55:44.933] iteration 1580 : loss : 388.666168, loss_ce: 0.023255, loss_kd: 1940.866455
[17:55:50.568] iteration 1590 : loss : 450.500977, loss_ce: 0.047143, loss_kd: 2249.974365
[17:55:56.203] iteration 1600 : loss : 415.600861, loss_ce: 0.022122, loss_kd: 2075.526855
[17:56:01.848] iteration 1610 : loss : 369.863800, loss_ce: 0.024923, loss_kd: 1846.888794
[17:56:07.470] iteration 1620 : loss : 554.706055, loss_ce: 0.021289, loss_kd: 2771.015625
[17:56:13.121] iteration 1630 : loss : 463.528595, loss_ce: 0.026887, loss_kd: 2315.161621
[17:56:18.747] iteration 1640 : loss : 530.693176, loss_ce: 0.024328, loss_kd: 2650.936523
[17:56:24.386] iteration 1650 : loss : 348.298248, loss_ce: 0.040020, loss_kd: 1739.009155
[17:56:30.013] iteration 1660 : loss : 446.174866, loss_ce: 0.038298, loss_kd: 2228.394043
[17:56:35.646] iteration 1670 : loss : 332.164215, loss_ce: 0.030208, loss_kd: 1658.341431
[17:56:41.285] iteration 1680 : loss : 367.826385, loss_ce: 0.020852, loss_kd: 1836.650146
[17:56:46.913] iteration 1690 : loss : 378.608978, loss_ce: 0.030515, loss_kd: 1890.552612
[17:56:52.547] iteration 1700 : loss : 503.897095, loss_ce: 0.023354, loss_kd: 2516.991943
[17:56:58.199] iteration 1710 : loss : 429.188171, loss_ce: 0.032480, loss_kd: 2143.417725
[17:57:03.826] iteration 1720 : loss : 520.262268, loss_ce: 0.033458, loss_kd: 2598.838867
[17:57:09.478] iteration 1730 : loss : 443.629700, loss_ce: 0.029365, loss_kd: 2215.662842
[17:57:15.106] iteration 1740 : loss : 382.587311, loss_ce: 0.035546, loss_kd: 1910.439209
[17:57:20.748] iteration 1750 : loss : 439.635498, loss_ce: 0.023984, loss_kd: 2195.705078
[17:57:26.376] iteration 1760 : loss : 355.227203, loss_ce: 0.021436, loss_kd: 1773.500488
[17:57:32.021] iteration 1770 : loss : 368.125336, loss_ce: 0.032799, loss_kd: 1838.168213
[17:57:37.645] iteration 1780 : loss : 377.764557, loss_ce: 0.028315, loss_kd: 1886.384644
[17:57:43.278] iteration 1790 : loss : 360.305237, loss_ce: 0.028543, loss_kd: 1799.027710
[17:57:48.919] iteration 1800 : loss : 431.697784, loss_ce: 0.016237, loss_kd: 2155.999268
[17:57:54.562] iteration 1810 : loss : 399.590210, loss_ce: 0.020618, loss_kd: 1995.452881
[17:58:00.200] iteration 1820 : loss : 329.234253, loss_ce: 0.038009, loss_kd: 1643.687500
[17:58:05.832] iteration 1830 : loss : 392.065582, loss_ce: 0.034859, loss_kd: 1957.827271
[17:58:11.460] iteration 1840 : loss : 350.084076, loss_ce: 0.019382, loss_kd: 1747.945679
[17:58:17.092] iteration 1850 : loss : 563.681885, loss_ce: 0.030005, loss_kd: 2815.917969
[17:58:22.712] iteration 1860 : loss : 442.499817, loss_ce: 0.024716, loss_kd: 2210.042725
[17:58:28.346] iteration 1870 : loss : 435.337952, loss_ce: 0.025402, loss_kd: 2174.205811
[17:58:33.973] iteration 1880 : loss : 322.709534, loss_ce: 0.022746, loss_kd: 1611.055786
[17:58:39.615] iteration 1890 : loss : 407.336792, loss_ce: 0.035303, loss_kd: 2034.186646
[17:58:45.240] iteration 1900 : loss : 518.661072, loss_ce: 0.034840, loss_kd: 2590.802490
[17:58:50.886] iteration 1910 : loss : 429.241211, loss_ce: 0.018274, loss_kd: 2143.754150
[17:58:56.507] iteration 1920 : loss : 401.338593, loss_ce: 0.031981, loss_kd: 2004.152710
[17:59:02.162] iteration 1930 : loss : 423.134064, loss_ce: 0.017135, loss_kd: 2113.155762
[17:59:07.796] iteration 1940 : loss : 369.934052, loss_ce: 0.032055, loss_kd: 1847.197266
[17:59:13.438] iteration 1950 : loss : 479.433563, loss_ce: 0.020696, loss_kd: 2394.729492
[17:59:19.068] iteration 1960 : loss : 364.378723, loss_ce: 0.020203, loss_kd: 1819.429932
[17:59:24.712] iteration 1970 : loss : 403.787476, loss_ce: 0.025293, loss_kd: 2016.440308
[17:59:30.340] iteration 1980 : loss : 332.472656, loss_ce: 0.024628, loss_kd: 1659.897705
[17:59:35.981] iteration 1990 : loss : 419.984680, loss_ce: 0.026658, loss_kd: 2097.435303
[17:59:41.625] iteration 2000 : loss : 442.453430, loss_ce: 0.021920, loss_kd: 2209.775635
[17:59:47.280] iteration 2010 : loss : 407.280884, loss_ce: 0.027733, loss_kd: 2033.931152
[17:59:52.914] iteration 2020 : loss : 507.387329, loss_ce: 0.035702, loss_kd: 2534.483887
[17:59:58.556] iteration 2030 : loss : 428.828156, loss_ce: 0.019372, loss_kd: 2141.659180
[18:00:04.186] iteration 2040 : loss : 594.751404, loss_ce: 0.018373, loss_kd: 2971.320801
[18:00:09.832] iteration 2050 : loss : 422.165009, loss_ce: 0.016088, loss_kd: 2108.325439
[18:00:15.461] iteration 2060 : loss : 408.912964, loss_ce: 0.028625, loss_kd: 2042.045288
[18:00:21.112] iteration 2070 : loss : 349.030579, loss_ce: 0.025671, loss_kd: 1742.670044
[18:00:26.746] iteration 2080 : loss : 348.117493, loss_ce: 0.024389, loss_kd: 1738.093262
[18:00:42.826] iteration 2090 : loss : 465.603302, loss_ce: 0.025459, loss_kd: 2325.573730
[18:00:48.379] iteration 2100 : loss : 435.888519, loss_ce: 0.023608, loss_kd: 2176.955811
[18:00:53.945] iteration 2110 : loss : 421.968628, loss_ce: 0.026432, loss_kd: 2107.371582
[18:00:59.508] iteration 2120 : loss : 412.458466, loss_ce: 0.021346, loss_kd: 2059.816406
[18:01:05.084] iteration 2130 : loss : 359.635468, loss_ce: 0.029648, loss_kd: 1795.718384
[18:01:10.660] iteration 2140 : loss : 388.593536, loss_ce: 0.025771, loss_kd: 1940.504639
[18:01:16.252] iteration 2150 : loss : 295.044922, loss_ce: 0.023299, loss_kd: 1472.689941
[18:01:21.840] iteration 2160 : loss : 411.403839, loss_ce: 0.024019, loss_kd: 2054.537842
[18:01:27.444] iteration 2170 : loss : 388.603394, loss_ce: 0.021770, loss_kd: 1940.579346
[18:01:33.037] iteration 2180 : loss : 356.248444, loss_ce: 0.036647, loss_kd: 1778.800293
[18:01:38.649] iteration 2190 : loss : 381.498779, loss_ce: 0.032070, loss_kd: 1905.056641
[18:01:44.252] iteration 2200 : loss : 301.979706, loss_ce: 0.027558, loss_kd: 1507.415771
[18:01:49.868] iteration 2210 : loss : 352.786316, loss_ce: 0.035559, loss_kd: 1761.471191
[18:01:55.475] iteration 2220 : loss : 304.125854, loss_ce: 0.029925, loss_kd: 1518.181274
[18:02:01.097] iteration 2230 : loss : 314.062683, loss_ce: 0.015040, loss_kd: 1567.848755
[18:02:06.710] iteration 2240 : loss : 398.876862, loss_ce: 0.019346, loss_kd: 1991.875732
[18:02:12.333] iteration 2250 : loss : 396.632690, loss_ce: 0.017735, loss_kd: 1980.731201
[18:02:17.934] iteration 2260 : loss : 270.424133, loss_ce: 0.028930, loss_kd: 1349.632935
[18:02:23.557] iteration 2270 : loss : 308.559875, loss_ce: 0.019269, loss_kd: 1540.350830
[18:02:29.163] iteration 2280 : loss : 434.297211, loss_ce: 0.030576, loss_kd: 2169.000732
[18:02:34.805] iteration 2290 : loss : 414.203583, loss_ce: 0.022266, loss_kd: 2068.542480
[18:02:40.422] iteration 2300 : loss : 307.400757, loss_ce: 0.034329, loss_kd: 1534.496948
[18:02:46.066] iteration 2310 : loss : 306.143341, loss_ce: 0.036585, loss_kd: 1528.232910
[18:02:51.691] iteration 2320 : loss : 417.164276, loss_ce: 0.017348, loss_kd: 2083.414551
[18:02:57.336] iteration 2330 : loss : 415.544495, loss_ce: 0.024777, loss_kd: 2075.266357
[18:03:02.954] iteration 2340 : loss : 481.480560, loss_ce: 0.020601, loss_kd: 2404.963867
[18:03:08.599] iteration 2350 : loss : 399.714661, loss_ce: 0.019933, loss_kd: 1996.128906
[18:03:14.223] iteration 2360 : loss : 271.053925, loss_ce: 0.029378, loss_kd: 1352.796631
[18:03:19.866] iteration 2370 : loss : 266.660553, loss_ce: 0.027550, loss_kd: 1330.859619
[18:03:25.509] iteration 2380 : loss : 402.619659, loss_ce: 0.020935, loss_kd: 2010.664307
[18:03:31.149] iteration 2390 : loss : 391.047180, loss_ce: 0.022192, loss_kd: 1952.774780
[18:03:36.778] iteration 2400 : loss : 317.258942, loss_ce: 0.023782, loss_kd: 1583.815552
[18:03:42.449] iteration 2410 : loss : 433.641754, loss_ce: 0.028428, loss_kd: 2165.763672
[18:03:48.078] iteration 2420 : loss : 299.919067, loss_ce: 0.034769, loss_kd: 1497.053345
[18:03:53.717] iteration 2430 : loss : 317.221039, loss_ce: 0.027778, loss_kd: 1583.593506
[18:03:59.357] iteration 2440 : loss : 404.718353, loss_ce: 0.018612, loss_kd: 2021.154419
[18:04:05.000] iteration 2450 : loss : 379.468292, loss_ce: 0.024060, loss_kd: 1894.851807
[18:04:10.626] iteration 2460 : loss : 336.550781, loss_ce: 0.021750, loss_kd: 1680.299927
[18:04:16.278] iteration 2470 : loss : 416.284882, loss_ce: 0.017483, loss_kd: 2078.949463
[18:04:21.898] iteration 2480 : loss : 441.741211, loss_ce: 0.023227, loss_kd: 2206.218262
[18:04:27.545] iteration 2490 : loss : 442.863525, loss_ce: 0.054923, loss_kd: 2211.783203
[18:04:33.183] iteration 2500 : loss : 424.035156, loss_ce: 0.025172, loss_kd: 2117.714111
[18:04:38.831] iteration 2510 : loss : 365.324280, loss_ce: 0.026550, loss_kd: 1824.163330
[18:04:44.474] iteration 2520 : loss : 477.046143, loss_ce: 0.024878, loss_kd: 2382.734375
[18:04:50.098] iteration 2530 : loss : 353.059357, loss_ce: 0.020802, loss_kd: 1762.849487
[18:04:55.740] iteration 2540 : loss : 293.306549, loss_ce: 0.026779, loss_kd: 1464.052368
[18:05:01.389] iteration 2550 : loss : 307.257568, loss_ce: 0.031532, loss_kd: 1533.780518
[18:05:07.024] iteration 2560 : loss : 427.134125, loss_ce: 0.021682, loss_kd: 2133.246582
[18:05:12.684] iteration 2570 : loss : 282.432434, loss_ce: 0.029637, loss_kd: 1409.708618
[18:05:18.310] iteration 2580 : loss : 339.855377, loss_ce: 0.023943, loss_kd: 1696.794800
[18:05:23.952] iteration 2590 : loss : 428.970673, loss_ce: 0.026282, loss_kd: 2142.406982
[18:05:29.588] iteration 2600 : loss : 371.108673, loss_ce: 0.033343, loss_kd: 1853.045410
[18:05:35.248] iteration 2610 : loss : 313.236542, loss_ce: 0.021779, loss_kd: 1563.687622
[18:05:40.880] iteration 2620 : loss : 306.656311, loss_ce: 0.031297, loss_kd: 1530.801636
[18:05:46.535] iteration 2630 : loss : 428.005768, loss_ce: 0.027251, loss_kd: 2137.557861
[18:05:52.183] iteration 2640 : loss : 350.288727, loss_ce: 0.026683, loss_kd: 1748.936890
[18:05:57.825] iteration 2650 : loss : 306.753540, loss_ce: 0.025649, loss_kd: 1531.277100
[18:06:03.470] iteration 2660 : loss : 321.536285, loss_ce: 0.020164, loss_kd: 1605.228882
[18:06:09.137] iteration 2670 : loss : 281.784302, loss_ce: 0.025715, loss_kd: 1406.440674
[18:06:14.767] iteration 2680 : loss : 407.886047, loss_ce: 0.020585, loss_kd: 2036.931152
[18:06:20.453] iteration 2690 : loss : 378.090637, loss_ce: 0.021945, loss_kd: 1888.005737
[18:06:26.089] iteration 2700 : loss : 557.440918, loss_ce: 0.023290, loss_kd: 2784.767090
[18:06:31.753] iteration 2710 : loss : 386.671204, loss_ce: 0.029231, loss_kd: 1930.883179
[18:06:37.411] iteration 2720 : loss : 332.924164, loss_ce: 0.015410, loss_kd: 1662.148438
[18:06:43.053] iteration 2730 : loss : 328.040344, loss_ce: 0.032350, loss_kd: 1637.714600
[18:06:48.700] iteration 2740 : loss : 339.716797, loss_ce: 0.024529, loss_kd: 1696.094360
[18:06:54.347] iteration 2750 : loss : 342.601196, loss_ce: 0.035391, loss_kd: 1710.528687
[18:06:59.973] iteration 2760 : loss : 373.068115, loss_ce: 0.033880, loss_kd: 1862.843140
[18:07:05.616] iteration 2770 : loss : 316.141693, loss_ce: 0.034382, loss_kd: 1578.194336
[18:07:11.251] iteration 2780 : loss : 324.829254, loss_ce: 0.025281, loss_kd: 1621.672607
[18:07:16.907] iteration 2790 : loss : 325.798737, loss_ce: 0.031350, loss_kd: 1626.512329
[18:07:22.559] iteration 2800 : loss : 303.317139, loss_ce: 0.024164, loss_kd: 1514.124878
[18:07:28.215] iteration 2810 : loss : 280.530975, loss_ce: 0.031314, loss_kd: 1400.132568
[18:07:33.862] iteration 2820 : loss : 430.010895, loss_ce: 0.031287, loss_kd: 2147.561768
[18:07:39.504] iteration 2830 : loss : 325.398224, loss_ce: 0.025098, loss_kd: 1624.514893
[18:07:45.164] iteration 2840 : loss : 340.400604, loss_ce: 0.025071, loss_kd: 1699.539673
[18:07:50.826] iteration 2850 : loss : 328.103180, loss_ce: 0.017141, loss_kd: 1637.956543
[18:07:56.459] iteration 2860 : loss : 352.450958, loss_ce: 0.029370, loss_kd: 1759.770142
[18:08:02.115] iteration 2870 : loss : 323.156281, loss_ce: 0.021188, loss_kd: 1613.262207
[18:08:07.760] iteration 2880 : loss : 287.581848, loss_ce: 0.024245, loss_kd: 1435.433105
[18:08:13.419] iteration 2890 : loss : 309.154083, loss_ce: 0.027869, loss_kd: 1543.290405
[18:08:19.051] iteration 2900 : loss : 353.245178, loss_ce: 0.023253, loss_kd: 1763.770508
[18:08:24.708] iteration 2910 : loss : 308.832794, loss_ce: 0.045928, loss_kd: 1541.669189
[18:08:30.367] iteration 2920 : loss : 346.492279, loss_ce: 0.027110, loss_kd: 1729.950073
[18:08:36.028] iteration 2930 : loss : 308.150452, loss_ce: 0.029050, loss_kd: 1538.292236
[18:08:41.655] iteration 2940 : loss : 246.939636, loss_ce: 0.023872, loss_kd: 1232.232056
[18:08:47.317] iteration 2950 : loss : 338.554901, loss_ce: 0.021711, loss_kd: 1690.308350
[18:08:52.959] iteration 2960 : loss : 284.262146, loss_ce: 0.025696, loss_kd: 1418.857422
[18:08:58.615] iteration 2970 : loss : 265.271698, loss_ce: 0.016178, loss_kd: 1323.913574
[18:09:04.246] iteration 2980 : loss : 325.660889, loss_ce: 0.018779, loss_kd: 1625.837891
[18:09:09.909] iteration 2990 : loss : 248.880112, loss_ce: 0.020069, loss_kd: 1241.946777
[18:09:15.555] iteration 3000 : loss : 305.372589, loss_ce: 0.027789, loss_kd: 1524.404419
[18:09:21.187] iteration 3010 : loss : 309.618530, loss_ce: 0.016079, loss_kd: 1545.668213
[18:09:26.830] iteration 3020 : loss : 377.022247, loss_ce: 0.025856, loss_kd: 1882.637085
[18:09:32.493] iteration 3030 : loss : 297.261475, loss_ce: 0.029145, loss_kd: 1483.884277
[18:09:38.139] iteration 3040 : loss : 347.478119, loss_ce: 0.016799, loss_kd: 1734.944458
[18:09:43.799] iteration 3050 : loss : 306.869476, loss_ce: 0.021525, loss_kd: 1531.851074
[18:09:49.447] iteration 3060 : loss : 510.072998, loss_ce: 0.024958, loss_kd: 2547.916748
[18:09:55.098] iteration 3070 : loss : 354.260834, loss_ce: 0.023114, loss_kd: 1768.856201
[18:10:00.745] iteration 3080 : loss : 356.581696, loss_ce: 0.023930, loss_kd: 1780.401733
[18:10:06.391] iteration 3090 : loss : 281.963348, loss_ce: 0.021918, loss_kd: 1407.332764
[18:10:12.035] iteration 3100 : loss : 283.431427, loss_ce: 0.017153, loss_kd: 1414.636597
[18:10:17.676] iteration 3110 : loss : 342.156128, loss_ce: 0.028594, loss_kd: 1708.312988
[18:10:23.318] iteration 3120 : loss : 288.902344, loss_ce: 0.025913, loss_kd: 1442.052490
[18:10:27.054] Running TPGM constraint optimization after epoch 3
[18:15:10.256] iteration 3130 : loss : 227.991882, loss_ce: 0.018167, loss_kd: 1137.479126
[18:15:15.782] iteration 3140 : loss : 272.045197, loss_ce: 0.016161, loss_kd: 1357.675049
[18:15:21.324] iteration 3150 : loss : 288.591797, loss_ce: 0.036074, loss_kd: 1440.440552
[18:15:26.860] iteration 3160 : loss : 285.040955, loss_ce: 0.039800, loss_kd: 1422.756104
[18:15:32.406] iteration 3170 : loss : 327.373596, loss_ce: 0.022610, loss_kd: 1634.429688
[18:15:37.942] iteration 3180 : loss : 391.126801, loss_ce: 0.022189, loss_kd: 1953.166992
[18:15:43.501] iteration 3190 : loss : 397.957245, loss_ce: 0.018657, loss_kd: 1987.302490
[18:15:49.050] iteration 3200 : loss : 267.285187, loss_ce: 0.014087, loss_kd: 1333.947998
[18:15:54.618] iteration 3210 : loss : 307.183716, loss_ce: 0.035551, loss_kd: 1533.447632
[18:16:00.177] iteration 3220 : loss : 376.304047, loss_ce: 0.025857, loss_kd: 1879.017822
[18:16:05.753] iteration 3230 : loss : 273.850739, loss_ce: 0.036101, loss_kd: 1366.784912
[18:16:11.322] iteration 3240 : loss : 291.651764, loss_ce: 0.026805, loss_kd: 1455.789307
[18:16:16.912] iteration 3250 : loss : 273.495056, loss_ce: 0.014827, loss_kd: 1365.030029
[18:16:22.490] iteration 3260 : loss : 318.636993, loss_ce: 0.021238, loss_kd: 1590.708008
[18:16:28.080] iteration 3270 : loss : 265.673035, loss_ce: 0.015266, loss_kd: 1325.897705
[18:16:33.666] iteration 3280 : loss : 294.303925, loss_ce: 0.026049, loss_kd: 1469.049927
[18:16:39.265] iteration 3290 : loss : 340.832703, loss_ce: 0.024767, loss_kd: 1701.665405
[18:16:44.848] iteration 3300 : loss : 300.886353, loss_ce: 0.025737, loss_kd: 1501.975830
[18:16:50.454] iteration 3310 : loss : 308.546509, loss_ce: 0.035496, loss_kd: 1540.288452
[18:16:56.044] iteration 3320 : loss : 320.965546, loss_ce: 0.020950, loss_kd: 1602.373047
[18:17:01.650] iteration 3330 : loss : 289.727478, loss_ce: 0.022336, loss_kd: 1446.148804
[18:17:07.243] iteration 3340 : loss : 326.812286, loss_ce: 0.030102, loss_kd: 1631.599609
[18:17:12.850] iteration 3350 : loss : 364.307404, loss_ce: 0.030360, loss_kd: 1819.076416
[18:17:18.446] iteration 3360 : loss : 293.519318, loss_ce: 0.020162, loss_kd: 1465.161743
[18:17:24.068] iteration 3370 : loss : 352.874939, loss_ce: 0.024373, loss_kd: 1761.920654
[18:17:29.678] iteration 3380 : loss : 297.006561, loss_ce: 0.028826, loss_kd: 1482.575073
[18:17:35.290] iteration 3390 : loss : 334.535034, loss_ce: 0.022085, loss_kd: 1670.187256
[18:17:40.891] iteration 3400 : loss : 223.306137, loss_ce: 0.019253, loss_kd: 1114.061157
[18:17:46.504] iteration 3410 : loss : 271.769836, loss_ce: 0.022184, loss_kd: 1356.377563
[18:17:52.128] iteration 3420 : loss : 278.365753, loss_ce: 0.016024, loss_kd: 1389.369507
[18:17:57.747] iteration 3430 : loss : 358.663330, loss_ce: 0.033063, loss_kd: 1790.834473
[18:18:03.347] iteration 3440 : loss : 259.624390, loss_ce: 0.020930, loss_kd: 1295.625977
[18:18:08.961] iteration 3450 : loss : 236.893082, loss_ce: 0.032742, loss_kd: 1182.007812
[18:18:14.572] iteration 3460 : loss : 344.550232, loss_ce: 0.019634, loss_kd: 1720.308716
[18:18:20.210] iteration 3470 : loss : 255.999359, loss_ce: 0.035445, loss_kd: 1277.511230
[18:18:25.824] iteration 3480 : loss : 337.480774, loss_ce: 0.025893, loss_kd: 1684.907227
[18:18:31.452] iteration 3490 : loss : 327.662964, loss_ce: 0.020555, loss_kd: 1635.854614
[18:18:37.073] iteration 3500 : loss : 311.740723, loss_ce: 0.010385, loss_kd: 1556.225098
[18:18:42.709] iteration 3510 : loss : 362.336365, loss_ce: 0.032286, loss_kd: 1809.211426
[18:18:48.339] iteration 3520 : loss : 296.850647, loss_ce: 0.016582, loss_kd: 1481.846436
[18:18:53.976] iteration 3530 : loss : 450.218781, loss_ce: 0.022990, loss_kd: 2248.646240
[18:18:59.607] iteration 3540 : loss : 293.056946, loss_ce: 0.030692, loss_kd: 1462.808960
[18:19:05.246] iteration 3550 : loss : 252.535583, loss_ce: 0.026127, loss_kd: 1260.173340
[18:19:10.870] iteration 3560 : loss : 332.086456, loss_ce: 0.023886, loss_kd: 1657.949951
[18:19:16.514] iteration 3570 : loss : 372.006683, loss_ce: 0.023079, loss_kd: 1857.587036
[18:19:22.140] iteration 3580 : loss : 305.146576, loss_ce: 0.036777, loss_kd: 1523.262817
[18:19:27.769] iteration 3590 : loss : 325.727936, loss_ce: 0.028362, loss_kd: 1626.213867
[18:19:33.403] iteration 3600 : loss : 233.319916, loss_ce: 0.023719, loss_kd: 1164.136719
[18:19:39.037] iteration 3610 : loss : 361.961365, loss_ce: 0.021172, loss_kd: 1807.333496
[18:19:44.669] iteration 3620 : loss : 305.247040, loss_ce: 0.019246, loss_kd: 1523.774902
[18:19:50.288] iteration 3630 : loss : 300.096771, loss_ce: 0.021667, loss_kd: 1498.028320
[18:19:55.923] iteration 3640 : loss : 291.669525, loss_ce: 0.015956, loss_kd: 1455.895142
[18:20:01.563] iteration 3650 : loss : 298.568787, loss_ce: 0.021768, loss_kd: 1490.362549
[18:20:07.197] iteration 3660 : loss : 417.058655, loss_ce: 0.030047, loss_kd: 2082.805420
[18:20:12.835] iteration 3670 : loss : 354.085266, loss_ce: 0.014623, loss_kd: 1767.950928
[18:20:18.469] iteration 3680 : loss : 237.637619, loss_ce: 0.031286, loss_kd: 1185.733276
[18:20:24.102] iteration 3690 : loss : 278.053741, loss_ce: 0.020357, loss_kd: 1387.780518
[18:20:29.736] iteration 3700 : loss : 361.479950, loss_ce: 0.017226, loss_kd: 1804.955322
[18:20:35.372] iteration 3710 : loss : 296.562378, loss_ce: 0.034201, loss_kd: 1480.362549
[18:20:41.013] iteration 3720 : loss : 265.132294, loss_ce: 0.023520, loss_kd: 1323.202148
[18:20:46.663] iteration 3730 : loss : 214.059967, loss_ce: 0.022545, loss_kd: 1067.857910
[18:20:52.290] iteration 3740 : loss : 259.363403, loss_ce: 0.023749, loss_kd: 1294.265869
[18:20:57.936] iteration 3750 : loss : 294.862427, loss_ce: 0.021256, loss_kd: 1471.857300
[18:21:03.574] iteration 3760 : loss : 314.452148, loss_ce: 0.021553, loss_kd: 1569.831787
[18:21:09.228] iteration 3770 : loss : 406.064758, loss_ce: 0.023105, loss_kd: 2027.881592
[18:21:14.844] iteration 3780 : loss : 419.145294, loss_ce: 0.020863, loss_kd: 2093.259277
[18:21:20.494] iteration 3790 : loss : 279.235931, loss_ce: 0.019977, loss_kd: 1393.735718
[18:21:26.130] iteration 3800 : loss : 357.010834, loss_ce: 0.017411, loss_kd: 1782.562134
[18:21:31.764] iteration 3810 : loss : 230.915634, loss_ce: 0.022629, loss_kd: 1152.093140
[18:21:37.406] iteration 3820 : loss : 294.029449, loss_ce: 0.022711, loss_kd: 1467.692993
[18:21:43.051] iteration 3830 : loss : 341.498352, loss_ce: 0.028925, loss_kd: 1705.007812
[18:21:48.693] iteration 3840 : loss : 303.233734, loss_ce: 0.030480, loss_kd: 1513.717773
[18:21:54.344] iteration 3850 : loss : 279.020294, loss_ce: 0.031006, loss_kd: 1392.606201
[18:21:59.972] iteration 3860 : loss : 319.655884, loss_ce: 0.034907, loss_kd: 1595.818237
[18:22:05.616] iteration 3870 : loss : 316.840790, loss_ce: 0.019875, loss_kd: 1581.762939
[18:22:11.245] iteration 3880 : loss : 290.643799, loss_ce: 0.032832, loss_kd: 1450.752075
[18:22:16.896] iteration 3890 : loss : 262.213013, loss_ce: 0.024802, loss_kd: 1308.589233
[18:22:22.534] iteration 3900 : loss : 317.643677, loss_ce: 0.020756, loss_kd: 1585.800659
[18:22:28.172] iteration 3910 : loss : 271.726074, loss_ce: 0.017462, loss_kd: 1356.180054
[18:22:33.817] iteration 3920 : loss : 350.946503, loss_ce: 0.012424, loss_kd: 1752.342529
[18:22:39.466] iteration 3930 : loss : 272.275116, loss_ce: 0.019722, loss_kd: 1358.931641
[18:22:45.092] iteration 3940 : loss : 228.757050, loss_ce: 0.021094, loss_kd: 1141.297607
[18:22:50.751] iteration 3950 : loss : 301.305115, loss_ce: 0.021527, loss_kd: 1504.060181
[18:22:56.378] iteration 3960 : loss : 264.387207, loss_ce: 0.017785, loss_kd: 1319.468018
[18:23:02.026] iteration 3970 : loss : 267.397339, loss_ce: 0.029623, loss_kd: 1334.537842
[18:23:07.658] iteration 3980 : loss : 256.691010, loss_ce: 0.016179, loss_kd: 1280.994629
[18:23:13.295] iteration 3990 : loss : 306.757446, loss_ce: 0.025309, loss_kd: 1531.328003
[18:23:18.935] iteration 4000 : loss : 260.392822, loss_ce: 0.025278, loss_kd: 1299.511719
[18:23:24.583] iteration 4010 : loss : 299.698120, loss_ce: 0.033315, loss_kd: 1496.026733
[18:23:30.221] iteration 4020 : loss : 260.712219, loss_ce: 0.027533, loss_kd: 1301.071045
[18:23:35.878] iteration 4030 : loss : 262.399384, loss_ce: 0.013732, loss_kd: 1309.570801
[18:23:41.507] iteration 4040 : loss : 348.145386, loss_ce: 0.024052, loss_kd: 1738.276611
[18:23:47.152] iteration 4050 : loss : 276.765564, loss_ce: 0.031004, loss_kd: 1381.221802
[18:23:52.793] iteration 4060 : loss : 289.449219, loss_ce: 0.032150, loss_kd: 1444.756836
[18:23:58.439] iteration 4070 : loss : 432.346893, loss_ce: 0.029818, loss_kd: 2159.244873
[18:24:04.060] iteration 4080 : loss : 385.559814, loss_ce: 0.028541, loss_kd: 1925.339355
[18:24:09.699] iteration 4090 : loss : 317.425659, loss_ce: 0.021977, loss_kd: 1584.656250
[18:24:15.340] iteration 4100 : loss : 250.255905, loss_ce: 0.024498, loss_kd: 1248.853149
[18:24:20.986] iteration 4110 : loss : 270.344055, loss_ce: 0.020334, loss_kd: 1349.228516
[18:24:26.627] iteration 4120 : loss : 310.015717, loss_ce: 0.027409, loss_kd: 1547.610229
[18:24:32.284] iteration 4130 : loss : 251.271652, loss_ce: 0.020865, loss_kd: 1253.889893
[18:24:37.927] iteration 4140 : loss : 253.812027, loss_ce: 0.024480, loss_kd: 1266.610596
[18:24:43.578] iteration 4150 : loss : 240.490005, loss_ce: 0.021213, loss_kd: 1200.011353
[18:24:49.220] iteration 4160 : loss : 345.258881, loss_ce: 0.024941, loss_kd: 1723.841675
[18:25:05.399] iteration 4170 : loss : 322.146942, loss_ce: 0.035212, loss_kd: 1608.238892
[18:25:10.944] iteration 4180 : loss : 203.717178, loss_ce: 0.020696, loss_kd: 1016.165466
[18:25:16.507] iteration 4190 : loss : 278.699554, loss_ce: 0.020184, loss_kd: 1391.011475
[18:25:22.068] iteration 4200 : loss : 325.700287, loss_ce: 0.031908, loss_kd: 1626.042480
[18:25:27.651] iteration 4210 : loss : 234.511795, loss_ce: 0.026402, loss_kd: 1170.147461
[18:25:33.225] iteration 4220 : loss : 647.879211, loss_ce: 0.025282, loss_kd: 3236.928223
[18:25:38.813] iteration 4230 : loss : 201.677780, loss_ce: 0.024554, loss_kd: 1005.928528
[18:25:44.410] iteration 4240 : loss : 200.248123, loss_ce: 0.027135, loss_kd: 998.818604
[18:25:50.020] iteration 4250 : loss : 258.108521, loss_ce: 0.023790, loss_kd: 1288.083130
[18:25:55.618] iteration 4260 : loss : 290.230438, loss_ce: 0.020206, loss_kd: 1448.661133
[18:26:01.220] iteration 4270 : loss : 259.824677, loss_ce: 0.028994, loss_kd: 1296.633057
[18:26:06.822] iteration 4280 : loss : 342.086517, loss_ce: 0.047265, loss_kd: 1707.903564
[18:26:12.429] iteration 4290 : loss : 238.294525, loss_ce: 0.026170, loss_kd: 1189.034668
[18:26:18.024] iteration 4300 : loss : 385.227997, loss_ce: 0.015721, loss_kd: 1923.704590
[18:26:23.637] iteration 4310 : loss : 233.043442, loss_ce: 0.029068, loss_kd: 1162.699463
[18:26:29.254] iteration 4320 : loss : 238.476944, loss_ce: 0.026385, loss_kd: 1189.937988
[18:26:34.881] iteration 4330 : loss : 290.493713, loss_ce: 0.034839, loss_kd: 1450.017578
[18:26:40.490] iteration 4340 : loss : 281.777527, loss_ce: 0.022131, loss_kd: 1406.463379
[18:26:46.115] iteration 4350 : loss : 300.446594, loss_ce: 0.023007, loss_kd: 1499.699463
[18:26:51.728] iteration 4360 : loss : 264.505798, loss_ce: 0.024492, loss_kd: 1320.075195
[18:26:57.358] iteration 4370 : loss : 265.872681, loss_ce: 0.031110, loss_kd: 1326.911499
[18:27:02.976] iteration 4380 : loss : 226.584702, loss_ce: 0.020765, loss_kd: 1130.467041
[18:27:08.607] iteration 4390 : loss : 296.929016, loss_ce: 0.024029, loss_kd: 1482.143555
[18:27:14.237] iteration 4400 : loss : 296.509094, loss_ce: 0.019625, loss_kd: 1480.100952
[18:27:19.864] iteration 4410 : loss : 300.358032, loss_ce: 0.030595, loss_kd: 1499.314941
[18:27:25.503] iteration 4420 : loss : 336.193909, loss_ce: 0.013852, loss_kd: 1678.534302
[18:27:31.140] iteration 4430 : loss : 218.290710, loss_ce: 0.018886, loss_kd: 1089.017456
[18:27:36.756] iteration 4440 : loss : 236.006226, loss_ce: 0.024197, loss_kd: 1177.571899
[18:27:42.382] iteration 4450 : loss : 260.080231, loss_ce: 0.024807, loss_kd: 1297.954102
[18:27:48.014] iteration 4460 : loss : 220.572037, loss_ce: 0.028862, loss_kd: 1100.402954
[18:27:53.646] iteration 4470 : loss : 205.312988, loss_ce: 0.012636, loss_kd: 1024.146118
[18:27:59.277] iteration 4480 : loss : 288.408173, loss_ce: 0.040834, loss_kd: 1439.587769
[18:28:04.924] iteration 4490 : loss : 305.422729, loss_ce: 0.017775, loss_kd: 1524.649170
[18:28:10.563] iteration 4500 : loss : 226.948715, loss_ce: 0.021280, loss_kd: 1132.290527
[18:28:16.212] iteration 4510 : loss : 318.618317, loss_ce: 0.020338, loss_kd: 1590.568848
[18:28:21.826] iteration 4520 : loss : 306.188751, loss_ce: 0.030027, loss_kd: 1528.471436
[18:28:27.450] iteration 4530 : loss : 259.857239, loss_ce: 0.035658, loss_kd: 1296.823486
[18:28:33.089] iteration 4540 : loss : 311.659973, loss_ce: 0.014509, loss_kd: 1555.856323
[18:28:38.744] iteration 4550 : loss : 269.292206, loss_ce: 0.029871, loss_kd: 1344.004517
[18:28:44.363] iteration 4560 : loss : 210.210312, loss_ce: 0.027114, loss_kd: 1048.577148
[18:28:50.022] iteration 4570 : loss : 233.043289, loss_ce: 0.020800, loss_kd: 1162.780640
[18:28:55.654] iteration 4580 : loss : 239.154388, loss_ce: 0.019099, loss_kd: 1193.287598
[18:29:01.295] iteration 4590 : loss : 333.345032, loss_ce: 0.016088, loss_kd: 1664.299316
[18:29:06.918] iteration 4600 : loss : 216.976105, loss_ce: 0.018714, loss_kd: 1082.278931
[18:29:12.576] iteration 4610 : loss : 263.103485, loss_ce: 0.016714, loss_kd: 1313.081543
[18:29:18.216] iteration 4620 : loss : 249.383972, loss_ce: 0.039361, loss_kd: 1244.474854
[18:29:23.864] iteration 4630 : loss : 281.936005, loss_ce: 0.023579, loss_kd: 1407.204712
[18:29:29.497] iteration 4640 : loss : 241.167587, loss_ce: 0.028806, loss_kd: 1203.369873
[18:29:35.140] iteration 4650 : loss : 187.718246, loss_ce: 0.022722, loss_kd: 936.146240
[18:29:40.782] iteration 4660 : loss : 234.841171, loss_ce: 0.033223, loss_kd: 1171.733398
[18:29:46.441] iteration 4670 : loss : 193.062134, loss_ce: 0.023639, loss_kd: 962.779297
[18:29:52.066] iteration 4680 : loss : 260.798645, loss_ce: 0.028176, loss_kd: 1301.556885
[18:29:57.705] iteration 4690 : loss : 244.366730, loss_ce: 0.023092, loss_kd: 1219.397217
[18:30:03.339] iteration 4700 : loss : 248.350769, loss_ce: 0.015710, loss_kd: 1239.325684
[18:30:08.984] iteration 4710 : loss : 280.508392, loss_ce: 0.029561, loss_kd: 1400.055664
[18:30:14.628] iteration 4720 : loss : 382.853577, loss_ce: 0.017860, loss_kd: 1911.787354
[18:30:20.269] iteration 4730 : loss : 376.363129, loss_ce: 0.032150, loss_kd: 1879.344360
[18:30:25.908] iteration 4740 : loss : 225.951202, loss_ce: 0.022132, loss_kd: 1127.298584
[18:30:31.561] iteration 4750 : loss : 252.757706, loss_ce: 0.030046, loss_kd: 1261.328247
[18:30:37.199] iteration 4760 : loss : 237.219437, loss_ce: 0.041985, loss_kd: 1183.644897
[18:30:42.836] iteration 4770 : loss : 299.744781, loss_ce: 0.023976, loss_kd: 1496.281006
[18:30:48.472] iteration 4780 : loss : 231.899399, loss_ce: 0.016006, loss_kd: 1157.060059
[18:30:54.110] iteration 4790 : loss : 388.767639, loss_ce: 0.033808, loss_kd: 1941.372070
[18:30:59.755] iteration 4800 : loss : 218.421631, loss_ce: 0.037885, loss_kd: 1089.658325
[18:31:05.407] iteration 4810 : loss : 223.497543, loss_ce: 0.017850, loss_kd: 1114.998779
[18:31:11.050] iteration 4820 : loss : 238.431915, loss_ce: 0.017178, loss_kd: 1189.740112
[18:31:16.692] iteration 4830 : loss : 268.918152, loss_ce: 0.018521, loss_kd: 1342.176392
[18:31:22.326] iteration 4840 : loss : 276.868469, loss_ce: 0.020325, loss_kd: 1381.895508
[18:31:27.974] iteration 4850 : loss : 225.556625, loss_ce: 0.020770, loss_kd: 1125.366821
[18:31:33.607] iteration 4860 : loss : 300.728729, loss_ce: 0.031153, loss_kd: 1501.172363
[18:31:39.255] iteration 4870 : loss : 282.943756, loss_ce: 0.033865, loss_kd: 1412.262207
[18:31:44.897] iteration 4880 : loss : 250.520157, loss_ce: 0.022256, loss_kd: 1250.153809
[18:31:50.526] iteration 4890 : loss : 257.215179, loss_ce: 0.020917, loss_kd: 1283.662598
[18:31:56.174] iteration 4900 : loss : 233.382324, loss_ce: 0.030017, loss_kd: 1164.396118
[18:32:01.818] iteration 4910 : loss : 204.067551, loss_ce: 0.027027, loss_kd: 1017.761108
[18:32:07.453] iteration 4920 : loss : 271.243256, loss_ce: 0.032859, loss_kd: 1353.750366
[18:32:13.106] iteration 4930 : loss : 202.503204, loss_ce: 0.020988, loss_kd: 1010.075073
[18:32:18.753] iteration 4940 : loss : 259.843964, loss_ce: 0.025186, loss_kd: 1296.773926
[18:32:24.396] iteration 4950 : loss : 230.804337, loss_ce: 0.026873, loss_kd: 1151.513916
[18:32:30.033] iteration 4960 : loss : 222.714111, loss_ce: 0.017719, loss_kd: 1111.134155
[18:32:35.664] iteration 4970 : loss : 275.153900, loss_ce: 0.020234, loss_kd: 1373.278320
[18:32:41.301] iteration 4980 : loss : 255.157410, loss_ce: 0.021065, loss_kd: 1273.307983
[18:32:46.964] iteration 4990 : loss : 201.103561, loss_ce: 0.029901, loss_kd: 1003.072266
[18:32:52.605] iteration 5000 : loss : 230.456070, loss_ce: 0.016915, loss_kd: 1149.825806
[18:32:58.261] iteration 5010 : loss : 240.418060, loss_ce: 0.028033, loss_kd: 1199.616943
[18:33:03.908] iteration 5020 : loss : 225.480423, loss_ce: 0.019982, loss_kd: 1124.929932
[18:33:09.553] iteration 5030 : loss : 244.407883, loss_ce: 0.027041, loss_kd: 1219.564209
[18:33:15.188] iteration 5040 : loss : 302.393036, loss_ce: 0.024609, loss_kd: 1509.501831
[18:33:20.844] iteration 5050 : loss : 385.016052, loss_ce: 0.046348, loss_kd: 1922.587280
[18:33:26.482] iteration 5060 : loss : 263.284393, loss_ce: 0.023086, loss_kd: 1313.989258
[18:33:32.118] iteration 5070 : loss : 218.086777, loss_ce: 0.016898, loss_kd: 1088.016846
[18:33:37.756] iteration 5080 : loss : 278.397125, loss_ce: 0.030324, loss_kd: 1389.540649
[18:33:43.402] iteration 5090 : loss : 229.440796, loss_ce: 0.016413, loss_kd: 1144.777344
[18:33:49.043] iteration 5100 : loss : 235.091599, loss_ce: 0.020723, loss_kd: 1172.976929
[18:33:54.687] iteration 5110 : loss : 280.225433, loss_ce: 0.021211, loss_kd: 1398.660889
[18:34:00.320] iteration 5120 : loss : 176.548172, loss_ce: 0.032193, loss_kd: 880.301331
[18:34:05.977] iteration 5130 : loss : 293.459106, loss_ce: 0.019648, loss_kd: 1464.895996
[18:34:11.611] iteration 5140 : loss : 227.213303, loss_ce: 0.021947, loss_kd: 1133.627197
[18:34:17.257] iteration 5150 : loss : 225.100723, loss_ce: 0.017029, loss_kd: 1123.066162
[18:34:22.909] iteration 5160 : loss : 273.080597, loss_ce: 0.018501, loss_kd: 1362.961182
[18:34:28.562] iteration 5170 : loss : 212.672134, loss_ce: 0.029356, loss_kd: 1060.889404
[18:34:34.206] iteration 5180 : loss : 255.417358, loss_ce: 0.031309, loss_kd: 1274.665527
[18:34:39.857] iteration 5190 : loss : 225.885376, loss_ce: 0.019413, loss_kd: 1127.004272
[18:34:45.494] iteration 5200 : loss : 210.876938, loss_ce: 0.023017, loss_kd: 1051.940918
[18:34:50.848] iteration 5210 : loss : 267.298309, loss_ce: 0.028369, loss_kd: 1334.011963
[18:34:51.562] save model to ./debug_fixed_tpgm\continual_surgical_tpgm_stage1_epoch_4.pth
[18:34:51.564] Running TPGM constraint optimization after epoch 5
[18:39:47.516] iteration 5220 : loss : 372.847748, loss_ce: 0.023524, loss_kd: 1861.788208
[18:39:53.046] iteration 5230 : loss : 290.732208, loss_ce: 0.029406, loss_kd: 1451.239258
[18:39:58.572] iteration 5240 : loss : 278.989288, loss_ce: 0.018279, loss_kd: 1392.476440
[18:40:04.126] iteration 5250 : loss : 311.589966, loss_ce: 0.018507, loss_kd: 1555.536865
[18:40:09.661] iteration 5260 : loss : 241.808228, loss_ce: 0.025008, loss_kd: 1206.588379
[18:40:15.206] iteration 5270 : loss : 252.327438, loss_ce: 0.029363, loss_kd: 1259.181396
[18:40:20.748] iteration 5280 : loss : 223.617676, loss_ce: 0.032559, loss_kd: 1115.643188
[18:40:26.306] iteration 5290 : loss : 219.151321, loss_ce: 0.017636, loss_kd: 1093.276978
[18:40:31.855] iteration 5300 : loss : 244.902206, loss_ce: 0.027957, loss_kd: 1222.082886
[18:40:37.420] iteration 5310 : loss : 240.316254, loss_ce: 0.018600, loss_kd: 1199.146729
[18:40:42.976] iteration 5320 : loss : 221.822510, loss_ce: 0.021177, loss_kd: 1106.666016
[18:40:48.545] iteration 5330 : loss : 240.453293, loss_ce: 0.026462, loss_kd: 1199.805664
[18:40:54.117] iteration 5340 : loss : 279.925659, loss_ce: 0.034501, loss_kd: 1397.209351
[18:40:59.693] iteration 5350 : loss : 206.077103, loss_ce: 0.024499, loss_kd: 1027.959106
[18:41:05.268] iteration 5360 : loss : 213.172516, loss_ce: 0.035916, loss_kd: 1063.436890
[18:41:10.854] iteration 5370 : loss : 269.963074, loss_ce: 0.014997, loss_kd: 1347.361206
[18:41:16.434] iteration 5380 : loss : 196.187332, loss_ce: 0.014898, loss_kd: 978.519958
[18:41:22.016] iteration 5390 : loss : 256.942993, loss_ce: 0.030993, loss_kd: 1282.244995
[18:41:27.597] iteration 5400 : loss : 278.364624, loss_ce: 0.038515, loss_kd: 1389.415039
[18:41:33.193] iteration 5410 : loss : 274.731110, loss_ce: 0.027714, loss_kd: 1371.179321
[18:41:38.778] iteration 5420 : loss : 205.577576, loss_ce: 0.030120, loss_kd: 1025.444458
[18:41:44.385] iteration 5430 : loss : 247.376083, loss_ce: 0.017376, loss_kd: 1234.511841
[18:41:49.978] iteration 5440 : loss : 261.199066, loss_ce: 0.017028, loss_kd: 1303.531372
[18:41:55.582] iteration 5450 : loss : 193.186218, loss_ce: 0.015831, loss_kd: 963.472961
[18:42:01.187] iteration 5460 : loss : 143.703232, loss_ce: 0.016363, loss_kd: 715.998962
[18:42:06.794] iteration 5470 : loss : 291.002136, loss_ce: 0.032568, loss_kd: 1452.559814
[18:42:12.391] iteration 5480 : loss : 205.797623, loss_ce: 0.017775, loss_kd: 1026.540405
[18:42:18.005] iteration 5490 : loss : 200.790619, loss_ce: 0.033774, loss_kd: 1001.512451
[18:42:23.597] iteration 5500 : loss : 196.603043, loss_ce: 0.018704, loss_kd: 980.578979
[18:42:29.210] iteration 5510 : loss : 216.102509, loss_ce: 0.016124, loss_kd: 1078.064209
[18:42:34.812] iteration 5520 : loss : 263.942169, loss_ce: 0.017454, loss_kd: 1317.245239
[18:42:40.442] iteration 5530 : loss : 295.380829, loss_ce: 0.024758, loss_kd: 1474.455811
[18:42:46.051] iteration 5540 : loss : 340.675751, loss_ce: 0.019835, loss_kd: 1700.950317
[18:42:51.673] iteration 5550 : loss : 181.892242, loss_ce: 0.019776, loss_kd: 907.024780
[18:42:57.281] iteration 5560 : loss : 273.430573, loss_ce: 0.026378, loss_kd: 1364.668945
[18:43:02.913] iteration 5570 : loss : 339.554077, loss_ce: 0.018383, loss_kd: 1695.323364
[18:43:08.522] iteration 5580 : loss : 305.743225, loss_ce: 0.013037, loss_kd: 1526.241577
[18:43:14.169] iteration 5590 : loss : 178.237350, loss_ce: 0.018640, loss_kd: 888.751038
[18:43:19.785] iteration 5600 : loss : 244.109344, loss_ce: 0.014683, loss_kd: 1218.070435
[18:43:25.409] iteration 5610 : loss : 233.652771, loss_ce: 0.017610, loss_kd: 1165.751587
[18:43:31.020] iteration 5620 : loss : 333.414948, loss_ce: 0.022345, loss_kd: 1664.682861
[18:43:36.659] iteration 5630 : loss : 375.318481, loss_ce: 0.019242, loss_kd: 1874.176147
[18:43:42.290] iteration 5640 : loss : 196.191757, loss_ce: 0.015355, loss_kd: 978.567444
[18:43:47.929] iteration 5650 : loss : 227.317749, loss_ce: 0.018216, loss_kd: 1134.153931
[18:43:53.548] iteration 5660 : loss : 163.074326, loss_ce: 0.017027, loss_kd: 812.939819
[18:43:59.185] iteration 5670 : loss : 241.976791, loss_ce: 0.021901, loss_kd: 1207.443726
[18:44:04.807] iteration 5680 : loss : 249.818817, loss_ce: 0.020681, loss_kd: 1246.639771
[18:44:10.448] iteration 5690 : loss : 245.321335, loss_ce: 0.027520, loss_kd: 1224.176025
[18:44:16.067] iteration 5700 : loss : 234.408035, loss_ce: 0.015506, loss_kd: 1169.598389
[18:44:21.703] iteration 5710 : loss : 221.213776, loss_ce: 0.016892, loss_kd: 1103.646118
[18:44:27.324] iteration 5720 : loss : 214.976608, loss_ce: 0.025206, loss_kd: 1072.488770
[18:44:32.971] iteration 5730 : loss : 192.591049, loss_ce: 0.022620, loss_kd: 960.463745
[18:44:38.595] iteration 5740 : loss : 226.662552, loss_ce: 0.013480, loss_kd: 1130.892578
[18:44:44.247] iteration 5750 : loss : 248.563644, loss_ce: 0.016760, loss_kd: 1240.329102
[18:44:49.877] iteration 5760 : loss : 255.175354, loss_ce: 0.020943, loss_kd: 1273.422241
[18:44:55.532] iteration 5770 : loss : 341.573730, loss_ce: 0.014164, loss_kd: 1705.424194
[18:45:01.178] iteration 5780 : loss : 272.239990, loss_ce: 0.032493, loss_kd: 1358.759155
[18:45:06.822] iteration 5790 : loss : 206.097977, loss_ce: 0.022449, loss_kd: 1028.032837
[18:45:12.464] iteration 5800 : loss : 253.389160, loss_ce: 0.013053, loss_kd: 1264.526855
[18:45:18.120] iteration 5810 : loss : 275.870087, loss_ce: 0.023394, loss_kd: 1376.902222
[18:45:23.754] iteration 5820 : loss : 186.806137, loss_ce: 0.019470, loss_kd: 931.648682
[18:45:29.407] iteration 5830 : loss : 212.535416, loss_ce: 0.012516, loss_kd: 1060.239990
[18:45:35.044] iteration 5840 : loss : 213.330643, loss_ce: 0.024773, loss_kd: 1064.195801
[18:45:40.681] iteration 5850 : loss : 196.458694, loss_ce: 0.024946, loss_kd: 979.824036
[18:45:46.328] iteration 5860 : loss : 237.382599, loss_ce: 0.024962, loss_kd: 1184.453979
[18:45:51.981] iteration 5870 : loss : 300.191376, loss_ce: 0.022009, loss_kd: 1498.524048
[18:45:57.614] iteration 5880 : loss : 261.643738, loss_ce: 0.021855, loss_kd: 1305.796265
[18:46:03.268] iteration 5890 : loss : 234.999954, loss_ce: 0.016795, loss_kd: 1172.578247
[18:46:08.909] iteration 5900 : loss : 244.061371, loss_ce: 0.018717, loss_kd: 1217.874756
[18:46:14.559] iteration 5910 : loss : 187.900818, loss_ce: 0.025117, loss_kd: 937.026611
[18:46:20.209] iteration 5920 : loss : 236.545700, loss_ce: 0.022549, loss_kd: 1180.281494
[18:46:25.865] iteration 5930 : loss : 252.786972, loss_ce: 0.017838, loss_kd: 1261.525391
[18:46:31.483] iteration 5940 : loss : 283.500122, loss_ce: 0.032387, loss_kd: 1415.050903
[18:46:37.130] iteration 5950 : loss : 235.179871, loss_ce: 0.025732, loss_kd: 1173.439819
[18:46:42.749] iteration 5960 : loss : 267.067261, loss_ce: 0.020693, loss_kd: 1332.887695
[18:46:48.397] iteration 5970 : loss : 215.762985, loss_ce: 0.024712, loss_kd: 1076.357056
[18:46:54.019] iteration 5980 : loss : 263.494781, loss_ce: 0.022613, loss_kd: 1315.022949
[18:46:59.674] iteration 5990 : loss : 265.281036, loss_ce: 0.025633, loss_kd: 1323.951660
[18:47:05.315] iteration 6000 : loss : 242.081039, loss_ce: 0.016674, loss_kd: 1207.969482
[18:47:10.973] iteration 6010 : loss : 201.433762, loss_ce: 0.028388, loss_kd: 1004.659607
[18:47:16.598] iteration 6020 : loss : 210.407654, loss_ce: 0.016830, loss_kd: 1049.573120
[18:47:22.242] iteration 6030 : loss : 195.172165, loss_ce: 0.015668, loss_kd: 973.419800
[18:47:27.882] iteration 6040 : loss : 314.872040, loss_ce: 0.023958, loss_kd: 1571.927246
[18:47:33.536] iteration 6050 : loss : 188.825943, loss_ce: 0.018366, loss_kd: 941.737488
[18:47:39.191] iteration 6060 : loss : 196.809937, loss_ce: 0.029396, loss_kd: 981.585754
[18:47:44.837] iteration 6070 : loss : 167.565613, loss_ce: 0.020427, loss_kd: 835.388672
[18:47:50.463] iteration 6080 : loss : 201.898834, loss_ce: 0.013286, loss_kd: 1007.015381
[18:47:56.129] iteration 6090 : loss : 219.768982, loss_ce: 0.030741, loss_kd: 1096.394775
[18:48:01.765] iteration 6100 : loss : 243.794785, loss_ce: 0.020826, loss_kd: 1216.583130
[18:48:07.412] iteration 6110 : loss : 286.823090, loss_ce: 0.021485, loss_kd: 1431.674316
[18:48:13.054] iteration 6120 : loss : 219.970978, loss_ce: 0.011388, loss_kd: 1097.424805
[18:48:18.695] iteration 6130 : loss : 176.561493, loss_ce: 0.012573, loss_kd: 880.400940
[18:48:24.332] iteration 6140 : loss : 281.675812, loss_ce: 0.013344, loss_kd: 1405.940308
[18:48:29.986] iteration 6150 : loss : 180.060272, loss_ce: 0.017868, loss_kd: 897.881287
[18:48:35.625] iteration 6160 : loss : 259.739563, loss_ce: 0.013292, loss_kd: 1296.234863
[18:48:41.281] iteration 6170 : loss : 206.034775, loss_ce: 0.027790, loss_kd: 1027.747559
[18:48:46.923] iteration 6180 : loss : 314.803589, loss_ce: 0.015955, loss_kd: 1571.592285
[18:48:52.571] iteration 6190 : loss : 255.511108, loss_ce: 0.028274, loss_kd: 1275.115479
[18:48:58.215] iteration 6200 : loss : 219.989548, loss_ce: 0.017805, loss_kd: 1097.563354
[18:49:03.880] iteration 6210 : loss : 244.966278, loss_ce: 0.020709, loss_kd: 1222.412720
[18:49:09.520] iteration 6220 : loss : 219.146973, loss_ce: 0.019599, loss_kd: 1093.298462
[18:49:15.177] iteration 6230 : loss : 257.297638, loss_ce: 0.026188, loss_kd: 1284.050049
[18:49:20.818] iteration 6240 : loss : 177.292191, loss_ce: 0.027990, loss_kd: 884.016541
[18:49:26.474] iteration 6250 : loss : 181.984726, loss_ce: 0.022974, loss_kd: 907.501648
[18:49:43.858] iteration 6260 : loss : 267.966675, loss_ce: 0.022604, loss_kd: 1337.432739
[18:49:49.426] iteration 6270 : loss : 215.101852, loss_ce: 0.024078, loss_kd: 1073.072754
[18:49:54.991] iteration 6280 : loss : 203.633514, loss_ce: 0.025885, loss_kd: 1015.725586
[18:50:00.570] iteration 6290 : loss : 274.785461, loss_ce: 0.028194, loss_kd: 1371.481567
[18:50:06.136] iteration 6300 : loss : 273.774689, loss_ce: 0.021406, loss_kd: 1366.448486
[18:50:11.730] iteration 6310 : loss : 196.890564, loss_ce: 0.015290, loss_kd: 981.985901
[18:50:17.316] iteration 6320 : loss : 177.005356, loss_ce: 0.026286, loss_kd: 882.596802
[18:50:22.910] iteration 6330 : loss : 252.448303, loss_ce: 0.016721, loss_kd: 1259.835693
[18:50:28.509] iteration 6340 : loss : 199.782059, loss_ce: 0.016581, loss_kd: 996.494263
[18:50:34.123] iteration 6350 : loss : 253.707947, loss_ce: 0.014946, loss_kd: 1266.107666
[18:50:39.744] iteration 6360 : loss : 202.707962, loss_ce: 0.017983, loss_kd: 1011.151123
[18:50:45.356] iteration 6370 : loss : 206.120834, loss_ce: 0.019455, loss_kd: 1028.176025
[18:50:50.960] iteration 6380 : loss : 372.746368, loss_ce: 0.021804, loss_kd: 1861.319092
[18:50:56.588] iteration 6390 : loss : 268.585510, loss_ce: 0.010777, loss_kd: 1340.534180
[18:51:02.193] iteration 6400 : loss : 221.096298, loss_ce: 0.039716, loss_kd: 1103.012451
[18:51:07.812] iteration 6410 : loss : 202.613678, loss_ce: 0.019875, loss_kd: 1010.620667
[18:51:13.421] iteration 6420 : loss : 243.053574, loss_ce: 0.018227, loss_kd: 1212.811157
[18:51:19.071] iteration 6430 : loss : 218.249527, loss_ce: 0.017250, loss_kd: 1088.817627
[18:51:24.683] iteration 6440 : loss : 199.230255, loss_ce: 0.019046, loss_kd: 993.738281
[18:51:30.321] iteration 6450 : loss : 226.308838, loss_ce: 0.023358, loss_kd: 1129.097534
[18:51:35.949] iteration 6460 : loss : 232.936493, loss_ce: 0.015309, loss_kd: 1162.262939
[18:51:41.585] iteration 6470 : loss : 245.725662, loss_ce: 0.013538, loss_kd: 1226.223633
[18:51:47.207] iteration 6480 : loss : 281.795502, loss_ce: 0.021598, loss_kd: 1406.515015
[18:51:52.856] iteration 6490 : loss : 235.409302, loss_ce: 0.014121, loss_kd: 1174.662598
[18:51:58.480] iteration 6500 : loss : 232.056229, loss_ce: 0.022939, loss_kd: 1157.841187
[18:52:04.096] iteration 6510 : loss : 252.121048, loss_ce: 0.033458, loss_kd: 1258.183350
[18:52:09.738] iteration 6520 : loss : 267.254120, loss_ce: 0.015757, loss_kd: 1333.869019
[18:52:15.379] iteration 6530 : loss : 175.370239, loss_ce: 0.026438, loss_kd: 874.411987
[18:52:21.014] iteration 6540 : loss : 215.603500, loss_ce: 0.039950, loss_kd: 1075.574341
[18:52:26.649] iteration 6550 : loss : 157.259338, loss_ce: 0.014914, loss_kd: 783.823425
[18:52:32.288] iteration 6560 : loss : 167.469269, loss_ce: 0.021071, loss_kd: 834.920166
[18:52:37.936] iteration 6570 : loss : 203.832367, loss_ce: 0.018872, loss_kd: 1016.703796
[18:52:43.571] iteration 6580 : loss : 191.171967, loss_ce: 0.021662, loss_kd: 953.416870
[18:52:49.225] iteration 6590 : loss : 216.890015, loss_ce: 0.022625, loss_kd: 1082.032593
[18:52:54.875] iteration 6600 : loss : 249.199509, loss_ce: 0.029775, loss_kd: 1243.556885
[18:53:00.531] iteration 6610 : loss : 274.706787, loss_ce: 0.025183, loss_kd: 1371.065430
[18:53:06.163] iteration 6620 : loss : 241.501495, loss_ce: 0.029514, loss_kd: 1205.049927
[18:53:11.806] iteration 6630 : loss : 198.101425, loss_ce: 0.015204, loss_kd: 988.014709
[18:53:17.437] iteration 6640 : loss : 189.107742, loss_ce: 0.019177, loss_kd: 943.125854
[18:53:23.089] iteration 6650 : loss : 183.684677, loss_ce: 0.023425, loss_kd: 915.959351
[18:53:28.726] iteration 6660 : loss : 306.285217, loss_ce: 0.019281, loss_kd: 1528.991089
[18:53:34.370] iteration 6670 : loss : 221.958282, loss_ce: 0.016266, loss_kd: 1107.395142
[18:53:40.000] iteration 6680 : loss : 218.478058, loss_ce: 0.019255, loss_kd: 1089.979736
[18:53:45.656] iteration 6690 : loss : 228.438385, loss_ce: 0.015941, loss_kd: 1139.730347
[18:53:51.296] iteration 6700 : loss : 257.360535, loss_ce: 0.014102, loss_kd: 1284.377930
[18:53:56.948] iteration 6710 : loss : 229.477875, loss_ce: 0.011561, loss_kd: 1144.959473
[18:54:02.576] iteration 6720 : loss : 242.395935, loss_ce: 0.016559, loss_kd: 1209.455322
[18:54:08.228] iteration 6730 : loss : 247.941223, loss_ce: 0.015613, loss_kd: 1237.285522
[18:54:13.858] iteration 6740 : loss : 168.946930, loss_ce: 0.020545, loss_kd: 842.295898
[18:54:19.511] iteration 6750 : loss : 202.345718, loss_ce: 0.026008, loss_kd: 1009.286865
[18:54:25.147] iteration 6760 : loss : 239.211044, loss_ce: 0.025026, loss_kd: 1193.644531
[18:54:30.794] iteration 6770 : loss : 202.566940, loss_ce: 0.030730, loss_kd: 1010.358093
[18:54:36.437] iteration 6780 : loss : 215.628113, loss_ce: 0.043627, loss_kd: 1075.689453
[18:54:42.096] iteration 6790 : loss : 239.479248, loss_ce: 0.021388, loss_kd: 1194.964844
[18:54:47.741] iteration 6800 : loss : 220.359894, loss_ce: 0.035689, loss_kd: 1099.337158
[18:54:53.401] iteration 6810 : loss : 225.271957, loss_ce: 0.018762, loss_kd: 1123.934448
[18:54:59.036] iteration 6820 : loss : 192.458344, loss_ce: 0.020611, loss_kd: 959.901611
[18:55:04.693] iteration 6830 : loss : 275.934998, loss_ce: 0.019808, loss_kd: 1377.220581
[18:55:10.331] iteration 6840 : loss : 267.293030, loss_ce: 0.017607, loss_kd: 1334.014526
[18:55:15.989] iteration 6850 : loss : 253.407547, loss_ce: 0.017652, loss_kd: 1264.553833
[18:55:21.638] iteration 6860 : loss : 178.200592, loss_ce: 0.031852, loss_kd: 888.574829
[18:55:27.292] iteration 6870 : loss : 225.082947, loss_ce: 0.032797, loss_kd: 1122.963257
[18:55:32.917] iteration 6880 : loss : 211.399094, loss_ce: 0.024479, loss_kd: 1054.554443
[18:55:38.566] iteration 6890 : loss : 205.887100, loss_ce: 0.022739, loss_kd: 1027.007812
[18:55:44.207] iteration 6900 : loss : 252.681656, loss_ce: 0.026086, loss_kd: 1260.877563
[18:55:49.875] iteration 6910 : loss : 215.061462, loss_ce: 0.015341, loss_kd: 1072.894897
[18:55:55.531] iteration 6920 : loss : 210.508957, loss_ce: 0.020322, loss_kd: 1050.098145
[18:56:01.183] iteration 6930 : loss : 194.264557, loss_ce: 0.026494, loss_kd: 968.898987
[18:56:06.832] iteration 6940 : loss : 197.351456, loss_ce: 0.021615, loss_kd: 984.292053
[18:56:12.473] iteration 6950 : loss : 205.685837, loss_ce: 0.024595, loss_kd: 1026.003662
[18:56:18.114] iteration 6960 : loss : 224.124741, loss_ce: 0.020122, loss_kd: 1118.196167
[18:56:23.781] iteration 6970 : loss : 203.931061, loss_ce: 0.019666, loss_kd: 1017.205017
[18:56:29.434] iteration 6980 : loss : 194.098541, loss_ce: 0.029890, loss_kd: 968.055176
[18:56:35.096] iteration 6990 : loss : 181.305862, loss_ce: 0.028708, loss_kd: 904.104919
[18:56:40.744] iteration 7000 : loss : 197.851410, loss_ce: 0.018819, loss_kd: 986.808350
[18:56:46.425] iteration 7010 : loss : 218.998810, loss_ce: 0.012673, loss_kd: 1092.542358
[18:56:52.052] iteration 7020 : loss : 209.731308, loss_ce: 0.017884, loss_kd: 1046.211792
[18:56:57.707] iteration 7030 : loss : 155.102661, loss_ce: 0.033729, loss_kd: 773.054321
[18:57:03.347] iteration 7040 : loss : 225.404480, loss_ce: 0.030155, loss_kd: 1124.552612
[18:57:08.999] iteration 7050 : loss : 192.661804, loss_ce: 0.017680, loss_kd: 960.871277
[18:57:14.639] iteration 7060 : loss : 252.986374, loss_ce: 0.018304, loss_kd: 1262.488647
[18:57:20.293] iteration 7070 : loss : 150.920380, loss_ce: 0.017204, loss_kd: 752.203308
[18:57:25.943] iteration 7080 : loss : 265.070312, loss_ce: 0.022032, loss_kd: 1322.906860
[18:57:31.579] iteration 7090 : loss : 253.154877, loss_ce: 0.015881, loss_kd: 1263.330200
[18:57:37.234] iteration 7100 : loss : 169.482773, loss_ce: 0.016363, loss_kd: 844.984009
[18:57:42.894] iteration 7110 : loss : 222.691391, loss_ce: 0.026160, loss_kd: 1110.936035
[18:57:48.521] iteration 7120 : loss : 188.893967, loss_ce: 0.014506, loss_kd: 942.026428
[18:57:54.186] iteration 7130 : loss : 246.581711, loss_ce: 0.026924, loss_kd: 1230.454102
[18:57:59.838] iteration 7140 : loss : 221.020737, loss_ce: 0.014543, loss_kd: 1102.626831
[18:58:05.500] iteration 7150 : loss : 154.856766, loss_ce: 0.024791, loss_kd: 771.867004
[18:58:11.139] iteration 7160 : loss : 222.885834, loss_ce: 0.016622, loss_kd: 1112.000610
[18:58:16.779] iteration 7170 : loss : 185.019501, loss_ce: 0.015547, loss_kd: 922.674133
[18:58:22.423] iteration 7180 : loss : 223.370712, loss_ce: 0.017018, loss_kd: 1114.404907
[18:58:28.093] iteration 7190 : loss : 163.709579, loss_ce: 0.022145, loss_kd: 816.105530
[18:58:33.729] iteration 7200 : loss : 149.209030, loss_ce: 0.023145, loss_kd: 743.622131
[18:58:39.384] iteration 7210 : loss : 188.355972, loss_ce: 0.014235, loss_kd: 939.339661
[18:58:45.014] iteration 7220 : loss : 257.841614, loss_ce: 0.021982, loss_kd: 1286.755615
[18:58:50.676] iteration 7230 : loss : 191.345062, loss_ce: 0.028411, loss_kd: 954.320374
[18:58:56.314] iteration 7240 : loss : 249.995911, loss_ce: 0.008582, loss_kd: 1247.581299
[18:59:01.968] iteration 7250 : loss : 254.351791, loss_ce: 0.015333, loss_kd: 1269.293457
[18:59:07.636] iteration 7260 : loss : 172.857635, loss_ce: 0.011745, loss_kd: 861.840759
[18:59:13.284] iteration 7270 : loss : 194.411438, loss_ce: 0.021580, loss_kd: 969.596069
[18:59:18.935] iteration 7280 : loss : 216.827240, loss_ce: 0.020008, loss_kd: 1081.715820
[18:59:24.597] iteration 7290 : loss : 189.602936, loss_ce: 0.018029, loss_kd: 945.588440
[18:59:27.191] Running TPGM constraint optimization after epoch 7
[19:04:12.887] iteration 7300 : loss : 228.460907, loss_ce: 0.020673, loss_kd: 1139.919312
[19:04:18.429] iteration 7310 : loss : 215.411346, loss_ce: 0.029917, loss_kd: 1074.634155
[19:04:23.965] iteration 7320 : loss : 215.243607, loss_ce: 0.021213, loss_kd: 1073.790894
[19:04:29.513] iteration 7330 : loss : 199.632996, loss_ce: 0.016314, loss_kd: 995.724854
[19:04:35.053] iteration 7340 : loss : 211.975464, loss_ce: 0.024105, loss_kd: 1057.455200
[19:04:40.615] iteration 7350 : loss : 229.071289, loss_ce: 0.020910, loss_kd: 1142.938232
[19:04:46.170] iteration 7360 : loss : 165.687302, loss_ce: 0.014073, loss_kd: 825.969604
[19:04:51.731] iteration 7370 : loss : 224.659195, loss_ce: 0.020086, loss_kd: 1120.855591
[19:04:57.295] iteration 7380 : loss : 257.458221, loss_ce: 0.016834, loss_kd: 1284.905518
[19:05:02.875] iteration 7390 : loss : 225.701370, loss_ce: 0.032339, loss_kd: 1126.093384
[19:05:08.439] iteration 7400 : loss : 188.718475, loss_ce: 0.026817, loss_kd: 941.169739
[19:05:14.024] iteration 7410 : loss : 198.057297, loss_ce: 0.017967, loss_kd: 987.859741
[19:05:19.597] iteration 7420 : loss : 157.515945, loss_ce: 0.030058, loss_kd: 785.162292
[19:05:25.189] iteration 7430 : loss : 143.794846, loss_ce: 0.023767, loss_kd: 716.540955
[19:05:30.768] iteration 7440 : loss : 159.977554, loss_ce: 0.011314, loss_kd: 797.485352
[19:05:36.361] iteration 7450 : loss : 204.405090, loss_ce: 0.014028, loss_kd: 1019.604004
[19:05:41.955] iteration 7460 : loss : 190.797409, loss_ce: 0.017132, loss_kd: 951.576843
[19:05:47.558] iteration 7470 : loss : 201.520157, loss_ce: 0.017762, loss_kd: 1005.157471
[19:05:53.159] iteration 7480 : loss : 196.909729, loss_ce: 0.019581, loss_kd: 982.102905
[19:05:58.760] iteration 7490 : loss : 242.346222, loss_ce: 0.022512, loss_kd: 1209.291138
[19:06:04.354] iteration 7500 : loss : 204.698822, loss_ce: 0.017675, loss_kd: 1021.076904
[19:06:09.971] iteration 7510 : loss : 211.331192, loss_ce: 0.026536, loss_kd: 1054.239624
[19:06:15.564] iteration 7520 : loss : 300.202850, loss_ce: 0.022416, loss_kd: 1498.377686
[19:06:21.175] iteration 7530 : loss : 269.833618, loss_ce: 0.015675, loss_kd: 1346.782104
[19:06:26.790] iteration 7540 : loss : 247.662430, loss_ce: 0.020871, loss_kd: 1235.920166
[19:06:32.413] iteration 7550 : loss : 213.111542, loss_ce: 0.016700, loss_kd: 1063.160278
[19:06:38.023] iteration 7560 : loss : 179.953232, loss_ce: 0.015462, loss_kd: 897.362610
[19:06:43.650] iteration 7570 : loss : 185.552841, loss_ce: 0.022365, loss_kd: 925.329895
[19:06:49.256] iteration 7580 : loss : 149.043961, loss_ce: 0.022696, loss_kd: 742.774170
[19:06:54.886] iteration 7590 : loss : 172.197128, loss_ce: 0.017168, loss_kd: 858.586548
[19:07:00.497] iteration 7600 : loss : 238.407227, loss_ce: 0.019195, loss_kd: 1189.596558
[19:07:06.112] iteration 7610 : loss : 229.899811, loss_ce: 0.016263, loss_kd: 1147.055664
[19:07:11.746] iteration 7620 : loss : 228.266464, loss_ce: 0.022834, loss_kd: 1138.924805
[19:07:17.372] iteration 7630 : loss : 197.628098, loss_ce: 0.025439, loss_kd: 985.668213
[19:07:23.004] iteration 7640 : loss : 206.056992, loss_ce: 0.023436, loss_kd: 1027.833496
[19:07:28.641] iteration 7650 : loss : 269.338470, loss_ce: 0.014410, loss_kd: 1344.290161
[19:07:34.263] iteration 7660 : loss : 232.546509, loss_ce: 0.017362, loss_kd: 1160.289551
[19:07:39.907] iteration 7670 : loss : 214.925980, loss_ce: 0.019035, loss_kd: 1072.205444
[19:07:45.536] iteration 7680 : loss : 195.528229, loss_ce: 0.014407, loss_kd: 975.199463
[19:07:51.171] iteration 7690 : loss : 201.028442, loss_ce: 0.018782, loss_kd: 1002.702942
[19:07:56.792] iteration 7700 : loss : 222.650604, loss_ce: 0.044318, loss_kd: 1110.766968
[19:08:02.425] iteration 7710 : loss : 196.681961, loss_ce: 0.021412, loss_kd: 980.977966
[19:08:08.048] iteration 7720 : loss : 148.422729, loss_ce: 0.026676, loss_kd: 739.680054
[19:08:13.698] iteration 7730 : loss : 214.151505, loss_ce: 0.018576, loss_kd: 1068.312378
[19:08:19.308] iteration 7740 : loss : 201.889267, loss_ce: 0.022720, loss_kd: 1007.025269
[19:08:24.953] iteration 7750 : loss : 184.498581, loss_ce: 0.023743, loss_kd: 920.024231
[19:08:30.571] iteration 7760 : loss : 257.282074, loss_ce: 0.025232, loss_kd: 1283.943359
[19:08:36.215] iteration 7770 : loss : 207.021088, loss_ce: 0.019171, loss_kd: 1032.724121
[19:08:41.829] iteration 7780 : loss : 135.937256, loss_ce: 0.023370, loss_kd: 677.266541
[19:08:47.485] iteration 7790 : loss : 215.146729, loss_ce: 0.019327, loss_kd: 1073.305542
[19:08:53.119] iteration 7800 : loss : 242.779709, loss_ce: 0.015991, loss_kd: 1211.500244
[19:08:58.779] iteration 7810 : loss : 205.089371, loss_ce: 0.023408, loss_kd: 1023.015686
[19:09:04.412] iteration 7820 : loss : 247.031036, loss_ce: 0.018216, loss_kd: 1232.662476
[19:09:10.054] iteration 7830 : loss : 156.672989, loss_ce: 0.022330, loss_kd: 780.973511
[19:09:15.688] iteration 7840 : loss : 166.065933, loss_ce: 0.024020, loss_kd: 827.902466
[19:09:21.325] iteration 7850 : loss : 272.116364, loss_ce: 0.023856, loss_kd: 1358.095093
[19:09:26.962] iteration 7860 : loss : 230.985016, loss_ce: 0.018924, loss_kd: 1152.500854
[19:09:32.603] iteration 7870 : loss : 190.895828, loss_ce: 0.018402, loss_kd: 952.061646
[19:09:38.245] iteration 7880 : loss : 213.590286, loss_ce: 0.021965, loss_kd: 1065.509399
[19:09:43.901] iteration 7890 : loss : 267.283508, loss_ce: 0.017199, loss_kd: 1333.969849
[19:09:49.538] iteration 7900 : loss : 234.211578, loss_ce: 0.017013, loss_kd: 1168.627197
[19:09:55.189] iteration 7910 : loss : 213.080200, loss_ce: 0.023594, loss_kd: 1062.977661
[19:10:00.838] iteration 7920 : loss : 189.696609, loss_ce: 0.020629, loss_kd: 946.054504
[19:10:06.504] iteration 7930 : loss : 182.315536, loss_ce: 0.013432, loss_kd: 909.155762
[19:10:12.164] iteration 7940 : loss : 222.860947, loss_ce: 0.026340, loss_kd: 1111.873779
[19:10:17.831] iteration 7950 : loss : 205.854095, loss_ce: 0.024457, loss_kd: 1026.811890
[19:10:23.477] iteration 7960 : loss : 220.940262, loss_ce: 0.028328, loss_kd: 1102.272705
[19:10:29.140] iteration 7970 : loss : 289.901245, loss_ce: 0.025427, loss_kd: 1447.062256
[19:10:34.796] iteration 7980 : loss : 204.564438, loss_ce: 0.027771, loss_kd: 1020.350342
[19:10:40.467] iteration 7990 : loss : 198.580368, loss_ce: 0.021322, loss_kd: 990.460083
[19:10:46.103] iteration 8000 : loss : 199.368530, loss_ce: 0.025978, loss_kd: 994.404785
[19:10:51.780] iteration 8010 : loss : 219.762573, loss_ce: 0.017353, loss_kd: 1096.384644
[19:10:57.431] iteration 8020 : loss : 213.955505, loss_ce: 0.026200, loss_kd: 1067.285034
[19:11:03.097] iteration 8030 : loss : 238.135040, loss_ce: 0.019903, loss_kd: 1188.269409
[19:11:08.750] iteration 8040 : loss : 181.326935, loss_ce: 0.022561, loss_kd: 904.222473
[19:11:14.408] iteration 8050 : loss : 246.174606, loss_ce: 0.022910, loss_kd: 1228.406738
[19:11:20.063] iteration 8060 : loss : 279.249329, loss_ce: 0.020884, loss_kd: 1393.821899
[19:11:25.733] iteration 8070 : loss : 298.598694, loss_ce: 0.018395, loss_kd: 1490.558228
[19:11:31.388] iteration 8080 : loss : 216.144485, loss_ce: 0.014496, loss_kd: 1078.298096
[19:11:37.046] iteration 8090 : loss : 166.702301, loss_ce: 0.015141, loss_kd: 831.057007
[19:11:42.683] iteration 8100 : loss : 137.937607, loss_ce: 0.021357, loss_kd: 687.246399
[19:11:48.358] iteration 8110 : loss : 163.439743, loss_ce: 0.020608, loss_kd: 814.794617
[19:11:54.002] iteration 8120 : loss : 223.853867, loss_ce: 0.033913, loss_kd: 1116.827515
[19:11:59.670] iteration 8130 : loss : 212.188354, loss_ce: 0.024338, loss_kd: 1058.475464
[19:12:05.327] iteration 8140 : loss : 300.740479, loss_ce: 0.021969, loss_kd: 1501.256836
[19:12:10.998] iteration 8150 : loss : 209.830399, loss_ce: 0.017721, loss_kd: 1046.741333
[19:12:16.662] iteration 8160 : loss : 222.026031, loss_ce: 0.016212, loss_kd: 1107.695801
[19:12:22.333] iteration 8170 : loss : 166.915375, loss_ce: 0.021432, loss_kd: 832.154846
[19:12:28.001] iteration 8180 : loss : 182.554977, loss_ce: 0.012143, loss_kd: 910.377563
[19:12:33.674] iteration 8190 : loss : 190.982071, loss_ce: 0.014575, loss_kd: 952.492615
[19:12:39.321] iteration 8200 : loss : 194.253937, loss_ce: 0.014093, loss_kd: 968.863586
[19:12:44.988] iteration 8210 : loss : 233.509186, loss_ce: 0.022779, loss_kd: 1165.129150
[19:12:50.643] iteration 8220 : loss : 210.109009, loss_ce: 0.014812, loss_kd: 1048.160889
[19:12:56.316] iteration 8230 : loss : 230.176407, loss_ce: 0.020098, loss_kd: 1148.433594
[19:13:01.967] iteration 8240 : loss : 180.730820, loss_ce: 0.023879, loss_kd: 901.285522
[19:13:07.627] iteration 8250 : loss : 179.495087, loss_ce: 0.015947, loss_kd: 895.073608
[19:13:13.289] iteration 8260 : loss : 213.407959, loss_ce: 0.016674, loss_kd: 1064.624268
[19:13:18.962] iteration 8270 : loss : 235.535583, loss_ce: 0.015629, loss_kd: 1175.264160
[19:13:24.624] iteration 8280 : loss : 153.361435, loss_ce: 0.021034, loss_kd: 764.372437
[19:13:30.299] iteration 8290 : loss : 141.911575, loss_ce: 0.018545, loss_kd: 707.088806
[19:13:35.960] iteration 8300 : loss : 179.062302, loss_ce: 0.015678, loss_kd: 892.863403
[19:13:41.627] iteration 8310 : loss : 201.434525, loss_ce: 0.015300, loss_kd: 1004.696594
[19:13:47.276] iteration 8320 : loss : 212.384476, loss_ce: 0.023367, loss_kd: 1059.499878
[19:13:52.950] iteration 8330 : loss : 199.221756, loss_ce: 0.020260, loss_kd: 993.683960
[19:14:10.988] iteration 8340 : loss : 166.426376, loss_ce: 0.016631, loss_kd: 829.673584
[19:14:16.562] iteration 8350 : loss : 179.615158, loss_ce: 0.011881, loss_kd: 895.643738
[19:14:22.126] iteration 8360 : loss : 164.541031, loss_ce: 0.021863, loss_kd: 820.299683
[19:14:27.701] iteration 8370 : loss : 196.141342, loss_ce: 0.032064, loss_kd: 978.288025
[19:14:33.273] iteration 8380 : loss : 161.206329, loss_ce: 0.019459, loss_kd: 803.626282
[19:14:38.846] iteration 8390 : loss : 163.458435, loss_ce: 0.018168, loss_kd: 814.895508
[19:14:44.426] iteration 8400 : loss : 185.469406, loss_ce: 0.017552, loss_kd: 924.886292
[19:14:50.024] iteration 8410 : loss : 248.671143, loss_ce: 0.013438, loss_kd: 1240.908203
[19:14:55.615] iteration 8420 : loss : 232.367279, loss_ce: 0.032251, loss_kd: 1159.401123
[19:15:01.223] iteration 8430 : loss : 241.997467, loss_ce: 0.015169, loss_kd: 1207.554688
[19:15:06.822] iteration 8440 : loss : 210.333389, loss_ce: 0.028753, loss_kd: 1049.242432
[19:15:12.433] iteration 8450 : loss : 222.098511, loss_ce: 0.021843, loss_kd: 1108.067017
[19:15:18.034] iteration 8460 : loss : 217.571487, loss_ce: 0.014320, loss_kd: 1085.432129
[19:15:23.645] iteration 8470 : loss : 202.862534, loss_ce: 0.017044, loss_kd: 1011.872437
[19:15:29.236] iteration 8480 : loss : 188.624252, loss_ce: 0.013367, loss_kd: 940.676025
[19:15:34.851] iteration 8490 : loss : 242.073776, loss_ce: 0.018291, loss_kd: 1207.939209
[19:15:40.468] iteration 8500 : loss : 217.753830, loss_ce: 0.021402, loss_kd: 1086.316528
[19:15:46.096] iteration 8510 : loss : 229.397171, loss_ce: 0.018368, loss_kd: 1144.567627
[19:15:51.702] iteration 8520 : loss : 292.309875, loss_ce: 0.028685, loss_kd: 1459.125488
[19:15:57.322] iteration 8530 : loss : 171.978867, loss_ce: 0.019702, loss_kd: 857.444031
[19:16:02.955] iteration 8540 : loss : 189.924850, loss_ce: 0.020455, loss_kd: 947.157898
[19:16:08.575] iteration 8550 : loss : 228.597153, loss_ce: 0.018965, loss_kd: 1140.593140
[19:16:14.185] iteration 8560 : loss : 194.133362, loss_ce: 0.017941, loss_kd: 968.265869
[19:16:19.810] iteration 8570 : loss : 201.191299, loss_ce: 0.015597, loss_kd: 1003.537476
[19:16:25.434] iteration 8580 : loss : 188.735565, loss_ce: 0.017682, loss_kd: 941.282227
[19:16:31.057] iteration 8590 : loss : 165.193695, loss_ce: 0.023934, loss_kd: 823.516602
[19:16:36.683] iteration 8600 : loss : 191.208786, loss_ce: 0.013458, loss_kd: 953.598755
[19:16:42.321] iteration 8610 : loss : 172.501541, loss_ce: 0.016399, loss_kd: 860.070251
[19:16:47.938] iteration 8620 : loss : 227.457809, loss_ce: 0.017441, loss_kd: 1134.869141
[19:16:53.576] iteration 8630 : loss : 189.385040, loss_ce: 0.011052, loss_kd: 944.502319
[19:16:59.188] iteration 8640 : loss : 247.395004, loss_ce: 0.027784, loss_kd: 1234.491211
[19:17:04.827] iteration 8650 : loss : 179.937729, loss_ce: 0.019025, loss_kd: 897.211792
[19:17:10.432] iteration 8660 : loss : 193.390366, loss_ce: 0.025611, loss_kd: 964.513550
[19:17:16.064] iteration 8670 : loss : 319.036987, loss_ce: 0.011081, loss_kd: 1592.723389
[19:17:21.696] iteration 8680 : loss : 224.072495, loss_ce: 0.022083, loss_kd: 1117.942871
[19:17:27.326] iteration 8690 : loss : 198.815109, loss_ce: 0.016158, loss_kd: 991.666382
[19:17:32.947] iteration 8700 : loss : 160.265442, loss_ce: 0.015201, loss_kd: 798.888367
[19:17:38.567] iteration 8710 : loss : 188.481567, loss_ce: 0.009170, loss_kd: 939.962341
[19:17:44.186] iteration 8720 : loss : 222.117981, loss_ce: 0.023537, loss_kd: 1108.170898
[19:17:49.830] iteration 8730 : loss : 201.570541, loss_ce: 0.013880, loss_kd: 1005.477783
[19:17:55.447] iteration 8740 : loss : 299.605652, loss_ce: 0.015840, loss_kd: 1495.594116
[19:18:01.096] iteration 8750 : loss : 308.389221, loss_ce: 0.024412, loss_kd: 1539.507446
[19:18:06.713] iteration 8760 : loss : 193.242416, loss_ce: 0.019531, loss_kd: 963.776489
[19:18:12.356] iteration 8770 : loss : 214.742188, loss_ce: 0.024219, loss_kd: 1071.271240
[19:18:17.975] iteration 8780 : loss : 163.527817, loss_ce: 0.014078, loss_kd: 815.219727
[19:18:23.623] iteration 8790 : loss : 231.259552, loss_ce: 0.027916, loss_kd: 1153.852173
[19:18:29.229] iteration 8800 : loss : 214.377243, loss_ce: 0.018618, loss_kd: 1069.518799
[19:18:34.863] iteration 8810 : loss : 194.330582, loss_ce: 0.017581, loss_kd: 969.233643
[19:18:40.485] iteration 8820 : loss : 173.767014, loss_ce: 0.015479, loss_kd: 866.386780
[19:18:46.114] iteration 8830 : loss : 175.166229, loss_ce: 0.014861, loss_kd: 873.432007
[19:18:51.746] iteration 8840 : loss : 199.819550, loss_ce: 0.017192, loss_kd: 996.681030
[19:18:57.375] iteration 8850 : loss : 204.466675, loss_ce: 0.014006, loss_kd: 1019.925049
[19:19:02.986] iteration 8860 : loss : 152.102478, loss_ce: 0.020849, loss_kd: 758.042480
[19:19:08.619] iteration 8870 : loss : 197.318558, loss_ce: 0.021579, loss_kd: 984.141846
[19:19:14.236] iteration 8880 : loss : 187.574936, loss_ce: 0.012893, loss_kd: 935.416199
[19:19:19.871] iteration 8890 : loss : 140.639648, loss_ce: 0.024354, loss_kd: 700.776672
[19:19:25.480] iteration 8900 : loss : 216.907928, loss_ce: 0.017507, loss_kd: 1082.106323
[19:19:31.101] iteration 8910 : loss : 221.209702, loss_ce: 0.012008, loss_kd: 1103.636841
[19:19:36.711] iteration 8920 : loss : 219.287292, loss_ce: 0.023920, loss_kd: 1094.022339
[19:19:42.342] iteration 8930 : loss : 244.240616, loss_ce: 0.017351, loss_kd: 1218.798096
[19:19:47.964] iteration 8940 : loss : 123.561943, loss_ce: 0.018731, loss_kd: 615.418274
[19:19:53.602] iteration 8950 : loss : 172.019226, loss_ce: 0.023798, loss_kd: 857.667053
[19:19:59.215] iteration 8960 : loss : 167.236008, loss_ce: 0.018145, loss_kd: 833.768372
[19:20:04.841] iteration 8970 : loss : 189.914261, loss_ce: 0.018050, loss_kd: 947.151184
[19:20:10.466] iteration 8980 : loss : 212.031235, loss_ce: 0.021772, loss_kd: 1057.739746
[19:20:16.103] iteration 8990 : loss : 167.822556, loss_ce: 0.016777, loss_kd: 836.707031
[19:20:21.725] iteration 9000 : loss : 211.918396, loss_ce: 0.014438, loss_kd: 1057.180542
[19:20:27.374] iteration 9010 : loss : 171.514053, loss_ce: 0.011187, loss_kd: 855.126953
[19:20:33.011] iteration 9020 : loss : 192.542175, loss_ce: 0.016994, loss_kd: 960.252258
[19:20:38.664] iteration 9030 : loss : 211.369751, loss_ce: 0.017812, loss_kd: 1054.436768
[19:20:44.295] iteration 9040 : loss : 165.559265, loss_ce: 0.022002, loss_kd: 825.335388
[19:20:49.931] iteration 9050 : loss : 143.460007, loss_ce: 0.022886, loss_kd: 714.858337
[19:20:55.566] iteration 9060 : loss : 248.023743, loss_ce: 0.021925, loss_kd: 1237.691406
[19:21:01.216] iteration 9070 : loss : 260.737946, loss_ce: 0.021753, loss_kd: 1301.266846
[19:21:06.841] iteration 9080 : loss : 216.076981, loss_ce: 0.015045, loss_kd: 1077.969727
[19:21:12.485] iteration 9090 : loss : 187.608917, loss_ce: 0.022720, loss_kd: 935.637207
[19:21:18.109] iteration 9100 : loss : 186.084473, loss_ce: 0.014641, loss_kd: 928.020752
[19:21:23.782] iteration 9110 : loss : 176.102631, loss_ce: 0.019963, loss_kd: 878.123413
[19:21:29.407] iteration 9120 : loss : 137.053635, loss_ce: 0.013564, loss_kd: 682.877380
[19:21:35.038] iteration 9130 : loss : 245.817429, loss_ce: 0.012906, loss_kd: 1226.700073
[19:21:40.672] iteration 9140 : loss : 159.476273, loss_ce: 0.018054, loss_kd: 794.975525
[19:21:46.293] iteration 9150 : loss : 207.760986, loss_ce: 0.014718, loss_kd: 1036.329590
[19:21:51.907] iteration 9160 : loss : 184.581100, loss_ce: 0.016551, loss_kd: 920.501770
[19:21:57.543] iteration 9170 : loss : 182.444962, loss_ce: 0.012719, loss_kd: 909.811401
[19:22:03.151] iteration 9180 : loss : 216.260147, loss_ce: 0.020517, loss_kd: 1078.901855
[19:22:08.783] iteration 9190 : loss : 178.910645, loss_ce: 0.012175, loss_kd: 892.128662
[19:22:14.407] iteration 9200 : loss : 216.139557, loss_ce: 0.021495, loss_kd: 1078.273315
[19:22:20.037] iteration 9210 : loss : 170.320221, loss_ce: 0.017998, loss_kd: 849.164124
[19:22:25.670] iteration 9220 : loss : 225.787292, loss_ce: 0.025256, loss_kd: 1126.506104
[19:22:31.294] iteration 9230 : loss : 141.099808, loss_ce: 0.017004, loss_kd: 703.057556
[19:22:36.932] iteration 9240 : loss : 216.118546, loss_ce: 0.012771, loss_kd: 1078.204590
[19:22:42.552] iteration 9250 : loss : 178.810257, loss_ce: 0.017493, loss_kd: 891.619873
[19:22:48.168] iteration 9260 : loss : 178.878098, loss_ce: 0.021054, loss_kd: 891.958923
[19:22:53.808] iteration 9270 : loss : 207.894104, loss_ce: 0.021932, loss_kd: 1037.018433
[19:22:59.432] iteration 9280 : loss : 176.524704, loss_ce: 0.026839, loss_kd: 880.166504
[19:23:05.075] iteration 9290 : loss : 155.160782, loss_ce: 0.027249, loss_kd: 773.372803
[19:23:10.704] iteration 9300 : loss : 155.096664, loss_ce: 0.017016, loss_kd: 773.048035
[19:23:16.349] iteration 9310 : loss : 179.302002, loss_ce: 0.019547, loss_kd: 894.094604
[19:23:21.967] iteration 9320 : loss : 186.220886, loss_ce: 0.016482, loss_kd: 928.655640
[19:23:27.607] iteration 9330 : loss : 193.337830, loss_ce: 0.026464, loss_kd: 964.243469
[19:23:33.220] iteration 9340 : loss : 164.846725, loss_ce: 0.015493, loss_kd: 821.772217
[19:23:38.866] iteration 9350 : loss : 233.743240, loss_ce: 0.018130, loss_kd: 1166.320312
[19:23:44.492] iteration 9360 : loss : 187.840820, loss_ce: 0.018795, loss_kd: 936.768433
[19:23:50.138] iteration 9370 : loss : 225.201080, loss_ce: 0.024538, loss_kd: 1123.567749
[19:23:55.036] Running TPGM constraint optimization after epoch 9
[19:28:58.606] iteration 9380 : loss : 194.420731, loss_ce: 0.029733, loss_kd: 969.682556
[19:29:04.142] iteration 9390 : loss : 202.451035, loss_ce: 0.017723, loss_kd: 1009.864441
[19:29:09.671] iteration 9400 : loss : 175.805054, loss_ce: 0.014399, loss_kd: 876.609131
[19:29:15.225] iteration 9410 : loss : 191.316681, loss_ce: 0.027793, loss_kd: 954.129517
[19:29:20.764] iteration 9420 : loss : 172.633911, loss_ce: 0.017472, loss_kd: 860.797302
[19:29:26.320] iteration 9430 : loss : 199.090637, loss_ce: 0.022974, loss_kd: 993.021484
[19:29:31.866] iteration 9440 : loss : 149.211212, loss_ce: 0.020771, loss_kd: 743.600403
[19:29:37.424] iteration 9450 : loss : 209.323303, loss_ce: 0.022272, loss_kd: 1044.171387
[19:29:42.978] iteration 9460 : loss : 153.782349, loss_ce: 0.019242, loss_kd: 766.485962
[19:29:48.548] iteration 9470 : loss : 154.824081, loss_ce: 0.017315, loss_kd: 771.659668
[19:29:54.114] iteration 9480 : loss : 190.004898, loss_ce: 0.023459, loss_kd: 947.574585
[19:29:59.693] iteration 9490 : loss : 186.803192, loss_ce: 0.034171, loss_kd: 931.524597
[19:30:05.249] iteration 9500 : loss : 153.957550, loss_ce: 0.019914, loss_kd: 767.378540
[19:30:10.821] iteration 9510 : loss : 167.490784, loss_ce: 0.017968, loss_kd: 835.051208
[19:30:16.399] iteration 9520 : loss : 220.905975, loss_ce: 0.021367, loss_kd: 1102.052856
[19:30:21.987] iteration 9530 : loss : 190.076599, loss_ce: 0.022223, loss_kd: 947.978149
[19:30:27.564] iteration 9540 : loss : 137.816055, loss_ce: 0.026292, loss_kd: 686.691284
[19:30:33.156] iteration 9550 : loss : 170.003983, loss_ce: 0.018191, loss_kd: 847.623108
[19:30:38.733] iteration 9560 : loss : 214.432266, loss_ce: 0.017290, loss_kd: 1069.714722
[19:30:44.330] iteration 9570 : loss : 162.819397, loss_ce: 0.019173, loss_kd: 811.681335
[19:30:49.918] iteration 9580 : loss : 169.698837, loss_ce: 0.028236, loss_kd: 846.055420
[19:30:55.526] iteration 9590 : loss : 172.021332, loss_ce: 0.018692, loss_kd: 857.694946
[19:31:01.126] iteration 9600 : loss : 189.578018, loss_ce: 0.017475, loss_kd: 945.445618
[19:31:06.726] iteration 9610 : loss : 169.875366, loss_ce: 0.016111, loss_kd: 846.962402
[19:31:12.313] iteration 9620 : loss : 250.330292, loss_ce: 0.021504, loss_kd: 1249.223755
[19:31:17.923] iteration 9630 : loss : 241.294662, loss_ce: 0.009879, loss_kd: 1204.075195
[19:31:23.518] iteration 9640 : loss : 181.483826, loss_ce: 0.014760, loss_kd: 904.999329
[19:31:29.125] iteration 9650 : loss : 157.804230, loss_ce: 0.019201, loss_kd: 786.587769
[19:31:34.720] iteration 9660 : loss : 218.803711, loss_ce: 0.016740, loss_kd: 1091.604614
[19:31:40.328] iteration 9670 : loss : 177.865356, loss_ce: 0.025005, loss_kd: 886.892273
[19:31:45.919] iteration 9680 : loss : 194.491852, loss_ce: 0.011523, loss_kd: 970.079590
[19:31:51.522] iteration 9690 : loss : 170.387390, loss_ce: 0.035160, loss_kd: 849.493652
[19:31:57.122] iteration 9700 : loss : 171.217361, loss_ce: 0.012229, loss_kd: 853.646057
[19:32:02.734] iteration 9710 : loss : 151.508652, loss_ce: 0.016137, loss_kd: 755.142334
[19:32:08.336] iteration 9720 : loss : 248.310440, loss_ce: 0.023572, loss_kd: 1239.120361
[19:32:13.954] iteration 9730 : loss : 184.248672, loss_ce: 0.026397, loss_kd: 918.815674
[19:32:19.563] iteration 9740 : loss : 168.523483, loss_ce: 0.029090, loss_kd: 840.196167
[19:32:25.174] iteration 9750 : loss : 180.937149, loss_ce: 0.013650, loss_kd: 902.255615
[19:32:30.780] iteration 9760 : loss : 142.325104, loss_ce: 0.024141, loss_kd: 709.199097
[19:32:36.396] iteration 9770 : loss : 167.112320, loss_ce: 0.025800, loss_kd: 833.130737
[19:32:42.000] iteration 9780 : loss : 159.309113, loss_ce: 0.015388, loss_kd: 794.148926
[19:32:47.609] iteration 9790 : loss : 186.968719, loss_ce: 0.014504, loss_kd: 932.388123
[19:32:53.221] iteration 9800 : loss : 162.402481, loss_ce: 0.013339, loss_kd: 809.611694
[19:32:58.848] iteration 9810 : loss : 225.978333, loss_ce: 0.018224, loss_kd: 1127.471558
[19:33:04.452] iteration 9820 : loss : 200.761902, loss_ce: 0.013899, loss_kd: 1001.388367
[19:33:10.069] iteration 9830 : loss : 193.348740, loss_ce: 0.026516, loss_kd: 964.347839
[19:33:15.670] iteration 9840 : loss : 174.181854, loss_ce: 0.016293, loss_kd: 868.493530
[19:33:21.294] iteration 9850 : loss : 198.966476, loss_ce: 0.022150, loss_kd: 992.391174
[19:33:26.903] iteration 9860 : loss : 163.340134, loss_ce: 0.020107, loss_kd: 814.299072
[19:33:32.514] iteration 9870 : loss : 170.555634, loss_ce: 0.028785, loss_kd: 850.338501
[19:33:38.122] iteration 9880 : loss : 176.931107, loss_ce: 0.018480, loss_kd: 882.236084
[19:33:43.755] iteration 9890 : loss : 236.248062, loss_ce: 0.021830, loss_kd: 1178.847900
[19:33:49.375] iteration 9900 : loss : 206.050156, loss_ce: 0.019578, loss_kd: 1027.822998
[19:33:54.998] iteration 9910 : loss : 152.533875, loss_ce: 0.014549, loss_kd: 760.255737
[19:34:00.616] iteration 9920 : loss : 163.878174, loss_ce: 0.020518, loss_kd: 816.958496
[19:34:06.237] iteration 9930 : loss : 142.547287, loss_ce: 0.012279, loss_kd: 710.297241
[19:34:11.840] iteration 9940 : loss : 166.955414, loss_ce: 0.026916, loss_kd: 832.316956
[19:34:17.504] iteration 9950 : loss : 162.613602, loss_ce: 0.012379, loss_kd: 810.650391
[19:34:23.116] iteration 9960 : loss : 176.421967, loss_ce: 0.026124, loss_kd: 879.685303
[19:34:28.774] iteration 9970 : loss : 185.621124, loss_ce: 0.034622, loss_kd: 925.692200
[19:34:34.389] iteration 9980 : loss : 236.541031, loss_ce: 0.018946, loss_kd: 1180.282959
[19:34:40.020] iteration 9990 : loss : 199.934769, loss_ce: 0.010521, loss_kd: 997.288513
[19:34:45.643] iteration 10000 : loss : 187.443665, loss_ce: 0.026797, loss_kd: 934.805420
[19:34:51.283] iteration 10010 : loss : 199.236679, loss_ce: 0.027835, loss_kd: 993.770935
[19:34:56.897] iteration 10020 : loss : 233.608536, loss_ce: 0.013695, loss_kd: 1165.586182
[19:35:02.525] iteration 10030 : loss : 176.312897, loss_ce: 0.013777, loss_kd: 879.174866
[19:35:08.147] iteration 10040 : loss : 161.083450, loss_ce: 0.014693, loss_kd: 803.028259
[19:35:13.773] iteration 10050 : loss : 152.786697, loss_ce: 0.015708, loss_kd: 761.525635
[19:35:19.389] iteration 10060 : loss : 198.511154, loss_ce: 0.015725, loss_kd: 990.161011
[19:35:25.024] iteration 10070 : loss : 236.583206, loss_ce: 0.030287, loss_kd: 1180.453369
[19:35:30.631] iteration 10080 : loss : 158.909637, loss_ce: 0.025623, loss_kd: 792.026611
[19:35:36.262] iteration 10090 : loss : 177.688553, loss_ce: 0.017658, loss_kd: 886.031982
[19:35:41.895] iteration 10100 : loss : 191.324936, loss_ce: 0.020357, loss_kd: 954.206604
[19:35:47.531] iteration 10110 : loss : 174.842285, loss_ce: 0.023504, loss_kd: 871.767090
[19:35:53.159] iteration 10120 : loss : 200.130997, loss_ce: 0.026059, loss_kd: 998.272766
[19:35:58.781] iteration 10130 : loss : 183.335800, loss_ce: 0.022537, loss_kd: 914.246216
[19:36:04.385] iteration 10140 : loss : 166.287094, loss_ce: 0.019798, loss_kd: 829.052246
[19:36:10.029] iteration 10150 : loss : 206.196198, loss_ce: 0.020750, loss_kd: 1028.565674
[19:36:15.650] iteration 10160 : loss : 176.564423, loss_ce: 0.019850, loss_kd: 880.401001
[19:36:21.296] iteration 10170 : loss : 175.349594, loss_ce: 0.013360, loss_kd: 874.347656
[19:36:26.904] iteration 10180 : loss : 190.846298, loss_ce: 0.013816, loss_kd: 951.783936
[19:36:32.537] iteration 10190 : loss : 172.070358, loss_ce: 0.016228, loss_kd: 857.901855
[19:36:38.157] iteration 10200 : loss : 161.874924, loss_ce: 0.019754, loss_kd: 806.982605
[19:36:43.787] iteration 10210 : loss : 120.326431, loss_ce: 0.010693, loss_kd: 599.240417
[19:36:49.410] iteration 10220 : loss : 159.370499, loss_ce: 0.023817, loss_kd: 794.399963
[19:36:55.033] iteration 10230 : loss : 188.541260, loss_ce: 0.016947, loss_kd: 940.264648
[19:37:00.651] iteration 10240 : loss : 167.652740, loss_ce: 0.021795, loss_kd: 835.841309
[19:37:06.297] iteration 10250 : loss : 159.653946, loss_ce: 0.022663, loss_kd: 795.828613
[19:37:11.910] iteration 10260 : loss : 154.992065, loss_ce: 0.032065, loss_kd: 772.534241
[19:37:17.548] iteration 10270 : loss : 145.129456, loss_ce: 0.018643, loss_kd: 723.245361
[19:37:23.158] iteration 10280 : loss : 163.103027, loss_ce: 0.014430, loss_kd: 813.109985
[19:37:28.800] iteration 10290 : loss : 188.805176, loss_ce: 0.020962, loss_kd: 941.611389
[19:37:34.429] iteration 10300 : loss : 224.192291, loss_ce: 0.014521, loss_kd: 1118.560547
[19:37:40.074] iteration 10310 : loss : 158.978821, loss_ce: 0.013722, loss_kd: 792.496704
[19:37:45.693] iteration 10320 : loss : 186.024048, loss_ce: 0.013359, loss_kd: 927.689087
[19:37:51.335] iteration 10330 : loss : 130.446838, loss_ce: 0.031490, loss_kd: 649.808350
[19:37:56.950] iteration 10340 : loss : 195.060959, loss_ce: 0.014727, loss_kd: 972.922729
[19:38:02.570] iteration 10350 : loss : 174.217804, loss_ce: 0.020095, loss_kd: 868.662781
[19:38:08.208] iteration 10360 : loss : 164.594147, loss_ce: 0.015135, loss_kd: 820.564026
[19:38:13.829] iteration 10370 : loss : 177.962799, loss_ce: 0.019245, loss_kd: 887.394531
[19:38:19.444] iteration 10380 : loss : 164.433578, loss_ce: 0.022065, loss_kd: 819.754211
[19:38:25.082] iteration 10390 : loss : 171.378647, loss_ce: 0.028290, loss_kd: 854.484924
[19:38:30.707] iteration 10400 : loss : 215.055389, loss_ce: 0.016472, loss_kd: 1072.876343
[19:38:36.348] iteration 10410 : loss : 222.880905, loss_ce: 0.015411, loss_kd: 1112.028320
[19:38:41.668] iteration 10420 : loss : 156.190887, loss_ce: 0.023784, loss_kd: 778.537781
[19:38:42.436] save model to ./debug_fixed_tpgm\continual_surgical_tpgm_stage1_epoch_9.pth
[19:38:59.676] iteration 10430 : loss : 209.665527, loss_ce: 0.022476, loss_kd: 1045.919922
[19:39:05.225] iteration 10440 : loss : 206.177368, loss_ce: 0.025393, loss_kd: 1028.488892
[19:39:10.795] iteration 10450 : loss : 207.910950, loss_ce: 0.012380, loss_kd: 1037.134766
[19:39:16.361] iteration 10460 : loss : 168.729462, loss_ce: 0.013902, loss_kd: 841.253052
[19:39:21.935] iteration 10470 : loss : 163.984589, loss_ce: 0.019820, loss_kd: 817.478149
[19:39:27.508] iteration 10480 : loss : 307.073425, loss_ce: 0.026200, loss_kd: 1532.940796
[19:39:33.089] iteration 10490 : loss : 159.039810, loss_ce: 0.022790, loss_kd: 792.801819
[19:39:38.663] iteration 10500 : loss : 171.206528, loss_ce: 0.017544, loss_kd: 853.560974
[19:39:44.249] iteration 10510 : loss : 181.213730, loss_ce: 0.026656, loss_kd: 903.649048
[19:39:49.826] iteration 10520 : loss : 166.634232, loss_ce: 0.015917, loss_kd: 830.749939
[19:39:55.413] iteration 10530 : loss : 154.113724, loss_ce: 0.012911, loss_kd: 768.156250
[19:40:01.006] iteration 10540 : loss : 173.212509, loss_ce: 0.022760, loss_kd: 863.648682
[19:40:06.611] iteration 10550 : loss : 159.246490, loss_ce: 0.025346, loss_kd: 793.827026
[19:40:12.208] iteration 10560 : loss : 165.270645, loss_ce: 0.020956, loss_kd: 823.960754
[19:40:17.817] iteration 10570 : loss : 140.329865, loss_ce: 0.023463, loss_kd: 699.288696
[19:40:23.416] iteration 10580 : loss : 156.848007, loss_ce: 0.010144, loss_kd: 781.834473
[19:40:29.024] iteration 10590 : loss : 186.358047, loss_ce: 0.012174, loss_kd: 929.399170
[19:40:34.628] iteration 10600 : loss : 153.477936, loss_ce: 0.023811, loss_kd: 764.965820
[19:40:40.240] iteration 10610 : loss : 180.394714, loss_ce: 0.030411, loss_kd: 899.583984
[19:40:45.846] iteration 10620 : loss : 149.717651, loss_ce: 0.020703, loss_kd: 746.152954
[19:40:51.473] iteration 10630 : loss : 145.295319, loss_ce: 0.027447, loss_kd: 724.064575
[19:40:57.077] iteration 10640 : loss : 186.938568, loss_ce: 0.018832, loss_kd: 932.346802
[19:41:02.712] iteration 10650 : loss : 158.450912, loss_ce: 0.016275, loss_kd: 789.796021
[19:41:08.336] iteration 10660 : loss : 136.824127, loss_ce: 0.015211, loss_kd: 681.674622
[19:41:13.954] iteration 10670 : loss : 170.741425, loss_ce: 0.015123, loss_kd: 851.257202
[19:41:19.568] iteration 10680 : loss : 219.915176, loss_ce: 0.024301, loss_kd: 1097.157349
[19:41:25.188] iteration 10690 : loss : 200.183228, loss_ce: 0.013357, loss_kd: 998.522522
[19:41:30.805] iteration 10700 : loss : 142.305267, loss_ce: 0.028063, loss_kd: 709.108765
[19:41:36.430] iteration 10710 : loss : 155.343369, loss_ce: 0.013450, loss_kd: 774.307983
[19:41:42.040] iteration 10720 : loss : 161.417191, loss_ce: 0.009910, loss_kd: 804.702148
[19:41:47.667] iteration 10730 : loss : 160.955902, loss_ce: 0.015229, loss_kd: 802.337524
[19:41:53.277] iteration 10740 : loss : 187.938766, loss_ce: 0.020719, loss_kd: 937.291870
[19:41:58.895] iteration 10750 : loss : 149.496674, loss_ce: 0.014477, loss_kd: 745.088379
[19:42:04.504] iteration 10760 : loss : 201.310318, loss_ce: 0.013805, loss_kd: 1004.166626
[19:42:10.137] iteration 10770 : loss : 279.887878, loss_ce: 0.017795, loss_kd: 1397.006348
[19:42:15.746] iteration 10780 : loss : 220.568329, loss_ce: 0.017818, loss_kd: 1100.384888
[19:42:21.355] iteration 10790 : loss : 193.055222, loss_ce: 0.012707, loss_kd: 962.846680
[19:42:26.969] iteration 10800 : loss : 159.076797, loss_ce: 0.014322, loss_kd: 792.963928
[19:42:32.605] iteration 10810 : loss : 156.224518, loss_ce: 0.010136, loss_kd: 778.688416
[19:42:38.199] iteration 10820 : loss : 158.755737, loss_ce: 0.013872, loss_kd: 791.313354
[19:42:43.819] iteration 10830 : loss : 167.099564, loss_ce: 0.021609, loss_kd: 833.117493
[19:42:49.426] iteration 10840 : loss : 200.896667, loss_ce: 0.014900, loss_kd: 1002.070801
[19:42:55.061] iteration 10850 : loss : 137.340530, loss_ce: 0.013451, loss_kd: 684.341919
[19:43:00.664] iteration 10860 : loss : 181.116791, loss_ce: 0.014139, loss_kd: 903.178894
[19:43:06.287] iteration 10870 : loss : 166.630646, loss_ce: 0.016116, loss_kd: 830.731445
[19:43:11.904] iteration 10880 : loss : 173.265488, loss_ce: 0.018322, loss_kd: 863.892090
[19:43:17.521] iteration 10890 : loss : 167.664001, loss_ce: 0.015528, loss_kd: 835.912781
[19:43:23.134] iteration 10900 : loss : 151.581696, loss_ce: 0.016959, loss_kd: 755.507080
[19:43:28.753] iteration 10910 : loss : 212.605637, loss_ce: 0.017056, loss_kd: 1060.590454
[19:43:34.367] iteration 10920 : loss : 182.322525, loss_ce: 0.015338, loss_kd: 909.206360
[19:43:39.989] iteration 10930 : loss : 122.229233, loss_ce: 0.021926, loss_kd: 608.782104
[19:43:45.609] iteration 10940 : loss : 155.771851, loss_ce: 0.017106, loss_kd: 776.417542
[19:43:51.247] iteration 10950 : loss : 150.098358, loss_ce: 0.014789, loss_kd: 748.030090
[19:43:56.866] iteration 10960 : loss : 170.677582, loss_ce: 0.015106, loss_kd: 850.934814
[19:44:02.484] iteration 10970 : loss : 176.918747, loss_ce: 0.013914, loss_kd: 882.169006
[19:44:08.111] iteration 10980 : loss : 268.684235, loss_ce: 0.011127, loss_kd: 1341.008789
[19:44:13.738] iteration 10990 : loss : 195.040009, loss_ce: 0.020073, loss_kd: 972.810608
[19:44:19.352] iteration 11000 : loss : 160.611923, loss_ce: 0.017930, loss_kd: 800.617004
[19:44:24.991] iteration 11010 : loss : 171.359375, loss_ce: 0.008249, loss_kd: 854.410034
[19:44:30.600] iteration 11020 : loss : 198.729263, loss_ce: 0.016497, loss_kd: 991.228027
[19:44:36.230] iteration 11030 : loss : 179.800323, loss_ce: 0.015406, loss_kd: 896.639160
[19:44:41.851] iteration 11040 : loss : 183.929642, loss_ce: 0.011529, loss_kd: 917.251709
[19:44:47.466] iteration 11050 : loss : 185.345078, loss_ce: 0.022496, loss_kd: 924.306763
[19:44:53.105] iteration 11060 : loss : 166.929153, loss_ce: 0.026228, loss_kd: 832.205688
[19:44:58.727] iteration 11070 : loss : 187.377029, loss_ce: 0.022658, loss_kd: 934.485840
[19:45:04.350] iteration 11080 : loss : 209.728928, loss_ce: 0.019240, loss_kd: 1046.237061
[19:45:09.994] iteration 11090 : loss : 143.646439, loss_ce: 0.022940, loss_kd: 715.832642
[19:45:15.617] iteration 11100 : loss : 167.728714, loss_ce: 0.015567, loss_kd: 836.254517
[19:45:21.251] iteration 11110 : loss : 276.658478, loss_ce: 0.012559, loss_kd: 1380.896851
[19:45:26.878] iteration 11120 : loss : 157.784607, loss_ce: 0.014819, loss_kd: 786.500793
[19:45:32.521] iteration 11130 : loss : 178.011444, loss_ce: 0.018732, loss_kd: 887.629395
[19:45:38.157] iteration 11140 : loss : 328.515594, loss_ce: 0.015254, loss_kd: 1640.189697
[19:45:43.787] iteration 11150 : loss : 232.481430, loss_ce: 0.024918, loss_kd: 1160.005859
[19:45:49.414] iteration 11160 : loss : 222.449677, loss_ce: 0.018211, loss_kd: 1109.836548
[19:45:55.053] iteration 11170 : loss : 188.176575, loss_ce: 0.020650, loss_kd: 938.462891
[19:46:00.686] iteration 11180 : loss : 169.755127, loss_ce: 0.022461, loss_kd: 846.338623
[19:46:06.327] iteration 11190 : loss : 230.534607, loss_ce: 0.022167, loss_kd: 1150.247437
[19:46:11.988] iteration 11200 : loss : 199.772888, loss_ce: 0.021523, loss_kd: 996.443970
[19:46:17.635] iteration 11210 : loss : 168.314468, loss_ce: 0.015170, loss_kd: 839.146729
[19:46:23.266] iteration 11220 : loss : 159.243515, loss_ce: 0.028877, loss_kd: 793.786255
[19:46:28.914] iteration 11230 : loss : 149.880783, loss_ce: 0.012946, loss_kd: 746.970337
[19:46:34.548] iteration 11240 : loss : 128.872238, loss_ce: 0.015746, loss_kd: 641.923584
[19:46:40.190] iteration 11250 : loss : 221.938766, loss_ce: 0.018657, loss_kd: 1107.291382
[19:46:45.815] iteration 11260 : loss : 188.651520, loss_ce: 0.013211, loss_kd: 940.900391
[19:46:51.459] iteration 11270 : loss : 150.147644, loss_ce: 0.024723, loss_kd: 748.310913
[19:46:57.084] iteration 11280 : loss : 208.414444, loss_ce: 0.016704, loss_kd: 1039.661499
[19:47:02.718] iteration 11290 : loss : 167.745728, loss_ce: 0.013776, loss_kd: 836.300293
[19:47:08.331] iteration 11300 : loss : 173.811096, loss_ce: 0.025443, loss_kd: 866.638855
[19:47:13.973] iteration 11310 : loss : 167.781036, loss_ce: 0.016846, loss_kd: 836.534546
[19:47:19.590] iteration 11320 : loss : 140.390717, loss_ce: 0.019429, loss_kd: 699.543274
[19:47:25.235] iteration 11330 : loss : 192.045364, loss_ce: 0.010383, loss_kd: 957.843140
[19:47:30.850] iteration 11340 : loss : 204.318985, loss_ce: 0.012278, loss_kd: 1019.197266
[19:47:36.474] iteration 11350 : loss : 205.700516, loss_ce: 0.011400, loss_kd: 1026.098511
[19:47:42.089] iteration 11360 : loss : 124.578537, loss_ce: 0.015959, loss_kd: 620.496765
[19:47:47.719] iteration 11370 : loss : 182.578461, loss_ce: 0.010347, loss_kd: 910.453674
[19:47:53.330] iteration 11380 : loss : 188.051666, loss_ce: 0.025240, loss_kd: 937.856750
[19:47:58.952] iteration 11390 : loss : 181.820572, loss_ce: 0.017211, loss_kd: 906.693115
[19:48:04.584] iteration 11400 : loss : 235.373764, loss_ce: 0.023634, loss_kd: 1174.431030
[19:48:10.212] iteration 11410 : loss : 160.958267, loss_ce: 0.015166, loss_kd: 802.424805
[19:48:15.851] iteration 11420 : loss : 214.147186, loss_ce: 0.017564, loss_kd: 1068.343384
[19:48:21.488] iteration 11430 : loss : 165.570587, loss_ce: 0.019631, loss_kd: 825.440308
[19:48:27.113] iteration 11440 : loss : 160.395065, loss_ce: 0.019821, loss_kd: 799.565613
[19:48:32.737] iteration 11450 : loss : 191.098816, loss_ce: 0.027807, loss_kd: 953.090332
[19:48:38.358] iteration 11460 : loss : 152.040070, loss_ce: 0.013876, loss_kd: 757.854919
[19:48:39.819] Running TPGM constraint optimization after epoch 11
[19:53:30.065] iteration 11470 : loss : 170.101074, loss_ce: 0.017900, loss_kd: 848.132507
[19:53:35.594] iteration 11480 : loss : 153.088837, loss_ce: 0.019170, loss_kd: 763.023804
[19:53:41.141] iteration 11490 : loss : 145.207413, loss_ce: 0.018315, loss_kd: 723.634094
[19:53:46.677] iteration 11500 : loss : 221.136368, loss_ce: 0.019683, loss_kd: 1103.294434
[19:53:52.232] iteration 11510 : loss : 126.727440, loss_ce: 0.017933, loss_kd: 631.221436
[19:53:57.772] iteration 11520 : loss : 226.298523, loss_ce: 0.010078, loss_kd: 1129.040405
[19:54:03.331] iteration 11530 : loss : 143.108734, loss_ce: 0.022552, loss_kd: 713.123901
[19:54:08.874] iteration 11540 : loss : 160.926239, loss_ce: 0.016354, loss_kd: 802.235535
[19:54:14.437] iteration 11550 : loss : 212.467407, loss_ce: 0.014937, loss_kd: 1059.952637
[19:54:19.999] iteration 11560 : loss : 263.510040, loss_ce: 0.012506, loss_kd: 1315.124634
[19:54:25.574] iteration 11570 : loss : 189.112473, loss_ce: 0.015396, loss_kd: 943.168152
[19:54:31.133] iteration 11580 : loss : 172.296616, loss_ce: 0.017866, loss_kd: 859.093689
[19:54:36.713] iteration 11590 : loss : 171.184784, loss_ce: 0.017296, loss_kd: 853.523560
[19:54:42.283] iteration 11600 : loss : 127.265205, loss_ce: 0.011180, loss_kd: 633.948853
[19:54:47.865] iteration 11610 : loss : 169.140976, loss_ce: 0.030995, loss_kd: 843.265259
[19:54:53.445] iteration 11620 : loss : 136.884140, loss_ce: 0.017925, loss_kd: 682.000916
[19:54:59.034] iteration 11630 : loss : 185.944168, loss_ce: 0.015043, loss_kd: 927.298157
[19:55:04.608] iteration 11640 : loss : 149.138123, loss_ce: 0.014537, loss_kd: 743.268677
[19:55:10.198] iteration 11650 : loss : 179.160965, loss_ce: 0.011483, loss_kd: 893.421997
[19:55:15.778] iteration 11660 : loss : 178.555252, loss_ce: 0.017835, loss_kd: 890.358276
[19:55:21.377] iteration 11670 : loss : 156.163055, loss_ce: 0.010473, loss_kd: 778.441101
[19:55:26.967] iteration 11680 : loss : 168.311050, loss_ce: 0.010611, loss_kd: 839.190247
[19:55:32.567] iteration 11690 : loss : 174.342300, loss_ce: 0.015902, loss_kd: 869.286194
[19:55:38.154] iteration 11700 : loss : 146.491470, loss_ce: 0.014559, loss_kd: 730.074951
[19:55:43.766] iteration 11710 : loss : 147.168777, loss_ce: 0.020865, loss_kd: 733.442261
[19:55:49.363] iteration 11720 : loss : 208.263626, loss_ce: 0.033157, loss_kd: 1038.896729
[19:55:54.965] iteration 11730 : loss : 165.615845, loss_ce: 0.013477, loss_kd: 825.684204
[19:56:00.560] iteration 11740 : loss : 168.750702, loss_ce: 0.018464, loss_kd: 841.366577
[19:56:06.167] iteration 11750 : loss : 151.908463, loss_ce: 0.029398, loss_kd: 757.149658
[19:56:11.764] iteration 11760 : loss : 123.183022, loss_ce: 0.011078, loss_kd: 613.485596
[19:56:17.363] iteration 11770 : loss : 108.083595, loss_ce: 0.021578, loss_kd: 537.998718
[19:56:22.965] iteration 11780 : loss : 179.416519, loss_ce: 0.013275, loss_kd: 894.677612
[19:56:28.577] iteration 11790 : loss : 133.045288, loss_ce: 0.014087, loss_kd: 662.837585
[19:56:34.170] iteration 11800 : loss : 147.148788, loss_ce: 0.021269, loss_kd: 733.354309
[19:56:39.783] iteration 11810 : loss : 178.013123, loss_ce: 0.024170, loss_kd: 887.637756
[19:56:45.380] iteration 11820 : loss : 144.691025, loss_ce: 0.019251, loss_kd: 721.022705
[19:56:50.999] iteration 11830 : loss : 191.794113, loss_ce: 0.018484, loss_kd: 956.544189
[19:56:56.611] iteration 11840 : loss : 182.297607, loss_ce: 0.009738, loss_kd: 909.109375
[19:57:02.226] iteration 11850 : loss : 160.969940, loss_ce: 0.016099, loss_kd: 802.450623
[19:57:07.823] iteration 11860 : loss : 162.194611, loss_ce: 0.023886, loss_kd: 808.553711
[19:57:13.440] iteration 11870 : loss : 198.327240, loss_ce: 0.018459, loss_kd: 989.224609
[19:57:19.038] iteration 11880 : loss : 162.417969, loss_ce: 0.017751, loss_kd: 809.693237
[19:57:24.646] iteration 11890 : loss : 159.005066, loss_ce: 0.013582, loss_kd: 792.660278
[19:57:30.270] iteration 11900 : loss : 156.359222, loss_ce: 0.016054, loss_kd: 779.344299
[19:57:35.885] iteration 11910 : loss : 123.388969, loss_ce: 0.010537, loss_kd: 614.563232
[19:57:41.485] iteration 11920 : loss : 169.061996, loss_ce: 0.008689, loss_kd: 842.900513
[19:57:47.103] iteration 11930 : loss : 142.423477, loss_ce: 0.013462, loss_kd: 709.667908
[19:57:52.704] iteration 11940 : loss : 200.933456, loss_ce: 0.013143, loss_kd: 1002.255676
[19:57:58.323] iteration 11950 : loss : 137.783279, loss_ce: 0.015371, loss_kd: 686.510925
[19:58:03.944] iteration 11960 : loss : 132.371735, loss_ce: 0.018333, loss_kd: 659.449097
[19:58:09.565] iteration 11970 : loss : 163.936600, loss_ce: 0.022561, loss_kd: 817.290955
[19:58:15.177] iteration 11980 : loss : 132.562424, loss_ce: 0.026154, loss_kd: 660.361633
[19:58:20.802] iteration 11990 : loss : 150.497757, loss_ce: 0.031016, loss_kd: 750.074829
[19:58:26.418] iteration 12000 : loss : 177.948166, loss_ce: 0.016224, loss_kd: 887.343201
[19:58:32.046] iteration 12010 : loss : 164.442078, loss_ce: 0.028041, loss_kd: 819.789001
[19:58:37.658] iteration 12020 : loss : 170.411224, loss_ce: 0.017164, loss_kd: 849.631531
[19:58:43.284] iteration 12030 : loss : 165.252655, loss_ce: 0.017472, loss_kd: 823.875549
[19:58:48.895] iteration 12040 : loss : 163.407639, loss_ce: 0.017301, loss_kd: 814.580872
[19:58:54.530] iteration 12050 : loss : 147.920151, loss_ce: 0.012842, loss_kd: 737.172607
[19:59:00.154] iteration 12060 : loss : 157.445526, loss_ce: 0.015100, loss_kd: 784.774658
[19:59:05.784] iteration 12070 : loss : 148.013260, loss_ce: 0.025509, loss_kd: 737.659790
[19:59:11.410] iteration 12080 : loss : 192.066956, loss_ce: 0.022579, loss_kd: 957.915283
[19:59:17.038] iteration 12090 : loss : 141.704926, loss_ce: 0.021063, loss_kd: 706.096375
[19:59:22.671] iteration 12100 : loss : 175.412231, loss_ce: 0.018296, loss_kd: 874.663818
[19:59:28.306] iteration 12110 : loss : 172.141800, loss_ce: 0.023300, loss_kd: 858.249329
[19:59:33.933] iteration 12120 : loss : 132.249573, loss_ce: 0.013608, loss_kd: 658.854065
[19:59:39.566] iteration 12130 : loss : 228.488037, loss_ce: 0.014812, loss_kd: 1140.058472
[19:59:45.196] iteration 12140 : loss : 142.185806, loss_ce: 0.023317, loss_kd: 708.531860
[19:59:50.828] iteration 12150 : loss : 130.388748, loss_ce: 0.020925, loss_kd: 649.493042
[19:59:56.455] iteration 12160 : loss : 148.303329, loss_ce: 0.023900, loss_kd: 739.098511
[20:00:02.083] iteration 12170 : loss : 181.038132, loss_ce: 0.020272, loss_kd: 902.782898
[20:00:07.702] iteration 12180 : loss : 122.657463, loss_ce: 0.014340, loss_kd: 610.859741
[20:00:13.338] iteration 12190 : loss : 173.924850, loss_ce: 0.028322, loss_kd: 867.197937
[20:00:18.957] iteration 12200 : loss : 117.546234, loss_ce: 0.025352, loss_kd: 585.331665
[20:00:24.607] iteration 12210 : loss : 181.485306, loss_ce: 0.015815, loss_kd: 905.001221
[20:00:30.230] iteration 12220 : loss : 211.090622, loss_ce: 0.007835, loss_kd: 1053.036011
[20:00:35.866] iteration 12230 : loss : 186.624802, loss_ce: 0.013982, loss_kd: 930.688110
[20:00:41.490] iteration 12240 : loss : 160.182098, loss_ce: 0.026508, loss_kd: 798.491821
[20:00:47.126] iteration 12250 : loss : 166.656219, loss_ce: 0.015645, loss_kd: 830.864807
[20:00:52.753] iteration 12260 : loss : 141.110352, loss_ce: 0.012988, loss_kd: 703.129944
[20:00:58.379] iteration 12270 : loss : 227.386230, loss_ce: 0.017132, loss_kd: 1134.507935
[20:01:04.006] iteration 12280 : loss : 155.639435, loss_ce: 0.018999, loss_kd: 775.761047
[20:01:09.630] iteration 12290 : loss : 164.464020, loss_ce: 0.020299, loss_kd: 819.900330
[20:01:15.262] iteration 12300 : loss : 219.047852, loss_ce: 0.009975, loss_kd: 1092.819702
[20:01:20.891] iteration 12310 : loss : 146.818863, loss_ce: 0.016135, loss_kd: 731.670959
[20:01:26.515] iteration 12320 : loss : 127.004135, loss_ce: 0.025502, loss_kd: 632.616577
[20:01:32.144] iteration 12330 : loss : 141.862808, loss_ce: 0.010666, loss_kd: 706.911133
[20:01:37.758] iteration 12340 : loss : 175.781067, loss_ce: 0.019356, loss_kd: 876.488831
[20:01:43.404] iteration 12350 : loss : 222.563858, loss_ce: 0.012361, loss_kd: 1110.359131
[20:01:49.042] iteration 12360 : loss : 157.610840, loss_ce: 0.018334, loss_kd: 785.657776
[20:01:54.670] iteration 12370 : loss : 163.848953, loss_ce: 0.019428, loss_kd: 816.833374
[20:02:00.287] iteration 12380 : loss : 137.982376, loss_ce: 0.012612, loss_kd: 687.518494
[20:02:05.934] iteration 12390 : loss : 135.614899, loss_ce: 0.014657, loss_kd: 675.676086
[20:02:11.583] iteration 12400 : loss : 152.531235, loss_ce: 0.019953, loss_kd: 760.242798
[20:02:17.215] iteration 12410 : loss : 161.627838, loss_ce: 0.016091, loss_kd: 805.756226
[20:02:22.835] iteration 12420 : loss : 146.789566, loss_ce: 0.012311, loss_kd: 731.547180
[20:02:28.467] iteration 12430 : loss : 155.133270, loss_ce: 0.022304, loss_kd: 773.261047
[20:02:34.082] iteration 12440 : loss : 171.821457, loss_ce: 0.026690, loss_kd: 856.713318
[20:02:39.720] iteration 12450 : loss : 192.861526, loss_ce: 0.007713, loss_kd: 961.927979
[20:02:45.343] iteration 12460 : loss : 129.243912, loss_ce: 0.011039, loss_kd: 643.787903
[20:02:50.986] iteration 12470 : loss : 193.351257, loss_ce: 0.012870, loss_kd: 964.305542
[20:02:56.607] iteration 12480 : loss : 192.964294, loss_ce: 0.019720, loss_kd: 962.368713
[20:03:02.234] iteration 12490 : loss : 139.739456, loss_ce: 0.016422, loss_kd: 696.292480
[20:03:07.863] iteration 12500 : loss : 141.323135, loss_ce: 0.014790, loss_kd: 704.223206
[20:03:25.588] iteration 12510 : loss : 166.690216, loss_ce: 0.018476, loss_kd: 831.078186
[20:03:31.138] iteration 12520 : loss : 181.476959, loss_ce: 0.022733, loss_kd: 904.965210
[20:03:36.705] iteration 12530 : loss : 141.481750, loss_ce: 0.018411, loss_kd: 704.979614
[20:03:42.266] iteration 12540 : loss : 148.517471, loss_ce: 0.012188, loss_kd: 740.185120
[20:03:47.845] iteration 12550 : loss : 154.470734, loss_ce: 0.018653, loss_kd: 769.964478
[20:03:53.424] iteration 12560 : loss : 152.386124, loss_ce: 0.020642, loss_kd: 759.536255
[20:03:59.013] iteration 12570 : loss : 145.325363, loss_ce: 0.013986, loss_kd: 724.209961
[20:04:04.597] iteration 12580 : loss : 138.629410, loss_ce: 0.016895, loss_kd: 690.712891
[20:04:10.199] iteration 12590 : loss : 165.898041, loss_ce: 0.014575, loss_kd: 827.132202
[20:04:15.796] iteration 12600 : loss : 107.566078, loss_ce: 0.025721, loss_kd: 535.425903
[20:04:21.394] iteration 12610 : loss : 126.193802, loss_ce: 0.023240, loss_kd: 628.572205
[20:04:26.991] iteration 12620 : loss : 170.533264, loss_ce: 0.017089, loss_kd: 850.238403
[20:04:32.594] iteration 12630 : loss : 161.423874, loss_ce: 0.024440, loss_kd: 804.730530
[20:04:38.192] iteration 12640 : loss : 108.532112, loss_ce: 0.016675, loss_kd: 540.266968
[20:04:43.807] iteration 12650 : loss : 144.007858, loss_ce: 0.008257, loss_kd: 717.643372
[20:04:49.403] iteration 12660 : loss : 150.089752, loss_ce: 0.014225, loss_kd: 748.044128
[20:04:55.016] iteration 12670 : loss : 158.111465, loss_ce: 0.013955, loss_kd: 788.185303
[20:05:00.620] iteration 12680 : loss : 203.919586, loss_ce: 0.017452, loss_kd: 1017.151611
[20:05:06.223] iteration 12690 : loss : 123.991882, loss_ce: 0.018953, loss_kd: 617.527283
[20:05:11.846] iteration 12700 : loss : 223.587494, loss_ce: 0.017162, loss_kd: 1115.524414
[20:05:17.463] iteration 12710 : loss : 117.078514, loss_ce: 0.016638, loss_kd: 582.994385
[20:05:23.066] iteration 12720 : loss : 192.979141, loss_ce: 0.020941, loss_kd: 962.527832
[20:05:28.678] iteration 12730 : loss : 149.628525, loss_ce: 0.017596, loss_kd: 745.781738
[20:05:34.290] iteration 12740 : loss : 159.555115, loss_ce: 0.015173, loss_kd: 795.382019
[20:05:39.915] iteration 12750 : loss : 178.573227, loss_ce: 0.014104, loss_kd: 890.498352
[20:05:45.534] iteration 12760 : loss : 162.450531, loss_ce: 0.015182, loss_kd: 809.856628
[20:05:51.161] iteration 12770 : loss : 138.724945, loss_ce: 0.013856, loss_kd: 691.246704
[20:05:56.780] iteration 12780 : loss : 135.942703, loss_ce: 0.018572, loss_kd: 677.292847
[20:06:02.397] iteration 12790 : loss : 118.483116, loss_ce: 0.020777, loss_kd: 589.999023
[20:06:08.000] iteration 12800 : loss : 176.845535, loss_ce: 0.015578, loss_kd: 881.831177
[20:06:13.621] iteration 12810 : loss : 178.217590, loss_ce: 0.015864, loss_kd: 888.670959
[20:06:19.243] iteration 12820 : loss : 166.502792, loss_ce: 0.015310, loss_kd: 830.085083
[20:06:24.872] iteration 12830 : loss : 163.372543, loss_ce: 0.018925, loss_kd: 814.453674
[20:06:30.496] iteration 12840 : loss : 119.523087, loss_ce: 0.020943, loss_kd: 595.177490
[20:06:36.119] iteration 12850 : loss : 163.588135, loss_ce: 0.021199, loss_kd: 815.514709
[20:06:41.735] iteration 12860 : loss : 127.006699, loss_ce: 0.015542, loss_kd: 632.652954
[20:06:47.373] iteration 12870 : loss : 202.840851, loss_ce: 0.014649, loss_kd: 1011.795776
[20:06:52.994] iteration 12880 : loss : 155.308502, loss_ce: 0.018405, loss_kd: 774.131714
[20:06:58.613] iteration 12890 : loss : 164.078125, loss_ce: 0.011815, loss_kd: 817.977295
[20:07:04.237] iteration 12900 : loss : 161.672897, loss_ce: 0.015682, loss_kd: 805.944519
[20:07:09.865] iteration 12910 : loss : 121.893616, loss_ce: 0.035667, loss_kd: 607.013672
[20:07:15.472] iteration 12920 : loss : 147.605118, loss_ce: 0.016963, loss_kd: 735.608704
[20:07:21.114] iteration 12930 : loss : 124.525482, loss_ce: 0.022076, loss_kd: 620.242798
[20:07:26.733] iteration 12940 : loss : 156.251419, loss_ce: 0.014027, loss_kd: 778.833130
[20:07:32.371] iteration 12950 : loss : 160.844009, loss_ce: 0.021830, loss_kd: 801.810181
[20:07:37.993] iteration 12960 : loss : 183.992325, loss_ce: 0.013215, loss_kd: 917.563843
[20:07:43.639] iteration 12970 : loss : 172.061996, loss_ce: 0.022217, loss_kd: 857.851318
[20:07:49.257] iteration 12980 : loss : 162.324020, loss_ce: 0.015428, loss_kd: 809.258301
[20:07:54.889] iteration 12990 : loss : 148.316589, loss_ce: 0.021634, loss_kd: 739.170715
[20:08:00.510] iteration 13000 : loss : 140.033768, loss_ce: 0.015917, loss_kd: 697.754395
[20:08:06.144] iteration 13010 : loss : 155.528976, loss_ce: 0.015669, loss_kd: 775.257324
[20:08:11.774] iteration 13020 : loss : 190.768875, loss_ce: 0.017370, loss_kd: 951.438660
[20:08:17.402] iteration 13030 : loss : 117.077316, loss_ce: 0.018934, loss_kd: 582.945312
[20:08:23.038] iteration 13040 : loss : 140.429337, loss_ce: 0.022092, loss_kd: 699.773621
[20:08:28.674] iteration 13050 : loss : 174.384338, loss_ce: 0.019590, loss_kd: 869.528076
[20:08:34.299] iteration 13060 : loss : 157.570343, loss_ce: 0.018585, loss_kd: 785.380737
[20:08:39.925] iteration 13070 : loss : 172.438187, loss_ce: 0.015815, loss_kd: 859.770508
[20:08:45.550] iteration 13080 : loss : 131.425873, loss_ce: 0.017304, loss_kd: 654.729980
[20:08:51.179] iteration 13090 : loss : 135.810745, loss_ce: 0.017235, loss_kd: 676.648560
[20:08:56.795] iteration 13100 : loss : 194.069916, loss_ce: 0.014768, loss_kd: 967.920105
[20:09:02.441] iteration 13110 : loss : 137.219193, loss_ce: 0.012399, loss_kd: 683.704346
[20:09:08.068] iteration 13120 : loss : 166.484589, loss_ce: 0.014516, loss_kd: 830.001099
[20:09:13.704] iteration 13130 : loss : 171.860931, loss_ce: 0.015579, loss_kd: 856.907593
[20:09:19.327] iteration 13140 : loss : 167.295410, loss_ce: 0.010080, loss_kd: 834.089661
[20:09:24.946] iteration 13150 : loss : 195.422577, loss_ce: 0.019393, loss_kd: 974.686035
[20:09:30.576] iteration 13160 : loss : 217.416641, loss_ce: 0.018118, loss_kd: 1084.646729
[20:09:36.209] iteration 13170 : loss : 153.896698, loss_ce: 0.025131, loss_kd: 767.076660
[20:09:41.836] iteration 13180 : loss : 155.196259, loss_ce: 0.017859, loss_kd: 773.582031
[20:09:47.471] iteration 13190 : loss : 180.761948, loss_ce: 0.022208, loss_kd: 901.347046
[20:09:53.105] iteration 13200 : loss : 155.284607, loss_ce: 0.014429, loss_kd: 774.001160
[20:09:58.743] iteration 13210 : loss : 167.080688, loss_ce: 0.019821, loss_kd: 833.006592
[20:10:04.370] iteration 13220 : loss : 162.284302, loss_ce: 0.012401, loss_kd: 809.023071
[20:10:10.007] iteration 13230 : loss : 158.607849, loss_ce: 0.023434, loss_kd: 790.603271
[20:10:15.634] iteration 13240 : loss : 163.866409, loss_ce: 0.014609, loss_kd: 816.953735
[20:10:21.258] iteration 13250 : loss : 111.969460, loss_ce: 0.020342, loss_kd: 557.428528
[20:10:26.891] iteration 13260 : loss : 169.194107, loss_ce: 0.021746, loss_kd: 843.528625
[20:10:32.568] iteration 13270 : loss : 193.902069, loss_ce: 0.014015, loss_kd: 967.113464
[20:10:38.185] iteration 13280 : loss : 150.866928, loss_ce: 0.011865, loss_kd: 751.900940
[20:10:43.803] iteration 13290 : loss : 135.442062, loss_ce: 0.012289, loss_kd: 674.814331
[20:10:49.427] iteration 13300 : loss : 125.917870, loss_ce: 0.013080, loss_kd: 627.187683
[20:10:55.067] iteration 13310 : loss : 138.469070, loss_ce: 0.017376, loss_kd: 689.935486
[20:11:00.680] iteration 13320 : loss : 153.691650, loss_ce: 0.019434, loss_kd: 766.060364
[20:11:06.320] iteration 13330 : loss : 145.680328, loss_ce: 0.020035, loss_kd: 726.021973
[20:11:11.947] iteration 13340 : loss : 159.126831, loss_ce: 0.019837, loss_kd: 793.197571
[20:11:17.578] iteration 13350 : loss : 166.531830, loss_ce: 0.016206, loss_kd: 830.261597
[20:11:23.194] iteration 13360 : loss : 139.732407, loss_ce: 0.015509, loss_kd: 696.248718
[20:11:28.840] iteration 13370 : loss : 155.517349, loss_ce: 0.012089, loss_kd: 775.179565
[20:11:34.455] iteration 13380 : loss : 117.633858, loss_ce: 0.024222, loss_kd: 585.732910
[20:11:40.088] iteration 13390 : loss : 163.616943, loss_ce: 0.010177, loss_kd: 815.706970
[20:11:45.710] iteration 13400 : loss : 150.994690, loss_ce: 0.011356, loss_kd: 752.586304
[20:11:51.360] iteration 13410 : loss : 146.115768, loss_ce: 0.014221, loss_kd: 728.180420
[20:11:56.985] iteration 13420 : loss : 178.754623, loss_ce: 0.024679, loss_kd: 891.348328
[20:12:02.620] iteration 13430 : loss : 142.183487, loss_ce: 0.014559, loss_kd: 708.523193
[20:12:08.241] iteration 13440 : loss : 209.204041, loss_ce: 0.014559, loss_kd: 1043.600342
[20:12:13.882] iteration 13450 : loss : 152.783157, loss_ce: 0.021857, loss_kd: 761.538147
[20:12:19.505] iteration 13460 : loss : 126.204758, loss_ce: 0.014364, loss_kd: 628.617249
[20:12:25.146] iteration 13470 : loss : 176.632767, loss_ce: 0.012666, loss_kd: 880.767090
[20:12:30.780] iteration 13480 : loss : 197.031693, loss_ce: 0.015710, loss_kd: 982.764404
[20:12:36.413] iteration 13490 : loss : 190.429474, loss_ce: 0.015930, loss_kd: 949.746704
[20:12:42.042] iteration 13500 : loss : 165.776718, loss_ce: 0.013612, loss_kd: 826.450806
[20:12:47.671] iteration 13510 : loss : 265.728302, loss_ce: 0.016015, loss_kd: 1326.228271
[20:12:53.306] iteration 13520 : loss : 199.571014, loss_ce: 0.014083, loss_kd: 995.425903
[20:12:58.933] iteration 13530 : loss : 168.176392, loss_ce: 0.024417, loss_kd: 838.461060
[20:13:04.570] iteration 13540 : loss : 127.193420, loss_ce: 0.016024, loss_kd: 633.556396
[20:13:08.355] Running TPGM constraint optimization after epoch 13
[20:18:13.038] iteration 13550 : loss : 123.741783, loss_ce: 0.013723, loss_kd: 616.268860
[20:18:18.571] iteration 13560 : loss : 170.046646, loss_ce: 0.009675, loss_kd: 847.836670
[20:18:24.123] iteration 13570 : loss : 163.353745, loss_ce: 0.015936, loss_kd: 814.384277
[20:18:29.659] iteration 13580 : loss : 157.284409, loss_ce: 0.026852, loss_kd: 784.024292
[20:18:35.209] iteration 13590 : loss : 110.498962, loss_ce: 0.016136, loss_kd: 550.108521
[20:18:40.758] iteration 13600 : loss : 162.499725, loss_ce: 0.013680, loss_kd: 810.117554
[20:18:46.325] iteration 13610 : loss : 161.569977, loss_ce: 0.014139, loss_kd: 805.408691
[20:18:51.871] iteration 13620 : loss : 139.499283, loss_ce: 0.010160, loss_kd: 695.068481
[20:18:57.433] iteration 13630 : loss : 173.370132, loss_ce: 0.026770, loss_kd: 864.385254
[20:19:02.994] iteration 13640 : loss : 185.610992, loss_ce: 0.011797, loss_kd: 925.649109
[20:19:08.567] iteration 13650 : loss : 183.874374, loss_ce: 0.019494, loss_kd: 916.969604
[20:19:14.123] iteration 13660 : loss : 200.237030, loss_ce: 0.018784, loss_kd: 998.796631
[20:19:19.694] iteration 13670 : loss : 252.056290, loss_ce: 0.012507, loss_kd: 1257.877075
[20:19:25.259] iteration 13680 : loss : 115.875420, loss_ce: 0.020159, loss_kd: 576.949951
[20:19:30.843] iteration 13690 : loss : 140.732620, loss_ce: 0.009859, loss_kd: 701.247375
[20:19:36.429] iteration 13700 : loss : 151.042694, loss_ce: 0.016484, loss_kd: 752.790527
[20:19:42.025] iteration 13710 : loss : 150.934174, loss_ce: 0.017949, loss_kd: 752.285950
[20:19:47.606] iteration 13720 : loss : 131.706177, loss_ce: 0.020186, loss_kd: 656.101746
[20:19:53.207] iteration 13730 : loss : 173.937546, loss_ce: 0.023874, loss_kd: 867.300781
[20:19:58.789] iteration 13740 : loss : 145.751892, loss_ce: 0.017588, loss_kd: 726.341064
[20:20:04.389] iteration 13750 : loss : 150.808594, loss_ce: 0.016676, loss_kd: 751.634094
[20:20:09.969] iteration 13760 : loss : 177.936432, loss_ce: 0.016251, loss_kd: 887.285767
[20:20:15.560] iteration 13770 : loss : 156.493164, loss_ce: 0.019769, loss_kd: 780.078674
[20:20:21.154] iteration 13780 : loss : 127.329514, loss_ce: 0.016228, loss_kd: 634.230896
[20:20:26.760] iteration 13790 : loss : 151.598816, loss_ce: 0.017218, loss_kd: 755.583252
[20:20:32.359] iteration 13800 : loss : 138.935745, loss_ce: 0.020095, loss_kd: 692.235779
[20:20:37.969] iteration 13810 : loss : 156.471237, loss_ce: 0.011738, loss_kd: 779.958252
[20:20:43.558] iteration 13820 : loss : 156.086090, loss_ce: 0.017183, loss_kd: 777.972900
[20:20:49.171] iteration 13830 : loss : 174.524658, loss_ce: 0.013688, loss_kd: 870.233215
[20:20:54.770] iteration 13840 : loss : 161.993759, loss_ce: 0.008252, loss_kd: 807.576294
[20:21:00.375] iteration 13850 : loss : 145.276917, loss_ce: 0.026614, loss_kd: 723.933228
[20:21:05.971] iteration 13860 : loss : 132.573959, loss_ce: 0.019551, loss_kd: 660.417603
[20:21:11.581] iteration 13870 : loss : 141.043320, loss_ce: 0.020755, loss_kd: 702.813843
[20:21:17.180] iteration 13880 : loss : 170.741821, loss_ce: 0.011662, loss_kd: 851.289673
[20:21:22.800] iteration 13890 : loss : 134.099442, loss_ce: 0.022208, loss_kd: 668.073792
[20:21:28.437] iteration 13900 : loss : 186.821320, loss_ce: 0.014264, loss_kd: 931.710876
[20:21:34.061] iteration 13910 : loss : 188.655457, loss_ce: 0.014876, loss_kd: 940.880981
[20:21:39.668] iteration 13920 : loss : 164.434006, loss_ce: 0.006991, loss_kd: 819.728271
[20:21:45.280] iteration 13930 : loss : 177.400986, loss_ce: 0.025680, loss_kd: 884.592834
[20:21:50.885] iteration 13940 : loss : 175.365463, loss_ce: 0.013993, loss_kd: 874.459534
[20:21:56.513] iteration 13950 : loss : 276.474579, loss_ce: 0.011963, loss_kd: 1379.979004
[20:22:02.130] iteration 13960 : loss : 214.609283, loss_ce: 0.019323, loss_kd: 1070.631714
[20:22:07.756] iteration 13970 : loss : 143.313446, loss_ce: 0.015940, loss_kd: 714.162842
[20:22:13.374] iteration 13980 : loss : 205.889206, loss_ce: 0.018014, loss_kd: 1027.039185
[20:22:19.007] iteration 13990 : loss : 164.894302, loss_ce: 0.014474, loss_kd: 822.073120
[20:22:24.606] iteration 14000 : loss : 129.622955, loss_ce: 0.026465, loss_kd: 645.710388
[20:22:30.230] iteration 14010 : loss : 137.835815, loss_ce: 0.014234, loss_kd: 686.812256
[20:22:35.847] iteration 14020 : loss : 133.651260, loss_ce: 0.013368, loss_kd: 665.858032
[20:22:41.477] iteration 14030 : loss : 169.194839, loss_ce: 0.013944, loss_kd: 843.542419
[20:22:47.072] iteration 14040 : loss : 179.679886, loss_ce: 0.011142, loss_kd: 896.017273
[20:22:52.688] iteration 14050 : loss : 166.160919, loss_ce: 0.018292, loss_kd: 828.386780
[20:22:58.304] iteration 14060 : loss : 100.790489, loss_ce: 0.011574, loss_kd: 501.585175
[20:23:03.924] iteration 14070 : loss : 124.809769, loss_ce: 0.021272, loss_kd: 621.499939
[20:23:09.529] iteration 14080 : loss : 127.000992, loss_ce: 0.017196, loss_kd: 632.569458
[20:23:15.139] iteration 14090 : loss : 200.697433, loss_ce: 0.011082, loss_kd: 1001.058167
[20:23:20.734] iteration 14100 : loss : 123.899933, loss_ce: 0.021104, loss_kd: 617.098572
[20:23:26.345] iteration 14110 : loss : 155.635376, loss_ce: 0.015723, loss_kd: 775.764282
[20:23:31.945] iteration 14120 : loss : 198.115601, loss_ce: 0.009514, loss_kd: 988.178894
[20:23:37.565] iteration 14130 : loss : 146.802597, loss_ce: 0.018005, loss_kd: 731.638367
[20:23:43.194] iteration 14140 : loss : 158.920471, loss_ce: 0.012282, loss_kd: 792.210449
[20:23:48.822] iteration 14150 : loss : 112.166389, loss_ce: 0.014431, loss_kd: 558.472900
[20:23:54.434] iteration 14160 : loss : 120.113945, loss_ce: 0.018787, loss_kd: 598.173584
[20:24:00.054] iteration 14170 : loss : 118.187126, loss_ce: 0.016904, loss_kd: 588.548218
[20:24:05.666] iteration 14180 : loss : 141.127213, loss_ce: 0.016286, loss_kd: 703.250427
[20:24:11.289] iteration 14190 : loss : 164.303238, loss_ce: 0.021230, loss_kd: 819.106079
[20:24:16.901] iteration 14200 : loss : 134.655182, loss_ce: 0.014256, loss_kd: 670.898804
[20:24:22.528] iteration 14210 : loss : 132.944611, loss_ce: 0.013743, loss_kd: 662.335449
[20:24:28.131] iteration 14220 : loss : 138.376022, loss_ce: 0.013750, loss_kd: 689.444458
[20:24:33.745] iteration 14230 : loss : 121.161171, loss_ce: 0.013645, loss_kd: 603.397644
[20:24:39.362] iteration 14240 : loss : 177.058746, loss_ce: 0.015385, loss_kd: 882.904724
[20:24:44.993] iteration 14250 : loss : 128.961319, loss_ce: 0.017349, loss_kd: 642.378723
[20:24:50.604] iteration 14260 : loss : 143.715927, loss_ce: 0.020543, loss_kd: 716.154968
[20:24:56.238] iteration 14270 : loss : 157.902222, loss_ce: 0.015513, loss_kd: 787.109253
[20:25:01.856] iteration 14280 : loss : 177.616562, loss_ce: 0.021253, loss_kd: 885.682373
[20:25:07.491] iteration 14290 : loss : 155.317154, loss_ce: 0.014368, loss_kd: 774.187256
[20:25:13.114] iteration 14300 : loss : 161.354385, loss_ce: 0.020065, loss_kd: 804.389709
[20:25:18.741] iteration 14310 : loss : 163.490005, loss_ce: 0.012078, loss_kd: 815.055481
[20:25:24.351] iteration 14320 : loss : 161.952332, loss_ce: 0.017504, loss_kd: 807.361267
[20:25:29.981] iteration 14330 : loss : 144.164322, loss_ce: 0.008596, loss_kd: 718.432251
[20:25:35.603] iteration 14340 : loss : 166.539337, loss_ce: 0.008106, loss_kd: 830.342346
[20:25:41.225] iteration 14350 : loss : 141.931274, loss_ce: 0.015497, loss_kd: 707.280029
[20:25:46.848] iteration 14360 : loss : 148.953873, loss_ce: 0.010802, loss_kd: 742.328064
[20:25:52.484] iteration 14370 : loss : 127.947189, loss_ce: 0.016911, loss_kd: 637.335327
[20:25:58.111] iteration 14380 : loss : 186.121475, loss_ce: 0.010328, loss_kd: 928.210083
[20:26:03.743] iteration 14390 : loss : 136.333450, loss_ce: 0.023395, loss_kd: 679.253967
[20:26:09.376] iteration 14400 : loss : 128.886169, loss_ce: 0.010693, loss_kd: 642.042480
[20:26:15.002] iteration 14410 : loss : 142.671158, loss_ce: 0.016566, loss_kd: 710.966370
[20:26:20.610] iteration 14420 : loss : 145.123795, loss_ce: 0.017093, loss_kd: 723.202271
[20:26:26.241] iteration 14430 : loss : 143.249939, loss_ce: 0.027335, loss_kd: 713.833923
[20:26:31.857] iteration 14440 : loss : 152.141357, loss_ce: 0.012981, loss_kd: 758.300415
[20:26:37.470] iteration 14450 : loss : 167.065628, loss_ce: 0.010386, loss_kd: 832.957886
[20:26:43.086] iteration 14460 : loss : 145.804337, loss_ce: 0.017205, loss_kd: 726.624756
[20:26:48.703] iteration 14470 : loss : 125.009583, loss_ce: 0.016582, loss_kd: 622.650757
[20:26:54.319] iteration 14480 : loss : 174.025284, loss_ce: 0.022980, loss_kd: 867.680298
[20:26:59.935] iteration 14490 : loss : 169.329895, loss_ce: 0.017225, loss_kd: 844.230347
[20:27:05.547] iteration 14500 : loss : 168.863846, loss_ce: 0.022235, loss_kd: 841.920227
[20:27:11.172] iteration 14510 : loss : 140.498550, loss_ce: 0.014654, loss_kd: 700.100342
[20:27:16.781] iteration 14520 : loss : 229.918839, loss_ce: 0.018018, loss_kd: 1147.201538
[20:27:22.400] iteration 14530 : loss : 152.258759, loss_ce: 0.014217, loss_kd: 758.859619
[20:27:28.018] iteration 14540 : loss : 129.547882, loss_ce: 0.019507, loss_kd: 645.333191
[20:27:33.641] iteration 14550 : loss : 150.249161, loss_ce: 0.015097, loss_kd: 748.799683
[20:27:39.250] iteration 14560 : loss : 156.605316, loss_ce: 0.018567, loss_kd: 780.626953
[20:27:44.876] iteration 14570 : loss : 133.230026, loss_ce: 0.013898, loss_kd: 663.758667
[20:27:50.493] iteration 14580 : loss : 159.662994, loss_ce: 0.024177, loss_kd: 795.878723
[20:28:07.944] iteration 14590 : loss : 129.669479, loss_ce: 0.020507, loss_kd: 645.957153
[20:28:13.491] iteration 14600 : loss : 194.039688, loss_ce: 0.016477, loss_kd: 967.807068
[20:28:19.052] iteration 14610 : loss : 160.618805, loss_ce: 0.015310, loss_kd: 800.665649
[20:28:24.614] iteration 14620 : loss : 181.001068, loss_ce: 0.025961, loss_kd: 902.556946
[20:28:30.181] iteration 14630 : loss : 126.293747, loss_ce: 0.015326, loss_kd: 629.093445
[20:28:35.751] iteration 14640 : loss : 208.831451, loss_ce: 0.024618, loss_kd: 1041.736450
[20:28:41.328] iteration 14650 : loss : 113.626816, loss_ce: 0.016813, loss_kd: 565.720459
[20:28:46.896] iteration 14660 : loss : 129.871338, loss_ce: 0.018487, loss_kd: 646.974426
[20:28:52.479] iteration 14670 : loss : 105.194870, loss_ce: 0.016334, loss_kd: 523.575317
[20:28:58.046] iteration 14680 : loss : 123.623878, loss_ce: 0.016231, loss_kd: 615.671204
[20:29:03.634] iteration 14690 : loss : 148.852295, loss_ce: 0.020426, loss_kd: 741.843689
[20:29:09.215] iteration 14700 : loss : 169.850723, loss_ce: 0.033542, loss_kd: 846.826416
[20:29:14.811] iteration 14710 : loss : 121.751678, loss_ce: 0.015589, loss_kd: 606.372253
[20:29:20.404] iteration 14720 : loss : 188.289978, loss_ce: 0.014245, loss_kd: 939.073242
[20:29:26.011] iteration 14730 : loss : 154.607758, loss_ce: 0.019626, loss_kd: 770.624878
[20:29:31.606] iteration 14740 : loss : 151.960770, loss_ce: 0.022385, loss_kd: 757.412170
[20:29:37.210] iteration 14750 : loss : 142.779861, loss_ce: 0.025499, loss_kd: 711.502563
[20:29:42.808] iteration 14760 : loss : 150.616104, loss_ce: 0.015124, loss_kd: 750.709534
[20:29:48.406] iteration 14770 : loss : 163.607971, loss_ce: 0.017705, loss_kd: 815.623047
[20:29:54.002] iteration 14780 : loss : 156.184937, loss_ce: 0.018409, loss_kd: 778.554077
[20:29:59.605] iteration 14790 : loss : 122.721756, loss_ce: 0.023154, loss_kd: 611.214355
[20:30:05.207] iteration 14800 : loss : 144.347687, loss_ce: 0.015757, loss_kd: 719.356262
[20:30:10.809] iteration 14810 : loss : 157.653503, loss_ce: 0.014947, loss_kd: 785.849304
[20:30:16.406] iteration 14820 : loss : 175.921555, loss_ce: 0.014890, loss_kd: 877.196960
[20:30:22.017] iteration 14830 : loss : 159.433975, loss_ce: 0.021385, loss_kd: 794.748535
[20:30:27.627] iteration 14840 : loss : 137.222366, loss_ce: 0.008549, loss_kd: 683.724731
[20:30:33.247] iteration 14850 : loss : 141.811401, loss_ce: 0.012930, loss_kd: 706.616028
[20:30:38.861] iteration 14860 : loss : 139.661896, loss_ce: 0.017698, loss_kd: 695.889771
[20:30:44.477] iteration 14870 : loss : 145.631851, loss_ce: 0.014579, loss_kd: 725.768555
[20:30:50.087] iteration 14880 : loss : 119.611740, loss_ce: 0.024250, loss_kd: 595.637512
[20:30:55.714] iteration 14890 : loss : 175.314499, loss_ce: 0.008492, loss_kd: 874.195923
[20:31:01.320] iteration 14900 : loss : 142.546875, loss_ce: 0.031418, loss_kd: 710.303040
[20:31:06.942] iteration 14910 : loss : 152.755219, loss_ce: 0.011019, loss_kd: 761.351562
[20:31:12.545] iteration 14920 : loss : 121.374435, loss_ce: 0.015632, loss_kd: 604.470581
[20:31:18.174] iteration 14930 : loss : 186.505463, loss_ce: 0.018303, loss_kd: 930.122437
[20:31:23.794] iteration 14940 : loss : 161.566299, loss_ce: 0.020028, loss_kd: 805.434509
[20:31:29.410] iteration 14950 : loss : 157.465942, loss_ce: 0.022457, loss_kd: 784.930420
[20:31:35.015] iteration 14960 : loss : 158.066833, loss_ce: 0.013588, loss_kd: 787.921021
[20:31:40.648] iteration 14970 : loss : 128.852890, loss_ce: 0.022037, loss_kd: 641.843384
[20:31:46.258] iteration 14980 : loss : 150.038834, loss_ce: 0.020014, loss_kd: 747.780945
[20:31:51.881] iteration 14990 : loss : 140.357346, loss_ce: 0.014632, loss_kd: 699.388428
[20:31:57.511] iteration 15000 : loss : 155.556824, loss_ce: 0.012871, loss_kd: 775.338501
[20:32:03.132] iteration 15010 : loss : 141.164337, loss_ce: 0.013006, loss_kd: 703.444031
[20:32:08.766] iteration 15020 : loss : 129.656006, loss_ce: 0.017364, loss_kd: 645.846680
[20:32:14.392] iteration 15030 : loss : 173.454025, loss_ce: 0.014087, loss_kd: 864.871277
[20:32:19.999] iteration 15040 : loss : 166.260941, loss_ce: 0.026386, loss_kd: 828.902649
[20:32:25.650] iteration 15050 : loss : 150.746231, loss_ce: 0.014155, loss_kd: 751.340942
[20:32:31.266] iteration 15060 : loss : 170.044189, loss_ce: 0.021067, loss_kd: 847.791443
[20:32:36.916] iteration 15070 : loss : 139.977264, loss_ce: 0.021035, loss_kd: 697.492981
[20:32:42.528] iteration 15080 : loss : 131.448456, loss_ce: 0.024925, loss_kd: 654.825623
[20:32:48.153] iteration 15090 : loss : 143.002792, loss_ce: 0.014632, loss_kd: 712.617859
[20:32:53.783] iteration 15100 : loss : 155.999130, loss_ce: 0.020337, loss_kd: 777.634277
[20:32:59.408] iteration 15110 : loss : 150.654892, loss_ce: 0.015286, loss_kd: 750.897034
[20:33:05.018] iteration 15120 : loss : 143.863602, loss_ce: 0.011226, loss_kd: 716.944641
[20:33:10.656] iteration 15130 : loss : 145.858032, loss_ce: 0.017135, loss_kd: 726.887512
[20:33:16.263] iteration 15140 : loss : 125.038246, loss_ce: 0.010594, loss_kd: 622.762695
[20:33:21.920] iteration 15150 : loss : 134.858124, loss_ce: 0.019266, loss_kd: 671.873657
[20:33:27.538] iteration 15160 : loss : 131.188553, loss_ce: 0.013906, loss_kd: 653.542603
[20:33:33.173] iteration 15170 : loss : 133.957916, loss_ce: 0.024603, loss_kd: 667.380127
[20:33:38.789] iteration 15180 : loss : 156.174774, loss_ce: 0.025560, loss_kd: 778.486755
[20:33:44.413] iteration 15190 : loss : 154.692871, loss_ce: 0.017018, loss_kd: 771.055420
[20:33:50.033] iteration 15200 : loss : 144.659180, loss_ce: 0.011117, loss_kd: 720.899231
[20:33:55.663] iteration 15210 : loss : 130.376251, loss_ce: 0.021440, loss_kd: 649.507080
[20:34:01.275] iteration 15220 : loss : 176.922363, loss_ce: 0.026071, loss_kd: 882.219666
[20:34:06.909] iteration 15230 : loss : 130.680573, loss_ce: 0.012547, loss_kd: 650.956482
[20:34:12.519] iteration 15240 : loss : 120.255287, loss_ce: 0.012074, loss_kd: 598.898560
[20:34:18.134] iteration 15250 : loss : 177.493622, loss_ce: 0.012793, loss_kd: 885.088928
[20:34:23.741] iteration 15260 : loss : 152.960434, loss_ce: 0.013121, loss_kd: 762.394714
[20:34:29.377] iteration 15270 : loss : 170.183655, loss_ce: 0.013588, loss_kd: 848.543945
[20:34:34.997] iteration 15280 : loss : 158.060013, loss_ce: 0.021332, loss_kd: 787.891968
[20:34:40.634] iteration 15290 : loss : 113.104004, loss_ce: 0.019798, loss_kd: 563.119385
[20:34:46.262] iteration 15300 : loss : 142.732910, loss_ce: 0.018979, loss_kd: 711.269043
[20:34:51.888] iteration 15310 : loss : 133.592758, loss_ce: 0.019271, loss_kd: 665.578491
[20:34:57.512] iteration 15320 : loss : 157.979965, loss_ce: 0.020436, loss_kd: 787.458801
[20:35:03.131] iteration 15330 : loss : 137.484146, loss_ce: 0.024044, loss_kd: 685.040222
[20:35:08.742] iteration 15340 : loss : 122.506454, loss_ce: 0.022912, loss_kd: 610.112000
[20:35:14.382] iteration 15350 : loss : 128.604324, loss_ce: 0.013698, loss_kd: 640.664490
[20:35:19.996] iteration 15360 : loss : 162.355057, loss_ce: 0.013616, loss_kd: 809.409790
[20:35:25.640] iteration 15370 : loss : 158.003693, loss_ce: 0.017373, loss_kd: 787.623901
[20:35:31.249] iteration 15380 : loss : 124.288574, loss_ce: 0.013435, loss_kd: 619.044373
[20:35:36.865] iteration 15390 : loss : 161.962097, loss_ce: 0.014621, loss_kd: 807.379517
[20:35:42.491] iteration 15400 : loss : 174.125351, loss_ce: 0.014766, loss_kd: 868.181396
[20:35:48.118] iteration 15410 : loss : 109.520500, loss_ce: 0.020291, loss_kd: 545.227234
[20:35:53.733] iteration 15420 : loss : 103.896065, loss_ce: 0.010861, loss_kd: 517.095764
[20:35:59.365] iteration 15430 : loss : 119.083305, loss_ce: 0.019036, loss_kd: 592.995361
[20:36:04.979] iteration 15440 : loss : 134.038101, loss_ce: 0.016707, loss_kd: 667.781433
[20:36:10.604] iteration 15450 : loss : 131.562393, loss_ce: 0.023588, loss_kd: 655.409058
[20:36:16.225] iteration 15460 : loss : 140.725723, loss_ce: 0.016509, loss_kd: 701.221130
[20:36:21.847] iteration 15470 : loss : 159.593048, loss_ce: 0.029857, loss_kd: 795.558716
[20:36:27.457] iteration 15480 : loss : 128.092102, loss_ce: 0.015103, loss_kd: 638.083130
[20:36:33.095] iteration 15490 : loss : 153.763199, loss_ce: 0.016691, loss_kd: 766.391357
[20:36:38.709] iteration 15500 : loss : 194.847839, loss_ce: 0.027553, loss_kd: 971.813477
[20:36:44.336] iteration 15510 : loss : 170.594223, loss_ce: 0.009120, loss_kd: 850.592651
[20:36:49.962] iteration 15520 : loss : 100.780525, loss_ce: 0.015281, loss_kd: 501.517700
[20:36:55.576] iteration 15530 : loss : 108.705040, loss_ce: 0.014881, loss_kd: 541.090332
[20:37:01.202] iteration 15540 : loss : 122.883781, loss_ce: 0.030477, loss_kd: 612.013245
[20:37:06.837] iteration 15550 : loss : 138.219971, loss_ce: 0.011865, loss_kd: 688.742310
[20:37:12.451] iteration 15560 : loss : 164.069641, loss_ce: 0.019550, loss_kd: 817.943115
[20:37:18.088] iteration 15570 : loss : 196.617188, loss_ce: 0.012753, loss_kd: 980.694702
[20:37:23.696] iteration 15580 : loss : 186.399963, loss_ce: 0.013264, loss_kd: 929.585754
[20:37:29.320] iteration 15590 : loss : 167.648148, loss_ce: 0.017568, loss_kd: 835.843811
[20:37:34.945] iteration 15600 : loss : 146.295303, loss_ce: 0.021086, loss_kd: 729.102661
[20:37:40.578] iteration 15610 : loss : 136.476059, loss_ce: 0.013932, loss_kd: 679.992676
[20:37:46.190] iteration 15620 : loss : 158.440521, loss_ce: 0.012048, loss_kd: 789.848022
[20:37:51.523] iteration 15630 : loss : 111.868385, loss_ce: 0.023814, loss_kd: 556.914978
[20:37:52.265] save model to ./debug_fixed_tpgm\continual_surgical_tpgm_stage1_epoch_14.pth
[20:37:52.266] Applying final TPGM projection
[20:37:52.434] save final model to ./debug_fixed_tpgm\continual_surgical_tpgm_stage1_final.pth
[18:48:20.877] Namespace(root_path='./datasets/kits23/train_npz', dataset='kits23', list_dir='./lists/kits23', stage=1, num_classes_old=9, num_classes_new=4, num_classes_lits17=3, output_dir='./debug_fixed_tpgm', max_iterations=10000, max_epochs=30, batch_size=32, n_gpu=1, deterministic=1, base_lr=0.001, img_size=224, seed=1234, cfg='configs/finetune.yaml', pretrained_path='./pretrain/epoch_149.pth', data_fraction=0.35, kd_temperature=3.0, kd_weight=0.2, freeze_old_classes=False, auto_tune='none', gradient_batches=5, tpgm_norm_mode='l2', tpgm_lr=0.05, tpgm_iters=500, tpgm_exclude=[], tpgm_frequency=2, tpgm_start_epoch=2, disable_tpgm=False, tpgm_data_fraction=0.3, opts=None, zip=False, cache_mode='part', resume=None, accumulation_steps=None, use_checkpoint=False, amp_opt_level='O1', tag=None, eval=False, throughput=False)
[18:48:20.897] Stage 1: Using 33327/95221 samples (35.0%) for continual learning
[18:48:20.897] Old classes: 9, New classes: 4, Total: 12
[18:48:20.897] Dataset: kits23
[18:48:20.897] TPGM enabled: True
[18:48:20.897] Surgical fine-tuning method: none
[18:50:36.064] Combined Continual Learning Stage 1 + Surgical + TPGM Configuration:
[18:50:36.064] KD Temperature: 3.0
[18:50:36.064] KD Weight: 0.2
[18:50:36.064] Auto-tune method: none
[18:50:36.064] TPGM start epoch: 2
[18:50:36.064] TPGM frequency: 2
[18:50:36.064] 1042 iterations per epoch. 31260 max iterations 
[18:50:52.721] iteration 10 : loss : 5603.246582, loss_ce: 0.254506, loss_kd: 28013.501953
[18:50:58.195] iteration 20 : loss : 3771.561279, loss_ce: 0.232940, loss_kd: 18854.687500
[18:51:03.696] iteration 30 : loss : 4068.643311, loss_ce: 0.170892, loss_kd: 20340.373047
[18:51:09.187] iteration 40 : loss : 2952.815674, loss_ce: 0.147216, loss_kd: 14761.041016
[18:51:14.700] iteration 50 : loss : 1991.151123, loss_ce: 0.134721, loss_kd: 9952.947266
[18:51:20.206] iteration 60 : loss : 1787.323975, loss_ce: 0.171531, loss_kd: 8933.642578
[18:51:25.715] iteration 70 : loss : 1302.562500, loss_ce: 0.168004, loss_kd: 6509.942871
[18:51:31.222] iteration 80 : loss : 1267.604736, loss_ce: 0.093403, loss_kd: 6335.222168
[18:51:36.740] iteration 90 : loss : 1514.672241, loss_ce: 0.126000, loss_kd: 7570.385254
[18:51:42.247] iteration 100 : loss : 1292.782593, loss_ce: 0.098314, loss_kd: 6461.148926
[18:51:47.778] iteration 110 : loss : 1334.174072, loss_ce: 0.080514, loss_kd: 6667.932617
[18:51:53.289] iteration 120 : loss : 1364.823608, loss_ce: 0.078627, loss_kd: 6821.250000
[18:51:58.811] iteration 130 : loss : 1067.468506, loss_ce: 0.098510, loss_kd: 5334.640625
[18:52:04.319] iteration 140 : loss : 1271.808838, loss_ce: 0.058937, loss_kd: 6356.400391
[18:52:09.849] iteration 150 : loss : 1064.039795, loss_ce: 0.085945, loss_kd: 5317.400391
[18:52:15.370] iteration 160 : loss : 1198.357788, loss_ce: 0.024793, loss_kd: 5989.071289
[18:52:20.900] iteration 170 : loss : 911.944824, loss_ce: 0.026217, loss_kd: 4557.009766
[18:52:26.421] iteration 180 : loss : 1339.675537, loss_ce: 0.018147, loss_kd: 6695.767090
[18:52:31.952] iteration 190 : loss : 909.561035, loss_ce: 0.043075, loss_kd: 4545.091309
[18:52:37.486] iteration 200 : loss : 862.236206, loss_ce: 0.034092, loss_kd: 4308.442383
[18:52:43.017] iteration 210 : loss : 838.607788, loss_ce: 0.025415, loss_kd: 4190.500000
[18:52:48.539] iteration 220 : loss : 907.366760, loss_ce: 0.021083, loss_kd: 4534.179199
[18:52:54.068] iteration 230 : loss : 1259.537231, loss_ce: 0.018248, loss_kd: 6295.015137
[18:52:59.596] iteration 240 : loss : 662.233398, loss_ce: 0.017866, loss_kd: 3308.486084
[18:53:05.132] iteration 250 : loss : 664.609619, loss_ce: 0.021476, loss_kd: 3320.434082
[18:53:10.658] iteration 260 : loss : 1170.447998, loss_ce: 0.030219, loss_kd: 5849.553711
[18:53:16.194] iteration 270 : loss : 840.907898, loss_ce: 0.012443, loss_kd: 4202.014160
[18:53:21.723] iteration 280 : loss : 951.925598, loss_ce: 0.027856, loss_kd: 4757.088379
[18:53:27.258] iteration 290 : loss : 781.685608, loss_ce: 0.009956, loss_kd: 3905.769775
[18:53:32.790] iteration 300 : loss : 727.529602, loss_ce: 0.010693, loss_kd: 3635.146484
[18:53:38.330] iteration 310 : loss : 841.190918, loss_ce: 0.022380, loss_kd: 4203.367676
[18:53:43.860] iteration 320 : loss : 1059.872925, loss_ce: 0.016011, loss_kd: 5296.823730
[18:53:49.405] iteration 330 : loss : 832.491272, loss_ce: 0.019374, loss_kd: 4159.865234
[18:53:54.943] iteration 340 : loss : 807.053101, loss_ce: 0.015402, loss_kd: 4032.727295
[18:54:00.489] iteration 350 : loss : 780.537109, loss_ce: 0.027872, loss_kd: 3900.122070
[18:54:06.026] iteration 360 : loss : 651.616821, loss_ce: 0.025221, loss_kd: 3255.549561
[18:54:11.571] iteration 370 : loss : 691.620728, loss_ce: 0.018099, loss_kd: 3455.562744
[18:54:17.113] iteration 380 : loss : 653.950623, loss_ce: 0.022522, loss_kd: 3267.224121
[18:54:22.664] iteration 390 : loss : 864.127869, loss_ce: 0.010945, loss_kd: 4318.078125
[18:54:28.210] iteration 400 : loss : 968.035828, loss_ce: 0.016071, loss_kd: 4837.653809
[18:54:33.769] iteration 410 : loss : 944.567200, loss_ce: 0.024826, loss_kd: 4720.268066
[18:54:39.315] iteration 420 : loss : 811.525940, loss_ce: 0.022086, loss_kd: 4055.094971
[18:54:44.868] iteration 430 : loss : 663.257751, loss_ce: 0.013856, loss_kd: 3313.819824
[18:54:50.414] iteration 440 : loss : 881.240173, loss_ce: 0.019214, loss_kd: 4403.725586
[18:54:55.973] iteration 450 : loss : 422.091400, loss_ce: 0.015780, loss_kd: 2107.873047
[18:55:01.524] iteration 460 : loss : 673.163757, loss_ce: 0.022679, loss_kd: 3363.295166
[18:55:07.085] iteration 470 : loss : 725.383789, loss_ce: 0.021429, loss_kd: 3624.394531
[18:55:12.626] iteration 480 : loss : 928.828247, loss_ce: 0.028458, loss_kd: 4641.640137
[18:55:18.196] iteration 490 : loss : 719.796387, loss_ce: 0.021234, loss_kd: 3596.501953
[18:55:23.749] iteration 500 : loss : 633.446045, loss_ce: 0.022232, loss_kd: 3164.729980
[18:55:29.322] iteration 510 : loss : 632.843079, loss_ce: 0.032295, loss_kd: 3161.754395
[18:55:34.876] iteration 520 : loss : 595.767456, loss_ce: 0.027955, loss_kd: 2976.213379
[18:55:40.442] iteration 530 : loss : 698.667603, loss_ce: 0.015485, loss_kd: 3490.791504
[18:55:45.997] iteration 540 : loss : 670.178711, loss_ce: 0.020205, loss_kd: 3348.348145
[18:55:51.566] iteration 550 : loss : 810.671631, loss_ce: 0.027695, loss_kd: 4050.761230
[18:55:57.130] iteration 560 : loss : 917.016113, loss_ce: 0.017088, loss_kd: 4582.431641
[18:56:02.702] iteration 570 : loss : 715.640076, loss_ce: 0.030183, loss_kd: 3575.730469
[18:56:08.263] iteration 580 : loss : 491.049988, loss_ce: 0.027736, loss_kd: 2452.772217
[18:56:13.835] iteration 590 : loss : 593.401489, loss_ce: 0.011959, loss_kd: 2964.468262
[18:56:19.398] iteration 600 : loss : 845.662842, loss_ce: 0.026428, loss_kd: 4225.774902
[18:56:24.983] iteration 610 : loss : 553.627136, loss_ce: 0.026654, loss_kd: 2765.651611
[18:56:30.548] iteration 620 : loss : 750.811279, loss_ce: 0.013163, loss_kd: 3751.528564
[18:56:36.128] iteration 630 : loss : 601.464478, loss_ce: 0.029541, loss_kd: 3004.751953
[18:56:41.691] iteration 640 : loss : 570.588257, loss_ce: 0.034777, loss_kd: 2850.468262
[18:56:47.264] iteration 650 : loss : 471.446289, loss_ce: 0.032394, loss_kd: 2354.735352
[18:56:52.835] iteration 660 : loss : 811.087646, loss_ce: 0.028226, loss_kd: 4052.979980
[18:56:58.419] iteration 670 : loss : 629.304749, loss_ce: 0.022235, loss_kd: 3144.053223
[18:57:03.987] iteration 680 : loss : 449.536713, loss_ce: 0.022644, loss_kd: 2245.185303
[18:57:09.565] iteration 690 : loss : 711.032776, loss_ce: 0.021610, loss_kd: 3552.645020
[18:57:15.148] iteration 700 : loss : 544.096558, loss_ce: 0.020175, loss_kd: 2717.778076
[18:57:20.747] iteration 710 : loss : 675.687744, loss_ce: 0.029739, loss_kd: 3375.739990
[18:57:26.320] iteration 720 : loss : 639.881836, loss_ce: 0.019859, loss_kd: 3196.955566
[18:57:31.906] iteration 730 : loss : 694.106384, loss_ce: 0.038939, loss_kd: 3467.986084
[18:57:37.483] iteration 740 : loss : 532.615906, loss_ce: 0.025773, loss_kd: 2660.572754
[18:57:43.074] iteration 750 : loss : 526.581787, loss_ce: 0.022426, loss_kd: 2630.363770
[18:57:48.659] iteration 760 : loss : 536.041443, loss_ce: 0.028603, loss_kd: 2677.488525
[18:57:54.257] iteration 770 : loss : 603.981323, loss_ce: 0.034181, loss_kd: 3017.374756
[18:57:59.835] iteration 780 : loss : 571.653442, loss_ce: 0.033517, loss_kd: 2855.755615
[18:58:05.422] iteration 790 : loss : 561.791809, loss_ce: 0.017171, loss_kd: 2806.466309
[18:58:11.008] iteration 800 : loss : 632.052185, loss_ce: 0.033404, loss_kd: 3157.659180
[18:58:16.604] iteration 810 : loss : 610.029785, loss_ce: 0.024912, loss_kd: 3047.596680
[18:58:22.192] iteration 820 : loss : 548.138855, loss_ce: 0.022109, loss_kd: 2738.201172
[18:58:27.792] iteration 830 : loss : 590.406189, loss_ce: 0.027461, loss_kd: 2949.470947
[18:58:33.373] iteration 840 : loss : 589.569702, loss_ce: 0.020586, loss_kd: 2945.408447
[18:58:38.965] iteration 850 : loss : 655.125549, loss_ce: 0.030032, loss_kd: 3273.090332
[18:58:44.547] iteration 860 : loss : 563.401611, loss_ce: 0.028497, loss_kd: 2814.505615
[18:58:50.138] iteration 870 : loss : 488.075439, loss_ce: 0.020553, loss_kd: 2437.838135
[18:58:55.723] iteration 880 : loss : 504.083862, loss_ce: 0.039870, loss_kd: 2517.945068
[18:59:01.324] iteration 890 : loss : 574.257141, loss_ce: 0.023527, loss_kd: 2868.891602
[18:59:06.911] iteration 900 : loss : 497.354889, loss_ce: 0.027568, loss_kd: 2484.265625
[18:59:12.518] iteration 910 : loss : 536.381226, loss_ce: 0.017047, loss_kd: 2679.436035
[18:59:18.152] iteration 920 : loss : 338.371033, loss_ce: 0.015665, loss_kd: 1689.400635
[18:59:23.753] iteration 930 : loss : 733.632996, loss_ce: 0.020874, loss_kd: 3665.660156
[18:59:29.344] iteration 940 : loss : 707.759094, loss_ce: 0.018978, loss_kd: 3536.263428
[18:59:34.935] iteration 950 : loss : 516.808350, loss_ce: 0.018901, loss_kd: 2581.474365
[18:59:40.519] iteration 960 : loss : 803.667908, loss_ce: 0.033328, loss_kd: 4015.752441
[18:59:46.116] iteration 970 : loss : 538.848511, loss_ce: 0.022242, loss_kd: 2691.707275
[18:59:51.706] iteration 980 : loss : 733.242310, loss_ce: 0.028122, loss_kd: 3663.610107
[18:59:57.299] iteration 990 : loss : 583.406555, loss_ce: 0.023614, loss_kd: 2914.543945
[19:00:02.880] iteration 1000 : loss : 668.314148, loss_ce: 0.022032, loss_kd: 3338.942627
[19:00:08.485] iteration 1010 : loss : 608.197205, loss_ce: 0.027397, loss_kd: 3038.499023
[19:00:14.062] iteration 1020 : loss : 710.695007, loss_ce: 0.028599, loss_kd: 3550.827881
[19:00:19.651] iteration 1030 : loss : 371.426361, loss_ce: 0.031638, loss_kd: 1854.553711
[19:00:25.278] iteration 1040 : loss : 463.645935, loss_ce: 0.025338, loss_kd: 2315.783936
[19:00:42.605] iteration 1050 : loss : 693.265869, loss_ce: 0.029213, loss_kd: 3463.863525
[19:00:48.142] iteration 1060 : loss : 526.721313, loss_ce: 0.026412, loss_kd: 2631.070801
[19:00:53.687] iteration 1070 : loss : 531.308167, loss_ce: 0.021096, loss_kd: 2654.069824
[19:00:59.225] iteration 1080 : loss : 465.289429, loss_ce: 0.024918, loss_kd: 2323.877441
[19:01:04.775] iteration 1090 : loss : 557.345154, loss_ce: 0.024157, loss_kd: 2784.248291
[19:01:10.313] iteration 1100 : loss : 488.818604, loss_ce: 0.018032, loss_kd: 2441.529541
[19:01:15.873] iteration 1110 : loss : 367.081024, loss_ce: 0.030003, loss_kd: 1832.895020
[19:01:21.414] iteration 1120 : loss : 761.583252, loss_ce: 0.018275, loss_kd: 3805.383545
[19:01:26.967] iteration 1130 : loss : 321.110199, loss_ce: 0.023297, loss_kd: 1603.010620
[19:01:32.520] iteration 1140 : loss : 421.631256, loss_ce: 0.023388, loss_kd: 2105.510742
[19:01:38.077] iteration 1150 : loss : 339.904968, loss_ce: 0.020129, loss_kd: 1697.022095
[19:01:43.627] iteration 1160 : loss : 542.822754, loss_ce: 0.029395, loss_kd: 2711.549072
[19:01:49.190] iteration 1170 : loss : 543.898987, loss_ce: 0.020503, loss_kd: 2716.927246
[19:01:54.753] iteration 1180 : loss : 489.604614, loss_ce: 0.015428, loss_kd: 2445.551758
[19:02:00.325] iteration 1190 : loss : 527.399109, loss_ce: 0.047504, loss_kd: 2634.424072
[19:02:05.888] iteration 1200 : loss : 383.224213, loss_ce: 0.028175, loss_kd: 1913.571167
[19:02:11.456] iteration 1210 : loss : 555.650635, loss_ce: 0.016882, loss_kd: 2775.752686
[19:02:17.013] iteration 1220 : loss : 734.489380, loss_ce: 0.014769, loss_kd: 3669.793457
[19:02:22.581] iteration 1230 : loss : 600.111450, loss_ce: 0.027435, loss_kd: 2998.081543
[19:02:28.155] iteration 1240 : loss : 560.240479, loss_ce: 0.022770, loss_kd: 2798.692627
[19:02:33.743] iteration 1250 : loss : 578.350159, loss_ce: 0.021862, loss_kd: 2889.231445
[19:02:39.315] iteration 1260 : loss : 513.895752, loss_ce: 0.020263, loss_kd: 2566.952637
[19:02:44.898] iteration 1270 : loss : 403.630890, loss_ce: 0.024735, loss_kd: 2015.665161
[19:02:50.472] iteration 1280 : loss : 450.795990, loss_ce: 0.017674, loss_kd: 2251.488281
[19:02:56.046] iteration 1290 : loss : 488.983002, loss_ce: 0.038278, loss_kd: 2442.421631
[19:03:01.614] iteration 1300 : loss : 442.602417, loss_ce: 0.050059, loss_kd: 2210.478516
[19:03:07.193] iteration 1310 : loss : 621.733215, loss_ce: 0.024205, loss_kd: 3106.199707
[19:03:12.755] iteration 1320 : loss : 494.742035, loss_ce: 0.034197, loss_kd: 2471.221191
[19:03:18.345] iteration 1330 : loss : 462.519531, loss_ce: 0.044558, loss_kd: 2310.078125
[19:03:23.921] iteration 1340 : loss : 484.624176, loss_ce: 0.021962, loss_kd: 2420.602783
[19:03:29.504] iteration 1350 : loss : 489.185913, loss_ce: 0.022276, loss_kd: 2443.464844
[19:03:35.071] iteration 1360 : loss : 447.813080, loss_ce: 0.021522, loss_kd: 2236.587158
[19:03:40.658] iteration 1370 : loss : 345.241547, loss_ce: 0.031159, loss_kd: 1723.673706
[19:03:46.226] iteration 1380 : loss : 437.907471, loss_ce: 0.037494, loss_kd: 2187.033203
[19:03:51.808] iteration 1390 : loss : 422.919373, loss_ce: 0.026022, loss_kd: 2112.125244
[19:03:57.375] iteration 1400 : loss : 464.317322, loss_ce: 0.026824, loss_kd: 2319.073975
[19:04:02.961] iteration 1410 : loss : 611.156616, loss_ce: 0.034536, loss_kd: 3053.287354
[19:04:08.534] iteration 1420 : loss : 481.393738, loss_ce: 0.020125, loss_kd: 2404.471191
[19:04:14.114] iteration 1430 : loss : 473.608459, loss_ce: 0.021267, loss_kd: 2365.627197
[19:04:19.687] iteration 1440 : loss : 443.332886, loss_ce: 0.028150, loss_kd: 2214.163818
[19:04:25.290] iteration 1450 : loss : 390.313080, loss_ce: 0.024271, loss_kd: 1949.092529
[19:04:30.862] iteration 1460 : loss : 480.257935, loss_ce: 0.025838, loss_kd: 2398.823486
[19:04:36.446] iteration 1470 : loss : 427.195007, loss_ce: 0.018336, loss_kd: 2133.534424
[19:04:42.025] iteration 1480 : loss : 500.947510, loss_ce: 0.019746, loss_kd: 2502.224121
[19:04:47.612] iteration 1490 : loss : 436.116302, loss_ce: 0.020804, loss_kd: 2178.084717
[19:04:53.191] iteration 1500 : loss : 413.759460, loss_ce: 0.017168, loss_kd: 2066.320801
[19:04:58.777] iteration 1510 : loss : 369.127502, loss_ce: 0.024736, loss_kd: 1843.124023
[19:05:04.359] iteration 1520 : loss : 493.222321, loss_ce: 0.019509, loss_kd: 2463.644287
[19:05:09.935] iteration 1530 : loss : 507.556366, loss_ce: 0.026606, loss_kd: 2535.323730
[19:05:15.509] iteration 1540 : loss : 424.680939, loss_ce: 0.030737, loss_kd: 2120.926758
[19:05:21.091] iteration 1550 : loss : 387.585114, loss_ce: 0.036477, loss_kd: 1935.456177
[19:05:26.666] iteration 1560 : loss : 353.994293, loss_ce: 0.035776, loss_kd: 1767.444214
[19:05:32.245] iteration 1570 : loss : 428.760468, loss_ce: 0.044744, loss_kd: 2141.295898
[19:05:37.821] iteration 1580 : loss : 440.287262, loss_ce: 0.022619, loss_kd: 2198.962646
[19:05:43.405] iteration 1590 : loss : 436.309113, loss_ce: 0.045775, loss_kd: 2179.011475
[19:05:48.972] iteration 1600 : loss : 473.530457, loss_ce: 0.023171, loss_kd: 2365.172607
[19:05:54.552] iteration 1610 : loss : 446.578888, loss_ce: 0.025705, loss_kd: 2230.471680
[19:06:00.120] iteration 1620 : loss : 484.461517, loss_ce: 0.024397, loss_kd: 2419.770508
[19:06:05.705] iteration 1630 : loss : 495.829620, loss_ce: 0.028396, loss_kd: 2476.646240
[19:06:11.278] iteration 1640 : loss : 569.037415, loss_ce: 0.021248, loss_kd: 2842.662598
[19:06:16.860] iteration 1650 : loss : 375.513306, loss_ce: 0.035308, loss_kd: 1875.105957
[19:06:22.429] iteration 1660 : loss : 370.453644, loss_ce: 0.038489, loss_kd: 1849.803223
[19:06:28.011] iteration 1670 : loss : 343.608856, loss_ce: 0.032383, loss_kd: 1715.508301
[19:06:33.581] iteration 1680 : loss : 498.630280, loss_ce: 0.019233, loss_kd: 2490.681152
[19:06:39.162] iteration 1690 : loss : 402.872772, loss_ce: 0.029012, loss_kd: 2011.862793
[19:06:44.737] iteration 1700 : loss : 465.833801, loss_ce: 0.021927, loss_kd: 2326.657715
[19:06:50.316] iteration 1710 : loss : 508.357788, loss_ce: 0.027184, loss_kd: 2539.237305
[19:06:55.885] iteration 1720 : loss : 443.846741, loss_ce: 0.031986, loss_kd: 2216.768066
[19:07:01.454] iteration 1730 : loss : 369.209930, loss_ce: 0.029868, loss_kd: 1843.567261
[19:07:07.022] iteration 1740 : loss : 418.791687, loss_ce: 0.031939, loss_kd: 2091.475098
[19:07:12.597] iteration 1750 : loss : 381.472961, loss_ce: 0.023700, loss_kd: 1904.811523
[19:07:18.164] iteration 1760 : loss : 403.712891, loss_ce: 0.021867, loss_kd: 2015.932861
[19:07:23.747] iteration 1770 : loss : 377.155151, loss_ce: 0.037700, loss_kd: 1883.295288
[19:07:29.316] iteration 1780 : loss : 355.336456, loss_ce: 0.027009, loss_kd: 1774.249268
[19:07:34.898] iteration 1790 : loss : 443.065643, loss_ce: 0.028031, loss_kd: 2212.818848
[19:07:40.471] iteration 1800 : loss : 404.587006, loss_ce: 0.015077, loss_kd: 2020.461304
[19:07:46.049] iteration 1810 : loss : 436.349365, loss_ce: 0.019904, loss_kd: 2179.262939
[19:07:51.617] iteration 1820 : loss : 322.582214, loss_ce: 0.041178, loss_kd: 1610.414062
[19:07:57.206] iteration 1830 : loss : 581.257141, loss_ce: 0.033284, loss_kd: 2903.778320
[19:08:02.776] iteration 1840 : loss : 413.283081, loss_ce: 0.017923, loss_kd: 2063.948975
[19:08:08.353] iteration 1850 : loss : 434.449402, loss_ce: 0.026544, loss_kd: 2169.757324
[19:08:13.929] iteration 1860 : loss : 388.257080, loss_ce: 0.024070, loss_kd: 1938.840332
[19:08:19.517] iteration 1870 : loss : 340.127533, loss_ce: 0.025816, loss_kd: 1698.153564
[19:08:25.087] iteration 1880 : loss : 356.175995, loss_ce: 0.021955, loss_kd: 1778.380127
[19:08:30.669] iteration 1890 : loss : 350.107605, loss_ce: 0.032188, loss_kd: 1748.041748
[19:08:36.237] iteration 1900 : loss : 383.855621, loss_ce: 0.031669, loss_kd: 1916.789551
[19:08:41.818] iteration 1910 : loss : 321.047516, loss_ce: 0.016519, loss_kd: 1602.778076
[19:08:47.387] iteration 1920 : loss : 504.198730, loss_ce: 0.034052, loss_kd: 2518.493652
[19:08:52.972] iteration 1930 : loss : 432.236206, loss_ce: 0.016240, loss_kd: 2158.658936
[19:08:58.545] iteration 1940 : loss : 391.055450, loss_ce: 0.028358, loss_kd: 1952.825562
[19:09:04.118] iteration 1950 : loss : 395.857758, loss_ce: 0.022763, loss_kd: 1976.836426
[19:09:09.690] iteration 1960 : loss : 377.242157, loss_ce: 0.020510, loss_kd: 1883.746826
[19:09:15.264] iteration 1970 : loss : 363.588715, loss_ce: 0.027149, loss_kd: 1815.444702
[19:09:20.833] iteration 1980 : loss : 255.039093, loss_ce: 0.023684, loss_kd: 1272.723877
[19:09:26.409] iteration 1990 : loss : 464.105530, loss_ce: 0.027266, loss_kd: 2318.044434
[19:09:31.974] iteration 2000 : loss : 318.215546, loss_ce: 0.023070, loss_kd: 1588.575439
[19:09:37.550] iteration 2010 : loss : 395.393646, loss_ce: 0.027775, loss_kd: 1974.499146
[19:09:43.115] iteration 2020 : loss : 449.837555, loss_ce: 0.037384, loss_kd: 2246.708252
[19:09:48.696] iteration 2030 : loss : 541.336487, loss_ce: 0.019093, loss_kd: 2704.214600
[19:09:54.272] iteration 2040 : loss : 295.279358, loss_ce: 0.019468, loss_kd: 1473.946533
[19:09:59.849] iteration 2050 : loss : 361.114441, loss_ce: 0.019209, loss_kd: 1803.052856
[19:10:05.417] iteration 2060 : loss : 430.042206, loss_ce: 0.031010, loss_kd: 2147.640869
[19:10:11.005] iteration 2070 : loss : 480.463379, loss_ce: 0.027856, loss_kd: 2399.824951
[19:10:16.579] iteration 2080 : loss : 344.223785, loss_ce: 0.024057, loss_kd: 1718.618164
[19:10:33.503] iteration 2090 : loss : 416.595734, loss_ce: 0.029258, loss_kd: 2080.528809
[19:10:39.033] iteration 2100 : loss : 385.070312, loss_ce: 0.024540, loss_kd: 1922.877930
[19:10:44.580] iteration 2110 : loss : 422.813507, loss_ce: 0.022840, loss_kd: 2111.591553
[19:10:50.115] iteration 2120 : loss : 391.535095, loss_ce: 0.025909, loss_kd: 1955.175171
[19:10:55.667] iteration 2130 : loss : 389.474854, loss_ce: 0.028383, loss_kd: 1944.919678
[19:11:01.208] iteration 2140 : loss : 535.435913, loss_ce: 0.025855, loss_kd: 2674.715576
[19:11:06.760] iteration 2150 : loss : 286.112946, loss_ce: 0.022315, loss_kd: 1428.016968
[19:11:12.304] iteration 2160 : loss : 355.715637, loss_ce: 0.025763, loss_kd: 1776.091064
[19:11:17.864] iteration 2170 : loss : 380.098450, loss_ce: 0.021265, loss_kd: 1898.049927
[19:11:23.422] iteration 2180 : loss : 329.043427, loss_ce: 0.038632, loss_kd: 1642.774292
[19:11:28.984] iteration 2190 : loss : 323.647125, loss_ce: 0.024204, loss_kd: 1615.810059
[19:11:34.544] iteration 2200 : loss : 336.905334, loss_ce: 0.023451, loss_kd: 1682.062622
[19:11:40.116] iteration 2210 : loss : 262.980530, loss_ce: 0.033236, loss_kd: 1312.442261
[19:11:45.678] iteration 2220 : loss : 277.050446, loss_ce: 0.028536, loss_kd: 1382.799438
[19:11:51.251] iteration 2230 : loss : 293.824341, loss_ce: 0.014581, loss_kd: 1466.652466
[19:11:56.808] iteration 2240 : loss : 366.931091, loss_ce: 0.019189, loss_kd: 1832.138550
[19:12:02.381] iteration 2250 : loss : 360.228119, loss_ce: 0.018771, loss_kd: 1798.702759
[19:12:07.945] iteration 2260 : loss : 381.615112, loss_ce: 0.024925, loss_kd: 1905.615601
[19:12:13.517] iteration 2270 : loss : 286.113922, loss_ce: 0.020081, loss_kd: 1428.111572
[19:12:19.079] iteration 2280 : loss : 385.750488, loss_ce: 0.026248, loss_kd: 1926.280762
[19:12:24.657] iteration 2290 : loss : 308.422852, loss_ce: 0.022206, loss_kd: 1539.649048
[19:12:30.219] iteration 2300 : loss : 421.665253, loss_ce: 0.031906, loss_kd: 2105.841309
[19:12:35.804] iteration 2310 : loss : 340.246918, loss_ce: 0.034427, loss_kd: 1698.777100
[19:12:41.381] iteration 2320 : loss : 482.244415, loss_ce: 0.018218, loss_kd: 2408.817383
[19:12:46.963] iteration 2330 : loss : 426.819458, loss_ce: 0.026142, loss_kd: 2131.639648
[19:12:52.525] iteration 2340 : loss : 474.089172, loss_ce: 0.020371, loss_kd: 2367.997559
[19:12:58.108] iteration 2350 : loss : 407.883118, loss_ce: 0.021412, loss_kd: 2036.977417
[19:13:03.672] iteration 2360 : loss : 279.885468, loss_ce: 0.031122, loss_kd: 1396.953735
[19:13:09.252] iteration 2370 : loss : 255.788651, loss_ce: 0.029037, loss_kd: 1276.483643
[19:13:14.820] iteration 2380 : loss : 412.906860, loss_ce: 0.020184, loss_kd: 2062.105957
[19:13:20.389] iteration 2390 : loss : 461.114197, loss_ce: 0.021561, loss_kd: 2303.099365
[19:13:25.964] iteration 2400 : loss : 786.906311, loss_ce: 0.021268, loss_kd: 3932.043701
[19:13:31.545] iteration 2410 : loss : 352.825653, loss_ce: 0.028553, loss_kd: 1761.677979
[19:13:37.109] iteration 2420 : loss : 281.821686, loss_ce: 0.031519, loss_kd: 1406.589233
[19:13:42.692] iteration 2430 : loss : 363.607574, loss_ce: 0.028464, loss_kd: 1815.550049
[19:13:48.254] iteration 2440 : loss : 390.589874, loss_ce: 0.019505, loss_kd: 1950.517334
[19:13:53.828] iteration 2450 : loss : 378.361816, loss_ce: 0.024022, loss_kd: 1889.322021
[19:13:59.397] iteration 2460 : loss : 328.248779, loss_ce: 0.023384, loss_kd: 1638.773926
[19:14:04.967] iteration 2470 : loss : 406.659607, loss_ce: 0.016995, loss_kd: 2030.835938
[19:14:10.533] iteration 2480 : loss : 355.564636, loss_ce: 0.023966, loss_kd: 1775.346436
[19:14:16.109] iteration 2490 : loss : 388.885101, loss_ce: 0.053900, loss_kd: 1941.888916
[19:14:21.674] iteration 2500 : loss : 453.821808, loss_ce: 0.024734, loss_kd: 2266.630859
[19:14:27.260] iteration 2510 : loss : 257.016998, loss_ce: 0.028075, loss_kd: 1282.619873
[19:14:32.824] iteration 2520 : loss : 340.703369, loss_ce: 0.023627, loss_kd: 1701.060181
[19:14:38.403] iteration 2530 : loss : 416.411713, loss_ce: 0.022701, loss_kd: 2079.616943
[19:14:43.962] iteration 2540 : loss : 282.754669, loss_ce: 0.026908, loss_kd: 1411.295166
[19:14:49.544] iteration 2550 : loss : 460.233093, loss_ce: 0.031992, loss_kd: 2298.659912
[19:14:55.123] iteration 2560 : loss : 418.317627, loss_ce: 0.021967, loss_kd: 2089.169434
[19:15:00.699] iteration 2570 : loss : 278.000732, loss_ce: 0.028569, loss_kd: 1387.562012
[19:15:06.261] iteration 2580 : loss : 411.208862, loss_ce: 0.025110, loss_kd: 2053.573242
[19:15:11.842] iteration 2590 : loss : 379.228485, loss_ce: 0.027030, loss_kd: 1893.700439
[19:15:17.407] iteration 2600 : loss : 416.668335, loss_ce: 0.031331, loss_kd: 2080.854492
[19:15:22.987] iteration 2610 : loss : 259.048035, loss_ce: 0.018337, loss_kd: 1292.747681
[19:15:28.554] iteration 2620 : loss : 263.408447, loss_ce: 0.031621, loss_kd: 1314.561401
[19:15:34.134] iteration 2630 : loss : 384.183472, loss_ce: 0.029488, loss_kd: 1918.432495
[19:15:39.703] iteration 2640 : loss : 435.471466, loss_ce: 0.024878, loss_kd: 2174.844727
[19:15:45.291] iteration 2650 : loss : 314.221619, loss_ce: 0.024814, loss_kd: 1568.623535
[19:15:50.873] iteration 2660 : loss : 279.322968, loss_ce: 0.020077, loss_kd: 1394.161499
[19:15:56.457] iteration 2670 : loss : 298.135193, loss_ce: 0.026556, loss_kd: 1488.201416
[19:16:02.031] iteration 2680 : loss : 370.440887, loss_ce: 0.018820, loss_kd: 1849.701050
[19:16:07.635] iteration 2690 : loss : 429.182892, loss_ce: 0.022328, loss_kd: 2143.463623
[19:16:13.215] iteration 2700 : loss : 373.674377, loss_ce: 0.022068, loss_kd: 1865.935059
[19:16:18.805] iteration 2710 : loss : 376.648132, loss_ce: 0.028352, loss_kd: 1880.768433
[19:16:24.385] iteration 2720 : loss : 362.793060, loss_ce: 0.015200, loss_kd: 1811.481812
[19:16:29.968] iteration 2730 : loss : 313.927063, loss_ce: 0.030691, loss_kd: 1567.164551
[19:16:35.540] iteration 2740 : loss : 355.545441, loss_ce: 0.023516, loss_kd: 1775.223511
[19:16:41.128] iteration 2750 : loss : 271.561523, loss_ce: 0.034000, loss_kd: 1355.315430
[19:16:46.706] iteration 2760 : loss : 369.907898, loss_ce: 0.032638, loss_kd: 1847.059692
[19:16:52.293] iteration 2770 : loss : 382.677856, loss_ce: 0.035731, loss_kd: 1910.859741
[19:16:57.872] iteration 2780 : loss : 322.149384, loss_ce: 0.025449, loss_kd: 1608.267334
[19:17:03.462] iteration 2790 : loss : 334.287170, loss_ce: 0.032095, loss_kd: 1668.955566
[19:17:09.043] iteration 2800 : loss : 356.965057, loss_ce: 0.024116, loss_kd: 1782.365479
[19:17:14.632] iteration 2810 : loss : 289.646729, loss_ce: 0.031387, loss_kd: 1445.724365
[19:17:20.210] iteration 2820 : loss : 348.635468, loss_ce: 0.030153, loss_kd: 1740.707886
[19:17:25.795] iteration 2830 : loss : 307.652283, loss_ce: 0.024926, loss_kd: 1535.762085
[19:17:31.384] iteration 2840 : loss : 321.333374, loss_ce: 0.024994, loss_kd: 1604.199219
[19:17:36.969] iteration 2850 : loss : 394.687042, loss_ce: 0.016130, loss_kd: 1970.784180
[19:17:42.544] iteration 2860 : loss : 303.818115, loss_ce: 0.026333, loss_kd: 1516.619385
[19:17:48.129] iteration 2870 : loss : 367.911407, loss_ce: 0.019207, loss_kd: 1837.033569
[19:17:53.711] iteration 2880 : loss : 327.162750, loss_ce: 0.020671, loss_kd: 1633.331055
[19:17:59.299] iteration 2890 : loss : 261.423584, loss_ce: 0.024004, loss_kd: 1304.650879
[19:18:04.874] iteration 2900 : loss : 289.108978, loss_ce: 0.024988, loss_kd: 1443.086304
[19:18:10.461] iteration 2910 : loss : 318.877228, loss_ce: 0.042123, loss_kd: 1591.896729
[19:18:16.036] iteration 2920 : loss : 414.606445, loss_ce: 0.027779, loss_kd: 2070.526611
[19:18:21.621] iteration 2930 : loss : 361.019257, loss_ce: 0.026365, loss_kd: 1802.620483
[19:18:27.194] iteration 2940 : loss : 283.029663, loss_ce: 0.023764, loss_kd: 1412.688843
[19:18:32.775] iteration 2950 : loss : 372.490082, loss_ce: 0.020836, loss_kd: 1859.985352
[19:18:38.356] iteration 2960 : loss : 267.554443, loss_ce: 0.027356, loss_kd: 1335.322266
[19:18:43.943] iteration 2970 : loss : 264.759003, loss_ce: 0.015581, loss_kd: 1321.350952
[19:18:49.516] iteration 2980 : loss : 410.406708, loss_ce: 0.017297, loss_kd: 2049.577393
[19:18:55.100] iteration 2990 : loss : 243.670151, loss_ce: 0.018587, loss_kd: 1215.901123
[19:19:00.673] iteration 3000 : loss : 352.648071, loss_ce: 0.028668, loss_kd: 1760.774048
[19:19:06.263] iteration 3010 : loss : 260.889221, loss_ce: 0.016742, loss_kd: 1302.012207
[19:19:11.829] iteration 3020 : loss : 372.472717, loss_ce: 0.023002, loss_kd: 1859.882568
[19:19:17.408] iteration 3030 : loss : 272.140472, loss_ce: 0.030072, loss_kd: 1358.277100
[19:19:22.979] iteration 3040 : loss : 321.660522, loss_ce: 0.015979, loss_kd: 1605.835327
[19:19:28.556] iteration 3050 : loss : 305.230591, loss_ce: 0.019268, loss_kd: 1523.669922
[19:19:34.124] iteration 3060 : loss : 376.380371, loss_ce: 0.023817, loss_kd: 1879.459717
[19:19:39.702] iteration 3070 : loss : 330.552460, loss_ce: 0.021104, loss_kd: 1650.319946
[19:19:45.268] iteration 3080 : loss : 258.761658, loss_ce: 0.025065, loss_kd: 1291.303589
[19:19:50.852] iteration 3090 : loss : 362.651764, loss_ce: 0.021817, loss_kd: 1810.759155
[19:19:56.424] iteration 3100 : loss : 289.807190, loss_ce: 0.016622, loss_kd: 1446.559082
[19:20:02.002] iteration 3110 : loss : 303.503235, loss_ce: 0.028009, loss_kd: 1515.023438
[19:20:07.565] iteration 3120 : loss : 361.621277, loss_ce: 0.026821, loss_kd: 1805.622314
[19:20:11.288] Running TPGM constraint optimization after epoch 3
[19:24:59.535] iteration 3130 : loss : 261.634979, loss_ce: 0.018616, loss_kd: 1305.725952
[19:25:05.057] iteration 3140 : loss : 270.966888, loss_ce: 0.014523, loss_kd: 1352.346558
[19:25:10.597] iteration 3150 : loss : 251.264343, loss_ce: 0.034574, loss_kd: 1253.814453
[19:25:16.150] iteration 3160 : loss : 247.948227, loss_ce: 0.037745, loss_kd: 1237.298096
[19:25:21.688] iteration 3170 : loss : 335.126495, loss_ce: 0.025503, loss_kd: 1673.196777
[19:25:27.214] iteration 3180 : loss : 336.109192, loss_ce: 0.021852, loss_kd: 1678.094482
[19:25:32.755] iteration 3190 : loss : 380.239075, loss_ce: 0.019572, loss_kd: 1898.709106
[19:25:38.286] iteration 3200 : loss : 265.500671, loss_ce: 0.014057, loss_kd: 1325.024170
[19:25:43.832] iteration 3210 : loss : 318.855194, loss_ce: 0.037192, loss_kd: 1591.794678
[19:25:49.373] iteration 3220 : loss : 282.736389, loss_ce: 0.023082, loss_kd: 1411.169678
[19:25:54.916] iteration 3230 : loss : 298.580322, loss_ce: 0.036675, loss_kd: 1490.435791
[19:26:00.454] iteration 3240 : loss : 347.453064, loss_ce: 0.026504, loss_kd: 1734.816650
[19:26:06.002] iteration 3250 : loss : 276.554993, loss_ce: 0.015745, loss_kd: 1380.320190
[19:26:11.542] iteration 3260 : loss : 300.948395, loss_ce: 0.021257, loss_kd: 1502.269653
[19:26:17.100] iteration 3270 : loss : 271.145447, loss_ce: 0.015747, loss_kd: 1353.272217
[19:26:22.642] iteration 3280 : loss : 272.546753, loss_ce: 0.025884, loss_kd: 1360.269043
[19:26:28.196] iteration 3290 : loss : 290.552032, loss_ce: 0.024667, loss_kd: 1450.246582
[19:26:33.741] iteration 3300 : loss : 290.568085, loss_ce: 0.026037, loss_kd: 1450.380249
[19:26:39.311] iteration 3310 : loss : 347.837280, loss_ce: 0.033659, loss_kd: 1736.746216
[19:26:44.857] iteration 3320 : loss : 265.667053, loss_ce: 0.019076, loss_kd: 1325.877563
[19:26:50.415] iteration 3330 : loss : 287.999451, loss_ce: 0.022159, loss_kd: 1437.513672
[19:26:55.976] iteration 3340 : loss : 296.305267, loss_ce: 0.027745, loss_kd: 1479.072632
[19:27:01.536] iteration 3350 : loss : 281.218414, loss_ce: 0.028753, loss_kd: 1403.652588
[19:27:07.096] iteration 3360 : loss : 283.913269, loss_ce: 0.020349, loss_kd: 1417.140747
[19:27:12.664] iteration 3370 : loss : 293.499451, loss_ce: 0.024657, loss_kd: 1465.037598
[19:27:18.212] iteration 3380 : loss : 380.756714, loss_ce: 0.029504, loss_kd: 1901.313721
[19:27:23.773] iteration 3390 : loss : 409.447693, loss_ce: 0.020365, loss_kd: 2044.746094
[19:27:29.336] iteration 3400 : loss : 251.261398, loss_ce: 0.020642, loss_kd: 1253.820435
[19:27:34.902] iteration 3410 : loss : 334.561157, loss_ce: 0.021671, loss_kd: 1670.328735
[19:27:40.465] iteration 3420 : loss : 250.954956, loss_ce: 0.013087, loss_kd: 1252.327271
[19:27:46.041] iteration 3430 : loss : 367.382721, loss_ce: 0.032618, loss_kd: 1834.422852
[19:27:51.600] iteration 3440 : loss : 233.117264, loss_ce: 0.022357, loss_kd: 1163.083374
[19:27:57.171] iteration 3450 : loss : 283.450409, loss_ce: 0.031349, loss_kd: 1414.785034
[19:28:02.723] iteration 3460 : loss : 360.491364, loss_ce: 0.019980, loss_kd: 1800.022095
[19:28:08.306] iteration 3470 : loss : 249.451187, loss_ce: 0.033621, loss_kd: 1244.769043
[19:28:13.867] iteration 3480 : loss : 246.218109, loss_ce: 0.025215, loss_kd: 1228.599365
[19:28:19.439] iteration 3490 : loss : 329.202942, loss_ce: 0.020540, loss_kd: 1643.580566
[19:28:24.996] iteration 3500 : loss : 285.341034, loss_ce: 0.011278, loss_kd: 1424.216309
[19:28:30.577] iteration 3510 : loss : 275.894043, loss_ce: 0.033652, loss_kd: 1377.012817
[19:28:36.141] iteration 3520 : loss : 295.236237, loss_ce: 0.017297, loss_kd: 1473.774902
[19:28:41.717] iteration 3530 : loss : 444.377380, loss_ce: 0.023410, loss_kd: 2219.443848
[19:28:47.281] iteration 3540 : loss : 306.518250, loss_ce: 0.031245, loss_kd: 1530.086426
[19:28:52.849] iteration 3550 : loss : 281.842316, loss_ce: 0.025603, loss_kd: 1406.710083
[19:28:58.412] iteration 3560 : loss : 293.930084, loss_ce: 0.025641, loss_kd: 1467.182129
[19:29:03.986] iteration 3570 : loss : 293.344849, loss_ce: 0.022756, loss_kd: 1464.277588
[19:29:09.555] iteration 3580 : loss : 277.444183, loss_ce: 0.037414, loss_kd: 1384.748535
[19:29:15.126] iteration 3590 : loss : 366.513702, loss_ce: 0.027048, loss_kd: 1830.150391
[19:29:20.691] iteration 3600 : loss : 253.776291, loss_ce: 0.022152, loss_kd: 1266.416260
[19:29:26.264] iteration 3610 : loss : 343.424164, loss_ce: 0.023037, loss_kd: 1714.639526
[19:29:31.821] iteration 3620 : loss : 304.846680, loss_ce: 0.021061, loss_kd: 1521.785278
[19:29:37.401] iteration 3630 : loss : 264.679413, loss_ce: 0.021318, loss_kd: 1320.957397
[19:29:42.958] iteration 3640 : loss : 279.826599, loss_ce: 0.015206, loss_kd: 1396.695923
[19:29:48.530] iteration 3650 : loss : 318.845947, loss_ce: 0.022154, loss_kd: 1591.721680
[19:29:54.089] iteration 3660 : loss : 368.583069, loss_ce: 0.030938, loss_kd: 1840.427490
[19:29:59.662] iteration 3670 : loss : 246.437851, loss_ce: 0.015859, loss_kd: 1229.697266
[19:30:05.222] iteration 3680 : loss : 234.713898, loss_ce: 0.031144, loss_kd: 1171.110718
[19:30:10.802] iteration 3690 : loss : 257.257599, loss_ce: 0.018635, loss_kd: 1283.796875
[19:30:16.360] iteration 3700 : loss : 295.882233, loss_ce: 0.015887, loss_kd: 1476.974243
[19:30:21.933] iteration 3710 : loss : 297.735046, loss_ce: 0.035005, loss_kd: 1486.224121
[19:30:27.498] iteration 3720 : loss : 275.728638, loss_ce: 0.023276, loss_kd: 1376.189209
[19:30:33.076] iteration 3730 : loss : 227.288208, loss_ce: 0.023940, loss_kd: 1133.989990
[19:30:38.637] iteration 3740 : loss : 328.184906, loss_ce: 0.024733, loss_kd: 1638.364258
[19:30:44.211] iteration 3750 : loss : 268.634613, loss_ce: 0.022996, loss_kd: 1340.716309
[19:30:49.775] iteration 3760 : loss : 352.042755, loss_ce: 0.020564, loss_kd: 1757.768311
[19:30:55.351] iteration 3770 : loss : 324.398529, loss_ce: 0.023013, loss_kd: 1619.544800
[19:31:00.907] iteration 3780 : loss : 274.390228, loss_ce: 0.022274, loss_kd: 1369.494995
[19:31:06.487] iteration 3790 : loss : 307.218292, loss_ce: 0.019166, loss_kd: 1533.640869
[19:31:12.050] iteration 3800 : loss : 309.735016, loss_ce: 0.016240, loss_kd: 1546.197388
[19:31:17.622] iteration 3810 : loss : 242.648941, loss_ce: 0.022578, loss_kd: 1210.768921
[19:31:23.183] iteration 3820 : loss : 287.713409, loss_ce: 0.024711, loss_kd: 1436.112549
[19:31:28.752] iteration 3830 : loss : 289.861816, loss_ce: 0.026719, loss_kd: 1446.827393
[19:31:34.310] iteration 3840 : loss : 225.399063, loss_ce: 0.030800, loss_kd: 1124.550903
[19:31:39.880] iteration 3850 : loss : 267.020355, loss_ce: 0.027711, loss_kd: 1332.603394
[19:31:45.440] iteration 3860 : loss : 363.517151, loss_ce: 0.036925, loss_kd: 1815.121826
[19:31:51.012] iteration 3870 : loss : 307.782593, loss_ce: 0.019491, loss_kd: 1536.467041
[19:31:56.577] iteration 3880 : loss : 320.369690, loss_ce: 0.031078, loss_kd: 1599.400391
[19:32:02.149] iteration 3890 : loss : 225.275986, loss_ce: 0.023976, loss_kd: 1123.912598
[19:32:07.715] iteration 3900 : loss : 270.738159, loss_ce: 0.023501, loss_kd: 1351.266357
[19:32:13.290] iteration 3910 : loss : 268.902252, loss_ce: 0.018266, loss_kd: 1342.070801
[19:32:18.848] iteration 3920 : loss : 336.628540, loss_ce: 0.012333, loss_kd: 1680.749268
[19:32:24.425] iteration 3930 : loss : 337.127319, loss_ce: 0.023163, loss_kd: 1683.199463
[19:32:29.996] iteration 3940 : loss : 261.656860, loss_ce: 0.019093, loss_kd: 1305.798462
[19:32:35.575] iteration 3950 : loss : 285.133209, loss_ce: 0.020600, loss_kd: 1423.208252
[19:32:41.139] iteration 3960 : loss : 247.527359, loss_ce: 0.016900, loss_kd: 1235.179932
[19:32:46.711] iteration 3970 : loss : 334.157471, loss_ce: 0.027869, loss_kd: 1668.345459
[19:32:52.275] iteration 3980 : loss : 248.039062, loss_ce: 0.014348, loss_kd: 1237.734009
[19:32:57.843] iteration 3990 : loss : 266.878815, loss_ce: 0.023543, loss_kd: 1331.944214
[19:33:03.412] iteration 4000 : loss : 284.182159, loss_ce: 0.025699, loss_kd: 1418.449951
[19:33:08.986] iteration 4010 : loss : 392.297821, loss_ce: 0.026593, loss_kd: 1959.042114
[19:33:14.552] iteration 4020 : loss : 338.610626, loss_ce: 0.028376, loss_kd: 1690.574463
[19:33:20.121] iteration 4030 : loss : 254.671570, loss_ce: 0.015479, loss_kd: 1270.941162
[19:33:25.684] iteration 4040 : loss : 285.196899, loss_ce: 0.024226, loss_kd: 1423.523071
[19:33:31.261] iteration 4050 : loss : 291.237152, loss_ce: 0.030670, loss_kd: 1453.687744
[19:33:36.825] iteration 4060 : loss : 247.994263, loss_ce: 0.033326, loss_kd: 1237.476074
[19:33:42.403] iteration 4070 : loss : 246.269485, loss_ce: 0.032425, loss_kd: 1228.856812
[19:33:47.961] iteration 4080 : loss : 349.592255, loss_ce: 0.034843, loss_kd: 1745.492676
[19:33:53.531] iteration 4090 : loss : 251.375702, loss_ce: 0.022274, loss_kd: 1254.421143
[19:33:59.090] iteration 4100 : loss : 269.523132, loss_ce: 0.023398, loss_kd: 1345.195312
[19:34:04.666] iteration 4110 : loss : 286.070648, loss_ce: 0.021722, loss_kd: 1427.853394
[19:34:10.225] iteration 4120 : loss : 274.533203, loss_ce: 0.028379, loss_kd: 1370.192383
[19:34:15.793] iteration 4130 : loss : 212.961273, loss_ce: 0.024526, loss_kd: 1062.318237
[19:34:21.353] iteration 4140 : loss : 228.973923, loss_ce: 0.023355, loss_kd: 1142.415161
[19:34:26.929] iteration 4150 : loss : 257.396179, loss_ce: 0.020147, loss_kd: 1284.536133
[19:34:32.488] iteration 4160 : loss : 297.060974, loss_ce: 0.024279, loss_kd: 1482.830322
[19:34:49.660] iteration 4170 : loss : 294.030273, loss_ce: 0.033352, loss_kd: 1467.686279
[19:34:55.185] iteration 4180 : loss : 203.791595, loss_ce: 0.019519, loss_kd: 1016.522339
[19:35:00.725] iteration 4190 : loss : 253.545334, loss_ce: 0.018980, loss_kd: 1265.251709
[19:35:06.257] iteration 4200 : loss : 227.617630, loss_ce: 0.029573, loss_kd: 1135.624268
[19:35:11.805] iteration 4210 : loss : 237.709961, loss_ce: 0.023966, loss_kd: 1186.140015
[19:35:17.338] iteration 4220 : loss : 321.684143, loss_ce: 0.029565, loss_kd: 1605.958130
[19:35:22.886] iteration 4230 : loss : 205.749680, loss_ce: 0.023032, loss_kd: 1026.292603
[19:35:28.422] iteration 4240 : loss : 243.454575, loss_ce: 0.025149, loss_kd: 1214.852539
[19:35:33.971] iteration 4250 : loss : 290.977692, loss_ce: 0.021176, loss_kd: 1452.455444
[19:35:39.514] iteration 4260 : loss : 261.023743, loss_ce: 0.020833, loss_kd: 1302.631592
[19:35:45.071] iteration 4270 : loss : 227.325211, loss_ce: 0.031095, loss_kd: 1134.138062
[19:35:50.618] iteration 4280 : loss : 298.532257, loss_ce: 0.046391, loss_kd: 1490.156982
[19:35:56.172] iteration 4290 : loss : 225.357803, loss_ce: 0.026590, loss_kd: 1124.341797
[19:36:01.716] iteration 4300 : loss : 292.817810, loss_ce: 0.022156, loss_kd: 1461.643433
[19:36:07.278] iteration 4310 : loss : 278.559601, loss_ce: 0.028545, loss_kd: 1390.293945
[19:36:12.826] iteration 4320 : loss : 272.944733, loss_ce: 0.025720, loss_kd: 1362.281860
[19:36:18.394] iteration 4330 : loss : 206.042801, loss_ce: 0.031959, loss_kd: 1027.755493
[19:36:23.946] iteration 4340 : loss : 233.181473, loss_ce: 0.021632, loss_kd: 1163.484375
[19:36:29.517] iteration 4350 : loss : 238.032516, loss_ce: 0.023988, loss_kd: 1187.638550
[19:36:35.079] iteration 4360 : loss : 222.946335, loss_ce: 0.023790, loss_kd: 1112.308472
[19:36:40.647] iteration 4370 : loss : 290.543915, loss_ce: 0.028776, loss_kd: 1450.255005
[19:36:46.210] iteration 4380 : loss : 229.709991, loss_ce: 0.019304, loss_kd: 1146.090332
[19:36:51.779] iteration 4390 : loss : 302.281860, loss_ce: 0.025327, loss_kd: 1508.895386
[19:36:57.344] iteration 4400 : loss : 296.061646, loss_ce: 0.021734, loss_kd: 1477.840210
[19:37:02.938] iteration 4410 : loss : 308.873657, loss_ce: 0.027423, loss_kd: 1541.889893
[19:37:08.498] iteration 4420 : loss : 236.149200, loss_ce: 0.011718, loss_kd: 1178.326904
[19:37:14.069] iteration 4430 : loss : 240.315811, loss_ce: 0.017470, loss_kd: 1199.123291
[19:37:19.636] iteration 4440 : loss : 222.778534, loss_ce: 0.023668, loss_kd: 1111.428345
[19:37:25.214] iteration 4450 : loss : 226.156021, loss_ce: 0.024738, loss_kd: 1128.327637
[19:37:30.783] iteration 4460 : loss : 218.725571, loss_ce: 0.029757, loss_kd: 1091.168335
[19:37:36.354] iteration 4470 : loss : 231.805862, loss_ce: 0.014971, loss_kd: 1156.594238
[19:37:41.915] iteration 4480 : loss : 257.775055, loss_ce: 0.039953, loss_kd: 1286.411621
[19:37:47.498] iteration 4490 : loss : 299.108795, loss_ce: 0.019450, loss_kd: 1493.067505
[19:37:53.066] iteration 4500 : loss : 243.833405, loss_ce: 0.020300, loss_kd: 1216.726562
[19:37:58.652] iteration 4510 : loss : 361.731293, loss_ce: 0.020014, loss_kd: 1806.129517
[19:38:04.221] iteration 4520 : loss : 300.690857, loss_ce: 0.029241, loss_kd: 1500.980957
[19:38:09.798] iteration 4530 : loss : 333.406738, loss_ce: 0.034034, loss_kd: 1664.568970
[19:38:15.374] iteration 4540 : loss : 436.377747, loss_ce: 0.018303, loss_kd: 2179.431152
[19:38:20.956] iteration 4550 : loss : 251.046158, loss_ce: 0.029403, loss_kd: 1252.773438
[19:38:26.534] iteration 4560 : loss : 189.956833, loss_ce: 0.026772, loss_kd: 947.305298
[19:38:32.116] iteration 4570 : loss : 223.785965, loss_ce: 0.022239, loss_kd: 1116.480469
[19:38:37.688] iteration 4580 : loss : 213.392899, loss_ce: 0.017711, loss_kd: 1064.476318
[19:38:43.272] iteration 4590 : loss : 273.269836, loss_ce: 0.016857, loss_kd: 1363.927979
[19:38:48.848] iteration 4600 : loss : 226.682068, loss_ce: 0.018969, loss_kd: 1130.897705
[19:38:54.437] iteration 4610 : loss : 191.871124, loss_ce: 0.018817, loss_kd: 956.904541
[19:39:00.022] iteration 4620 : loss : 241.050293, loss_ce: 0.040889, loss_kd: 1202.804321
[19:39:05.616] iteration 4630 : loss : 223.864731, loss_ce: 0.021916, loss_kd: 1116.857910
[19:39:11.186] iteration 4640 : loss : 233.058914, loss_ce: 0.028044, loss_kd: 1162.821777
[19:39:16.774] iteration 4650 : loss : 229.609985, loss_ce: 0.022775, loss_kd: 1145.609863
[19:39:22.358] iteration 4660 : loss : 318.882202, loss_ce: 0.031521, loss_kd: 1591.931030
[19:39:27.943] iteration 4670 : loss : 204.528442, loss_ce: 0.025025, loss_kd: 1020.150452
[19:39:33.523] iteration 4680 : loss : 279.527100, loss_ce: 0.028762, loss_kd: 1395.208618
[19:39:39.119] iteration 4690 : loss : 246.890778, loss_ce: 0.026299, loss_kd: 1232.002563
[19:39:44.701] iteration 4700 : loss : 236.162277, loss_ce: 0.016814, loss_kd: 1178.386475
[19:39:50.293] iteration 4710 : loss : 233.113708, loss_ce: 0.028054, loss_kd: 1163.074341
[19:39:55.879] iteration 4720 : loss : 301.408722, loss_ce: 0.017612, loss_kd: 1504.577148
[19:40:01.479] iteration 4730 : loss : 277.872955, loss_ce: 0.032389, loss_kd: 1386.895508
[19:40:07.064] iteration 4740 : loss : 234.150909, loss_ce: 0.020898, loss_kd: 1168.296021
[19:40:12.654] iteration 4750 : loss : 288.686493, loss_ce: 0.031484, loss_kd: 1440.972290
[19:40:18.232] iteration 4760 : loss : 239.222565, loss_ce: 0.039101, loss_kd: 1193.672241
[19:40:23.823] iteration 4770 : loss : 259.577484, loss_ce: 0.024051, loss_kd: 1295.441528
[19:40:29.406] iteration 4780 : loss : 311.968719, loss_ce: 0.017633, loss_kd: 1557.406494
[19:40:34.999] iteration 4790 : loss : 394.789032, loss_ce: 0.033138, loss_kd: 1971.477173
[19:40:40.582] iteration 4800 : loss : 232.585052, loss_ce: 0.038207, loss_kd: 1160.465820
[19:40:46.164] iteration 4810 : loss : 218.361496, loss_ce: 0.017291, loss_kd: 1089.322144
[19:40:51.734] iteration 4820 : loss : 211.573059, loss_ce: 0.015978, loss_kd: 1055.448120
[19:40:57.324] iteration 4830 : loss : 278.317078, loss_ce: 0.018391, loss_kd: 1389.165894
[19:41:02.906] iteration 4840 : loss : 321.810638, loss_ce: 0.021543, loss_kd: 1606.595215
[19:41:08.492] iteration 4850 : loss : 397.764343, loss_ce: 0.020324, loss_kd: 1986.420288
[19:41:14.064] iteration 4860 : loss : 273.700287, loss_ce: 0.030501, loss_kd: 1366.033447
[19:41:19.651] iteration 4870 : loss : 260.198792, loss_ce: 0.031459, loss_kd: 1298.542725
[19:41:25.215] iteration 4880 : loss : 236.276978, loss_ce: 0.023260, loss_kd: 1178.934937
[19:41:30.795] iteration 4890 : loss : 221.097977, loss_ce: 0.022371, loss_kd: 1103.062500
[19:41:36.360] iteration 4900 : loss : 273.359497, loss_ce: 0.027181, loss_kd: 1364.280029
[19:41:41.941] iteration 4910 : loss : 266.346619, loss_ce: 0.027380, loss_kd: 1329.278687
[19:41:47.502] iteration 4920 : loss : 250.008316, loss_ce: 0.035295, loss_kd: 1247.570312
[19:41:53.088] iteration 4930 : loss : 239.254044, loss_ce: 0.023139, loss_kd: 1193.835815
[19:41:58.651] iteration 4940 : loss : 271.461487, loss_ce: 0.027923, loss_kd: 1354.854614
[19:42:04.232] iteration 4950 : loss : 244.421692, loss_ce: 0.026101, loss_kd: 1219.640747
[19:42:09.810] iteration 4960 : loss : 242.563919, loss_ce: 0.016618, loss_kd: 1210.389282
[19:42:15.386] iteration 4970 : loss : 305.271881, loss_ce: 0.019261, loss_kd: 1523.852905
[19:42:20.949] iteration 4980 : loss : 239.100616, loss_ce: 0.021073, loss_kd: 1193.011841
[19:42:26.535] iteration 4990 : loss : 215.428787, loss_ce: 0.027918, loss_kd: 1074.691528
[19:42:32.096] iteration 5000 : loss : 183.837723, loss_ce: 0.016337, loss_kd: 916.749023
[19:42:37.687] iteration 5010 : loss : 226.980606, loss_ce: 0.027657, loss_kd: 1132.431396
[19:42:43.259] iteration 5020 : loss : 257.964996, loss_ce: 0.021156, loss_kd: 1287.393066
[19:42:48.848] iteration 5030 : loss : 309.615295, loss_ce: 0.028124, loss_kd: 1545.607056
[19:42:54.419] iteration 5040 : loss : 265.869293, loss_ce: 0.024091, loss_kd: 1326.892090
[19:43:00.002] iteration 5050 : loss : 398.547333, loss_ce: 0.040823, loss_kd: 1990.244507
[19:43:05.576] iteration 5060 : loss : 191.804321, loss_ce: 0.024300, loss_kd: 956.584534
[19:43:11.155] iteration 5070 : loss : 263.495026, loss_ce: 0.016988, loss_kd: 1315.047241
[19:43:16.724] iteration 5080 : loss : 435.182343, loss_ce: 0.027584, loss_kd: 2173.482178
[19:43:22.299] iteration 5090 : loss : 253.382980, loss_ce: 0.015573, loss_kd: 1264.487061
[19:43:27.861] iteration 5100 : loss : 259.577667, loss_ce: 0.019040, loss_kd: 1295.411621
[19:43:33.443] iteration 5110 : loss : 298.096741, loss_ce: 0.018936, loss_kd: 1488.026001
[19:43:39.004] iteration 5120 : loss : 170.883362, loss_ce: 0.032343, loss_kd: 851.965149
[19:43:44.582] iteration 5130 : loss : 363.091705, loss_ce: 0.018305, loss_kd: 1813.021729
[19:43:50.143] iteration 5140 : loss : 228.733948, loss_ce: 0.023230, loss_kd: 1141.234009
[19:43:55.713] iteration 5150 : loss : 223.670563, loss_ce: 0.017897, loss_kd: 1115.924927
[19:44:01.279] iteration 5160 : loss : 293.732361, loss_ce: 0.020167, loss_kd: 1466.220703
[19:44:06.854] iteration 5170 : loss : 326.362305, loss_ce: 0.026891, loss_kd: 1629.348145
[19:44:12.423] iteration 5180 : loss : 234.101135, loss_ce: 0.033451, loss_kd: 1168.082886
[19:44:17.999] iteration 5190 : loss : 287.176208, loss_ce: 0.016257, loss_kd: 1433.456299
[19:44:23.566] iteration 5200 : loss : 254.022476, loss_ce: 0.022781, loss_kd: 1267.681396
[19:44:28.850] iteration 5210 : loss : 240.705597, loss_ce: 0.029365, loss_kd: 1201.042603
[19:44:29.591] save model to ./debug_fixed_tpgm\continual_surgical_tpgm_stage1_epoch_4.pth
[19:44:29.594] Running TPGM constraint optimization after epoch 5
[19:49:33.422] iteration 5220 : loss : 275.210510, loss_ce: 0.025809, loss_kd: 1373.596436
[19:49:38.944] iteration 5230 : loss : 254.891373, loss_ce: 0.033703, loss_kd: 1272.012573
[19:49:44.459] iteration 5240 : loss : 277.757935, loss_ce: 0.020245, loss_kd: 1386.316040
[19:49:49.994] iteration 5250 : loss : 376.633331, loss_ce: 0.019309, loss_kd: 1880.756104
[19:49:55.512] iteration 5260 : loss : 196.794113, loss_ce: 0.024473, loss_kd: 981.509033
[19:50:01.046] iteration 5270 : loss : 240.911453, loss_ce: 0.028910, loss_kd: 1202.104004
[19:50:06.572] iteration 5280 : loss : 244.031250, loss_ce: 0.033123, loss_kd: 1217.712402
[19:50:12.112] iteration 5290 : loss : 216.239853, loss_ce: 0.016909, loss_kd: 1078.720215
[19:50:17.642] iteration 5300 : loss : 265.557922, loss_ce: 0.029185, loss_kd: 1325.374023
[19:50:23.189] iteration 5310 : loss : 279.247437, loss_ce: 0.018717, loss_kd: 1393.808960
[19:50:28.726] iteration 5320 : loss : 243.231827, loss_ce: 0.021679, loss_kd: 1213.707764
[19:50:34.269] iteration 5330 : loss : 241.724335, loss_ce: 0.024805, loss_kd: 1206.175293
[19:50:39.800] iteration 5340 : loss : 252.799347, loss_ce: 0.033336, loss_kd: 1261.579834
[19:50:45.345] iteration 5350 : loss : 315.690887, loss_ce: 0.025901, loss_kd: 1576.021484
[19:50:50.885] iteration 5360 : loss : 225.330078, loss_ce: 0.032834, loss_kd: 1124.244507
[19:50:56.434] iteration 5370 : loss : 292.810883, loss_ce: 0.014313, loss_kd: 1461.589355
[19:51:01.977] iteration 5380 : loss : 208.703201, loss_ce: 0.014646, loss_kd: 1041.095581
[19:51:07.522] iteration 5390 : loss : 229.224487, loss_ce: 0.028086, loss_kd: 1143.651855
[19:51:13.063] iteration 5400 : loss : 207.768600, loss_ce: 0.033756, loss_kd: 1036.434082
[19:51:18.615] iteration 5410 : loss : 266.706573, loss_ce: 0.026380, loss_kd: 1331.062256
[19:51:24.154] iteration 5420 : loss : 217.801041, loss_ce: 0.030227, loss_kd: 1086.557007
[19:51:29.703] iteration 5430 : loss : 273.340637, loss_ce: 0.019218, loss_kd: 1364.341675
[19:51:35.243] iteration 5440 : loss : 256.022308, loss_ce: 0.019773, loss_kd: 1277.640015
[19:51:40.801] iteration 5450 : loss : 204.321396, loss_ce: 0.015871, loss_kd: 1019.147583
[19:51:46.341] iteration 5460 : loss : 153.925461, loss_ce: 0.016247, loss_kd: 767.099121
[19:51:51.899] iteration 5470 : loss : 268.564148, loss_ce: 0.031509, loss_kd: 1340.372437
[19:51:57.450] iteration 5480 : loss : 204.319580, loss_ce: 0.016403, loss_kd: 1019.154846
[19:52:03.008] iteration 5490 : loss : 236.577499, loss_ce: 0.033789, loss_kd: 1180.457886
[19:52:08.563] iteration 5500 : loss : 215.757019, loss_ce: 0.018336, loss_kd: 1076.344727
[19:52:14.127] iteration 5510 : loss : 218.376205, loss_ce: 0.015941, loss_kd: 1089.446899
[19:52:19.681] iteration 5520 : loss : 284.613129, loss_ce: 0.017502, loss_kd: 1420.600220
[19:52:25.243] iteration 5530 : loss : 217.536728, loss_ce: 0.025783, loss_kd: 1085.240601
[19:52:30.800] iteration 5540 : loss : 250.049759, loss_ce: 0.019752, loss_kd: 1247.822754
[19:52:36.359] iteration 5550 : loss : 220.972153, loss_ce: 0.018808, loss_kd: 1102.423950
[19:52:41.921] iteration 5560 : loss : 367.504395, loss_ce: 0.024946, loss_kd: 1835.045044
[19:52:47.490] iteration 5570 : loss : 295.392792, loss_ce: 0.019590, loss_kd: 1474.507690
[19:52:53.047] iteration 5580 : loss : 232.859879, loss_ce: 0.014621, loss_kd: 1161.817505
[19:52:58.615] iteration 5590 : loss : 188.778198, loss_ce: 0.020831, loss_kd: 941.449768
[19:53:04.171] iteration 5600 : loss : 273.366180, loss_ce: 0.013645, loss_kd: 1364.375977
[19:53:09.751] iteration 5610 : loss : 232.675873, loss_ce: 0.016849, loss_kd: 1160.881348
[19:53:15.307] iteration 5620 : loss : 273.860748, loss_ce: 0.022787, loss_kd: 1366.892700
[19:53:20.876] iteration 5630 : loss : 365.441528, loss_ce: 0.020613, loss_kd: 1824.794922
[19:53:26.429] iteration 5640 : loss : 186.066620, loss_ce: 0.015356, loss_kd: 927.942505
[19:53:31.995] iteration 5650 : loss : 222.826599, loss_ce: 0.017715, loss_kd: 1111.699219
[19:53:37.560] iteration 5660 : loss : 185.069153, loss_ce: 0.016239, loss_kd: 922.901245
[19:53:43.134] iteration 5670 : loss : 254.479233, loss_ce: 0.022044, loss_kd: 1269.960938
[19:53:48.693] iteration 5680 : loss : 270.957886, loss_ce: 0.021502, loss_kd: 1352.340210
[19:53:54.261] iteration 5690 : loss : 257.833832, loss_ce: 0.025702, loss_kd: 1286.742432
[19:53:59.824] iteration 5700 : loss : 206.458878, loss_ce: 0.016552, loss_kd: 1029.840332
[19:54:05.405] iteration 5710 : loss : 239.943283, loss_ce: 0.018212, loss_kd: 1197.284546
[19:54:10.961] iteration 5720 : loss : 186.871170, loss_ce: 0.022930, loss_kd: 931.964844
[19:54:16.554] iteration 5730 : loss : 193.289215, loss_ce: 0.020708, loss_kd: 963.951172
[19:54:22.108] iteration 5740 : loss : 203.444519, loss_ce: 0.013745, loss_kd: 1014.802063
[19:54:27.677] iteration 5750 : loss : 240.785294, loss_ce: 0.015290, loss_kd: 1201.450562
[19:54:33.242] iteration 5760 : loss : 253.728394, loss_ce: 0.020193, loss_kd: 1266.191040
[19:54:38.814] iteration 5770 : loss : 269.382355, loss_ce: 0.014554, loss_kd: 1344.469971
[19:54:44.372] iteration 5780 : loss : 300.428741, loss_ce: 0.034450, loss_kd: 1499.693359
[19:54:49.945] iteration 5790 : loss : 236.959839, loss_ce: 0.021652, loss_kd: 1182.334717
[19:54:55.504] iteration 5800 : loss : 252.732758, loss_ce: 0.012602, loss_kd: 1261.251587
[19:55:01.080] iteration 5810 : loss : 277.090088, loss_ce: 0.024362, loss_kd: 1382.999634
[19:55:06.639] iteration 5820 : loss : 188.318802, loss_ce: 0.018405, loss_kd: 939.218567
[19:55:12.208] iteration 5830 : loss : 270.909576, loss_ce: 0.013413, loss_kd: 1352.112549
[19:55:17.762] iteration 5840 : loss : 254.733536, loss_ce: 0.025712, loss_kd: 1271.212402
[19:55:23.323] iteration 5850 : loss : 226.700089, loss_ce: 0.022897, loss_kd: 1131.039551
[19:55:28.886] iteration 5860 : loss : 207.915176, loss_ce: 0.023927, loss_kd: 1037.091553
[19:55:34.456] iteration 5870 : loss : 208.528702, loss_ce: 0.026017, loss_kd: 1040.207275
[19:55:40.019] iteration 5880 : loss : 166.271164, loss_ce: 0.023534, loss_kd: 828.927917
[19:55:45.586] iteration 5890 : loss : 353.441406, loss_ce: 0.017798, loss_kd: 1764.789673
[19:55:51.141] iteration 5900 : loss : 326.107025, loss_ce: 0.018327, loss_kd: 1628.112671
[19:55:56.708] iteration 5910 : loss : 201.174438, loss_ce: 0.023243, loss_kd: 1003.383606
[19:56:02.268] iteration 5920 : loss : 205.350693, loss_ce: 0.022507, loss_kd: 1024.261841
[19:56:07.838] iteration 5930 : loss : 220.534531, loss_ce: 0.018013, loss_kd: 1100.273682
[19:56:13.397] iteration 5940 : loss : 245.140991, loss_ce: 0.032449, loss_kd: 1223.254150
[19:56:18.974] iteration 5950 : loss : 314.765533, loss_ce: 0.024962, loss_kd: 1571.364624
[19:56:24.537] iteration 5960 : loss : 248.439468, loss_ce: 0.020965, loss_kd: 1239.746948
[19:56:30.108] iteration 5970 : loss : 265.281952, loss_ce: 0.023341, loss_kd: 1323.955811
[19:56:35.670] iteration 5980 : loss : 252.086609, loss_ce: 0.026183, loss_kd: 1257.964355
[19:56:41.242] iteration 5990 : loss : 260.104034, loss_ce: 0.026715, loss_kd: 1298.057129
[19:56:46.799] iteration 6000 : loss : 230.266586, loss_ce: 0.016453, loss_kd: 1148.901489
[19:56:52.374] iteration 6010 : loss : 257.270935, loss_ce: 0.030050, loss_kd: 1283.891724
[19:56:57.932] iteration 6020 : loss : 273.919464, loss_ce: 0.015763, loss_kd: 1367.121582
[19:57:03.499] iteration 6030 : loss : 221.812531, loss_ce: 0.015607, loss_kd: 1106.619141
[19:57:09.051] iteration 6040 : loss : 270.095337, loss_ce: 0.021507, loss_kd: 1348.045532
[19:57:14.623] iteration 6050 : loss : 222.316635, loss_ce: 0.017777, loss_kd: 1109.213745
[19:57:20.179] iteration 6060 : loss : 190.106735, loss_ce: 0.028989, loss_kd: 948.069458
[19:57:25.752] iteration 6070 : loss : 204.080017, loss_ce: 0.017775, loss_kd: 1017.966736
[19:57:31.308] iteration 6080 : loss : 209.623398, loss_ce: 0.015751, loss_kd: 1045.656860
[19:57:36.882] iteration 6090 : loss : 227.423279, loss_ce: 0.029690, loss_kd: 1134.657349
[19:57:42.437] iteration 6100 : loss : 200.844574, loss_ce: 0.022417, loss_kd: 1001.836121
[19:57:48.011] iteration 6110 : loss : 305.062561, loss_ce: 0.021165, loss_kd: 1522.881592
[19:57:53.568] iteration 6120 : loss : 232.066742, loss_ce: 0.012088, loss_kd: 1157.910400
[19:57:59.139] iteration 6130 : loss : 200.295258, loss_ce: 0.013581, loss_kd: 999.073547
[19:58:04.698] iteration 6140 : loss : 218.855774, loss_ce: 0.013032, loss_kd: 1091.836182
[19:58:10.259] iteration 6150 : loss : 178.154846, loss_ce: 0.016245, loss_kd: 888.358521
[19:58:15.815] iteration 6160 : loss : 232.092041, loss_ce: 0.013149, loss_kd: 1157.950195
[19:58:21.380] iteration 6170 : loss : 205.775162, loss_ce: 0.027537, loss_kd: 1026.459961
[19:58:26.936] iteration 6180 : loss : 245.207977, loss_ce: 0.015243, loss_kd: 1223.618774
[19:58:32.505] iteration 6190 : loss : 298.541779, loss_ce: 0.027200, loss_kd: 1490.273438
[19:58:38.059] iteration 6200 : loss : 228.302841, loss_ce: 0.019803, loss_kd: 1139.118164
[19:58:43.623] iteration 6210 : loss : 209.692657, loss_ce: 0.021554, loss_kd: 1046.034180
[19:58:49.184] iteration 6220 : loss : 294.539673, loss_ce: 0.021311, loss_kd: 1470.255981
[19:58:54.755] iteration 6230 : loss : 271.262756, loss_ce: 0.026829, loss_kd: 1353.876221
[19:59:00.315] iteration 6240 : loss : 245.878052, loss_ce: 0.025524, loss_kd: 1226.949951
[19:59:05.890] iteration 6250 : loss : 222.228989, loss_ce: 0.022163, loss_kd: 1108.723999
[19:59:23.321] iteration 6260 : loss : 301.610382, loss_ce: 0.023277, loss_kd: 1505.650024
[19:59:28.865] iteration 6270 : loss : 238.712143, loss_ce: 0.022349, loss_kd: 1191.124756
[19:59:34.398] iteration 6280 : loss : 175.018234, loss_ce: 0.026421, loss_kd: 872.641418
[19:59:39.944] iteration 6290 : loss : 269.058014, loss_ce: 0.024700, loss_kd: 1342.862549
[19:59:45.483] iteration 6300 : loss : 229.436142, loss_ce: 0.024138, loss_kd: 1144.753906
[19:59:51.032] iteration 6310 : loss : 226.013626, loss_ce: 0.014236, loss_kd: 1127.605713
[19:59:56.573] iteration 6320 : loss : 159.698578, loss_ce: 0.024828, loss_kd: 796.055298
[20:00:02.123] iteration 6330 : loss : 214.372635, loss_ce: 0.018817, loss_kd: 1069.452881
[20:00:07.664] iteration 6340 : loss : 222.797394, loss_ce: 0.017848, loss_kd: 1111.571289
[20:00:13.219] iteration 6350 : loss : 249.010376, loss_ce: 0.015910, loss_kd: 1242.610352
[20:00:18.766] iteration 6360 : loss : 200.381180, loss_ce: 0.017130, loss_kd: 999.524170
[20:00:24.323] iteration 6370 : loss : 241.871338, loss_ce: 0.019496, loss_kd: 1206.938477
[20:00:29.872] iteration 6380 : loss : 329.882233, loss_ce: 0.023127, loss_kd: 1647.000122
[20:00:35.437] iteration 6390 : loss : 251.057251, loss_ce: 0.011070, loss_kd: 1252.893555
[20:00:40.984] iteration 6400 : loss : 296.518036, loss_ce: 0.037418, loss_kd: 1480.128174
[20:00:46.546] iteration 6410 : loss : 217.081757, loss_ce: 0.020607, loss_kd: 1082.957886
[20:00:52.103] iteration 6420 : loss : 296.962830, loss_ce: 0.017885, loss_kd: 1482.359253
[20:00:57.661] iteration 6430 : loss : 207.974533, loss_ce: 0.017846, loss_kd: 1037.453735
[20:01:03.213] iteration 6440 : loss : 190.880432, loss_ce: 0.018049, loss_kd: 951.995422
[20:01:08.779] iteration 6450 : loss : 248.440048, loss_ce: 0.024022, loss_kd: 1239.748901
[20:01:14.341] iteration 6460 : loss : 205.873306, loss_ce: 0.015865, loss_kd: 1026.932007
[20:01:19.906] iteration 6470 : loss : 223.830261, loss_ce: 0.011135, loss_kd: 1116.746826
[20:01:25.458] iteration 6480 : loss : 253.146591, loss_ce: 0.021447, loss_kd: 1263.268188
[20:01:31.020] iteration 6490 : loss : 218.160110, loss_ce: 0.012922, loss_kd: 1088.411255
[20:01:36.577] iteration 6500 : loss : 283.020813, loss_ce: 0.023016, loss_kd: 1412.681641
[20:01:42.140] iteration 6510 : loss : 231.596298, loss_ce: 0.031423, loss_kd: 1155.553223
[20:01:47.692] iteration 6520 : loss : 225.694748, loss_ce: 0.015778, loss_kd: 1126.060303
[20:01:53.262] iteration 6530 : loss : 195.602493, loss_ce: 0.027092, loss_kd: 975.568481
[20:01:58.818] iteration 6540 : loss : 226.663315, loss_ce: 0.038077, loss_kd: 1130.882446
[20:02:04.380] iteration 6550 : loss : 172.868683, loss_ce: 0.016599, loss_kd: 861.872192
[20:02:09.939] iteration 6560 : loss : 189.399368, loss_ce: 0.021797, loss_kd: 944.565186
[20:02:15.510] iteration 6570 : loss : 212.335815, loss_ce: 0.020150, loss_kd: 1059.229614
[20:02:21.075] iteration 6580 : loss : 189.274689, loss_ce: 0.021481, loss_kd: 943.928589
[20:02:26.643] iteration 6590 : loss : 464.633179, loss_ce: 0.024035, loss_kd: 2320.742432
[20:02:32.199] iteration 6600 : loss : 243.547668, loss_ce: 0.031351, loss_kd: 1215.302490
[20:02:37.769] iteration 6610 : loss : 239.473511, loss_ce: 0.026313, loss_kd: 1194.899780
[20:02:43.319] iteration 6620 : loss : 231.369522, loss_ce: 0.027207, loss_kd: 1154.395386
[20:02:48.882] iteration 6630 : loss : 224.899368, loss_ce: 0.015871, loss_kd: 1121.972534
[20:02:54.438] iteration 6640 : loss : 250.626648, loss_ce: 0.021460, loss_kd: 1250.718750
[20:03:00.002] iteration 6650 : loss : 204.049484, loss_ce: 0.023344, loss_kd: 1017.789062
[20:03:05.556] iteration 6660 : loss : 246.138092, loss_ce: 0.019605, loss_kd: 1228.254761
[20:03:11.125] iteration 6670 : loss : 232.501129, loss_ce: 0.016805, loss_kd: 1160.097168
[20:03:16.680] iteration 6680 : loss : 212.196716, loss_ce: 0.019670, loss_kd: 1058.563354
[20:03:22.250] iteration 6690 : loss : 223.028610, loss_ce: 0.017742, loss_kd: 1112.681885
[20:03:27.808] iteration 6700 : loss : 217.423935, loss_ce: 0.014437, loss_kd: 1084.701172
[20:03:33.381] iteration 6710 : loss : 235.823013, loss_ce: 0.012651, loss_kd: 1176.676636
[20:03:38.939] iteration 6720 : loss : 219.292053, loss_ce: 0.016681, loss_kd: 1093.928223
[20:03:44.506] iteration 6730 : loss : 286.649109, loss_ce: 0.015915, loss_kd: 1430.823364
[20:03:50.064] iteration 6740 : loss : 141.058655, loss_ce: 0.021467, loss_kd: 702.852722
[20:03:55.639] iteration 6750 : loss : 220.787323, loss_ce: 0.026660, loss_kd: 1101.497925
[20:04:01.205] iteration 6760 : loss : 241.290848, loss_ce: 0.025216, loss_kd: 1204.034790
[20:04:06.775] iteration 6770 : loss : 201.277679, loss_ce: 0.031924, loss_kd: 1003.918945
[20:04:12.336] iteration 6780 : loss : 182.080811, loss_ce: 0.043090, loss_kd: 907.956543
[20:04:17.904] iteration 6790 : loss : 243.856354, loss_ce: 0.023073, loss_kd: 1216.825195
[20:04:23.472] iteration 6800 : loss : 220.160019, loss_ce: 0.035596, loss_kd: 1098.337646
[20:04:29.056] iteration 6810 : loss : 237.121521, loss_ce: 0.018791, loss_kd: 1183.184448
[20:04:34.617] iteration 6820 : loss : 211.596649, loss_ce: 0.020502, loss_kd: 1055.581421
[20:04:40.189] iteration 6830 : loss : 266.137085, loss_ce: 0.021130, loss_kd: 1328.200195
[20:04:45.750] iteration 6840 : loss : 275.022766, loss_ce: 0.018414, loss_kd: 1372.663086
[20:04:51.326] iteration 6850 : loss : 290.099487, loss_ce: 0.019791, loss_kd: 1447.989746
[20:04:56.893] iteration 6860 : loss : 197.907928, loss_ce: 0.033751, loss_kd: 987.114136
[20:05:02.468] iteration 6870 : loss : 260.410706, loss_ce: 0.030959, loss_kd: 1299.600464
[20:05:08.032] iteration 6880 : loss : 194.607971, loss_ce: 0.026842, loss_kd: 970.588745
[20:05:13.604] iteration 6890 : loss : 229.631729, loss_ce: 0.023410, loss_kd: 1145.732056
[20:05:19.176] iteration 6900 : loss : 205.464966, loss_ce: 0.025891, loss_kd: 1024.757568
[20:05:24.768] iteration 6910 : loss : 210.652100, loss_ce: 0.015421, loss_kd: 1050.845703
[20:05:30.332] iteration 6920 : loss : 190.839462, loss_ce: 0.020895, loss_kd: 951.745117
[20:05:35.914] iteration 6930 : loss : 185.910599, loss_ce: 0.025243, loss_kd: 927.132874
[20:05:41.477] iteration 6940 : loss : 229.343079, loss_ce: 0.023207, loss_kd: 1144.244751
[20:05:47.056] iteration 6950 : loss : 225.527649, loss_ce: 0.024620, loss_kd: 1125.203979
[20:05:52.628] iteration 6960 : loss : 203.592239, loss_ce: 0.019237, loss_kd: 1015.535645
[20:05:58.219] iteration 6970 : loss : 207.455856, loss_ce: 0.019137, loss_kd: 1034.834229
[20:06:03.777] iteration 6980 : loss : 195.865738, loss_ce: 0.030299, loss_kd: 976.894165
[20:06:09.358] iteration 6990 : loss : 191.550430, loss_ce: 0.027472, loss_kd: 955.331177
[20:06:14.923] iteration 7000 : loss : 183.071243, loss_ce: 0.019722, loss_kd: 912.893372
[20:06:20.501] iteration 7010 : loss : 177.565369, loss_ce: 0.011611, loss_kd: 885.370422
[20:06:26.069] iteration 7020 : loss : 248.686966, loss_ce: 0.017409, loss_kd: 1240.997681
[20:06:31.648] iteration 7030 : loss : 183.894119, loss_ce: 0.031881, loss_kd: 917.018433
[20:06:37.216] iteration 7040 : loss : 249.006485, loss_ce: 0.030450, loss_kd: 1242.568604
[20:06:42.801] iteration 7050 : loss : 195.574387, loss_ce: 0.017519, loss_kd: 975.443970
[20:06:48.371] iteration 7060 : loss : 213.474915, loss_ce: 0.019827, loss_kd: 1064.930664
[20:06:53.948] iteration 7070 : loss : 174.564407, loss_ce: 0.017691, loss_kd: 870.434814
[20:06:59.521] iteration 7080 : loss : 234.908356, loss_ce: 0.022801, loss_kd: 1172.092896
[20:07:05.102] iteration 7090 : loss : 223.684860, loss_ce: 0.016104, loss_kd: 1115.979736
[20:07:10.671] iteration 7100 : loss : 314.896301, loss_ce: 0.018914, loss_kd: 1572.052612
[20:07:16.255] iteration 7110 : loss : 429.020813, loss_ce: 0.031958, loss_kd: 2142.643555
[20:07:21.825] iteration 7120 : loss : 325.988403, loss_ce: 0.016516, loss_kd: 1627.503174
[20:07:27.405] iteration 7130 : loss : 247.590820, loss_ce: 0.028093, loss_kd: 1235.502686
[20:07:32.983] iteration 7140 : loss : 211.729385, loss_ce: 0.013467, loss_kd: 1056.167603
[20:07:38.566] iteration 7150 : loss : 135.632080, loss_ce: 0.024750, loss_kd: 675.734741
[20:07:44.133] iteration 7160 : loss : 207.110077, loss_ce: 0.018654, loss_kd: 1033.111206
[20:07:49.711] iteration 7170 : loss : 171.089233, loss_ce: 0.016082, loss_kd: 853.016418
[20:07:55.284] iteration 7180 : loss : 190.260895, loss_ce: 0.018113, loss_kd: 948.842041
[20:08:00.865] iteration 7190 : loss : 162.182983, loss_ce: 0.021589, loss_kd: 808.467957
[20:08:06.438] iteration 7200 : loss : 199.808746, loss_ce: 0.022631, loss_kd: 996.623535
[20:08:12.019] iteration 7210 : loss : 188.783936, loss_ce: 0.014652, loss_kd: 941.474304
[20:08:17.594] iteration 7220 : loss : 238.271408, loss_ce: 0.022092, loss_kd: 1188.921143
[20:08:23.182] iteration 7230 : loss : 221.915710, loss_ce: 0.029574, loss_kd: 1107.174194
[20:08:28.754] iteration 7240 : loss : 216.513077, loss_ce: 0.010015, loss_kd: 1080.167725
[20:08:34.344] iteration 7250 : loss : 201.254440, loss_ce: 0.014265, loss_kd: 1003.812927
[20:08:39.931] iteration 7260 : loss : 253.334412, loss_ce: 0.012037, loss_kd: 1264.199097
[20:08:45.525] iteration 7270 : loss : 268.146027, loss_ce: 0.018963, loss_kd: 1338.276611
[20:08:51.097] iteration 7280 : loss : 251.761688, loss_ce: 0.019136, loss_kd: 1256.387329
[20:08:56.685] iteration 7290 : loss : 205.944687, loss_ce: 0.018263, loss_kd: 1027.291260
[20:08:59.299] Running TPGM constraint optimization after epoch 7
[20:13:53.581] iteration 7300 : loss : 179.108093, loss_ce: 0.020558, loss_kd: 893.157471
[20:13:59.127] iteration 7310 : loss : 203.026810, loss_ce: 0.030465, loss_kd: 1012.696106
[20:14:04.667] iteration 7320 : loss : 236.757767, loss_ce: 0.021434, loss_kd: 1181.361084
[20:14:10.219] iteration 7330 : loss : 264.346710, loss_ce: 0.017066, loss_kd: 1319.294312
[20:14:15.762] iteration 7340 : loss : 171.215302, loss_ce: 0.021614, loss_kd: 853.643311
[20:14:21.326] iteration 7350 : loss : 221.064880, loss_ce: 0.021991, loss_kd: 1102.898682
[20:14:26.882] iteration 7360 : loss : 143.637222, loss_ce: 0.013971, loss_kd: 715.716553
[20:14:32.446] iteration 7370 : loss : 242.111343, loss_ce: 0.018292, loss_kd: 1208.110229
[20:14:38.003] iteration 7380 : loss : 245.495621, loss_ce: 0.019141, loss_kd: 1225.091187
[20:14:43.572] iteration 7390 : loss : 242.125717, loss_ce: 0.028895, loss_kd: 1208.191772
[20:14:49.127] iteration 7400 : loss : 162.610428, loss_ce: 0.027178, loss_kd: 810.635254
[20:14:54.697] iteration 7410 : loss : 240.470566, loss_ce: 0.017448, loss_kd: 1199.928101
[20:15:00.255] iteration 7420 : loss : 208.180252, loss_ce: 0.030501, loss_kd: 1038.480957
[20:15:05.833] iteration 7430 : loss : 116.511368, loss_ce: 0.023153, loss_kd: 580.123169
[20:15:11.393] iteration 7440 : loss : 186.277039, loss_ce: 0.010451, loss_kd: 928.980774
[20:15:16.970] iteration 7450 : loss : 191.794998, loss_ce: 0.012408, loss_kd: 956.561157
[20:15:22.545] iteration 7460 : loss : 188.686462, loss_ce: 0.018062, loss_kd: 941.026672
[20:15:28.133] iteration 7470 : loss : 190.910110, loss_ce: 0.021063, loss_kd: 952.103516
[20:15:33.702] iteration 7480 : loss : 150.211197, loss_ce: 0.020456, loss_kd: 748.605347
[20:15:39.289] iteration 7490 : loss : 241.149399, loss_ce: 0.021439, loss_kd: 1203.316650
[20:15:44.858] iteration 7500 : loss : 191.543335, loss_ce: 0.017634, loss_kd: 955.295776
[20:15:50.444] iteration 7510 : loss : 226.653564, loss_ce: 0.025432, loss_kd: 1130.853760
[20:15:56.027] iteration 7520 : loss : 185.334915, loss_ce: 0.023023, loss_kd: 924.051819
[20:16:01.612] iteration 7530 : loss : 211.379089, loss_ce: 0.016603, loss_kd: 1054.509644
[20:16:07.185] iteration 7540 : loss : 238.868454, loss_ce: 0.020509, loss_kd: 1191.947998
[20:16:12.769] iteration 7550 : loss : 211.762161, loss_ce: 0.016271, loss_kd: 1056.420288
[20:16:18.343] iteration 7560 : loss : 153.397751, loss_ce: 0.016678, loss_kd: 764.591309
[20:16:23.940] iteration 7570 : loss : 146.293335, loss_ce: 0.024087, loss_kd: 729.024292
[20:16:29.527] iteration 7580 : loss : 181.384018, loss_ce: 0.024221, loss_kd: 904.469910
[20:16:35.161] iteration 7590 : loss : 183.062317, loss_ce: 0.017497, loss_kd: 912.914429
[20:16:40.760] iteration 7600 : loss : 229.638077, loss_ce: 0.021149, loss_kd: 1145.753784
[20:16:46.378] iteration 7610 : loss : 228.247177, loss_ce: 0.017630, loss_kd: 1138.792847
[20:16:51.974] iteration 7620 : loss : 216.923706, loss_ce: 0.024732, loss_kd: 1082.204712
[20:16:57.578] iteration 7630 : loss : 221.919632, loss_ce: 0.028143, loss_kd: 1107.121826
[20:17:03.174] iteration 7640 : loss : 227.627869, loss_ce: 0.024186, loss_kd: 1135.688721
[20:17:08.770] iteration 7650 : loss : 230.999557, loss_ce: 0.014850, loss_kd: 1152.583374
[20:17:14.361] iteration 7660 : loss : 276.040039, loss_ce: 0.017746, loss_kd: 1377.753418
[20:17:19.960] iteration 7670 : loss : 242.906143, loss_ce: 0.020274, loss_kd: 1212.103271
[20:17:25.551] iteration 7680 : loss : 202.441498, loss_ce: 0.013889, loss_kd: 1009.778931
[20:17:31.150] iteration 7690 : loss : 202.324875, loss_ce: 0.018373, loss_kd: 1009.177551
[20:17:36.732] iteration 7700 : loss : 170.381027, loss_ce: 0.040147, loss_kd: 849.423218
[20:17:42.329] iteration 7710 : loss : 237.300690, loss_ce: 0.022469, loss_kd: 1184.062988
[20:17:47.914] iteration 7720 : loss : 160.032776, loss_ce: 0.023969, loss_kd: 797.742981
[20:17:53.512] iteration 7730 : loss : 216.116318, loss_ce: 0.017646, loss_kd: 1078.140747
[20:17:59.097] iteration 7740 : loss : 173.046722, loss_ce: 0.023041, loss_kd: 862.807434
[20:18:04.706] iteration 7750 : loss : 181.983337, loss_ce: 0.023011, loss_kd: 907.461914
[20:18:10.302] iteration 7760 : loss : 187.905426, loss_ce: 0.024981, loss_kd: 937.060425
[20:18:15.898] iteration 7770 : loss : 158.786896, loss_ce: 0.021163, loss_kd: 791.546143
[20:18:21.492] iteration 7780 : loss : 156.271744, loss_ce: 0.021131, loss_kd: 778.936279
[20:18:27.098] iteration 7790 : loss : 225.593933, loss_ce: 0.019435, loss_kd: 1125.531128
[20:18:32.688] iteration 7800 : loss : 306.697906, loss_ce: 0.016828, loss_kd: 1531.089844
[20:18:38.296] iteration 7810 : loss : 195.744614, loss_ce: 0.023801, loss_kd: 976.289673
[20:18:43.890] iteration 7820 : loss : 155.911926, loss_ce: 0.019928, loss_kd: 777.083130
[20:18:49.496] iteration 7830 : loss : 195.732452, loss_ce: 0.023510, loss_kd: 976.263916
[20:18:55.090] iteration 7840 : loss : 222.713104, loss_ce: 0.025391, loss_kd: 1111.124756
[20:19:00.700] iteration 7850 : loss : 251.232986, loss_ce: 0.022468, loss_kd: 1253.680908
[20:19:06.291] iteration 7860 : loss : 189.906219, loss_ce: 0.019973, loss_kd: 947.089478
[20:19:11.901] iteration 7870 : loss : 189.269974, loss_ce: 0.018995, loss_kd: 943.933655
[20:19:17.498] iteration 7880 : loss : 219.294678, loss_ce: 0.021150, loss_kd: 1094.043457
[20:19:23.103] iteration 7890 : loss : 246.436859, loss_ce: 0.015256, loss_kd: 1229.727417
[20:19:28.700] iteration 7900 : loss : 235.776306, loss_ce: 0.017540, loss_kd: 1176.455078
[20:19:34.326] iteration 7910 : loss : 185.558136, loss_ce: 0.022301, loss_kd: 925.371155
[20:19:39.927] iteration 7920 : loss : 189.353561, loss_ce: 0.019673, loss_kd: 944.340820
[20:19:45.538] iteration 7930 : loss : 197.486572, loss_ce: 0.012428, loss_kd: 985.005066
[20:19:51.134] iteration 7940 : loss : 229.722748, loss_ce: 0.025839, loss_kd: 1146.187866
[20:19:56.733] iteration 7950 : loss : 196.932602, loss_ce: 0.022979, loss_kd: 982.207397
[20:20:02.336] iteration 7960 : loss : 203.032684, loss_ce: 0.025827, loss_kd: 1012.739319
[20:20:07.933] iteration 7970 : loss : 284.131134, loss_ce: 0.023515, loss_kd: 1418.219604
[20:20:13.527] iteration 7980 : loss : 205.715500, loss_ce: 0.027992, loss_kd: 1026.091797
[20:20:19.136] iteration 7990 : loss : 181.097534, loss_ce: 0.021287, loss_kd: 903.038696
[20:20:24.727] iteration 8000 : loss : 187.779678, loss_ce: 0.025423, loss_kd: 936.466553
[20:20:30.329] iteration 8010 : loss : 191.104858, loss_ce: 0.017204, loss_kd: 953.097778
[20:20:35.923] iteration 8020 : loss : 211.605972, loss_ce: 0.023425, loss_kd: 1055.541260
[20:20:41.526] iteration 8030 : loss : 230.770035, loss_ce: 0.019542, loss_kd: 1151.442139
[20:20:47.120] iteration 8040 : loss : 196.141937, loss_ce: 0.022700, loss_kd: 978.291443
[20:20:52.728] iteration 8050 : loss : 222.869354, loss_ce: 0.022343, loss_kd: 1111.889282
[20:20:58.317] iteration 8060 : loss : 244.737442, loss_ce: 0.019032, loss_kd: 1221.266724
[20:21:03.928] iteration 8070 : loss : 183.454666, loss_ce: 0.019192, loss_kd: 914.835083
[20:21:09.542] iteration 8080 : loss : 257.378510, loss_ce: 0.014555, loss_kd: 1284.467651
[20:21:15.146] iteration 8090 : loss : 186.431976, loss_ce: 0.017032, loss_kd: 929.696960
[20:21:20.735] iteration 8100 : loss : 181.417664, loss_ce: 0.020055, loss_kd: 904.653198
[20:21:26.352] iteration 8110 : loss : 171.200729, loss_ce: 0.023633, loss_kd: 853.596191
[20:21:31.951] iteration 8120 : loss : 240.635574, loss_ce: 0.029210, loss_kd: 1200.746338
[20:21:37.560] iteration 8130 : loss : 205.884613, loss_ce: 0.024615, loss_kd: 1026.958984
[20:21:43.164] iteration 8140 : loss : 206.667969, loss_ce: 0.022714, loss_kd: 1030.895386
[20:21:48.772] iteration 8150 : loss : 214.922211, loss_ce: 0.017275, loss_kd: 1072.186890
[20:21:54.376] iteration 8160 : loss : 197.490799, loss_ce: 0.016371, loss_kd: 985.020996
[20:21:59.974] iteration 8170 : loss : 162.622498, loss_ce: 0.022345, loss_kd: 810.683533
[20:22:05.570] iteration 8180 : loss : 179.924225, loss_ce: 0.012043, loss_kd: 897.224609
[20:22:11.172] iteration 8190 : loss : 204.425140, loss_ce: 0.015916, loss_kd: 1019.705750
[20:22:16.766] iteration 8200 : loss : 164.879837, loss_ce: 0.014465, loss_kd: 821.990417
[20:22:22.376] iteration 8210 : loss : 249.937271, loss_ce: 0.021487, loss_kd: 1247.279175
[20:22:27.976] iteration 8220 : loss : 192.841629, loss_ce: 0.013181, loss_kd: 961.824463
[20:22:33.579] iteration 8230 : loss : 252.754959, loss_ce: 0.021023, loss_kd: 1261.325928
[20:22:39.172] iteration 8240 : loss : 202.608093, loss_ce: 0.025648, loss_kd: 1010.673462
[20:22:44.773] iteration 8250 : loss : 196.847107, loss_ce: 0.013865, loss_kd: 981.821899
[20:22:50.369] iteration 8260 : loss : 188.890198, loss_ce: 0.018018, loss_kd: 942.024902
[20:22:55.973] iteration 8270 : loss : 251.194275, loss_ce: 0.016744, loss_kd: 1253.559326
[20:23:01.573] iteration 8280 : loss : 215.867447, loss_ce: 0.019004, loss_kd: 1076.922119
[20:23:07.176] iteration 8290 : loss : 158.677292, loss_ce: 0.016516, loss_kd: 790.929993
[20:23:12.766] iteration 8300 : loss : 162.096054, loss_ce: 0.014626, loss_kd: 808.047180
[20:23:18.376] iteration 8310 : loss : 200.926727, loss_ce: 0.016004, loss_kd: 1002.177246
[20:23:23.966] iteration 8320 : loss : 198.208954, loss_ce: 0.024747, loss_kd: 988.619690
[20:23:29.567] iteration 8330 : loss : 169.422440, loss_ce: 0.021268, loss_kd: 844.682251
[20:23:47.490] iteration 8340 : loss : 161.782593, loss_ce: 0.014912, loss_kd: 806.457642
[20:23:53.047] iteration 8350 : loss : 215.398514, loss_ce: 0.011614, loss_kd: 1074.564087
[20:23:58.598] iteration 8360 : loss : 188.365829, loss_ce: 0.021070, loss_kd: 939.423706
[20:24:04.164] iteration 8370 : loss : 238.428177, loss_ce: 0.030594, loss_kd: 1189.725952
[20:24:09.724] iteration 8380 : loss : 165.367279, loss_ce: 0.018959, loss_kd: 824.431885
[20:24:15.298] iteration 8390 : loss : 159.279068, loss_ce: 0.017799, loss_kd: 793.982056
[20:24:20.859] iteration 8400 : loss : 171.069550, loss_ce: 0.016247, loss_kd: 852.887451
[20:24:26.438] iteration 8410 : loss : 192.487274, loss_ce: 0.011913, loss_kd: 959.993958
[20:24:32.008] iteration 8420 : loss : 218.448715, loss_ce: 0.027328, loss_kd: 1089.829346
[20:24:37.593] iteration 8430 : loss : 229.246017, loss_ce: 0.014969, loss_kd: 1143.791992
[20:24:43.163] iteration 8440 : loss : 201.607559, loss_ce: 0.027335, loss_kd: 1005.612061
[20:24:48.747] iteration 8450 : loss : 275.526978, loss_ce: 0.021111, loss_kd: 1375.205322
[20:24:54.318] iteration 8460 : loss : 179.812683, loss_ce: 0.013035, loss_kd: 896.648682
[20:24:59.903] iteration 8470 : loss : 234.284012, loss_ce: 0.017201, loss_kd: 1168.974976
[20:25:05.482] iteration 8480 : loss : 162.605072, loss_ce: 0.013316, loss_kd: 810.575928
[20:25:11.075] iteration 8490 : loss : 220.906830, loss_ce: 0.018721, loss_kd: 1102.091675
[20:25:16.654] iteration 8500 : loss : 207.176620, loss_ce: 0.019769, loss_kd: 1033.437866
[20:25:22.264] iteration 8510 : loss : 168.145966, loss_ce: 0.019241, loss_kd: 838.306274
[20:25:27.847] iteration 8520 : loss : 188.314224, loss_ce: 0.028828, loss_kd: 939.153809
[20:25:33.447] iteration 8530 : loss : 173.370987, loss_ce: 0.019193, loss_kd: 864.400024
[20:25:39.032] iteration 8540 : loss : 147.983704, loss_ce: 0.021648, loss_kd: 737.455627
[20:25:44.618] iteration 8550 : loss : 203.248566, loss_ce: 0.019426, loss_kd: 1013.852905
[20:25:50.197] iteration 8560 : loss : 226.211594, loss_ce: 0.017505, loss_kd: 1128.656006
[20:25:55.791] iteration 8570 : loss : 200.408295, loss_ce: 0.013710, loss_kd: 999.632080
[20:26:01.379] iteration 8580 : loss : 216.416107, loss_ce: 0.017908, loss_kd: 1079.693237
[20:26:06.978] iteration 8590 : loss : 189.362473, loss_ce: 0.024115, loss_kd: 944.329834
[20:26:12.566] iteration 8600 : loss : 201.791351, loss_ce: 0.011945, loss_kd: 1006.520264
[20:26:18.176] iteration 8610 : loss : 167.466187, loss_ce: 0.018918, loss_kd: 834.879211
[20:26:23.765] iteration 8620 : loss : 223.228851, loss_ce: 0.016881, loss_kd: 1113.727783
[20:26:29.362] iteration 8630 : loss : 170.695602, loss_ce: 0.010713, loss_kd: 851.053833
[20:26:34.941] iteration 8640 : loss : 259.893463, loss_ce: 0.026972, loss_kd: 1296.985718
[20:26:40.538] iteration 8650 : loss : 177.440323, loss_ce: 0.020722, loss_kd: 884.721985
[20:26:46.123] iteration 8660 : loss : 204.287521, loss_ce: 0.025988, loss_kd: 1019.003479
[20:26:51.724] iteration 8670 : loss : 277.488129, loss_ce: 0.011777, loss_kd: 1384.969971
[20:26:57.307] iteration 8680 : loss : 226.288147, loss_ce: 0.023136, loss_kd: 1129.015625
[20:27:02.910] iteration 8690 : loss : 167.850449, loss_ce: 0.015143, loss_kd: 836.849854
[20:27:08.496] iteration 8700 : loss : 160.852356, loss_ce: 0.016387, loss_kd: 801.828918
[20:27:14.102] iteration 8710 : loss : 233.441422, loss_ce: 0.009093, loss_kd: 1164.761230
[20:27:19.689] iteration 8720 : loss : 225.019089, loss_ce: 0.026186, loss_kd: 1122.670044
[20:27:25.288] iteration 8730 : loss : 195.853806, loss_ce: 0.013814, loss_kd: 976.886719
[20:27:30.879] iteration 8740 : loss : 242.933731, loss_ce: 0.016462, loss_kd: 1212.248291
[20:27:36.478] iteration 8750 : loss : 298.984772, loss_ce: 0.024206, loss_kd: 1492.492920
[20:27:42.078] iteration 8760 : loss : 204.110748, loss_ce: 0.019027, loss_kd: 1018.115967
[20:27:47.682] iteration 8770 : loss : 215.180908, loss_ce: 0.023492, loss_kd: 1073.465698
[20:27:53.279] iteration 8780 : loss : 200.052963, loss_ce: 0.014685, loss_kd: 997.848389
[20:27:58.879] iteration 8790 : loss : 183.245255, loss_ce: 0.028330, loss_kd: 913.776978
[20:28:04.474] iteration 8800 : loss : 170.649460, loss_ce: 0.018842, loss_kd: 850.879028
[20:28:10.085] iteration 8810 : loss : 163.303421, loss_ce: 0.017571, loss_kd: 814.091064
[20:28:15.678] iteration 8820 : loss : 219.176651, loss_ce: 0.018378, loss_kd: 1093.433716
[20:28:21.280] iteration 8830 : loss : 159.946503, loss_ce: 0.013463, loss_kd: 797.338989
[20:28:26.874] iteration 8840 : loss : 184.048248, loss_ce: 0.018714, loss_kd: 917.818298
[20:28:32.474] iteration 8850 : loss : 166.173676, loss_ce: 0.013067, loss_kd: 828.461609
[20:28:38.068] iteration 8860 : loss : 149.791183, loss_ce: 0.021818, loss_kd: 746.412170
[20:28:43.679] iteration 8870 : loss : 249.801773, loss_ce: 0.024332, loss_kd: 1246.546631
[20:28:49.274] iteration 8880 : loss : 186.532654, loss_ce: 0.013139, loss_kd: 930.206299
[20:28:54.875] iteration 8890 : loss : 142.483536, loss_ce: 0.025277, loss_kd: 709.990356
[20:29:00.472] iteration 8900 : loss : 213.271866, loss_ce: 0.016272, loss_kd: 1063.916748
[20:29:06.074] iteration 8910 : loss : 237.213913, loss_ce: 0.012455, loss_kd: 1183.659668
[20:29:11.665] iteration 8920 : loss : 205.512375, loss_ce: 0.023691, loss_kd: 1025.143921
[20:29:17.268] iteration 8930 : loss : 190.229675, loss_ce: 0.016232, loss_kd: 948.752502
[20:29:22.864] iteration 8940 : loss : 144.721558, loss_ce: 0.018278, loss_kd: 721.214844
[20:29:28.466] iteration 8950 : loss : 145.978882, loss_ce: 0.023967, loss_kd: 727.459229
[20:29:34.060] iteration 8960 : loss : 188.660828, loss_ce: 0.018287, loss_kd: 940.891846
[20:29:39.657] iteration 8970 : loss : 214.179657, loss_ce: 0.019160, loss_kd: 1068.470581
[20:29:45.262] iteration 8980 : loss : 159.542297, loss_ce: 0.019808, loss_kd: 795.305542
[20:29:50.867] iteration 8990 : loss : 162.788574, loss_ce: 0.016624, loss_kd: 811.548035
[20:29:56.466] iteration 9000 : loss : 183.308746, loss_ce: 0.013000, loss_kd: 914.142639
[20:30:02.075] iteration 9010 : loss : 214.361710, loss_ce: 0.011259, loss_kd: 1069.361084
[20:30:07.672] iteration 9020 : loss : 188.107605, loss_ce: 0.015933, loss_kd: 938.086731
[20:30:13.278] iteration 9030 : loss : 181.669556, loss_ce: 0.017220, loss_kd: 905.934753
[20:30:18.871] iteration 9040 : loss : 173.091461, loss_ce: 0.022720, loss_kd: 862.993591
[20:30:24.476] iteration 9050 : loss : 161.638153, loss_ce: 0.022813, loss_kd: 805.739075
[20:30:30.074] iteration 9060 : loss : 244.658325, loss_ce: 0.020721, loss_kd: 1220.865601
[20:30:35.674] iteration 9070 : loss : 253.997482, loss_ce: 0.022776, loss_kd: 1267.577393
[20:30:41.268] iteration 9080 : loss : 214.064407, loss_ce: 0.014726, loss_kd: 1067.912354
[20:30:46.879] iteration 9090 : loss : 171.322906, loss_ce: 0.023534, loss_kd: 854.205322
[20:30:52.485] iteration 9100 : loss : 205.228973, loss_ce: 0.014877, loss_kd: 1023.735474
[20:30:58.101] iteration 9110 : loss : 192.009598, loss_ce: 0.019326, loss_kd: 957.657349
[20:31:03.701] iteration 9120 : loss : 170.458313, loss_ce: 0.011673, loss_kd: 849.897827
[20:31:09.305] iteration 9130 : loss : 247.049072, loss_ce: 0.011658, loss_kd: 1232.865967
[20:31:14.902] iteration 9140 : loss : 187.924561, loss_ce: 0.018528, loss_kd: 937.208130
[20:31:20.503] iteration 9150 : loss : 172.644791, loss_ce: 0.014126, loss_kd: 860.737671
[20:31:26.101] iteration 9160 : loss : 196.024490, loss_ce: 0.018186, loss_kd: 977.731201
[20:31:31.710] iteration 9170 : loss : 238.420212, loss_ce: 0.012265, loss_kd: 1189.684448
[20:31:37.306] iteration 9180 : loss : 191.964813, loss_ce: 0.021313, loss_kd: 957.418396
[20:31:42.917] iteration 9190 : loss : 165.661499, loss_ce: 0.010975, loss_kd: 825.879028
[20:31:48.515] iteration 9200 : loss : 205.009995, loss_ce: 0.018587, loss_kd: 1022.628845
[20:31:54.119] iteration 9210 : loss : 200.319473, loss_ce: 0.016354, loss_kd: 999.167847
[20:31:59.720] iteration 9220 : loss : 194.513931, loss_ce: 0.023238, loss_kd: 970.145630
[20:32:05.341] iteration 9230 : loss : 155.854599, loss_ce: 0.016276, loss_kd: 776.835571
[20:32:10.942] iteration 9240 : loss : 204.767792, loss_ce: 0.011587, loss_kd: 1021.440063
[20:32:16.553] iteration 9250 : loss : 179.410049, loss_ce: 0.017111, loss_kd: 894.617676
[20:32:22.150] iteration 9260 : loss : 198.162827, loss_ce: 0.019799, loss_kd: 988.384155
[20:32:27.753] iteration 9270 : loss : 180.354095, loss_ce: 0.024259, loss_kd: 899.306213
[20:32:33.353] iteration 9280 : loss : 155.820572, loss_ce: 0.026469, loss_kd: 776.643738
[20:32:38.968] iteration 9290 : loss : 158.317017, loss_ce: 0.024522, loss_kd: 789.169495
[20:32:44.569] iteration 9300 : loss : 174.913849, loss_ce: 0.019287, loss_kd: 872.127136
[20:32:50.188] iteration 9310 : loss : 214.844543, loss_ce: 0.019822, loss_kd: 1071.802124
[20:32:55.795] iteration 9320 : loss : 202.157516, loss_ce: 0.017176, loss_kd: 1008.335327
[20:33:01.405] iteration 9330 : loss : 171.579620, loss_ce: 0.026719, loss_kd: 855.453796
[20:33:07.033] iteration 9340 : loss : 137.553009, loss_ce: 0.015429, loss_kd: 685.311951
[20:33:12.648] iteration 9350 : loss : 199.908875, loss_ce: 0.016168, loss_kd: 997.146545
[20:33:18.253] iteration 9360 : loss : 187.804718, loss_ce: 0.017718, loss_kd: 936.599609
[20:33:23.866] iteration 9370 : loss : 161.409851, loss_ce: 0.027280, loss_kd: 804.623718
[20:33:28.734] Running TPGM constraint optimization after epoch 9
[20:38:31.894] iteration 9380 : loss : 252.170212, loss_ce: 0.026846, loss_kd: 1258.420532
[20:38:37.431] iteration 9390 : loss : 180.159897, loss_ce: 0.017088, loss_kd: 898.407532
[20:38:42.960] iteration 9400 : loss : 171.701584, loss_ce: 0.015706, loss_kd: 856.080383
[20:38:48.530] iteration 9410 : loss : 184.191284, loss_ce: 0.031130, loss_kd: 918.503601
[20:38:54.072] iteration 9420 : loss : 168.858978, loss_ce: 0.015959, loss_kd: 841.921692
[20:38:59.631] iteration 9430 : loss : 228.106018, loss_ce: 0.023355, loss_kd: 1138.091187
[20:39:05.176] iteration 9440 : loss : 151.245132, loss_ce: 0.020000, loss_kd: 753.789307
[20:39:10.731] iteration 9450 : loss : 162.376678, loss_ce: 0.021276, loss_kd: 809.464722
[20:39:16.277] iteration 9460 : loss : 223.302139, loss_ce: 0.020013, loss_kd: 1114.075439
[20:39:21.839] iteration 9470 : loss : 157.433624, loss_ce: 0.016572, loss_kd: 784.705566
[20:39:27.392] iteration 9480 : loss : 182.543671, loss_ce: 0.020176, loss_kd: 910.278259
[20:39:32.962] iteration 9490 : loss : 171.876266, loss_ce: 0.032749, loss_kd: 856.895142
[20:39:38.518] iteration 9500 : loss : 153.700546, loss_ce: 0.017671, loss_kd: 766.104553
[20:39:44.091] iteration 9510 : loss : 156.469681, loss_ce: 0.017629, loss_kd: 779.946838
[20:39:49.647] iteration 9520 : loss : 239.122253, loss_ce: 0.020881, loss_kd: 1193.193115
[20:39:55.217] iteration 9530 : loss : 175.960175, loss_ce: 0.024808, loss_kd: 877.392883
[20:40:00.786] iteration 9540 : loss : 160.359543, loss_ce: 0.026336, loss_kd: 799.402466
[20:40:06.357] iteration 9550 : loss : 193.127045, loss_ce: 0.019631, loss_kd: 963.230164
[20:40:11.922] iteration 9560 : loss : 210.804031, loss_ce: 0.017454, loss_kd: 1051.569092
[20:40:17.506] iteration 9570 : loss : 180.315765, loss_ce: 0.018625, loss_kd: 899.183716
[20:40:23.074] iteration 9580 : loss : 186.716461, loss_ce: 0.026422, loss_kd: 931.148987
[20:40:28.656] iteration 9590 : loss : 160.204773, loss_ce: 0.018544, loss_kd: 798.617981
[20:40:34.226] iteration 9600 : loss : 165.915268, loss_ce: 0.017613, loss_kd: 827.127686
[20:40:39.822] iteration 9610 : loss : 223.337311, loss_ce: 0.015995, loss_kd: 1114.272095
[20:40:45.396] iteration 9620 : loss : 205.100739, loss_ce: 0.020264, loss_kd: 1023.065125
[20:40:50.980] iteration 9630 : loss : 242.859406, loss_ce: 0.010370, loss_kd: 1211.897949
[20:40:56.557] iteration 9640 : loss : 165.188568, loss_ce: 0.015985, loss_kd: 823.510559
[20:41:02.141] iteration 9650 : loss : 179.746964, loss_ce: 0.019913, loss_kd: 896.293457
[20:41:07.721] iteration 9660 : loss : 242.140533, loss_ce: 0.016827, loss_kd: 1208.292603
[20:41:13.309] iteration 9670 : loss : 177.620667, loss_ce: 0.022815, loss_kd: 885.671082
[20:41:18.893] iteration 9680 : loss : 192.061279, loss_ce: 0.011535, loss_kd: 957.921692
[20:41:24.478] iteration 9690 : loss : 183.453812, loss_ce: 0.033329, loss_kd: 914.836060
[20:41:30.068] iteration 9700 : loss : 168.860550, loss_ce: 0.012969, loss_kd: 841.859009
[20:41:35.668] iteration 9710 : loss : 154.464691, loss_ce: 0.015921, loss_kd: 769.923035
[20:41:41.261] iteration 9720 : loss : 175.121735, loss_ce: 0.023673, loss_kd: 873.174011
[20:41:46.864] iteration 9730 : loss : 239.153412, loss_ce: 0.026559, loss_kd: 1193.333252
[20:41:52.452] iteration 9740 : loss : 264.929138, loss_ce: 0.025654, loss_kd: 1322.231445
[20:41:58.061] iteration 9750 : loss : 197.213211, loss_ce: 0.013947, loss_kd: 983.638977
[20:42:03.658] iteration 9760 : loss : 162.472885, loss_ce: 0.022379, loss_kd: 809.944946
[20:42:09.267] iteration 9770 : loss : 164.229462, loss_ce: 0.023271, loss_kd: 818.731018
[20:42:14.863] iteration 9780 : loss : 166.859009, loss_ce: 0.015278, loss_kd: 831.887512
[20:42:20.471] iteration 9790 : loss : 168.170609, loss_ce: 0.013737, loss_kd: 838.394409
[20:42:26.064] iteration 9800 : loss : 148.997665, loss_ce: 0.012767, loss_kd: 742.576294
[20:42:31.664] iteration 9810 : loss : 205.684494, loss_ce: 0.018148, loss_kd: 1025.999146
[20:42:37.257] iteration 9820 : loss : 185.040604, loss_ce: 0.012652, loss_kd: 922.791748
[20:42:42.863] iteration 9830 : loss : 212.036606, loss_ce: 0.025939, loss_kd: 1057.783936
[20:42:48.451] iteration 9840 : loss : 194.692123, loss_ce: 0.014756, loss_kd: 971.051880
[20:42:54.057] iteration 9850 : loss : 161.327057, loss_ce: 0.020931, loss_kd: 804.193604
[20:42:59.654] iteration 9860 : loss : 149.659576, loss_ce: 0.020790, loss_kd: 745.892822
[20:43:05.255] iteration 9870 : loss : 152.246002, loss_ce: 0.028208, loss_kd: 758.787720
[20:43:10.851] iteration 9880 : loss : 190.134384, loss_ce: 0.018401, loss_kd: 948.253784
[20:43:16.453] iteration 9890 : loss : 192.461014, loss_ce: 0.020900, loss_kd: 959.912964
[20:43:22.049] iteration 9900 : loss : 180.778000, loss_ce: 0.018053, loss_kd: 901.478943
[20:43:27.652] iteration 9910 : loss : 143.041977, loss_ce: 0.014429, loss_kd: 712.802307
[20:43:33.246] iteration 9920 : loss : 154.902328, loss_ce: 0.021799, loss_kd: 772.077820
[20:43:38.848] iteration 9930 : loss : 154.957733, loss_ce: 0.012357, loss_kd: 772.352539
[20:43:44.442] iteration 9940 : loss : 169.852646, loss_ce: 0.027276, loss_kd: 846.806763
[20:43:50.046] iteration 9950 : loss : 157.847397, loss_ce: 0.011976, loss_kd: 786.781555
[20:43:55.643] iteration 9960 : loss : 151.681763, loss_ce: 0.027447, loss_kd: 755.984802
[20:44:01.250] iteration 9970 : loss : 191.930466, loss_ce: 0.034005, loss_kd: 957.241577
[20:44:06.849] iteration 9980 : loss : 238.542160, loss_ce: 0.019276, loss_kd: 1190.287842
[20:44:12.453] iteration 9990 : loss : 163.785049, loss_ce: 0.010372, loss_kd: 816.533020
[20:44:18.049] iteration 10000 : loss : 181.000381, loss_ce: 0.026401, loss_kd: 902.563232
[20:44:23.661] iteration 10010 : loss : 166.344208, loss_ce: 0.025794, loss_kd: 829.316650
[20:44:29.256] iteration 10020 : loss : 189.204025, loss_ce: 0.011781, loss_kd: 943.390930
[20:44:34.860] iteration 10030 : loss : 199.280350, loss_ce: 0.012954, loss_kd: 994.000122
[20:44:40.455] iteration 10040 : loss : 210.684357, loss_ce: 0.014651, loss_kd: 1051.033569
[20:44:46.066] iteration 10050 : loss : 160.056686, loss_ce: 0.014319, loss_kd: 797.886902
[20:44:51.672] iteration 10060 : loss : 190.382370, loss_ce: 0.014966, loss_kd: 949.516479
[20:44:57.290] iteration 10070 : loss : 182.897827, loss_ce: 0.031616, loss_kd: 912.017761
[20:45:02.890] iteration 10080 : loss : 174.986481, loss_ce: 0.023922, loss_kd: 872.460388
[20:45:08.497] iteration 10090 : loss : 165.303406, loss_ce: 0.019702, loss_kd: 824.098694
[20:45:14.098] iteration 10100 : loss : 161.737656, loss_ce: 0.020822, loss_kd: 806.284668
[20:45:19.714] iteration 10110 : loss : 152.151520, loss_ce: 0.022385, loss_kd: 758.314941
[20:45:25.318] iteration 10120 : loss : 193.151489, loss_ce: 0.025927, loss_kd: 963.342041
[20:45:30.934] iteration 10130 : loss : 199.392822, loss_ce: 0.023838, loss_kd: 994.520752
[20:45:36.543] iteration 10140 : loss : 158.711472, loss_ce: 0.019240, loss_kd: 791.172363
[20:45:42.152] iteration 10150 : loss : 170.915985, loss_ce: 0.020012, loss_kd: 852.163208
[20:45:47.750] iteration 10160 : loss : 162.956329, loss_ce: 0.020123, loss_kd: 812.355896
[20:45:53.373] iteration 10170 : loss : 167.610260, loss_ce: 0.011767, loss_kd: 835.667542
[20:45:58.982] iteration 10180 : loss : 218.799347, loss_ce: 0.014694, loss_kd: 1091.552002
[20:46:04.605] iteration 10190 : loss : 197.140549, loss_ce: 0.017284, loss_kd: 983.234070
[20:46:10.221] iteration 10200 : loss : 187.141556, loss_ce: 0.022524, loss_kd: 933.316711
[20:46:15.838] iteration 10210 : loss : 178.216904, loss_ce: 0.010410, loss_kd: 888.684021
[20:46:21.467] iteration 10220 : loss : 202.578400, loss_ce: 0.023487, loss_kd: 1010.447754
[20:46:27.073] iteration 10230 : loss : 142.444519, loss_ce: 0.016761, loss_kd: 709.803955
[20:46:32.675] iteration 10240 : loss : 152.913086, loss_ce: 0.023189, loss_kd: 762.140808
[20:46:38.292] iteration 10250 : loss : 108.163704, loss_ce: 0.019131, loss_kd: 538.384583
[20:46:43.899] iteration 10260 : loss : 172.464050, loss_ce: 0.029222, loss_kd: 859.897278
[20:46:49.519] iteration 10270 : loss : 148.361298, loss_ce: 0.019580, loss_kd: 739.401184
[20:46:55.119] iteration 10280 : loss : 230.798050, loss_ce: 0.012947, loss_kd: 1151.575439
[20:47:00.737] iteration 10290 : loss : 195.041306, loss_ce: 0.020906, loss_kd: 972.799438
[20:47:06.333] iteration 10300 : loss : 198.553894, loss_ce: 0.014495, loss_kd: 990.364136
[20:47:11.953] iteration 10310 : loss : 171.414703, loss_ce: 0.013918, loss_kd: 854.679382
[20:47:17.553] iteration 10320 : loss : 190.308655, loss_ce: 0.013773, loss_kd: 949.102295
[20:47:23.157] iteration 10330 : loss : 175.873642, loss_ce: 0.029803, loss_kd: 876.943481
[20:47:28.765] iteration 10340 : loss : 185.709290, loss_ce: 0.013859, loss_kd: 926.143311
[20:47:34.380] iteration 10350 : loss : 249.877274, loss_ce: 0.021441, loss_kd: 1246.950928
[20:47:39.983] iteration 10360 : loss : 217.328232, loss_ce: 0.013556, loss_kd: 1084.226807
[20:47:45.597] iteration 10370 : loss : 165.139816, loss_ce: 0.019749, loss_kd: 823.286316
[20:47:51.195] iteration 10380 : loss : 206.087326, loss_ce: 0.022774, loss_kd: 1028.024780
[20:47:56.807] iteration 10390 : loss : 168.557587, loss_ce: 0.025685, loss_kd: 840.392151
[20:48:02.407] iteration 10400 : loss : 156.707428, loss_ce: 0.016772, loss_kd: 781.136963
[20:48:08.020] iteration 10410 : loss : 136.958481, loss_ce: 0.014057, loss_kd: 682.406250
[20:48:13.333] iteration 10420 : loss : 123.517799, loss_ce: 0.023232, loss_kd: 615.161987
[20:48:14.150] save model to ./debug_fixed_tpgm\continual_surgical_tpgm_stage1_epoch_9.pth
[20:48:31.370] iteration 10430 : loss : 207.515488, loss_ce: 0.026730, loss_kd: 1035.151367
[20:48:36.923] iteration 10440 : loss : 220.758804, loss_ce: 0.024063, loss_kd: 1101.395508
[20:48:42.491] iteration 10450 : loss : 195.908142, loss_ce: 0.011447, loss_kd: 977.114746
[20:48:48.049] iteration 10460 : loss : 187.545349, loss_ce: 0.013477, loss_kd: 935.334778
[20:48:53.617] iteration 10470 : loss : 163.041840, loss_ce: 0.018858, loss_kd: 812.753418
[20:48:59.181] iteration 10480 : loss : 286.917908, loss_ce: 0.027209, loss_kd: 1432.160400
[20:49:04.771] iteration 10490 : loss : 125.539307, loss_ce: 0.024363, loss_kd: 625.291931
[20:49:10.344] iteration 10500 : loss : 165.108414, loss_ce: 0.016025, loss_kd: 823.079041
[20:49:15.944] iteration 10510 : loss : 174.357681, loss_ce: 0.027030, loss_kd: 869.373169
[20:49:21.519] iteration 10520 : loss : 134.255356, loss_ce: 0.015418, loss_kd: 668.859070
[20:49:27.116] iteration 10530 : loss : 145.047958, loss_ce: 0.013386, loss_kd: 722.835327
[20:49:32.704] iteration 10540 : loss : 189.618271, loss_ce: 0.019521, loss_kd: 945.684448
[20:49:38.299] iteration 10550 : loss : 177.626236, loss_ce: 0.024669, loss_kd: 885.732422
[20:49:43.883] iteration 10560 : loss : 173.612823, loss_ce: 0.020015, loss_kd: 865.671875
[20:49:49.471] iteration 10570 : loss : 148.352524, loss_ce: 0.022121, loss_kd: 739.408508
[20:49:55.053] iteration 10580 : loss : 157.743805, loss_ce: 0.010197, loss_kd: 786.309631
[20:50:00.653] iteration 10590 : loss : 183.410217, loss_ce: 0.012091, loss_kd: 914.660156
[20:50:06.241] iteration 10600 : loss : 193.227295, loss_ce: 0.026013, loss_kd: 963.694824
[20:50:11.839] iteration 10610 : loss : 162.603165, loss_ce: 0.028766, loss_kd: 810.617065
[20:50:17.435] iteration 10620 : loss : 147.303528, loss_ce: 0.019679, loss_kd: 734.090820
[20:50:23.045] iteration 10630 : loss : 213.164368, loss_ce: 0.026206, loss_kd: 1063.401367
[20:50:28.635] iteration 10640 : loss : 162.617691, loss_ce: 0.019378, loss_kd: 810.749817
[20:50:34.238] iteration 10650 : loss : 204.155136, loss_ce: 0.018524, loss_kd: 1018.314087
[20:50:39.841] iteration 10660 : loss : 157.675903, loss_ce: 0.014867, loss_kd: 785.941895
[20:50:45.444] iteration 10670 : loss : 177.814346, loss_ce: 0.016019, loss_kd: 886.625854
[20:50:51.034] iteration 10680 : loss : 191.929199, loss_ce: 0.024376, loss_kd: 957.214722
[20:50:56.636] iteration 10690 : loss : 156.358688, loss_ce: 0.014687, loss_kd: 779.387268
[20:51:02.230] iteration 10700 : loss : 164.279022, loss_ce: 0.025293, loss_kd: 818.981995
[20:51:07.841] iteration 10710 : loss : 133.507812, loss_ce: 0.014512, loss_kd: 665.128967
[20:51:13.434] iteration 10720 : loss : 124.585670, loss_ce: 0.010976, loss_kd: 620.541138
[20:51:19.046] iteration 10730 : loss : 201.076248, loss_ce: 0.015646, loss_kd: 1002.939575
[20:51:24.642] iteration 10740 : loss : 158.644073, loss_ce: 0.019223, loss_kd: 790.823303
[20:51:30.251] iteration 10750 : loss : 161.339050, loss_ce: 0.014500, loss_kd: 804.286987
[20:51:35.849] iteration 10760 : loss : 180.237747, loss_ce: 0.014133, loss_kd: 898.794678
[20:51:41.447] iteration 10770 : loss : 252.166779, loss_ce: 0.020231, loss_kd: 1258.408447
[20:51:47.046] iteration 10780 : loss : 162.267044, loss_ce: 0.018690, loss_kd: 808.873047
[20:51:52.673] iteration 10790 : loss : 170.651093, loss_ce: 0.012147, loss_kd: 850.833008
[20:51:58.273] iteration 10800 : loss : 159.040131, loss_ce: 0.016687, loss_kd: 792.757507
[20:52:03.893] iteration 10810 : loss : 165.592773, loss_ce: 0.010032, loss_kd: 825.506165
[20:52:09.491] iteration 10820 : loss : 171.685638, loss_ce: 0.013189, loss_kd: 855.941284
[20:52:15.108] iteration 10830 : loss : 186.013474, loss_ce: 0.021660, loss_kd: 927.688904
[20:52:20.705] iteration 10840 : loss : 267.512817, loss_ce: 0.015836, loss_kd: 1335.145630
[20:52:26.324] iteration 10850 : loss : 174.924850, loss_ce: 0.013337, loss_kd: 872.273621
[20:52:31.929] iteration 10860 : loss : 170.090027, loss_ce: 0.014522, loss_kd: 848.043335
[20:52:37.543] iteration 10870 : loss : 137.124924, loss_ce: 0.017372, loss_kd: 683.194336
[20:52:43.144] iteration 10880 : loss : 156.519394, loss_ce: 0.019188, loss_kd: 780.161194
[20:52:48.759] iteration 10890 : loss : 216.937958, loss_ce: 0.015138, loss_kd: 1082.275391
[20:52:54.355] iteration 10900 : loss : 213.817688, loss_ce: 0.016705, loss_kd: 1066.698730
[20:52:59.968] iteration 10910 : loss : 142.297195, loss_ce: 0.016683, loss_kd: 709.047180
[20:53:05.572] iteration 10920 : loss : 145.800842, loss_ce: 0.014887, loss_kd: 726.597656
[20:53:11.198] iteration 10930 : loss : 143.479630, loss_ce: 0.020862, loss_kd: 715.034058
[20:53:16.807] iteration 10940 : loss : 145.436951, loss_ce: 0.016916, loss_kd: 724.741699
[20:53:22.420] iteration 10950 : loss : 168.988754, loss_ce: 0.013214, loss_kd: 842.500610
[20:53:28.029] iteration 10960 : loss : 183.392776, loss_ce: 0.013565, loss_kd: 914.521851
[20:53:33.656] iteration 10970 : loss : 192.148636, loss_ce: 0.013812, loss_kd: 958.319580
[20:53:39.265] iteration 10980 : loss : 234.730560, loss_ce: 0.011564, loss_kd: 1171.236572
[20:53:44.875] iteration 10990 : loss : 237.015640, loss_ce: 0.018663, loss_kd: 1182.689087
[20:53:50.482] iteration 11000 : loss : 157.583679, loss_ce: 0.018823, loss_kd: 785.472900
[20:53:56.091] iteration 11010 : loss : 195.606750, loss_ce: 0.008487, loss_kd: 975.647034
[20:54:01.701] iteration 11020 : loss : 221.455688, loss_ce: 0.015983, loss_kd: 1104.864990
[20:54:07.323] iteration 11030 : loss : 180.967941, loss_ce: 0.015891, loss_kd: 902.467285
[20:54:12.929] iteration 11040 : loss : 148.621735, loss_ce: 0.012201, loss_kd: 740.705078
[20:54:18.550] iteration 11050 : loss : 161.814438, loss_ce: 0.021224, loss_kd: 806.652710
[20:54:24.154] iteration 11060 : loss : 169.642166, loss_ce: 0.024625, loss_kd: 845.767212
[20:54:29.778] iteration 11070 : loss : 171.244934, loss_ce: 0.020237, loss_kd: 853.827026
[20:54:35.387] iteration 11080 : loss : 168.025101, loss_ce: 0.016751, loss_kd: 837.727173
[20:54:40.993] iteration 11090 : loss : 146.389832, loss_ce: 0.019793, loss_kd: 729.556335
[20:54:46.587] iteration 11100 : loss : 141.433884, loss_ce: 0.015254, loss_kd: 704.785461
[20:54:52.200] iteration 11110 : loss : 169.223694, loss_ce: 0.013073, loss_kd: 843.724243
[20:54:57.798] iteration 11120 : loss : 163.852646, loss_ce: 0.014167, loss_kd: 816.823425
[20:55:03.414] iteration 11130 : loss : 150.070480, loss_ce: 0.018386, loss_kd: 747.929565
[20:55:09.019] iteration 11140 : loss : 213.268066, loss_ce: 0.013927, loss_kd: 1063.956787
[20:55:14.636] iteration 11150 : loss : 164.141602, loss_ce: 0.023753, loss_kd: 818.300232
[20:55:20.241] iteration 11160 : loss : 167.762695, loss_ce: 0.018376, loss_kd: 836.398926
[20:55:25.852] iteration 11170 : loss : 202.234329, loss_ce: 0.019970, loss_kd: 1008.752808
[20:55:31.446] iteration 11180 : loss : 168.672791, loss_ce: 0.021499, loss_kd: 840.932251
[20:55:37.060] iteration 11190 : loss : 183.203552, loss_ce: 0.019545, loss_kd: 913.598877
[20:55:42.660] iteration 11200 : loss : 211.545914, loss_ce: 0.021732, loss_kd: 1055.314209
[20:55:48.279] iteration 11210 : loss : 143.508789, loss_ce: 0.014365, loss_kd: 715.125610
[20:55:53.888] iteration 11220 : loss : 185.894592, loss_ce: 0.028259, loss_kd: 927.055786
[20:55:59.500] iteration 11230 : loss : 153.277969, loss_ce: 0.013211, loss_kd: 763.959106
[20:56:05.103] iteration 11240 : loss : 145.535782, loss_ce: 0.016206, loss_kd: 725.238464
[20:56:10.717] iteration 11250 : loss : 185.556442, loss_ce: 0.016932, loss_kd: 925.387634
[20:56:16.319] iteration 11260 : loss : 185.957336, loss_ce: 0.013347, loss_kd: 927.433105
[20:56:21.927] iteration 11270 : loss : 175.766068, loss_ce: 0.024361, loss_kd: 876.400940
[20:56:27.517] iteration 11280 : loss : 237.270203, loss_ce: 0.019022, loss_kd: 1183.943848
[20:56:33.123] iteration 11290 : loss : 192.726059, loss_ce: 0.012034, loss_kd: 961.203613
[20:56:38.729] iteration 11300 : loss : 159.799484, loss_ce: 0.024119, loss_kd: 796.585693
[20:56:44.349] iteration 11310 : loss : 149.842026, loss_ce: 0.017407, loss_kd: 746.838745
[20:56:49.952] iteration 11320 : loss : 137.032150, loss_ce: 0.020141, loss_kd: 682.738525
[20:56:55.563] iteration 11330 : loss : 150.657623, loss_ce: 0.011595, loss_kd: 750.887939
[20:57:01.176] iteration 11340 : loss : 166.392593, loss_ce: 0.012195, loss_kd: 829.560486
[20:57:06.800] iteration 11350 : loss : 205.570892, loss_ce: 0.011771, loss_kd: 1025.444824
[20:57:12.406] iteration 11360 : loss : 141.898331, loss_ce: 0.014447, loss_kd: 707.103394
[20:57:18.018] iteration 11370 : loss : 150.262817, loss_ce: 0.008924, loss_kd: 748.876404
[20:57:23.620] iteration 11380 : loss : 159.115479, loss_ce: 0.025866, loss_kd: 793.183899
[20:57:29.228] iteration 11390 : loss : 180.881927, loss_ce: 0.015904, loss_kd: 902.002808
[20:57:34.828] iteration 11400 : loss : 234.414703, loss_ce: 0.024300, loss_kd: 1169.637817
[20:57:40.443] iteration 11410 : loss : 159.685944, loss_ce: 0.013967, loss_kd: 796.068420
[20:57:46.046] iteration 11420 : loss : 194.320999, loss_ce: 0.017832, loss_kd: 969.210999
[20:57:51.670] iteration 11430 : loss : 147.026825, loss_ce: 0.019448, loss_kd: 732.718994
[20:57:57.272] iteration 11440 : loss : 148.387482, loss_ce: 0.018392, loss_kd: 739.532837
[20:58:02.906] iteration 11450 : loss : 180.630020, loss_ce: 0.025901, loss_kd: 900.755920
[20:58:08.504] iteration 11460 : loss : 157.324463, loss_ce: 0.014738, loss_kd: 784.275269
[20:58:10.046] Running TPGM constraint optimization after epoch 11
[21:03:06.179] iteration 11470 : loss : 174.306290, loss_ce: 0.016525, loss_kd: 869.162476
[21:03:11.709] iteration 11480 : loss : 180.743698, loss_ce: 0.018616, loss_kd: 901.294739
[21:03:17.250] iteration 11490 : loss : 157.369141, loss_ce: 0.017330, loss_kd: 784.450806
[21:03:22.789] iteration 11500 : loss : 239.174469, loss_ce: 0.018340, loss_kd: 1193.494141
[21:03:28.347] iteration 11510 : loss : 131.975449, loss_ce: 0.017644, loss_kd: 657.461304
[21:03:33.885] iteration 11520 : loss : 168.890747, loss_ce: 0.010780, loss_kd: 842.005493
[21:03:39.442] iteration 11530 : loss : 153.485336, loss_ce: 0.022097, loss_kd: 765.010437
[21:03:44.986] iteration 11540 : loss : 170.593948, loss_ce: 0.017153, loss_kd: 850.569458
[21:03:50.540] iteration 11550 : loss : 164.068939, loss_ce: 0.015186, loss_kd: 817.962891
[21:03:56.087] iteration 11560 : loss : 184.061646, loss_ce: 0.012359, loss_kd: 917.893677
[21:04:01.648] iteration 11570 : loss : 186.526840, loss_ce: 0.014178, loss_kd: 930.231934
[21:04:07.204] iteration 11580 : loss : 204.796936, loss_ce: 0.017446, loss_kd: 1021.590576
[21:04:12.776] iteration 11590 : loss : 154.577148, loss_ce: 0.016626, loss_kd: 770.486389
[21:04:18.366] iteration 11600 : loss : 132.830811, loss_ce: 0.010721, loss_kd: 661.774231
[21:04:23.938] iteration 11610 : loss : 169.393616, loss_ce: 0.030187, loss_kd: 844.512451
[21:04:29.501] iteration 11620 : loss : 130.803024, loss_ce: 0.017226, loss_kd: 651.597900
[21:04:35.073] iteration 11630 : loss : 160.891220, loss_ce: 0.014917, loss_kd: 802.039551
[21:04:40.635] iteration 11640 : loss : 162.802811, loss_ce: 0.013725, loss_kd: 811.588562
[21:04:46.212] iteration 11650 : loss : 174.761032, loss_ce: 0.012237, loss_kd: 871.411255
[21:04:51.782] iteration 11660 : loss : 185.187546, loss_ce: 0.018559, loss_kd: 923.521179
[21:04:57.364] iteration 11670 : loss : 182.954132, loss_ce: 0.010662, loss_kd: 912.397339
[21:05:02.940] iteration 11680 : loss : 150.557983, loss_ce: 0.010686, loss_kd: 750.421326
[21:05:08.526] iteration 11690 : loss : 164.644699, loss_ce: 0.015431, loss_kd: 820.803101
[21:05:14.096] iteration 11700 : loss : 160.662628, loss_ce: 0.015135, loss_kd: 800.923523
[21:05:19.686] iteration 11710 : loss : 128.479797, loss_ce: 0.020065, loss_kd: 640.007019
[21:05:25.261] iteration 11720 : loss : 228.865845, loss_ce: 0.031796, loss_kd: 1141.909424
[21:05:30.850] iteration 11730 : loss : 173.716858, loss_ce: 0.012180, loss_kd: 866.194641
[21:05:36.425] iteration 11740 : loss : 168.173019, loss_ce: 0.017757, loss_kd: 838.475708
[21:05:42.016] iteration 11750 : loss : 140.082886, loss_ce: 0.030689, loss_kd: 698.013916
[21:05:47.593] iteration 11760 : loss : 116.074059, loss_ce: 0.010930, loss_kd: 577.933044
[21:05:53.186] iteration 11770 : loss : 150.803436, loss_ce: 0.020290, loss_kd: 751.602417
[21:05:58.773] iteration 11780 : loss : 169.688248, loss_ce: 0.014793, loss_kd: 846.034668
[21:06:04.380] iteration 11790 : loss : 129.644821, loss_ce: 0.013994, loss_kd: 645.844604
[21:06:09.969] iteration 11800 : loss : 148.829361, loss_ce: 0.020463, loss_kd: 741.766357
[21:06:15.567] iteration 11810 : loss : 140.203552, loss_ce: 0.027149, loss_kd: 698.591125
[21:06:21.147] iteration 11820 : loss : 150.436508, loss_ce: 0.019808, loss_kd: 749.756226
[21:06:26.742] iteration 11830 : loss : 194.846863, loss_ce: 0.018793, loss_kd: 971.806030
[21:06:32.325] iteration 11840 : loss : 193.099701, loss_ce: 0.010008, loss_kd: 963.124023
[21:06:37.922] iteration 11850 : loss : 147.791443, loss_ce: 0.014522, loss_kd: 736.565674
[21:06:43.509] iteration 11860 : loss : 177.982849, loss_ce: 0.023144, loss_kd: 887.486755
[21:06:49.108] iteration 11870 : loss : 201.556625, loss_ce: 0.018361, loss_kd: 1005.372192
[21:06:54.695] iteration 11880 : loss : 159.670441, loss_ce: 0.017195, loss_kd: 795.957703
[21:07:00.300] iteration 11890 : loss : 144.401520, loss_ce: 0.013707, loss_kd: 719.644531
[21:07:05.892] iteration 11900 : loss : 159.925568, loss_ce: 0.016515, loss_kd: 797.168396
[21:07:11.496] iteration 11910 : loss : 165.954422, loss_ce: 0.011387, loss_kd: 827.379517
[21:07:17.088] iteration 11920 : loss : 161.683884, loss_ce: 0.008196, loss_kd: 806.021606
[21:07:22.697] iteration 11930 : loss : 199.328766, loss_ce: 0.013936, loss_kd: 994.188660
[21:07:28.293] iteration 11940 : loss : 180.946655, loss_ce: 0.012922, loss_kd: 902.321655
[21:07:33.895] iteration 11950 : loss : 118.047119, loss_ce: 0.015254, loss_kd: 587.827515
[21:07:39.492] iteration 11960 : loss : 146.524384, loss_ce: 0.018765, loss_kd: 730.214966
[21:07:45.092] iteration 11970 : loss : 236.031097, loss_ce: 0.022868, loss_kd: 1177.752686
[21:07:50.685] iteration 11980 : loss : 168.897339, loss_ce: 0.024147, loss_kd: 842.042908
[21:07:56.293] iteration 11990 : loss : 152.310455, loss_ce: 0.030624, loss_kd: 759.127136
[21:08:01.886] iteration 12000 : loss : 167.019257, loss_ce: 0.015804, loss_kd: 832.701660
[21:08:07.499] iteration 12010 : loss : 167.516342, loss_ce: 0.027812, loss_kd: 835.160889
[21:08:13.090] iteration 12020 : loss : 165.085587, loss_ce: 0.017187, loss_kd: 823.007935
[21:08:18.694] iteration 12030 : loss : 167.410202, loss_ce: 0.017883, loss_kd: 834.661560
[21:08:24.284] iteration 12040 : loss : 178.207153, loss_ce: 0.019330, loss_kd: 888.586243
[21:08:29.887] iteration 12050 : loss : 141.713379, loss_ce: 0.013419, loss_kd: 706.140320
[21:08:35.479] iteration 12060 : loss : 186.216568, loss_ce: 0.015842, loss_kd: 928.619629
[21:08:41.084] iteration 12070 : loss : 171.525726, loss_ce: 0.024876, loss_kd: 855.221680
[21:08:46.680] iteration 12080 : loss : 153.405487, loss_ce: 0.022256, loss_kd: 764.615723
[21:08:52.284] iteration 12090 : loss : 135.278488, loss_ce: 0.019323, loss_kd: 673.979370
[21:08:57.880] iteration 12100 : loss : 164.405533, loss_ce: 0.018756, loss_kd: 819.627197
[21:09:03.484] iteration 12110 : loss : 173.207626, loss_ce: 0.022671, loss_kd: 863.591309
[21:09:09.074] iteration 12120 : loss : 198.036331, loss_ce: 0.013219, loss_kd: 987.784729
[21:09:14.678] iteration 12130 : loss : 254.963928, loss_ce: 0.015293, loss_kd: 1272.436279
[21:09:20.269] iteration 12140 : loss : 262.072632, loss_ce: 0.023309, loss_kd: 1307.976196
[21:09:25.880] iteration 12150 : loss : 170.007904, loss_ce: 0.019841, loss_kd: 847.595886
[21:09:31.472] iteration 12160 : loss : 139.114059, loss_ce: 0.024335, loss_kd: 693.146667
[21:09:37.079] iteration 12170 : loss : 142.187439, loss_ce: 0.021028, loss_kd: 708.524109
[21:09:42.675] iteration 12180 : loss : 150.168945, loss_ce: 0.014560, loss_kd: 748.419373
[21:09:48.279] iteration 12190 : loss : 167.200897, loss_ce: 0.027272, loss_kd: 833.574280
[21:09:53.875] iteration 12200 : loss : 133.865082, loss_ce: 0.026614, loss_kd: 666.917786
[21:09:59.485] iteration 12210 : loss : 129.089844, loss_ce: 0.015289, loss_kd: 643.024841
[21:10:05.075] iteration 12220 : loss : 133.676025, loss_ce: 0.009158, loss_kd: 665.970947
[21:10:10.683] iteration 12230 : loss : 159.220612, loss_ce: 0.014969, loss_kd: 793.665588
[21:10:16.274] iteration 12240 : loss : 128.493439, loss_ce: 0.025489, loss_kd: 640.058838
[21:10:21.887] iteration 12250 : loss : 172.227905, loss_ce: 0.014648, loss_kd: 858.716125
[21:10:27.478] iteration 12260 : loss : 194.095306, loss_ce: 0.014312, loss_kd: 968.055359
[21:10:33.091] iteration 12270 : loss : 199.466858, loss_ce: 0.017753, loss_kd: 994.917480
[21:10:38.709] iteration 12280 : loss : 138.377563, loss_ce: 0.019581, loss_kd: 689.478210
[21:10:44.324] iteration 12290 : loss : 140.590698, loss_ce: 0.020558, loss_kd: 700.527893
[21:10:49.925] iteration 12300 : loss : 219.456299, loss_ce: 0.011911, loss_kd: 1094.850464
[21:10:55.543] iteration 12310 : loss : 151.664108, loss_ce: 0.017071, loss_kd: 755.892456
[21:11:01.144] iteration 12320 : loss : 126.684227, loss_ce: 0.020777, loss_kd: 631.028381
[21:11:06.762] iteration 12330 : loss : 179.063507, loss_ce: 0.011771, loss_kd: 892.918091
[21:11:12.367] iteration 12340 : loss : 175.386993, loss_ce: 0.018788, loss_kd: 874.518188
[21:11:17.982] iteration 12350 : loss : 206.780090, loss_ce: 0.011317, loss_kd: 1031.452148
[21:11:23.580] iteration 12360 : loss : 108.468788, loss_ce: 0.018441, loss_kd: 539.954163
[21:11:29.194] iteration 12370 : loss : 159.937347, loss_ce: 0.018915, loss_kd: 797.269897
[21:11:34.789] iteration 12380 : loss : 165.193588, loss_ce: 0.012185, loss_kd: 823.571655
[21:11:40.399] iteration 12390 : loss : 150.673523, loss_ce: 0.015352, loss_kd: 750.970032
[21:11:45.995] iteration 12400 : loss : 158.415283, loss_ce: 0.020961, loss_kd: 789.663635
[21:11:51.615] iteration 12410 : loss : 156.317490, loss_ce: 0.016834, loss_kd: 779.201355
[21:11:57.216] iteration 12420 : loss : 110.167244, loss_ce: 0.012658, loss_kd: 548.436951
[21:12:02.826] iteration 12430 : loss : 215.147293, loss_ce: 0.020973, loss_kd: 1073.326782
[21:12:08.421] iteration 12440 : loss : 183.948517, loss_ce: 0.025252, loss_kd: 917.358887
[21:12:14.030] iteration 12450 : loss : 176.465271, loss_ce: 0.007907, loss_kd: 879.942505
[21:12:19.630] iteration 12460 : loss : 143.818649, loss_ce: 0.011129, loss_kd: 716.658997
[21:12:25.238] iteration 12470 : loss : 145.301102, loss_ce: 0.011677, loss_kd: 724.060547
[21:12:30.844] iteration 12480 : loss : 172.469559, loss_ce: 0.019255, loss_kd: 859.902954
[21:12:36.448] iteration 12490 : loss : 165.354858, loss_ce: 0.016454, loss_kd: 824.374268
[21:12:42.050] iteration 12500 : loss : 192.228683, loss_ce: 0.014533, loss_kd: 958.754883
[21:12:59.503] iteration 12510 : loss : 154.853943, loss_ce: 0.016254, loss_kd: 771.899170
[21:13:05.056] iteration 12520 : loss : 140.219788, loss_ce: 0.022410, loss_kd: 698.688354
[21:13:10.627] iteration 12530 : loss : 135.101776, loss_ce: 0.019530, loss_kd: 673.083313
[21:13:16.181] iteration 12540 : loss : 158.614090, loss_ce: 0.012096, loss_kd: 790.674133
[21:13:21.756] iteration 12550 : loss : 136.362167, loss_ce: 0.019065, loss_kd: 679.424133
[21:13:27.324] iteration 12560 : loss : 146.374359, loss_ce: 0.019693, loss_kd: 729.478516
[21:13:32.901] iteration 12570 : loss : 132.001526, loss_ce: 0.013161, loss_kd: 657.589050
[21:13:38.470] iteration 12580 : loss : 169.099091, loss_ce: 0.017077, loss_kd: 843.063904
[21:13:44.061] iteration 12590 : loss : 185.181274, loss_ce: 0.015074, loss_kd: 923.550232
[21:13:49.643] iteration 12600 : loss : 146.579178, loss_ce: 0.027297, loss_kd: 730.489319
[21:13:55.228] iteration 12610 : loss : 240.330780, loss_ce: 0.023171, loss_kd: 1199.257935
[21:14:00.815] iteration 12620 : loss : 130.900299, loss_ce: 0.017087, loss_kd: 652.073547
[21:14:06.406] iteration 12630 : loss : 128.819672, loss_ce: 0.025799, loss_kd: 641.708374
[21:14:11.999] iteration 12640 : loss : 132.271530, loss_ce: 0.017076, loss_kd: 658.971802
[21:14:17.600] iteration 12650 : loss : 132.115662, loss_ce: 0.006954, loss_kd: 658.189697
[21:14:23.195] iteration 12660 : loss : 123.129486, loss_ce: 0.014197, loss_kd: 613.247925
[21:14:28.797] iteration 12670 : loss : 161.211395, loss_ce: 0.013362, loss_kd: 803.683411
[21:14:34.389] iteration 12680 : loss : 154.311050, loss_ce: 0.019983, loss_kd: 769.093079
[21:14:39.992] iteration 12690 : loss : 97.670403, loss_ce: 0.016582, loss_kd: 485.927277
[21:14:45.589] iteration 12700 : loss : 185.181381, loss_ce: 0.020139, loss_kd: 923.482178
[21:14:51.195] iteration 12710 : loss : 127.885651, loss_ce: 0.016467, loss_kd: 637.042480
[21:14:56.789] iteration 12720 : loss : 152.458923, loss_ce: 0.021821, loss_kd: 759.924683
[21:15:02.394] iteration 12730 : loss : 156.528122, loss_ce: 0.017847, loss_kd: 780.282410
[21:15:07.990] iteration 12740 : loss : 146.127991, loss_ce: 0.013727, loss_kd: 728.255676
[21:15:13.587] iteration 12750 : loss : 185.396805, loss_ce: 0.015067, loss_kd: 924.609924
[21:15:19.186] iteration 12760 : loss : 172.260040, loss_ce: 0.013810, loss_kd: 858.912354
[21:15:24.787] iteration 12770 : loss : 138.514557, loss_ce: 0.013004, loss_kd: 690.195862
[21:15:30.388] iteration 12780 : loss : 153.068588, loss_ce: 0.018138, loss_kd: 762.929199
[21:15:35.997] iteration 12790 : loss : 145.039291, loss_ce: 0.021744, loss_kd: 722.778870
[21:15:41.583] iteration 12800 : loss : 189.367676, loss_ce: 0.015201, loss_kd: 944.437012
[21:15:47.187] iteration 12810 : loss : 187.626694, loss_ce: 0.015099, loss_kd: 935.722290
[21:15:52.781] iteration 12820 : loss : 170.484268, loss_ce: 0.016264, loss_kd: 849.988037
[21:15:58.389] iteration 12830 : loss : 152.425125, loss_ce: 0.020207, loss_kd: 759.714600
[21:16:03.987] iteration 12840 : loss : 148.357727, loss_ce: 0.021685, loss_kd: 739.355103
[21:16:09.635] iteration 12850 : loss : 131.092102, loss_ce: 0.020878, loss_kd: 653.029907
[21:16:15.239] iteration 12860 : loss : 101.056641, loss_ce: 0.014159, loss_kd: 502.914001
[21:16:20.853] iteration 12870 : loss : 158.297363, loss_ce: 0.016356, loss_kd: 789.072388
[21:16:26.451] iteration 12880 : loss : 132.122925, loss_ce: 0.017353, loss_kd: 658.213867
[21:16:32.066] iteration 12890 : loss : 138.326691, loss_ce: 0.013386, loss_kd: 689.214661
[21:16:37.668] iteration 12900 : loss : 153.939362, loss_ce: 0.015372, loss_kd: 767.280640
[21:16:43.297] iteration 12910 : loss : 156.112564, loss_ce: 0.032681, loss_kd: 778.119263
[21:16:48.902] iteration 12920 : loss : 157.996002, loss_ce: 0.015144, loss_kd: 787.577332
[21:16:54.524] iteration 12930 : loss : 187.141464, loss_ce: 0.022075, loss_kd: 933.316284
[21:17:00.126] iteration 12940 : loss : 173.302551, loss_ce: 0.014850, loss_kd: 864.095459
[21:17:05.756] iteration 12950 : loss : 146.929153, loss_ce: 0.019603, loss_kd: 732.242432
[21:17:11.364] iteration 12960 : loss : 126.575653, loss_ce: 0.012809, loss_kd: 630.476562
[21:17:16.973] iteration 12970 : loss : 130.812561, loss_ce: 0.023226, loss_kd: 651.592285
[21:17:22.570] iteration 12980 : loss : 144.415283, loss_ce: 0.017084, loss_kd: 719.705688
[21:17:28.178] iteration 12990 : loss : 129.342743, loss_ce: 0.018540, loss_kd: 644.314148
[21:17:33.784] iteration 13000 : loss : 137.364670, loss_ce: 0.015165, loss_kd: 684.412842
[21:17:39.408] iteration 13010 : loss : 195.094009, loss_ce: 0.016214, loss_kd: 973.089111
[21:17:45.012] iteration 13020 : loss : 177.907272, loss_ce: 0.019989, loss_kd: 887.131592
[21:17:50.632] iteration 13030 : loss : 135.415649, loss_ce: 0.018399, loss_kd: 674.638428
[21:17:56.225] iteration 13040 : loss : 122.395309, loss_ce: 0.021793, loss_kd: 609.602905
[21:18:01.833] iteration 13050 : loss : 146.167450, loss_ce: 0.018589, loss_kd: 728.448059
[21:18:07.430] iteration 13060 : loss : 192.931137, loss_ce: 0.019346, loss_kd: 962.183838
[21:18:13.037] iteration 13070 : loss : 167.801605, loss_ce: 0.015648, loss_kd: 836.590210
[21:18:18.633] iteration 13080 : loss : 137.925110, loss_ce: 0.019507, loss_kd: 687.232056
[21:18:24.238] iteration 13090 : loss : 146.892807, loss_ce: 0.017236, loss_kd: 732.055298
[21:18:29.836] iteration 13100 : loss : 151.279648, loss_ce: 0.014771, loss_kd: 753.963684
[21:18:35.442] iteration 13110 : loss : 162.430450, loss_ce: 0.011914, loss_kd: 809.760132
[21:18:41.035] iteration 13120 : loss : 181.059372, loss_ce: 0.015163, loss_kd: 902.894348
[21:18:46.639] iteration 13130 : loss : 225.240845, loss_ce: 0.014392, loss_kd: 1123.808105
[21:18:52.238] iteration 13140 : loss : 290.781738, loss_ce: 0.009783, loss_kd: 1451.524780
[21:18:57.850] iteration 13150 : loss : 144.768402, loss_ce: 0.022093, loss_kd: 721.419067
[21:19:03.457] iteration 13160 : loss : 149.252060, loss_ce: 0.015653, loss_kd: 743.829468
[21:19:09.069] iteration 13170 : loss : 175.936508, loss_ce: 0.024273, loss_kd: 877.275879
[21:19:14.667] iteration 13180 : loss : 147.267975, loss_ce: 0.018469, loss_kd: 733.947021
[21:19:20.281] iteration 13190 : loss : 176.001190, loss_ce: 0.022609, loss_kd: 877.525330
[21:19:25.882] iteration 13200 : loss : 160.081573, loss_ce: 0.013168, loss_kd: 797.984375
[21:19:31.491] iteration 13210 : loss : 165.914505, loss_ce: 0.020209, loss_kd: 827.176880
[21:19:37.093] iteration 13220 : loss : 150.956635, loss_ce: 0.012172, loss_kd: 752.393555
[21:19:42.709] iteration 13230 : loss : 159.811539, loss_ce: 0.023754, loss_kd: 796.626343
[21:19:48.314] iteration 13240 : loss : 176.553253, loss_ce: 0.015634, loss_kd: 880.387146
[21:19:53.928] iteration 13250 : loss : 122.810127, loss_ce: 0.018877, loss_kd: 611.639587
[21:19:59.524] iteration 13260 : loss : 161.130569, loss_ce: 0.020529, loss_kd: 803.214966
[21:20:05.136] iteration 13270 : loss : 193.018112, loss_ce: 0.014903, loss_kd: 962.699036
[21:20:10.730] iteration 13280 : loss : 150.461349, loss_ce: 0.012595, loss_kd: 749.864502
[21:20:16.346] iteration 13290 : loss : 161.598999, loss_ce: 0.011118, loss_kd: 805.610291
[21:20:21.942] iteration 13300 : loss : 148.657196, loss_ce: 0.014590, loss_kd: 740.878357
[21:20:27.565] iteration 13310 : loss : 140.897507, loss_ce: 0.017904, loss_kd: 702.077515
[21:20:33.170] iteration 13320 : loss : 125.051018, loss_ce: 0.022135, loss_kd: 622.851685
[21:20:38.787] iteration 13330 : loss : 155.173904, loss_ce: 0.018766, loss_kd: 773.496582
[21:20:44.387] iteration 13340 : loss : 171.403244, loss_ce: 0.020105, loss_kd: 854.578369
[21:20:50.001] iteration 13350 : loss : 191.233490, loss_ce: 0.016090, loss_kd: 953.768616
[21:20:55.603] iteration 13360 : loss : 143.943390, loss_ce: 0.016249, loss_kd: 717.311707
[21:21:01.206] iteration 13370 : loss : 181.904037, loss_ce: 0.012399, loss_kd: 907.106812
[21:21:06.806] iteration 13380 : loss : 121.523743, loss_ce: 0.022243, loss_kd: 605.183838
[21:21:12.427] iteration 13390 : loss : 166.224289, loss_ce: 0.009645, loss_kd: 828.746643
[21:21:18.026] iteration 13400 : loss : 164.004120, loss_ce: 0.011347, loss_kd: 817.637817
[21:21:23.637] iteration 13410 : loss : 143.134354, loss_ce: 0.014373, loss_kd: 713.275208
[21:21:29.239] iteration 13420 : loss : 185.352539, loss_ce: 0.022250, loss_kd: 924.342590
[21:21:34.848] iteration 13430 : loss : 126.308884, loss_ce: 0.013390, loss_kd: 629.147461
[21:21:40.436] iteration 13440 : loss : 187.794403, loss_ce: 0.014468, loss_kd: 936.546143
[21:21:46.044] iteration 13450 : loss : 161.980072, loss_ce: 0.022331, loss_kd: 807.517029
[21:21:51.627] iteration 13460 : loss : 123.826813, loss_ce: 0.013544, loss_kd: 616.727417
[21:21:57.227] iteration 13470 : loss : 165.390594, loss_ce: 0.012221, loss_kd: 824.564331
[21:22:02.825] iteration 13480 : loss : 193.486176, loss_ce: 0.015453, loss_kd: 965.035828
[21:22:08.428] iteration 13490 : loss : 155.348724, loss_ce: 0.016721, loss_kd: 774.346313
[21:22:14.020] iteration 13500 : loss : 136.113647, loss_ce: 0.014855, loss_kd: 678.120361
[21:22:19.630] iteration 13510 : loss : 139.407578, loss_ce: 0.015617, loss_kd: 694.615540
[21:22:25.221] iteration 13520 : loss : 161.623718, loss_ce: 0.012350, loss_kd: 805.688416
[21:22:30.819] iteration 13530 : loss : 151.310516, loss_ce: 0.027594, loss_kd: 754.125977
[21:22:36.418] iteration 13540 : loss : 172.830414, loss_ce: 0.016006, loss_kd: 861.744934
[21:22:40.209] Running TPGM constraint optimization after epoch 13
[21:27:43.703] iteration 13550 : loss : 128.261627, loss_ce: 0.013864, loss_kd: 638.867615
[21:27:49.231] iteration 13560 : loss : 163.636093, loss_ce: 0.010310, loss_kd: 815.780396
[21:27:54.775] iteration 13570 : loss : 152.515381, loss_ce: 0.016407, loss_kd: 760.197937
[21:28:00.309] iteration 13580 : loss : 141.915939, loss_ce: 0.021768, loss_kd: 707.204346
[21:28:05.863] iteration 13590 : loss : 129.058105, loss_ce: 0.017127, loss_kd: 642.912170
[21:28:11.411] iteration 13600 : loss : 135.915451, loss_ce: 0.015006, loss_kd: 677.194702
[21:28:16.978] iteration 13610 : loss : 149.075409, loss_ce: 0.014532, loss_kd: 742.933838
[21:28:22.527] iteration 13620 : loss : 154.992142, loss_ce: 0.009754, loss_kd: 772.540771
[21:28:28.096] iteration 13630 : loss : 252.665710, loss_ce: 0.027348, loss_kd: 1260.909546
[21:28:33.657] iteration 13640 : loss : 227.763229, loss_ce: 0.012973, loss_kd: 1136.422241
[21:28:39.227] iteration 13650 : loss : 176.843369, loss_ce: 0.021537, loss_kd: 881.825867
[21:28:44.777] iteration 13660 : loss : 192.278702, loss_ce: 0.017212, loss_kd: 959.004150
[21:28:50.353] iteration 13670 : loss : 156.362244, loss_ce: 0.012414, loss_kd: 779.408752
[21:28:55.914] iteration 13680 : loss : 135.362747, loss_ce: 0.020122, loss_kd: 674.388306
[21:29:01.494] iteration 13690 : loss : 138.763901, loss_ce: 0.010777, loss_kd: 691.406006
[21:29:07.061] iteration 13700 : loss : 188.333847, loss_ce: 0.014837, loss_kd: 939.253479
[21:29:12.637] iteration 13710 : loss : 150.325470, loss_ce: 0.017764, loss_kd: 749.244324
[21:29:18.215] iteration 13720 : loss : 119.160698, loss_ce: 0.022411, loss_kd: 593.371033
[21:29:23.791] iteration 13730 : loss : 157.315842, loss_ce: 0.025336, loss_kd: 784.195801
[21:29:29.361] iteration 13740 : loss : 145.638809, loss_ce: 0.016802, loss_kd: 725.776672
[21:29:34.937] iteration 13750 : loss : 132.920456, loss_ce: 0.014786, loss_kd: 662.193054
[21:29:40.502] iteration 13760 : loss : 146.788528, loss_ce: 0.017035, loss_kd: 731.556030
[21:29:46.080] iteration 13770 : loss : 159.266586, loss_ce: 0.018734, loss_kd: 793.940674
[21:29:51.648] iteration 13780 : loss : 134.582870, loss_ce: 0.015185, loss_kd: 670.502686
[21:29:57.231] iteration 13790 : loss : 147.459915, loss_ce: 0.017263, loss_kd: 734.884827
[21:30:02.805] iteration 13800 : loss : 214.926651, loss_ce: 0.019645, loss_kd: 1072.189941
[21:30:08.399] iteration 13810 : loss : 196.812103, loss_ce: 0.011758, loss_kd: 981.661194
[21:30:13.968] iteration 13820 : loss : 122.345398, loss_ce: 0.017741, loss_kd: 609.259033
[21:30:19.558] iteration 13830 : loss : 156.071945, loss_ce: 0.014297, loss_kd: 777.972046
[21:30:25.134] iteration 13840 : loss : 177.755112, loss_ce: 0.008535, loss_kd: 886.384705
[21:30:30.727] iteration 13850 : loss : 137.146530, loss_ce: 0.026129, loss_kd: 683.284668
[21:30:36.314] iteration 13860 : loss : 183.492020, loss_ce: 0.018489, loss_kd: 915.008179
[21:30:41.916] iteration 13870 : loss : 169.193100, loss_ce: 0.018306, loss_kd: 843.568237
[21:30:47.513] iteration 13880 : loss : 144.847687, loss_ce: 0.011672, loss_kd: 721.815918
[21:30:53.119] iteration 13890 : loss : 164.681320, loss_ce: 0.021003, loss_kd: 820.986328
[21:30:58.720] iteration 13900 : loss : 143.601654, loss_ce: 0.012286, loss_kd: 715.614441
[21:31:04.328] iteration 13910 : loss : 144.062607, loss_ce: 0.015636, loss_kd: 717.905457
[21:31:09.945] iteration 13920 : loss : 162.956848, loss_ce: 0.006564, loss_kd: 812.354919
[21:31:15.536] iteration 13930 : loss : 222.611221, loss_ce: 0.021650, loss_kd: 1110.653198
[21:31:21.133] iteration 13940 : loss : 167.599503, loss_ce: 0.014926, loss_kd: 835.627808
[21:31:26.736] iteration 13950 : loss : 230.461136, loss_ce: 0.012035, loss_kd: 1149.909180
[21:31:32.324] iteration 13960 : loss : 145.430252, loss_ce: 0.020355, loss_kd: 724.738647
[21:31:37.920] iteration 13970 : loss : 133.992111, loss_ce: 0.015822, loss_kd: 667.559326
[21:31:43.511] iteration 13980 : loss : 189.249023, loss_ce: 0.017451, loss_kd: 943.839172
[21:31:49.106] iteration 13990 : loss : 137.452576, loss_ce: 0.014172, loss_kd: 684.857910
[21:31:54.701] iteration 14000 : loss : 133.694275, loss_ce: 0.027088, loss_kd: 666.063538
[21:32:00.304] iteration 14010 : loss : 176.744019, loss_ce: 0.013399, loss_kd: 881.350464
[21:32:05.898] iteration 14020 : loss : 134.724319, loss_ce: 0.012852, loss_kd: 671.225220
[21:32:11.496] iteration 14030 : loss : 159.370651, loss_ce: 0.015173, loss_kd: 794.423340
[21:32:17.093] iteration 14040 : loss : 210.309891, loss_ce: 0.011094, loss_kd: 1049.173462
[21:32:22.690] iteration 14050 : loss : 166.306305, loss_ce: 0.016585, loss_kd: 829.121948
[21:32:28.284] iteration 14060 : loss : 123.078087, loss_ce: 0.011871, loss_kd: 613.028076
[21:32:33.889] iteration 14070 : loss : 112.681915, loss_ce: 0.021313, loss_kd: 560.862671
[21:32:39.475] iteration 14080 : loss : 140.262741, loss_ce: 0.017693, loss_kd: 698.876709
[21:32:45.079] iteration 14090 : loss : 171.859406, loss_ce: 0.010946, loss_kd: 856.869629
[21:32:50.668] iteration 14100 : loss : 113.500748, loss_ce: 0.021083, loss_kd: 565.108887
[21:32:56.277] iteration 14110 : loss : 155.435959, loss_ce: 0.017002, loss_kd: 774.765869
[21:33:01.877] iteration 14120 : loss : 177.214096, loss_ce: 0.010508, loss_kd: 883.669800
[21:33:07.481] iteration 14130 : loss : 190.073563, loss_ce: 0.016137, loss_kd: 947.994812
[21:33:13.076] iteration 14140 : loss : 131.810913, loss_ce: 0.013007, loss_kd: 656.676086
[21:33:18.679] iteration 14150 : loss : 109.260307, loss_ce: 0.015887, loss_kd: 543.939636
[21:33:24.283] iteration 14160 : loss : 104.581276, loss_ce: 0.018867, loss_kd: 520.515625
[21:33:29.887] iteration 14170 : loss : 120.976753, loss_ce: 0.016484, loss_kd: 602.494080
[21:33:35.474] iteration 14180 : loss : 140.206528, loss_ce: 0.015809, loss_kd: 698.652344
[21:33:41.078] iteration 14190 : loss : 179.377426, loss_ce: 0.021599, loss_kd: 894.468933
[21:33:46.675] iteration 14200 : loss : 163.805511, loss_ce: 0.015028, loss_kd: 816.646057
[21:33:52.280] iteration 14210 : loss : 187.035889, loss_ce: 0.012778, loss_kd: 932.793152
[21:33:57.872] iteration 14220 : loss : 192.598755, loss_ce: 0.012817, loss_kd: 960.571167
[21:34:03.475] iteration 14230 : loss : 148.565674, loss_ce: 0.012995, loss_kd: 740.419800
[21:34:09.068] iteration 14240 : loss : 125.071396, loss_ce: 0.014983, loss_kd: 622.968018
[21:34:14.673] iteration 14250 : loss : 117.564369, loss_ce: 0.014788, loss_kd: 585.405029
[21:34:20.265] iteration 14260 : loss : 136.408966, loss_ce: 0.020043, loss_kd: 679.621765
[21:34:25.876] iteration 14270 : loss : 167.485016, loss_ce: 0.016602, loss_kd: 835.015137
[21:34:31.462] iteration 14280 : loss : 208.073730, loss_ce: 0.021943, loss_kd: 1037.965332
[21:34:37.062] iteration 14290 : loss : 159.450424, loss_ce: 0.014514, loss_kd: 794.857727
[21:34:42.656] iteration 14300 : loss : 149.268814, loss_ce: 0.020610, loss_kd: 743.961304
[21:34:48.266] iteration 14310 : loss : 219.395660, loss_ce: 0.011292, loss_kd: 1094.589111
[21:34:53.856] iteration 14320 : loss : 143.814789, loss_ce: 0.017058, loss_kd: 716.690430
[21:34:59.472] iteration 14330 : loss : 159.027237, loss_ce: 0.009500, loss_kd: 792.756104
[21:35:05.069] iteration 14340 : loss : 149.734192, loss_ce: 0.008821, loss_kd: 746.305176
[21:35:10.679] iteration 14350 : loss : 114.253761, loss_ce: 0.014262, loss_kd: 568.893372
[21:35:16.269] iteration 14360 : loss : 140.109543, loss_ce: 0.010847, loss_kd: 698.110718
[21:35:21.871] iteration 14370 : loss : 128.587524, loss_ce: 0.017520, loss_kd: 640.537964
[21:35:27.457] iteration 14380 : loss : 166.276398, loss_ce: 0.010226, loss_kd: 828.983276
[21:35:33.064] iteration 14390 : loss : 160.388245, loss_ce: 0.025395, loss_kd: 799.527161
[21:35:38.662] iteration 14400 : loss : 125.538879, loss_ce: 0.010653, loss_kd: 625.311462
[21:35:44.280] iteration 14410 : loss : 163.909103, loss_ce: 0.017196, loss_kd: 817.146118
[21:35:49.889] iteration 14420 : loss : 135.826874, loss_ce: 0.015424, loss_kd: 676.728210
[21:35:55.498] iteration 14430 : loss : 159.512039, loss_ce: 0.024955, loss_kd: 795.144531
[21:36:01.100] iteration 14440 : loss : 176.968109, loss_ce: 0.011951, loss_kd: 882.436096
[21:36:06.718] iteration 14450 : loss : 142.236313, loss_ce: 0.012064, loss_kd: 708.790100
[21:36:12.317] iteration 14460 : loss : 115.713867, loss_ce: 0.016568, loss_kd: 576.166504
[21:36:17.919] iteration 14470 : loss : 143.776352, loss_ce: 0.015215, loss_kd: 716.483887
[21:36:23.510] iteration 14480 : loss : 168.126328, loss_ce: 0.023457, loss_kd: 838.186523
[21:36:29.119] iteration 14490 : loss : 117.596504, loss_ce: 0.016961, loss_kd: 585.566956
[21:36:34.710] iteration 14500 : loss : 145.971268, loss_ce: 0.021207, loss_kd: 727.459717
[21:36:40.337] iteration 14510 : loss : 175.132385, loss_ce: 0.015016, loss_kd: 873.271484
[21:36:45.944] iteration 14520 : loss : 153.209656, loss_ce: 0.017083, loss_kd: 763.664612
[21:36:51.554] iteration 14530 : loss : 161.764664, loss_ce: 0.014806, loss_kd: 806.394714
[21:36:57.149] iteration 14540 : loss : 173.862183, loss_ce: 0.018581, loss_kd: 866.903687
[21:37:02.756] iteration 14550 : loss : 153.857132, loss_ce: 0.014681, loss_kd: 766.841431
[21:37:08.346] iteration 14560 : loss : 160.019943, loss_ce: 0.018507, loss_kd: 797.687683
[21:37:13.951] iteration 14570 : loss : 147.910965, loss_ce: 0.013210, loss_kd: 737.167480
[21:37:19.543] iteration 14580 : loss : 155.414490, loss_ce: 0.025072, loss_kd: 774.646362
[21:37:37.032] iteration 14590 : loss : 142.355087, loss_ce: 0.021167, loss_kd: 709.384033
[21:37:42.570] iteration 14600 : loss : 130.060898, loss_ce: 0.017761, loss_kd: 647.908142
[21:37:48.118] iteration 14610 : loss : 160.792236, loss_ce: 0.014607, loss_kd: 801.538879
[21:37:53.662] iteration 14620 : loss : 167.127182, loss_ce: 0.025228, loss_kd: 833.199402
[21:37:59.221] iteration 14630 : loss : 183.925354, loss_ce: 0.015681, loss_kd: 917.257324
[21:38:04.775] iteration 14640 : loss : 324.965210, loss_ce: 0.021602, loss_kd: 1622.407471
[21:38:10.348] iteration 14650 : loss : 212.157318, loss_ce: 0.013470, loss_kd: 1058.387939
[21:38:15.912] iteration 14660 : loss : 137.224762, loss_ce: 0.018451, loss_kd: 683.736145
[21:38:21.479] iteration 14670 : loss : 101.693626, loss_ce: 0.015142, loss_kd: 506.074402
[21:38:27.044] iteration 14680 : loss : 145.018341, loss_ce: 0.016961, loss_kd: 722.644653
[21:38:32.624] iteration 14690 : loss : 150.404129, loss_ce: 0.021990, loss_kd: 749.602722
[21:38:38.187] iteration 14700 : loss : 131.743195, loss_ce: 0.032888, loss_kd: 656.292114
[21:38:43.768] iteration 14710 : loss : 126.210968, loss_ce: 0.015874, loss_kd: 628.670105
[21:38:49.343] iteration 14720 : loss : 181.820297, loss_ce: 0.014828, loss_kd: 906.724060
[21:38:54.925] iteration 14730 : loss : 159.830215, loss_ce: 0.021050, loss_kd: 796.726501
[21:39:00.507] iteration 14740 : loss : 133.691223, loss_ce: 0.020889, loss_kd: 666.073364
[21:39:06.104] iteration 14750 : loss : 152.757217, loss_ce: 0.024799, loss_kd: 761.384644
[21:39:11.684] iteration 14760 : loss : 149.208511, loss_ce: 0.015625, loss_kd: 743.659607
[21:39:17.269] iteration 14770 : loss : 148.784103, loss_ce: 0.018538, loss_kd: 741.505554
[21:39:22.851] iteration 14780 : loss : 140.494781, loss_ce: 0.016968, loss_kd: 700.101013
[21:39:28.444] iteration 14790 : loss : 123.901344, loss_ce: 0.023453, loss_kd: 617.105713
[21:39:34.032] iteration 14800 : loss : 157.257675, loss_ce: 0.016420, loss_kd: 783.910889
[21:39:39.634] iteration 14810 : loss : 128.004807, loss_ce: 0.014196, loss_kd: 637.609863
[21:39:45.228] iteration 14820 : loss : 152.149445, loss_ce: 0.014024, loss_kd: 758.345825
[21:39:50.830] iteration 14830 : loss : 144.599075, loss_ce: 0.021175, loss_kd: 720.576355
[21:39:56.422] iteration 14840 : loss : 175.278824, loss_ce: 0.009608, loss_kd: 873.989746
[21:40:02.024] iteration 14850 : loss : 132.608170, loss_ce: 0.014124, loss_kd: 660.612183
[21:40:07.618] iteration 14860 : loss : 133.408218, loss_ce: 0.016472, loss_kd: 664.630737
[21:40:13.220] iteration 14870 : loss : 156.590927, loss_ce: 0.015610, loss_kd: 780.566467
[21:40:18.818] iteration 14880 : loss : 141.095764, loss_ce: 0.024646, loss_kd: 703.054688
[21:40:24.422] iteration 14890 : loss : 134.904999, loss_ce: 0.009883, loss_kd: 672.150879
[21:40:30.016] iteration 14900 : loss : 149.186005, loss_ce: 0.031950, loss_kd: 743.499634
[21:40:35.623] iteration 14910 : loss : 174.630341, loss_ce: 0.010053, loss_kd: 870.727905
[21:40:41.220] iteration 14920 : loss : 122.443726, loss_ce: 0.015366, loss_kd: 609.813599
[21:40:46.818] iteration 14930 : loss : 171.441544, loss_ce: 0.017177, loss_kd: 854.797607
[21:40:52.410] iteration 14940 : loss : 173.113052, loss_ce: 0.020541, loss_kd: 863.167175
[21:40:58.015] iteration 14950 : loss : 147.128525, loss_ce: 0.021670, loss_kd: 733.247498
[21:41:03.609] iteration 14960 : loss : 160.162735, loss_ce: 0.014328, loss_kd: 798.391968
[21:41:09.211] iteration 14970 : loss : 163.154297, loss_ce: 0.022101, loss_kd: 813.357300
[21:41:14.814] iteration 14980 : loss : 159.336060, loss_ce: 0.019793, loss_kd: 794.268127
[21:41:20.410] iteration 14990 : loss : 141.631683, loss_ce: 0.014332, loss_kd: 705.762146
[21:41:26.006] iteration 15000 : loss : 149.032166, loss_ce: 0.012556, loss_kd: 742.722168
[21:41:31.617] iteration 15010 : loss : 141.754517, loss_ce: 0.013249, loss_kd: 706.400574
[21:41:37.209] iteration 15020 : loss : 130.568985, loss_ce: 0.016151, loss_kd: 650.430115
[21:41:42.811] iteration 15030 : loss : 166.924393, loss_ce: 0.012503, loss_kd: 832.233032
[21:41:48.409] iteration 15040 : loss : 128.016678, loss_ce: 0.025575, loss_kd: 637.686035
[21:41:54.006] iteration 15050 : loss : 126.652542, loss_ce: 0.014255, loss_kd: 630.871948
[21:41:59.594] iteration 15060 : loss : 153.602585, loss_ce: 0.021835, loss_kd: 765.586670
[21:42:05.201] iteration 15070 : loss : 140.756958, loss_ce: 0.021216, loss_kd: 701.372192
[21:42:10.792] iteration 15080 : loss : 162.403229, loss_ce: 0.026077, loss_kd: 809.595032
[21:42:16.396] iteration 15090 : loss : 172.722855, loss_ce: 0.014812, loss_kd: 861.221802
[21:42:21.997] iteration 15100 : loss : 170.439102, loss_ce: 0.021751, loss_kd: 849.832275
[21:42:27.610] iteration 15110 : loss : 160.255508, loss_ce: 0.015923, loss_kd: 798.895203
[21:42:33.199] iteration 15120 : loss : 94.449867, loss_ce: 0.012149, loss_kd: 469.868805
[21:42:38.803] iteration 15130 : loss : 127.991531, loss_ce: 0.018221, loss_kd: 637.557739
[21:42:44.389] iteration 15140 : loss : 137.563446, loss_ce: 0.011611, loss_kd: 685.385925
[21:42:49.991] iteration 15150 : loss : 195.423401, loss_ce: 0.017452, loss_kd: 974.704468
[21:42:55.585] iteration 15160 : loss : 122.081650, loss_ce: 0.013556, loss_kd: 608.005737
[21:43:01.181] iteration 15170 : loss : 138.179352, loss_ce: 0.025296, loss_kd: 688.492310
[21:43:06.804] iteration 15180 : loss : 130.665588, loss_ce: 0.029262, loss_kd: 650.933105
[21:43:12.409] iteration 15190 : loss : 135.789307, loss_ce: 0.016985, loss_kd: 676.541260
[21:43:18.006] iteration 15200 : loss : 162.102707, loss_ce: 0.011571, loss_kd: 808.110596
[21:43:23.621] iteration 15210 : loss : 155.271317, loss_ce: 0.024345, loss_kd: 773.969788
[21:43:29.226] iteration 15220 : loss : 158.295609, loss_ce: 0.024199, loss_kd: 789.102905
[21:43:34.838] iteration 15230 : loss : 122.858009, loss_ce: 0.012186, loss_kd: 611.838074
[21:43:40.439] iteration 15240 : loss : 136.187241, loss_ce: 0.011758, loss_kd: 678.565308
[21:43:46.048] iteration 15250 : loss : 154.695419, loss_ce: 0.013642, loss_kd: 771.095459
[21:43:51.643] iteration 15260 : loss : 149.019089, loss_ce: 0.013427, loss_kd: 742.694031
[21:43:57.250] iteration 15270 : loss : 139.077881, loss_ce: 0.013500, loss_kd: 693.018738
[21:44:02.846] iteration 15280 : loss : 166.760544, loss_ce: 0.022774, loss_kd: 831.371826
[21:44:08.450] iteration 15290 : loss : 148.043411, loss_ce: 0.017803, loss_kd: 737.826477
[21:44:14.041] iteration 15300 : loss : 113.139587, loss_ce: 0.017457, loss_kd: 563.307739
[21:44:19.656] iteration 15310 : loss : 132.567612, loss_ce: 0.019937, loss_kd: 660.461792
[21:44:25.251] iteration 15320 : loss : 149.508316, loss_ce: 0.020660, loss_kd: 745.107910
[21:44:30.853] iteration 15330 : loss : 169.930222, loss_ce: 0.023792, loss_kd: 847.269592
[21:44:36.451] iteration 15340 : loss : 231.055450, loss_ce: 0.017163, loss_kd: 1152.878540
[21:44:42.053] iteration 15350 : loss : 153.414825, loss_ce: 0.013391, loss_kd: 764.721130
[21:44:47.650] iteration 15360 : loss : 169.047546, loss_ce: 0.014466, loss_kd: 842.866638
[21:44:53.253] iteration 15370 : loss : 123.978760, loss_ce: 0.017168, loss_kd: 617.496277
[21:44:58.847] iteration 15380 : loss : 94.765472, loss_ce: 0.012470, loss_kd: 471.428619
[21:45:04.470] iteration 15390 : loss : 157.201370, loss_ce: 0.013603, loss_kd: 783.577881
[21:45:10.072] iteration 15400 : loss : 172.421051, loss_ce: 0.014491, loss_kd: 859.664673
[21:45:15.681] iteration 15410 : loss : 207.268326, loss_ce: 0.017722, loss_kd: 1033.979004
[21:45:21.271] iteration 15420 : loss : 100.401375, loss_ce: 0.010763, loss_kd: 499.620911
[21:45:26.876] iteration 15430 : loss : 112.914528, loss_ce: 0.019779, loss_kd: 562.147949
[21:45:32.467] iteration 15440 : loss : 113.552963, loss_ce: 0.015782, loss_kd: 565.377197
[21:45:38.074] iteration 15450 : loss : 148.483292, loss_ce: 0.022221, loss_kd: 740.012817
[21:45:43.670] iteration 15460 : loss : 111.968842, loss_ce: 0.016398, loss_kd: 557.439026
[21:45:49.288] iteration 15470 : loss : 118.472862, loss_ce: 0.028896, loss_kd: 589.956421
[21:45:54.885] iteration 15480 : loss : 115.000931, loss_ce: 0.016428, loss_kd: 572.633179
[21:46:00.486] iteration 15490 : loss : 176.955475, loss_ce: 0.016615, loss_kd: 882.360107
[21:46:06.076] iteration 15500 : loss : 176.244568, loss_ce: 0.026310, loss_kd: 878.799866
[21:46:11.689] iteration 15510 : loss : 125.552597, loss_ce: 0.009335, loss_kd: 625.383667
[21:46:17.285] iteration 15520 : loss : 129.369324, loss_ce: 0.014551, loss_kd: 644.462769
[21:46:22.887] iteration 15530 : loss : 136.000214, loss_ce: 0.013023, loss_kd: 677.584351
[21:46:28.486] iteration 15540 : loss : 126.980446, loss_ce: 0.028587, loss_kd: 632.502197
[21:46:34.086] iteration 15550 : loss : 139.153076, loss_ce: 0.011688, loss_kd: 693.411499
[21:46:39.676] iteration 15560 : loss : 150.584549, loss_ce: 0.018969, loss_kd: 750.524536
[21:46:45.282] iteration 15570 : loss : 172.030899, loss_ce: 0.012242, loss_kd: 857.761719
[21:46:50.873] iteration 15580 : loss : 201.812515, loss_ce: 0.012849, loss_kd: 1006.656738
[21:46:56.471] iteration 15590 : loss : 140.139099, loss_ce: 0.016575, loss_kd: 698.303955
[21:47:02.070] iteration 15600 : loss : 155.701981, loss_ce: 0.021988, loss_kd: 776.130676
[21:47:07.672] iteration 15610 : loss : 171.621246, loss_ce: 0.013603, loss_kd: 855.717590
[21:47:13.268] iteration 15620 : loss : 126.994995, loss_ce: 0.011483, loss_kd: 632.621582
[21:47:18.576] iteration 15630 : loss : 118.452019, loss_ce: 0.022609, loss_kd: 589.831543
[21:47:19.347] save model to ./debug_fixed_tpgm\continual_surgical_tpgm_stage1_epoch_14.pth
[21:47:19.351] Running TPGM constraint optimization after epoch 15
[21:52:26.786] iteration 15640 : loss : 128.747696, loss_ce: 0.025253, loss_kd: 641.308105
[21:52:32.321] iteration 15650 : loss : 177.870880, loss_ce: 0.024091, loss_kd: 886.945557
[21:52:37.855] iteration 15660 : loss : 181.556763, loss_ce: 0.012743, loss_kd: 905.369873
[21:52:43.406] iteration 15670 : loss : 208.573883, loss_ce: 0.013903, loss_kd: 1040.494507
[21:52:48.944] iteration 15680 : loss : 228.623230, loss_ce: 0.019674, loss_kd: 1140.685547
[21:52:54.488] iteration 15690 : loss : 166.638641, loss_ce: 0.021863, loss_kd: 830.789612
[21:53:00.027] iteration 15700 : loss : 168.950409, loss_ce: 0.022094, loss_kd: 842.353210
[21:53:05.589] iteration 15710 : loss : 166.933136, loss_ce: 0.015292, loss_kd: 832.213196
[21:53:11.128] iteration 15720 : loss : 149.478439, loss_ce: 0.023606, loss_kd: 744.993713
[21:53:16.674] iteration 15730 : loss : 180.936584, loss_ce: 0.015104, loss_kd: 902.281250
[21:53:22.216] iteration 15740 : loss : 116.119751, loss_ce: 0.013053, loss_kd: 578.205933
[21:53:27.780] iteration 15750 : loss : 141.134216, loss_ce: 0.019097, loss_kd: 703.272827
[21:53:33.334] iteration 15760 : loss : 106.148544, loss_ce: 0.025937, loss_kd: 528.365845
[21:53:38.903] iteration 15770 : loss : 135.239548, loss_ce: 0.016348, loss_kd: 673.819580
[21:53:44.457] iteration 15780 : loss : 118.376778, loss_ce: 0.021177, loss_kd: 589.548096
[21:53:50.024] iteration 15790 : loss : 181.215347, loss_ce: 0.010492, loss_kd: 903.682495
[21:53:55.580] iteration 15800 : loss : 158.679245, loss_ce: 0.010241, loss_kd: 791.030579
[21:54:01.150] iteration 15810 : loss : 159.396210, loss_ce: 0.023831, loss_kd: 794.569519
[21:54:06.707] iteration 15820 : loss : 125.588417, loss_ce: 0.028585, loss_kd: 625.562073
[21:54:12.281] iteration 15830 : loss : 135.428665, loss_ce: 0.022537, loss_kd: 674.713623
[21:54:17.849] iteration 15840 : loss : 93.717606, loss_ce: 0.029615, loss_kd: 466.174255
[21:54:23.428] iteration 15850 : loss : 160.100464, loss_ce: 0.017374, loss_kd: 798.156860
[21:54:28.997] iteration 15860 : loss : 168.617691, loss_ce: 0.015206, loss_kd: 840.646118
[21:54:34.572] iteration 15870 : loss : 114.767166, loss_ce: 0.013006, loss_kd: 571.404846
[21:54:40.140] iteration 15880 : loss : 122.979736, loss_ce: 0.014193, loss_kd: 612.458679
[21:54:45.718] iteration 15890 : loss : 190.452942, loss_ce: 0.023545, loss_kd: 949.862793
[21:54:51.295] iteration 15900 : loss : 132.713242, loss_ce: 0.013825, loss_kd: 661.168091
[21:54:56.881] iteration 15910 : loss : 134.529694, loss_ce: 0.025405, loss_kd: 670.229492
[21:55:02.457] iteration 15920 : loss : 112.634338, loss_ce: 0.012649, loss_kd: 560.768311
[21:55:08.041] iteration 15930 : loss : 192.892410, loss_ce: 0.009958, loss_kd: 962.078613
[21:55:13.624] iteration 15940 : loss : 150.323227, loss_ce: 0.012336, loss_kd: 749.192200
[21:55:19.209] iteration 15950 : loss : 164.245773, loss_ce: 0.018658, loss_kd: 818.822144
[21:55:24.801] iteration 15960 : loss : 166.281433, loss_ce: 0.013753, loss_kd: 829.025757
[21:55:30.384] iteration 15970 : loss : 144.295578, loss_ce: 0.014531, loss_kd: 719.085022
[21:55:35.966] iteration 15980 : loss : 181.858215, loss_ce: 0.017855, loss_kd: 906.860474
[21:55:41.563] iteration 15990 : loss : 146.142670, loss_ce: 0.015756, loss_kd: 728.278442
[21:55:47.146] iteration 16000 : loss : 129.319000, loss_ce: 0.010279, loss_kd: 644.186462
[21:55:52.750] iteration 16010 : loss : 133.389236, loss_ce: 0.013094, loss_kd: 664.557373
[21:55:58.322] iteration 16020 : loss : 130.744965, loss_ce: 0.009139, loss_kd: 651.304199
[21:56:03.912] iteration 16030 : loss : 189.501099, loss_ce: 0.014716, loss_kd: 945.067444
[21:56:09.491] iteration 16040 : loss : 152.538132, loss_ce: 0.018609, loss_kd: 760.317871
[21:56:15.088] iteration 16050 : loss : 235.576981, loss_ce: 0.014558, loss_kd: 1175.481812
[21:56:20.670] iteration 16060 : loss : 115.513176, loss_ce: 0.013980, loss_kd: 575.208618
[21:56:26.254] iteration 16070 : loss : 150.956085, loss_ce: 0.011527, loss_kd: 752.392273
[21:56:31.826] iteration 16080 : loss : 102.461632, loss_ce: 0.014309, loss_kd: 509.910156
[21:56:37.414] iteration 16090 : loss : 138.943817, loss_ce: 0.017963, loss_kd: 692.291382
[21:56:42.997] iteration 16100 : loss : 198.468903, loss_ce: 0.015046, loss_kd: 989.960510
[21:56:48.595] iteration 16110 : loss : 156.275192, loss_ce: 0.016999, loss_kd: 778.980713
[21:56:54.170] iteration 16120 : loss : 140.853836, loss_ce: 0.014363, loss_kd: 701.862610
[21:56:59.754] iteration 16130 : loss : 147.005890, loss_ce: 0.013001, loss_kd: 732.630615
[21:57:05.331] iteration 16140 : loss : 105.396011, loss_ce: 0.020053, loss_kd: 524.614624
[21:57:10.919] iteration 16150 : loss : 126.643387, loss_ce: 0.016360, loss_kd: 630.765076
[21:57:16.506] iteration 16160 : loss : 172.260345, loss_ce: 0.012269, loss_kd: 858.903687
[21:57:22.096] iteration 16170 : loss : 147.056519, loss_ce: 0.010666, loss_kd: 732.857544
[21:57:27.676] iteration 16180 : loss : 189.496704, loss_ce: 0.014631, loss_kd: 945.059875
[21:57:33.266] iteration 16190 : loss : 168.046631, loss_ce: 0.010513, loss_kd: 837.843506
[21:57:38.846] iteration 16200 : loss : 177.117584, loss_ce: 0.021690, loss_kd: 883.180359
[21:57:44.444] iteration 16210 : loss : 146.693710, loss_ce: 0.018825, loss_kd: 731.032898
[21:57:50.028] iteration 16220 : loss : 207.147751, loss_ce: 0.008083, loss_kd: 1033.382568
[21:57:55.620] iteration 16230 : loss : 188.138412, loss_ce: 0.014604, loss_kd: 938.278564
[21:58:01.199] iteration 16240 : loss : 137.136673, loss_ce: 0.012621, loss_kd: 683.348755
[21:58:06.792] iteration 16250 : loss : 143.356628, loss_ce: 0.009628, loss_kd: 714.396851
[21:58:12.371] iteration 16260 : loss : 143.025253, loss_ce: 0.024392, loss_kd: 712.706665
[21:58:17.964] iteration 16270 : loss : 108.809082, loss_ce: 0.021475, loss_kd: 541.630249
[21:58:23.552] iteration 16280 : loss : 164.823944, loss_ce: 0.016020, loss_kd: 821.723877
[21:58:29.227] iteration 16290 : loss : 135.194748, loss_ce: 0.018761, loss_kd: 673.573914
[21:58:34.815] iteration 16300 : loss : 128.394455, loss_ce: 0.017863, loss_kd: 639.574341
[21:58:40.417] iteration 16310 : loss : 109.012535, loss_ce: 0.015822, loss_kd: 542.675720
[21:58:45.997] iteration 16320 : loss : 176.489853, loss_ce: 0.012229, loss_kd: 880.047241
[21:58:51.595] iteration 16330 : loss : 136.549347, loss_ce: 0.012963, loss_kd: 680.361450
[21:58:57.175] iteration 16340 : loss : 192.449417, loss_ce: 0.016093, loss_kd: 959.847839
[21:59:02.759] iteration 16350 : loss : 159.033386, loss_ce: 0.014934, loss_kd: 792.791077
[21:59:08.345] iteration 16360 : loss : 160.628204, loss_ce: 0.021213, loss_kd: 800.746887
[21:59:13.941] iteration 16370 : loss : 158.401108, loss_ce: 0.016684, loss_kd: 789.601746
[21:59:19.519] iteration 16380 : loss : 144.551163, loss_ce: 0.019916, loss_kd: 720.349487
[21:59:25.115] iteration 16390 : loss : 188.112244, loss_ce: 0.025119, loss_kd: 938.122681
[21:59:30.696] iteration 16400 : loss : 223.663589, loss_ce: 0.013302, loss_kd: 1115.950684
[21:59:36.282] iteration 16410 : loss : 173.203690, loss_ce: 0.019814, loss_kd: 863.627136
[21:59:41.864] iteration 16420 : loss : 141.222076, loss_ce: 0.010455, loss_kd: 703.721436
[21:59:47.459] iteration 16430 : loss : 141.449493, loss_ce: 0.025921, loss_kd: 704.843811
[21:59:53.039] iteration 16440 : loss : 120.014534, loss_ce: 0.010941, loss_kd: 597.643494
[21:59:58.625] iteration 16450 : loss : 165.884476, loss_ce: 0.016487, loss_kd: 826.996216
[22:00:04.202] iteration 16460 : loss : 154.891556, loss_ce: 0.016386, loss_kd: 772.091675
[22:00:09.792] iteration 16470 : loss : 124.754616, loss_ce: 0.013876, loss_kd: 621.431335
[22:00:15.374] iteration 16480 : loss : 142.924316, loss_ce: 0.019922, loss_kd: 712.213745
[22:00:20.968] iteration 16490 : loss : 130.586166, loss_ce: 0.016731, loss_kd: 650.526733
[22:00:26.541] iteration 16500 : loss : 125.236099, loss_ce: 0.012755, loss_kd: 623.735657
[22:00:32.122] iteration 16510 : loss : 125.774323, loss_ce: 0.023157, loss_kd: 626.455933
[22:00:37.707] iteration 16520 : loss : 145.877136, loss_ce: 0.012809, loss_kd: 727.035583
[22:00:43.302] iteration 16530 : loss : 148.613922, loss_ce: 0.020760, loss_kd: 740.667603
[22:00:48.882] iteration 16540 : loss : 156.188477, loss_ce: 0.011678, loss_kd: 778.578430
[22:00:54.473] iteration 16550 : loss : 89.340004, loss_ce: 0.011959, loss_kd: 444.326752
[22:01:00.050] iteration 16560 : loss : 171.214249, loss_ce: 0.010508, loss_kd: 853.664307
[22:01:05.637] iteration 16570 : loss : 113.280556, loss_ce: 0.015393, loss_kd: 564.021790
[22:01:11.214] iteration 16580 : loss : 130.688736, loss_ce: 0.010084, loss_kd: 651.017700
[22:01:16.800] iteration 16590 : loss : 116.841316, loss_ce: 0.024551, loss_kd: 581.820801
[22:01:22.369] iteration 16600 : loss : 163.170227, loss_ce: 0.010409, loss_kd: 813.466187
[22:01:27.957] iteration 16610 : loss : 210.576294, loss_ce: 0.017913, loss_kd: 1050.482666
[22:01:33.540] iteration 16620 : loss : 158.067398, loss_ce: 0.011712, loss_kd: 787.999329
[22:01:39.128] iteration 16630 : loss : 140.877563, loss_ce: 0.016085, loss_kd: 702.019104
[22:01:44.700] iteration 16640 : loss : 133.591080, loss_ce: 0.019135, loss_kd: 665.557495
[22:01:50.289] iteration 16650 : loss : 132.194550, loss_ce: 0.017255, loss_kd: 658.586365
[22:01:55.869] iteration 16660 : loss : 109.232368, loss_ce: 0.024372, loss_kd: 543.796265
[22:02:01.468] iteration 16670 : loss : 118.885368, loss_ce: 0.016215, loss_kd: 592.085999
[22:02:17.506] iteration 16680 : loss : 161.613007, loss_ce: 0.016612, loss_kd: 805.702393
[22:02:23.062] iteration 16690 : loss : 106.091156, loss_ce: 0.015894, loss_kd: 528.061035
[22:02:28.596] iteration 16700 : loss : 128.542587, loss_ce: 0.017997, loss_kd: 640.292603
[22:02:34.152] iteration 16710 : loss : 153.069260, loss_ce: 0.016645, loss_kd: 762.984070
[22:02:39.699] iteration 16720 : loss : 117.692558, loss_ce: 0.020875, loss_kd: 586.049744
[22:02:45.253] iteration 16730 : loss : 143.639893, loss_ce: 0.011208, loss_kd: 715.749146
[22:02:50.803] iteration 16740 : loss : 134.349670, loss_ce: 0.019661, loss_kd: 669.363037
[22:02:56.377] iteration 16750 : loss : 151.987015, loss_ce: 0.017828, loss_kd: 757.547302
[22:03:01.937] iteration 16760 : loss : 141.005707, loss_ce: 0.013231, loss_kd: 702.647705
[22:03:07.512] iteration 16770 : loss : 166.774536, loss_ce: 0.011371, loss_kd: 831.466064
[22:03:13.077] iteration 16780 : loss : 130.363495, loss_ce: 0.013809, loss_kd: 649.439270
[22:03:18.647] iteration 16790 : loss : 165.867828, loss_ce: 0.016691, loss_kd: 826.947510
[22:03:24.212] iteration 16800 : loss : 197.711670, loss_ce: 0.015892, loss_kd: 986.187500
[22:03:29.792] iteration 16810 : loss : 148.164963, loss_ce: 0.011235, loss_kd: 738.453735
[22:03:35.367] iteration 16820 : loss : 110.409599, loss_ce: 0.025761, loss_kd: 549.630859
[22:03:40.941] iteration 16830 : loss : 126.659485, loss_ce: 0.016375, loss_kd: 630.896667
[22:03:46.518] iteration 16840 : loss : 145.087555, loss_ce: 0.013497, loss_kd: 723.038696
[22:03:52.105] iteration 16850 : loss : 143.039368, loss_ce: 0.013640, loss_kd: 712.799683
[22:03:57.687] iteration 16860 : loss : 113.637512, loss_ce: 0.012679, loss_kd: 565.803589
[22:04:03.279] iteration 16870 : loss : 141.449142, loss_ce: 0.017897, loss_kd: 704.837952
[22:04:08.862] iteration 16880 : loss : 124.346550, loss_ce: 0.009513, loss_kd: 619.381897
[22:04:14.455] iteration 16890 : loss : 103.721916, loss_ce: 0.012366, loss_kd: 516.232727
[22:04:20.039] iteration 16900 : loss : 112.991547, loss_ce: 0.014358, loss_kd: 562.562256
[22:04:25.643] iteration 16910 : loss : 119.567627, loss_ce: 0.011193, loss_kd: 595.489502
[22:04:31.229] iteration 16920 : loss : 131.104553, loss_ce: 0.017386, loss_kd: 653.133240
[22:04:36.831] iteration 16930 : loss : 135.153625, loss_ce: 0.034186, loss_kd: 673.359985
[22:04:42.435] iteration 16940 : loss : 148.988312, loss_ce: 0.010295, loss_kd: 742.583862
[22:04:48.034] iteration 16950 : loss : 159.406982, loss_ce: 0.015918, loss_kd: 794.665527
[22:04:53.631] iteration 16960 : loss : 136.047241, loss_ce: 0.023060, loss_kd: 677.873291
[22:04:59.231] iteration 16970 : loss : 142.461685, loss_ce: 0.010460, loss_kd: 709.877441
[22:05:04.824] iteration 16980 : loss : 108.295280, loss_ce: 0.021340, loss_kd: 539.065125
[22:05:10.426] iteration 16990 : loss : 162.079117, loss_ce: 0.016351, loss_kd: 807.988953
[22:05:16.028] iteration 17000 : loss : 113.108498, loss_ce: 0.014069, loss_kd: 563.163940
[22:05:21.630] iteration 17010 : loss : 126.174026, loss_ce: 0.019536, loss_kd: 628.491821
[22:05:27.223] iteration 17020 : loss : 277.703339, loss_ce: 0.024518, loss_kd: 1386.107422
[22:05:32.824] iteration 17030 : loss : 128.867447, loss_ce: 0.021930, loss_kd: 641.900635
[22:05:38.416] iteration 17040 : loss : 126.469727, loss_ce: 0.020711, loss_kd: 629.929443
[22:05:44.015] iteration 17050 : loss : 130.388794, loss_ce: 0.012159, loss_kd: 649.565063
[22:05:49.615] iteration 17060 : loss : 121.272896, loss_ce: 0.015245, loss_kd: 603.978394
[22:05:55.222] iteration 17070 : loss : 171.502701, loss_ce: 0.021526, loss_kd: 855.103027
[22:06:00.826] iteration 17080 : loss : 156.348907, loss_ce: 0.014997, loss_kd: 779.376953
[22:06:06.436] iteration 17090 : loss : 150.056061, loss_ce: 0.023002, loss_kd: 747.868164
[22:06:12.037] iteration 17100 : loss : 135.712296, loss_ce: 0.012358, loss_kd: 676.214661
[22:06:17.639] iteration 17110 : loss : 141.001984, loss_ce: 0.016148, loss_kd: 702.575134
[22:06:23.238] iteration 17120 : loss : 150.861771, loss_ce: 0.011008, loss_kd: 751.908813
[22:06:28.863] iteration 17130 : loss : 155.372986, loss_ce: 0.009028, loss_kd: 774.464844
[22:06:34.475] iteration 17140 : loss : 119.282082, loss_ce: 0.013224, loss_kd: 593.974182
[22:06:40.078] iteration 17150 : loss : 166.992279, loss_ce: 0.011417, loss_kd: 832.561279
[22:06:45.675] iteration 17160 : loss : 160.912460, loss_ce: 0.015494, loss_kd: 802.160095
[22:06:51.291] iteration 17170 : loss : 112.766579, loss_ce: 0.021847, loss_kd: 561.428833
[22:06:56.898] iteration 17180 : loss : 133.885818, loss_ce: 0.022406, loss_kd: 667.059021
[22:07:02.498] iteration 17190 : loss : 160.584595, loss_ce: 0.018335, loss_kd: 800.504883
[22:07:08.099] iteration 17200 : loss : 143.626099, loss_ce: 0.026861, loss_kd: 715.740173
[22:07:13.736] iteration 17210 : loss : 117.225021, loss_ce: 0.016265, loss_kd: 583.727112
[22:07:19.342] iteration 17220 : loss : 109.976562, loss_ce: 0.023482, loss_kd: 547.473938
[22:07:24.951] iteration 17230 : loss : 147.146011, loss_ce: 0.015374, loss_kd: 733.310486
[22:07:30.557] iteration 17240 : loss : 123.154526, loss_ce: 0.016399, loss_kd: 613.395813
[22:07:36.179] iteration 17250 : loss : 153.427048, loss_ce: 0.014270, loss_kd: 764.702942
[22:07:41.784] iteration 17260 : loss : 151.013062, loss_ce: 0.012144, loss_kd: 752.665771
[22:07:47.396] iteration 17270 : loss : 128.246002, loss_ce: 0.014845, loss_kd: 638.792603
[22:07:53.000] iteration 17280 : loss : 148.300552, loss_ce: 0.026124, loss_kd: 739.097107
[22:07:58.610] iteration 17290 : loss : 152.569305, loss_ce: 0.021524, loss_kd: 760.449463
[22:08:04.215] iteration 17300 : loss : 128.703506, loss_ce: 0.018381, loss_kd: 641.104309
[22:08:09.833] iteration 17310 : loss : 161.982651, loss_ce: 0.018814, loss_kd: 807.517273
[22:08:15.453] iteration 17320 : loss : 131.314621, loss_ce: 0.021112, loss_kd: 654.160400
[22:08:21.066] iteration 17330 : loss : 121.118553, loss_ce: 0.011801, loss_kd: 603.217285
[22:08:26.661] iteration 17340 : loss : 139.324814, loss_ce: 0.015330, loss_kd: 694.225708
[22:08:32.272] iteration 17350 : loss : 143.633209, loss_ce: 0.019148, loss_kd: 715.785095
[22:08:37.878] iteration 17360 : loss : 170.986649, loss_ce: 0.021201, loss_kd: 852.497742
[22:08:43.512] iteration 17370 : loss : 122.313911, loss_ce: 0.019048, loss_kd: 609.196350
[22:08:49.117] iteration 17380 : loss : 182.412415, loss_ce: 0.021478, loss_kd: 909.644775
[22:08:54.732] iteration 17390 : loss : 106.233566, loss_ce: 0.014094, loss_kd: 528.747925
[22:09:00.342] iteration 17400 : loss : 144.477386, loss_ce: 0.021028, loss_kd: 719.980591
[22:09:05.976] iteration 17410 : loss : 131.279373, loss_ce: 0.028030, loss_kd: 653.975281
[22:09:11.587] iteration 17420 : loss : 129.919083, loss_ce: 0.013065, loss_kd: 647.193054
[22:09:17.207] iteration 17430 : loss : 146.196182, loss_ce: 0.008151, loss_kd: 728.568115
[22:09:22.810] iteration 17440 : loss : 215.598068, loss_ce: 0.013974, loss_kd: 1075.545288
[22:09:28.439] iteration 17450 : loss : 173.899002, loss_ce: 0.023604, loss_kd: 867.091736
[22:09:34.044] iteration 17460 : loss : 113.535522, loss_ce: 0.018113, loss_kd: 565.257629
[22:09:39.665] iteration 17470 : loss : 160.302826, loss_ce: 0.011121, loss_kd: 799.112549
[22:09:45.271] iteration 17480 : loss : 136.993744, loss_ce: 0.017263, loss_kd: 682.552734
[22:09:50.899] iteration 17490 : loss : 170.061966, loss_ce: 0.016763, loss_kd: 847.923828
[22:09:56.504] iteration 17500 : loss : 135.609909, loss_ce: 0.019324, loss_kd: 675.598511
[22:10:02.128] iteration 17510 : loss : 116.827606, loss_ce: 0.010376, loss_kd: 581.726440
[22:10:07.736] iteration 17520 : loss : 184.125931, loss_ce: 0.014279, loss_kd: 918.212891
[22:10:13.367] iteration 17530 : loss : 117.150070, loss_ce: 0.022810, loss_kd: 583.374878
[22:10:18.970] iteration 17540 : loss : 149.589050, loss_ce: 0.013445, loss_kd: 745.534790
[22:10:24.582] iteration 17550 : loss : 154.046494, loss_ce: 0.017340, loss_kd: 767.834961
[22:10:30.189] iteration 17560 : loss : 202.360046, loss_ce: 0.011519, loss_kd: 1009.362244
[22:10:35.806] iteration 17570 : loss : 141.921326, loss_ce: 0.018584, loss_kd: 707.220337
[22:10:41.414] iteration 17580 : loss : 140.740829, loss_ce: 0.017662, loss_kd: 701.298584
[22:10:47.039] iteration 17590 : loss : 129.369629, loss_ce: 0.012566, loss_kd: 644.462952
[22:10:52.641] iteration 17600 : loss : 130.791611, loss_ce: 0.014072, loss_kd: 651.562195
[22:10:58.263] iteration 17610 : loss : 111.802650, loss_ce: 0.018500, loss_kd: 556.593872
[22:11:03.881] iteration 17620 : loss : 150.099792, loss_ce: 0.017268, loss_kd: 748.114685
[22:11:09.505] iteration 17630 : loss : 116.398201, loss_ce: 0.012338, loss_kd: 579.577271
[22:11:15.105] iteration 17640 : loss : 160.825684, loss_ce: 0.020182, loss_kd: 801.732544
[22:11:20.718] iteration 17650 : loss : 160.484131, loss_ce: 0.022909, loss_kd: 800.047913
[22:11:26.328] iteration 17660 : loss : 161.100418, loss_ce: 0.008951, loss_kd: 803.112427
[22:11:31.955] iteration 17670 : loss : 110.503242, loss_ce: 0.010357, loss_kd: 550.083374
[22:11:37.562] iteration 17680 : loss : 174.905090, loss_ce: 0.009958, loss_kd: 872.117249
[22:11:43.175] iteration 17690 : loss : 114.264229, loss_ce: 0.016314, loss_kd: 568.912231
[22:11:48.775] iteration 17700 : loss : 135.579208, loss_ce: 0.017789, loss_kd: 675.477905
[22:11:54.400] iteration 17710 : loss : 139.293793, loss_ce: 0.012087, loss_kd: 694.078735
[22:11:56.934] Running TPGM constraint optimization after epoch 17
[22:16:40.116] iteration 17720 : loss : 128.724915, loss_ce: 0.017583, loss_kd: 641.266724
[22:16:45.650] iteration 17730 : loss : 160.521118, loss_ce: 0.023177, loss_kd: 800.201050
[22:16:51.178] iteration 17740 : loss : 121.768761, loss_ce: 0.016605, loss_kd: 606.453369
[22:16:56.718] iteration 17750 : loss : 130.044571, loss_ce: 0.011875, loss_kd: 647.819824
[22:17:02.254] iteration 17760 : loss : 143.794006, loss_ce: 0.018261, loss_kd: 716.584961
[22:17:07.802] iteration 17770 : loss : 143.661591, loss_ce: 0.017036, loss_kd: 715.918640
[22:17:13.338] iteration 17780 : loss : 153.788437, loss_ce: 0.014575, loss_kd: 766.516846
[22:17:18.890] iteration 17790 : loss : 131.490524, loss_ce: 0.016220, loss_kd: 655.038818
[22:17:24.432] iteration 17800 : loss : 189.380325, loss_ce: 0.013363, loss_kd: 944.555725
[22:17:29.997] iteration 17810 : loss : 94.930763, loss_ce: 0.025189, loss_kd: 472.264404
[22:17:35.548] iteration 17820 : loss : 108.389046, loss_ce: 0.020009, loss_kd: 539.557434
[22:17:41.116] iteration 17830 : loss : 114.345253, loss_ce: 0.015733, loss_kd: 569.313965
[22:17:46.670] iteration 17840 : loss : 118.321022, loss_ce: 0.023713, loss_kd: 589.227051
[22:17:52.251] iteration 17850 : loss : 104.732651, loss_ce: 0.014665, loss_kd: 521.265442
[22:17:57.809] iteration 17860 : loss : 120.892151, loss_ce: 0.005820, loss_kd: 602.081299
[22:18:03.386] iteration 17870 : loss : 145.357254, loss_ce: 0.013104, loss_kd: 724.398926
[22:18:08.955] iteration 17880 : loss : 134.976196, loss_ce: 0.013096, loss_kd: 672.513916
[22:18:14.532] iteration 17890 : loss : 116.810776, loss_ce: 0.017427, loss_kd: 581.635254
[22:18:20.105] iteration 17900 : loss : 105.235374, loss_ce: 0.018283, loss_kd: 523.751648
[22:18:25.692] iteration 17910 : loss : 138.712326, loss_ce: 0.017157, loss_kd: 691.169556
[22:18:31.261] iteration 17920 : loss : 113.899612, loss_ce: 0.015717, loss_kd: 567.106079
[22:18:36.850] iteration 17930 : loss : 149.636383, loss_ce: 0.018419, loss_kd: 745.823364
[22:18:42.424] iteration 17940 : loss : 143.169434, loss_ce: 0.016064, loss_kd: 713.484680
[22:18:48.009] iteration 17950 : loss : 152.002899, loss_ce: 0.013625, loss_kd: 757.628418
[22:18:53.594] iteration 17960 : loss : 138.448227, loss_ce: 0.013228, loss_kd: 689.881958
[22:18:59.186] iteration 17970 : loss : 172.409073, loss_ce: 0.014770, loss_kd: 859.661560
[22:19:04.772] iteration 17980 : loss : 172.649216, loss_ce: 0.013539, loss_kd: 860.866882
[22:19:10.376] iteration 17990 : loss : 104.724052, loss_ce: 0.017092, loss_kd: 521.223755
[22:19:15.962] iteration 18000 : loss : 119.300591, loss_ce: 0.021022, loss_kd: 594.111084
[22:19:21.557] iteration 18010 : loss : 175.880493, loss_ce: 0.013521, loss_kd: 877.024231
[22:19:27.156] iteration 18020 : loss : 161.447296, loss_ce: 0.014910, loss_kd: 804.822205
[22:19:32.758] iteration 18030 : loss : 124.142593, loss_ce: 0.012754, loss_kd: 618.295288
[22:19:38.357] iteration 18040 : loss : 158.587296, loss_ce: 0.024040, loss_kd: 790.509827
[22:19:43.964] iteration 18050 : loss : 119.681503, loss_ce: 0.016918, loss_kd: 595.989197
[22:19:49.557] iteration 18060 : loss : 144.020676, loss_ce: 0.019303, loss_kd: 717.673035
[22:19:55.165] iteration 18070 : loss : 145.643005, loss_ce: 0.016552, loss_kd: 725.844299
[22:20:00.764] iteration 18080 : loss : 139.329498, loss_ce: 0.014054, loss_kd: 694.246216
[22:20:06.367] iteration 18090 : loss : 196.062119, loss_ce: 0.014160, loss_kd: 977.933105
[22:20:11.959] iteration 18100 : loss : 112.738655, loss_ce: 0.010940, loss_kd: 561.300049
[22:20:17.572] iteration 18110 : loss : 110.007416, loss_ce: 0.015669, loss_kd: 547.625427
[22:20:23.164] iteration 18120 : loss : 108.667801, loss_ce: 0.030128, loss_kd: 540.927307
[22:20:28.764] iteration 18130 : loss : 104.581596, loss_ce: 0.014409, loss_kd: 520.513367
[22:20:34.374] iteration 18140 : loss : 143.197174, loss_ce: 0.019925, loss_kd: 713.600525
[22:20:39.980] iteration 18150 : loss : 157.695496, loss_ce: 0.014641, loss_kd: 786.060364
[22:20:45.578] iteration 18160 : loss : 155.680176, loss_ce: 0.014638, loss_kd: 776.022766
[22:20:51.188] iteration 18170 : loss : 110.104340, loss_ce: 0.014433, loss_kd: 548.116272
[22:20:56.786] iteration 18180 : loss : 140.201721, loss_ce: 0.024219, loss_kd: 698.571167
[22:21:02.408] iteration 18190 : loss : 120.057068, loss_ce: 0.015439, loss_kd: 597.928528
[22:21:08.012] iteration 18200 : loss : 100.517677, loss_ce: 0.015847, loss_kd: 500.202393
[22:21:13.625] iteration 18210 : loss : 110.798637, loss_ce: 0.014752, loss_kd: 551.589661
[22:21:19.228] iteration 18220 : loss : 167.625122, loss_ce: 0.012072, loss_kd: 835.759094
[22:21:24.835] iteration 18230 : loss : 136.684128, loss_ce: 0.020539, loss_kd: 681.024170
[22:21:30.433] iteration 18240 : loss : 135.285812, loss_ce: 0.013519, loss_kd: 674.011230
[22:21:36.041] iteration 18250 : loss : 129.553284, loss_ce: 0.022533, loss_kd: 645.409668
[22:21:41.640] iteration 18260 : loss : 143.798492, loss_ce: 0.016829, loss_kd: 716.618530
[22:21:47.266] iteration 18270 : loss : 122.196091, loss_ce: 0.019332, loss_kd: 608.530090
[22:21:52.865] iteration 18280 : loss : 127.084236, loss_ce: 0.014891, loss_kd: 633.014160
[22:21:58.481] iteration 18290 : loss : 126.160042, loss_ce: 0.018078, loss_kd: 628.406311
[22:22:04.077] iteration 18300 : loss : 140.000687, loss_ce: 0.015446, loss_kd: 697.614868
[22:22:09.689] iteration 18310 : loss : 164.883514, loss_ce: 0.013816, loss_kd: 821.998718
[22:22:15.289] iteration 18320 : loss : 121.889580, loss_ce: 0.013400, loss_kd: 607.086548
[22:22:20.900] iteration 18330 : loss : 142.637680, loss_ce: 0.016401, loss_kd: 710.807556
[22:22:26.510] iteration 18340 : loss : 157.587097, loss_ce: 0.015337, loss_kd: 785.551880
[22:22:32.130] iteration 18350 : loss : 156.305313, loss_ce: 0.009810, loss_kd: 779.129517
[22:22:37.741] iteration 18360 : loss : 201.933990, loss_ce: 0.015769, loss_kd: 1007.269165
[22:22:43.354] iteration 18370 : loss : 133.725586, loss_ce: 0.016139, loss_kd: 666.203735
[22:22:48.953] iteration 18380 : loss : 118.089928, loss_ce: 0.019979, loss_kd: 588.047180
[22:22:54.580] iteration 18390 : loss : 122.111046, loss_ce: 0.019784, loss_kd: 608.187073
[22:23:00.191] iteration 18400 : loss : 130.006943, loss_ce: 0.023921, loss_kd: 647.566956
[22:23:05.808] iteration 18410 : loss : 117.284271, loss_ce: 0.015934, loss_kd: 584.011902
[22:23:11.413] iteration 18420 : loss : 117.280067, loss_ce: 0.021027, loss_kd: 584.011230
[22:23:17.022] iteration 18430 : loss : 115.015282, loss_ce: 0.013564, loss_kd: 572.685791
[22:23:22.630] iteration 18440 : loss : 115.326973, loss_ce: 0.024353, loss_kd: 574.193176
[22:23:28.255] iteration 18450 : loss : 130.137756, loss_ce: 0.013473, loss_kd: 648.312378
[22:23:33.872] iteration 18460 : loss : 122.901688, loss_ce: 0.019381, loss_kd: 612.111877
[22:23:39.489] iteration 18470 : loss : 131.908463, loss_ce: 0.019982, loss_kd: 657.102173
[22:23:45.110] iteration 18480 : loss : 136.591049, loss_ce: 0.015601, loss_kd: 680.571655
[22:23:50.725] iteration 18490 : loss : 107.758888, loss_ce: 0.013563, loss_kd: 536.412292
[22:23:56.329] iteration 18500 : loss : 109.819344, loss_ce: 0.013031, loss_kd: 546.689026
[22:24:01.960] iteration 18510 : loss : 150.834854, loss_ce: 0.013913, loss_kd: 751.779907
[22:24:07.568] iteration 18520 : loss : 124.018265, loss_ce: 0.016323, loss_kd: 617.683228
[22:24:13.185] iteration 18530 : loss : 108.609131, loss_ce: 0.022095, loss_kd: 540.667969
[22:24:18.794] iteration 18540 : loss : 117.927025, loss_ce: 0.026220, loss_kd: 587.245850
[22:24:24.412] iteration 18550 : loss : 167.929108, loss_ce: 0.020662, loss_kd: 837.220398
[22:24:30.022] iteration 18560 : loss : 163.692978, loss_ce: 0.016678, loss_kd: 816.060730
[22:24:35.644] iteration 18570 : loss : 123.703133, loss_ce: 0.016459, loss_kd: 616.131714
[22:24:41.252] iteration 18580 : loss : 139.229080, loss_ce: 0.011136, loss_kd: 693.750366
[22:24:46.862] iteration 18590 : loss : 95.267586, loss_ce: 0.020561, loss_kd: 473.919769
[22:24:52.469] iteration 18600 : loss : 130.595184, loss_ce: 0.009835, loss_kd: 650.608398
[22:24:58.093] iteration 18610 : loss : 147.652512, loss_ce: 0.010236, loss_kd: 735.893799
[22:25:03.707] iteration 18620 : loss : 161.421005, loss_ce: 0.014358, loss_kd: 804.717590
[22:25:09.332] iteration 18630 : loss : 124.621567, loss_ce: 0.022395, loss_kd: 620.705566
[22:25:14.935] iteration 18640 : loss : 124.022438, loss_ce: 0.013886, loss_kd: 617.719482
[22:25:20.544] iteration 18650 : loss : 112.053818, loss_ce: 0.013386, loss_kd: 557.865173
[22:25:26.163] iteration 18660 : loss : 98.397057, loss_ce: 0.019071, loss_kd: 489.622009
[22:25:31.782] iteration 18670 : loss : 131.888153, loss_ce: 0.015148, loss_kd: 657.047668
[22:25:37.376] iteration 18680 : loss : 111.562691, loss_ce: 0.011459, loss_kd: 555.441101
[22:25:42.992] iteration 18690 : loss : 151.032928, loss_ce: 0.014718, loss_kd: 752.810608
[22:25:48.593] iteration 18700 : loss : 120.325394, loss_ce: 0.014287, loss_kd: 599.244873
[22:25:54.210] iteration 18710 : loss : 123.068184, loss_ce: 0.013013, loss_kd: 612.912964
[22:25:59.822] iteration 18720 : loss : 153.977737, loss_ce: 0.012976, loss_kd: 767.477905
[22:26:05.440] iteration 18730 : loss : 122.140015, loss_ce: 0.013892, loss_kd: 608.302002
[22:26:11.050] iteration 18740 : loss : 117.831810, loss_ce: 0.023627, loss_kd: 586.758240
[22:26:16.665] iteration 18750 : loss : 125.165009, loss_ce: 0.016988, loss_kd: 623.417969
[22:26:33.037] iteration 18760 : loss : 86.806427, loss_ce: 0.014392, loss_kd: 431.592438
[22:26:38.587] iteration 18770 : loss : 102.482986, loss_ce: 0.011634, loss_kd: 510.022095
[22:26:44.131] iteration 18780 : loss : 124.910599, loss_ce: 0.015996, loss_kd: 622.168457
[22:26:49.697] iteration 18790 : loss : 167.312683, loss_ce: 0.018632, loss_kd: 834.202026
[22:26:55.248] iteration 18800 : loss : 155.343124, loss_ce: 0.016557, loss_kd: 774.332764
[22:27:00.827] iteration 18810 : loss : 121.964020, loss_ce: 0.013418, loss_kd: 607.448792
[22:27:06.383] iteration 18820 : loss : 123.327271, loss_ce: 0.013781, loss_kd: 614.202881
[22:27:11.955] iteration 18830 : loss : 98.346809, loss_ce: 0.009858, loss_kd: 489.315613
[22:27:17.524] iteration 18840 : loss : 136.971161, loss_ce: 0.020874, loss_kd: 682.483276
[22:27:23.105] iteration 18850 : loss : 113.374153, loss_ce: 0.013033, loss_kd: 564.493958
[22:27:28.685] iteration 18860 : loss : 135.085480, loss_ce: 0.028385, loss_kd: 673.032898
[22:27:34.273] iteration 18870 : loss : 131.802887, loss_ce: 0.018544, loss_kd: 656.617126
[22:27:39.844] iteration 18880 : loss : 150.942062, loss_ce: 0.012310, loss_kd: 752.297485
[22:27:45.429] iteration 18890 : loss : 142.862717, loss_ce: 0.013271, loss_kd: 711.908997
[22:27:51.011] iteration 18900 : loss : 116.873352, loss_ce: 0.010231, loss_kd: 581.948242
[22:27:56.610] iteration 18910 : loss : 120.833504, loss_ce: 0.014888, loss_kd: 601.765198
[22:28:02.204] iteration 18920 : loss : 125.550583, loss_ce: 0.015520, loss_kd: 625.348816
[22:28:07.809] iteration 18930 : loss : 131.703827, loss_ce: 0.019108, loss_kd: 656.106262
[22:28:13.401] iteration 18940 : loss : 163.243805, loss_ce: 0.023682, loss_kd: 813.856567
[22:28:19.004] iteration 18950 : loss : 116.050751, loss_ce: 0.018226, loss_kd: 577.827026
[22:28:24.602] iteration 18960 : loss : 118.506195, loss_ce: 0.013888, loss_kd: 590.135742
[22:28:30.216] iteration 18970 : loss : 123.930229, loss_ce: 0.017215, loss_kd: 617.267822
[22:28:35.806] iteration 18980 : loss : 134.245605, loss_ce: 0.016909, loss_kd: 668.863708
[22:28:41.410] iteration 18990 : loss : 84.697906, loss_ce: 0.011020, loss_kd: 421.111450
[22:28:47.008] iteration 19000 : loss : 117.955948, loss_ce: 0.015900, loss_kd: 587.410950
[22:28:52.607] iteration 19010 : loss : 143.793442, loss_ce: 0.022177, loss_kd: 716.528198
[22:28:58.205] iteration 19020 : loss : 132.798737, loss_ce: 0.011458, loss_kd: 661.604187
[22:29:03.811] iteration 19030 : loss : 119.576668, loss_ce: 0.016315, loss_kd: 595.440979
[22:29:09.400] iteration 19040 : loss : 167.234558, loss_ce: 0.014488, loss_kd: 833.798462
[22:29:15.001] iteration 19050 : loss : 183.455154, loss_ce: 0.009610, loss_kd: 914.887512
[22:29:20.595] iteration 19060 : loss : 150.458344, loss_ce: 0.021915, loss_kd: 749.854675
[22:29:26.190] iteration 19070 : loss : 120.684212, loss_ce: 0.020143, loss_kd: 600.987183
[22:29:31.787] iteration 19080 : loss : 116.440414, loss_ce: 0.019651, loss_kd: 579.812439
[22:29:37.392] iteration 19090 : loss : 120.044876, loss_ce: 0.009791, loss_kd: 597.814392
[22:29:42.986] iteration 19100 : loss : 118.322388, loss_ce: 0.020732, loss_kd: 589.206848
[22:29:48.590] iteration 19110 : loss : 94.468521, loss_ce: 0.011978, loss_kd: 469.974243
[22:29:54.187] iteration 19120 : loss : 132.997635, loss_ce: 0.012462, loss_kd: 662.590942
[22:29:59.783] iteration 19130 : loss : 127.981194, loss_ce: 0.006627, loss_kd: 637.494446
[22:30:05.384] iteration 19140 : loss : 131.190903, loss_ce: 0.016747, loss_kd: 653.571411
[22:30:10.990] iteration 19150 : loss : 156.553482, loss_ce: 0.014611, loss_kd: 780.399780
[22:30:16.582] iteration 19160 : loss : 173.234756, loss_ce: 0.013737, loss_kd: 863.769165
[22:30:22.187] iteration 19170 : loss : 128.262756, loss_ce: 0.019341, loss_kd: 638.924927
[22:30:27.776] iteration 19180 : loss : 109.006943, loss_ce: 0.019189, loss_kd: 542.642395
[22:30:33.378] iteration 19190 : loss : 112.570885, loss_ce: 0.017105, loss_kd: 560.462769
[22:30:38.978] iteration 19200 : loss : 136.611664, loss_ce: 0.012920, loss_kd: 680.662903
[22:30:44.586] iteration 19210 : loss : 128.524033, loss_ce: 0.026219, loss_kd: 640.218750
[22:30:50.172] iteration 19220 : loss : 129.567688, loss_ce: 0.013900, loss_kd: 645.506592
[22:30:55.773] iteration 19230 : loss : 115.482941, loss_ce: 0.014701, loss_kd: 575.019104
[22:31:01.374] iteration 19240 : loss : 136.224960, loss_ce: 0.014219, loss_kd: 678.693665
[22:31:06.976] iteration 19250 : loss : 141.329956, loss_ce: 0.010700, loss_kd: 704.272400
[22:31:12.570] iteration 19260 : loss : 129.330704, loss_ce: 0.016789, loss_kd: 644.257935
[22:31:18.181] iteration 19270 : loss : 139.636566, loss_ce: 0.010440, loss_kd: 695.817566
[22:31:23.771] iteration 19280 : loss : 119.752090, loss_ce: 0.018988, loss_kd: 596.328125
[22:31:29.376] iteration 19290 : loss : 154.175644, loss_ce: 0.016659, loss_kd: 768.453979
[22:31:34.977] iteration 19300 : loss : 125.784706, loss_ce: 0.009030, loss_kd: 626.481689
[22:31:40.583] iteration 19310 : loss : 98.184807, loss_ce: 0.021690, loss_kd: 488.523834
[22:31:46.181] iteration 19320 : loss : 110.733261, loss_ce: 0.015476, loss_kd: 551.272522
[22:31:51.787] iteration 19330 : loss : 165.330292, loss_ce: 0.011018, loss_kd: 824.275635
[22:31:57.380] iteration 19340 : loss : 147.414749, loss_ce: 0.011142, loss_kd: 734.729797
[22:32:02.995] iteration 19350 : loss : 151.628525, loss_ce: 0.011098, loss_kd: 755.778931
[22:32:08.594] iteration 19360 : loss : 100.115326, loss_ce: 0.015269, loss_kd: 498.223572
[22:32:14.215] iteration 19370 : loss : 143.305054, loss_ce: 0.017161, loss_kd: 714.164185
[22:32:19.822] iteration 19380 : loss : 134.887238, loss_ce: 0.015073, loss_kd: 672.056274
[22:32:25.453] iteration 19390 : loss : 117.919106, loss_ce: 0.014584, loss_kd: 587.208130
[22:32:31.065] iteration 19400 : loss : 150.747437, loss_ce: 0.017380, loss_kd: 751.351562
[22:32:36.683] iteration 19410 : loss : 115.372505, loss_ce: 0.014500, loss_kd: 574.504822
[22:32:42.279] iteration 19420 : loss : 148.784912, loss_ce: 0.014348, loss_kd: 741.536743
[22:32:47.886] iteration 19430 : loss : 129.232910, loss_ce: 0.010422, loss_kd: 643.757141
[22:32:53.490] iteration 19440 : loss : 110.394646, loss_ce: 0.013393, loss_kd: 549.554443
[22:32:59.103] iteration 19450 : loss : 119.665039, loss_ce: 0.016214, loss_kd: 595.947144
[22:33:04.703] iteration 19460 : loss : 99.253723, loss_ce: 0.015635, loss_kd: 493.859344
[22:33:10.315] iteration 19470 : loss : 118.467659, loss_ce: 0.020003, loss_kd: 589.917664
[22:33:15.920] iteration 19480 : loss : 133.343689, loss_ce: 0.015196, loss_kd: 664.342041
[22:33:21.536] iteration 19490 : loss : 159.842865, loss_ce: 0.018071, loss_kd: 796.831116
[22:33:27.136] iteration 19500 : loss : 146.077209, loss_ce: 0.014150, loss_kd: 727.996704
[22:33:32.751] iteration 19510 : loss : 157.865845, loss_ce: 0.016798, loss_kd: 786.976501
[22:33:38.355] iteration 19520 : loss : 113.676903, loss_ce: 0.010901, loss_kd: 566.003601
[22:33:43.962] iteration 19530 : loss : 141.252625, loss_ce: 0.016827, loss_kd: 703.871643
[22:33:49.563] iteration 19540 : loss : 124.302773, loss_ce: 0.011355, loss_kd: 619.105591
[22:33:55.178] iteration 19550 : loss : 128.650665, loss_ce: 0.008581, loss_kd: 640.905518
[22:34:00.796] iteration 19560 : loss : 111.948189, loss_ce: 0.015662, loss_kd: 557.358459
[22:34:06.422] iteration 19570 : loss : 132.643326, loss_ce: 0.012046, loss_kd: 660.770630
[22:34:12.019] iteration 19580 : loss : 151.899506, loss_ce: 0.019459, loss_kd: 757.105896
[22:34:17.628] iteration 19590 : loss : 158.406784, loss_ce: 0.009460, loss_kd: 789.639954
[22:34:23.250] iteration 19600 : loss : 133.683945, loss_ce: 0.021448, loss_kd: 666.020996
[22:34:28.862] iteration 19610 : loss : 107.658394, loss_ce: 0.009578, loss_kd: 535.921509
[22:34:34.468] iteration 19620 : loss : 154.358063, loss_ce: 0.017183, loss_kd: 769.402405
[22:34:40.082] iteration 19630 : loss : 120.061493, loss_ce: 0.016365, loss_kd: 597.894165
[22:34:45.683] iteration 19640 : loss : 140.200775, loss_ce: 0.023724, loss_kd: 698.602173
[22:34:51.302] iteration 19650 : loss : 106.498215, loss_ce: 0.011745, loss_kd: 530.098450
[22:34:56.910] iteration 19660 : loss : 116.052734, loss_ce: 0.010556, loss_kd: 577.897888
[22:35:02.525] iteration 19670 : loss : 134.696014, loss_ce: 0.017963, loss_kd: 671.075195
[22:35:08.119] iteration 19680 : loss : 134.855026, loss_ce: 0.017041, loss_kd: 671.879395
[22:35:13.730] iteration 19690 : loss : 163.366898, loss_ce: 0.019966, loss_kd: 814.410461
[22:35:19.330] iteration 19700 : loss : 103.020897, loss_ce: 0.018382, loss_kd: 512.681152
[22:35:24.936] iteration 19710 : loss : 175.844803, loss_ce: 0.020277, loss_kd: 876.825317
[22:35:30.537] iteration 19720 : loss : 146.048523, loss_ce: 0.011384, loss_kd: 727.846863
[22:35:36.161] iteration 19730 : loss : 128.971146, loss_ce: 0.016917, loss_kd: 642.460693
[22:35:41.771] iteration 19740 : loss : 172.202377, loss_ce: 0.016867, loss_kd: 858.578674
[22:35:47.380] iteration 19750 : loss : 139.436447, loss_ce: 0.018482, loss_kd: 694.811279
[22:35:52.985] iteration 19760 : loss : 101.384003, loss_ce: 0.013008, loss_kd: 504.480408
[22:35:58.584] iteration 19770 : loss : 125.998169, loss_ce: 0.018285, loss_kd: 627.608643
[22:36:04.176] iteration 19780 : loss : 135.879105, loss_ce: 0.013248, loss_kd: 677.017334
[22:36:09.787] iteration 19790 : loss : 125.737297, loss_ce: 0.026915, loss_kd: 626.259766
[22:36:14.598] Running TPGM constraint optimization after epoch 19
[22:41:09.471] iteration 19800 : loss : 132.226593, loss_ce: 0.019398, loss_kd: 658.758850
[22:41:15.003] iteration 19810 : loss : 91.055519, loss_ce: 0.013561, loss_kd: 452.900055
[22:41:20.519] iteration 19820 : loss : 121.377731, loss_ce: 0.012157, loss_kd: 604.480469
[22:41:26.057] iteration 19830 : loss : 133.759506, loss_ce: 0.027017, loss_kd: 666.350098
[22:41:31.581] iteration 19840 : loss : 131.486023, loss_ce: 0.012855, loss_kd: 655.090698
[22:41:37.122] iteration 19850 : loss : 168.125488, loss_ce: 0.019193, loss_kd: 838.241577
[22:41:42.658] iteration 19860 : loss : 173.023422, loss_ce: 0.017266, loss_kd: 862.703735
[22:41:48.204] iteration 19870 : loss : 164.980209, loss_ce: 0.018607, loss_kd: 822.532166
[22:41:53.742] iteration 19880 : loss : 124.770660, loss_ce: 0.015314, loss_kd: 621.452820
[22:41:59.294] iteration 19890 : loss : 111.254150, loss_ce: 0.014861, loss_kd: 553.853394
[22:42:04.834] iteration 19900 : loss : 108.357719, loss_ce: 0.022372, loss_kd: 539.382751
[22:42:10.397] iteration 19910 : loss : 106.310112, loss_ce: 0.029581, loss_kd: 529.157715
[22:42:15.943] iteration 19920 : loss : 98.564278, loss_ce: 0.017172, loss_kd: 490.446503
[22:42:21.505] iteration 19930 : loss : 163.294724, loss_ce: 0.018997, loss_kd: 814.100952
[22:42:27.060] iteration 19940 : loss : 118.424683, loss_ce: 0.018891, loss_kd: 589.732666
[22:42:32.626] iteration 19950 : loss : 103.768654, loss_ce: 0.019155, loss_kd: 516.467590
[22:42:38.181] iteration 19960 : loss : 101.913734, loss_ce: 0.022724, loss_kd: 507.184418
[22:42:43.756] iteration 19970 : loss : 121.327415, loss_ce: 0.016381, loss_kd: 604.260803
[22:42:49.317] iteration 19980 : loss : 160.000290, loss_ce: 0.015605, loss_kd: 797.593384
[22:42:54.891] iteration 19990 : loss : 107.981529, loss_ce: 0.016565, loss_kd: 537.532349
[22:43:00.457] iteration 20000 : loss : 115.211021, loss_ce: 0.024516, loss_kd: 573.638489
[22:43:06.033] iteration 20010 : loss : 103.564690, loss_ce: 0.015501, loss_kd: 515.456970
[22:43:11.599] iteration 20020 : loss : 107.776878, loss_ce: 0.016555, loss_kd: 536.467163
[22:43:17.179] iteration 20030 : loss : 124.429276, loss_ce: 0.015184, loss_kd: 619.751526
[22:43:22.746] iteration 20040 : loss : 145.047638, loss_ce: 0.022559, loss_kd: 722.802612
[22:43:28.323] iteration 20050 : loss : 145.265137, loss_ce: 0.008123, loss_kd: 723.949646
[22:43:33.895] iteration 20060 : loss : 80.404205, loss_ce: 0.013766, loss_kd: 399.621521
[22:43:39.486] iteration 20070 : loss : 103.737465, loss_ce: 0.016209, loss_kd: 516.283203
[22:43:45.056] iteration 20080 : loss : 116.726433, loss_ce: 0.013811, loss_kd: 581.250732
[22:43:50.639] iteration 20090 : loss : 108.817566, loss_ce: 0.024046, loss_kd: 541.679199
[22:43:56.214] iteration 20100 : loss : 96.838326, loss_ce: 0.009080, loss_kd: 481.817505
[22:44:01.804] iteration 20110 : loss : 128.040115, loss_ce: 0.027279, loss_kd: 637.781006
[22:44:07.378] iteration 20120 : loss : 130.597351, loss_ce: 0.009291, loss_kd: 650.591064
[22:44:12.958] iteration 20130 : loss : 98.413345, loss_ce: 0.013990, loss_kd: 489.699158
[22:44:18.542] iteration 20140 : loss : 129.476776, loss_ce: 0.016605, loss_kd: 644.985413
[22:44:24.140] iteration 20150 : loss : 165.192657, loss_ce: 0.021346, loss_kd: 823.555481
[22:44:29.736] iteration 20160 : loss : 115.963188, loss_ce: 0.021021, loss_kd: 577.419861
[22:44:35.335] iteration 20170 : loss : 199.921875, loss_ce: 0.010274, loss_kd: 997.232483
[22:44:40.914] iteration 20180 : loss : 125.741409, loss_ce: 0.020447, loss_kd: 626.299133
[22:44:46.502] iteration 20190 : loss : 103.873184, loss_ce: 0.016854, loss_kd: 516.984070
[22:44:52.081] iteration 20200 : loss : 117.247597, loss_ce: 0.013644, loss_kd: 583.846313
[22:44:57.675] iteration 20210 : loss : 113.532990, loss_ce: 0.012245, loss_kd: 565.240112
[22:45:03.260] iteration 20220 : loss : 132.301712, loss_ce: 0.011413, loss_kd: 659.140564
[22:45:08.860] iteration 20230 : loss : 154.905182, loss_ce: 0.015409, loss_kd: 772.137268
[22:45:14.448] iteration 20240 : loss : 128.714951, loss_ce: 0.013809, loss_kd: 641.187378
[22:45:20.045] iteration 20250 : loss : 113.808197, loss_ce: 0.023549, loss_kd: 566.660156
[22:45:25.627] iteration 20260 : loss : 134.749985, loss_ce: 0.015934, loss_kd: 671.348389
[22:45:31.222] iteration 20270 : loss : 126.734627, loss_ce: 0.020511, loss_kd: 631.254089
[22:45:36.804] iteration 20280 : loss : 89.276085, loss_ce: 0.019883, loss_kd: 443.973969
[22:45:42.396] iteration 20290 : loss : 134.591278, loss_ce: 0.024090, loss_kd: 670.553284
[22:45:47.985] iteration 20300 : loss : 131.152435, loss_ce: 0.015850, loss_kd: 653.362244
[22:45:53.582] iteration 20310 : loss : 118.091072, loss_ce: 0.020264, loss_kd: 588.091675
[22:45:59.178] iteration 20320 : loss : 126.431755, loss_ce: 0.013573, loss_kd: 629.798035
[22:46:04.785] iteration 20330 : loss : 117.500755, loss_ce: 0.011712, loss_kd: 585.142944
[22:46:10.370] iteration 20340 : loss : 112.868446, loss_ce: 0.016927, loss_kd: 561.935974
[22:46:15.973] iteration 20350 : loss : 139.797211, loss_ce: 0.008465, loss_kd: 696.575989
[22:46:21.567] iteration 20360 : loss : 153.537354, loss_ce: 0.018493, loss_kd: 765.277039
[22:46:27.165] iteration 20370 : loss : 90.080498, loss_ce: 0.013816, loss_kd: 447.988525
[22:46:32.763] iteration 20380 : loss : 108.643219, loss_ce: 0.025532, loss_kd: 540.811890
[22:46:38.366] iteration 20390 : loss : 121.416412, loss_ce: 0.020388, loss_kd: 604.716797
[22:46:43.964] iteration 20400 : loss : 167.290680, loss_ce: 0.016439, loss_kd: 834.048828
[22:46:49.569] iteration 20410 : loss : 115.453568, loss_ce: 0.011037, loss_kd: 574.873169
[22:46:55.163] iteration 20420 : loss : 189.338501, loss_ce: 0.022875, loss_kd: 944.317322
[22:47:00.765] iteration 20430 : loss : 113.915367, loss_ce: 0.022572, loss_kd: 567.202026
[22:47:06.365] iteration 20440 : loss : 111.982224, loss_ce: 0.011444, loss_kd: 557.476562
[22:47:11.965] iteration 20450 : loss : 108.895668, loss_ce: 0.011515, loss_kd: 542.115112
[22:47:17.562] iteration 20460 : loss : 155.695648, loss_ce: 0.013726, loss_kd: 776.107422
[22:47:23.164] iteration 20470 : loss : 148.767288, loss_ce: 0.011069, loss_kd: 741.464233
[22:47:28.762] iteration 20480 : loss : 152.943695, loss_ce: 0.014266, loss_kd: 762.339111
[22:47:34.367] iteration 20490 : loss : 124.469696, loss_ce: 0.023658, loss_kd: 619.938293
[22:47:39.957] iteration 20500 : loss : 130.038544, loss_ce: 0.014517, loss_kd: 647.805420
[22:47:45.561] iteration 20510 : loss : 97.900841, loss_ce: 0.018584, loss_kd: 487.128937
[22:47:51.160] iteration 20520 : loss : 119.912743, loss_ce: 0.020527, loss_kd: 597.193604
[22:47:56.760] iteration 20530 : loss : 103.916641, loss_ce: 0.020834, loss_kd: 517.145935
[22:48:02.353] iteration 20540 : loss : 129.364731, loss_ce: 0.019115, loss_kd: 644.463440
[22:48:07.956] iteration 20550 : loss : 120.913483, loss_ce: 0.019820, loss_kd: 602.158569
[22:48:13.552] iteration 20560 : loss : 121.634201, loss_ce: 0.014604, loss_kd: 605.804810
[22:48:19.156] iteration 20570 : loss : 120.603165, loss_ce: 0.014878, loss_kd: 600.656372
[22:48:24.748] iteration 20580 : loss : 140.125488, loss_ce: 0.015251, loss_kd: 698.243530
[22:48:30.349] iteration 20590 : loss : 110.676468, loss_ce: 0.012768, loss_kd: 550.994751
[22:48:35.944] iteration 20600 : loss : 128.017593, loss_ce: 0.014998, loss_kd: 637.671326
[22:48:41.545] iteration 20610 : loss : 116.491692, loss_ce: 0.015817, loss_kd: 580.009949
[22:48:47.151] iteration 20620 : loss : 124.621109, loss_ce: 0.019666, loss_kd: 620.749573
[22:48:52.752] iteration 20630 : loss : 117.051659, loss_ce: 0.010879, loss_kd: 582.838867
[22:48:58.345] iteration 20640 : loss : 112.210358, loss_ce: 0.019389, loss_kd: 558.635010
[22:49:03.952] iteration 20650 : loss : 140.054993, loss_ce: 0.015971, loss_kd: 697.897339
[22:49:09.541] iteration 20660 : loss : 136.762482, loss_ce: 0.023177, loss_kd: 681.415100
[22:49:15.141] iteration 20670 : loss : 96.527603, loss_ce: 0.014475, loss_kd: 480.244598
[22:49:20.741] iteration 20680 : loss : 123.316765, loss_ce: 0.025318, loss_kd: 614.191345
[22:49:26.337] iteration 20690 : loss : 109.713928, loss_ce: 0.016304, loss_kd: 546.214539
[22:49:31.929] iteration 20700 : loss : 150.218811, loss_ce: 0.015613, loss_kd: 748.686340
[22:49:37.530] iteration 20710 : loss : 147.904846, loss_ce: 0.019449, loss_kd: 737.136414
[22:49:43.129] iteration 20720 : loss : 135.019363, loss_ce: 0.008757, loss_kd: 672.737427
[22:49:48.734] iteration 20730 : loss : 129.364639, loss_ce: 0.013774, loss_kd: 644.456787
[22:49:54.325] iteration 20740 : loss : 142.625458, loss_ce: 0.015245, loss_kd: 710.691345
[22:49:59.926] iteration 20750 : loss : 80.125595, loss_ce: 0.027291, loss_kd: 398.253845
[22:50:05.521] iteration 20760 : loss : 109.105011, loss_ce: 0.010440, loss_kd: 543.178833
[22:50:11.124] iteration 20770 : loss : 132.090775, loss_ce: 0.016987, loss_kd: 658.065796
[22:50:16.715] iteration 20780 : loss : 130.861404, loss_ce: 0.013922, loss_kd: 651.921143
[22:50:22.321] iteration 20790 : loss : 182.490311, loss_ce: 0.013368, loss_kd: 910.051941
[22:50:27.918] iteration 20800 : loss : 142.857544, loss_ce: 0.018893, loss_kd: 711.903198
[22:50:33.526] iteration 20810 : loss : 164.281540, loss_ce: 0.021181, loss_kd: 819.037415
[22:50:39.120] iteration 20820 : loss : 125.582062, loss_ce: 0.014401, loss_kd: 625.525940
[22:50:44.725] iteration 20830 : loss : 114.464195, loss_ce: 0.010537, loss_kd: 569.990784
[22:50:50.010] iteration 20840 : loss : 87.735641, loss_ce: 0.019447, loss_kd: 436.273956
[22:50:50.745] save model to ./debug_fixed_tpgm\continual_surgical_tpgm_stage1_epoch_19.pth
[22:51:06.531] iteration 20850 : loss : 124.058357, loss_ce: 0.024122, loss_kd: 617.889709
[22:51:12.075] iteration 20860 : loss : 117.286926, loss_ce: 0.018758, loss_kd: 584.070129
[22:51:17.634] iteration 20870 : loss : 159.869171, loss_ce: 0.012587, loss_kd: 796.942078
[22:51:23.183] iteration 20880 : loss : 138.920700, loss_ce: 0.010838, loss_kd: 692.248962
[22:51:28.748] iteration 20890 : loss : 97.551056, loss_ce: 0.017093, loss_kd: 485.336700
[22:51:34.304] iteration 20900 : loss : 120.294281, loss_ce: 0.022747, loss_kd: 599.086731
[22:51:39.877] iteration 20910 : loss : 138.592682, loss_ce: 0.018995, loss_kd: 690.578857
[22:51:45.442] iteration 20920 : loss : 117.731361, loss_ce: 0.013303, loss_kd: 586.222351
[22:51:51.024] iteration 20930 : loss : 115.684624, loss_ce: 0.023367, loss_kd: 576.048950
[22:51:56.591] iteration 20940 : loss : 115.944557, loss_ce: 0.015099, loss_kd: 577.325928
[22:52:02.167] iteration 20950 : loss : 117.147881, loss_ce: 0.012070, loss_kd: 583.365234
[22:52:07.751] iteration 20960 : loss : 152.362778, loss_ce: 0.020249, loss_kd: 759.415100
[22:52:13.336] iteration 20970 : loss : 120.195183, loss_ce: 0.027881, loss_kd: 598.616516
[22:52:18.904] iteration 20980 : loss : 110.094788, loss_ce: 0.017198, loss_kd: 548.084961
[22:52:24.491] iteration 20990 : loss : 119.214523, loss_ce: 0.022272, loss_kd: 593.742798
[22:52:30.075] iteration 21000 : loss : 107.940460, loss_ce: 0.010700, loss_kd: 537.316650
[22:52:35.677] iteration 21010 : loss : 113.909088, loss_ce: 0.010226, loss_kd: 567.198975
[22:52:41.274] iteration 21020 : loss : 123.751167, loss_ce: 0.023339, loss_kd: 616.349060
[22:52:46.874] iteration 21030 : loss : 119.867401, loss_ce: 0.028214, loss_kd: 596.972046
[22:52:52.457] iteration 21040 : loss : 110.376274, loss_ce: 0.019071, loss_kd: 549.465698
[22:52:58.069] iteration 21050 : loss : 77.966080, loss_ce: 0.025932, loss_kd: 387.440826
[22:53:03.666] iteration 21060 : loss : 103.454735, loss_ce: 0.020534, loss_kd: 514.950928
[22:53:09.268] iteration 21070 : loss : 134.359573, loss_ce: 0.013818, loss_kd: 669.374573
[22:53:14.864] iteration 21080 : loss : 93.629379, loss_ce: 0.013317, loss_kd: 465.725739
[22:53:20.468] iteration 21090 : loss : 105.323059, loss_ce: 0.014258, loss_kd: 524.182251
[22:53:26.056] iteration 21100 : loss : 177.218811, loss_ce: 0.022731, loss_kd: 883.690369
[22:53:31.657] iteration 21110 : loss : 99.628387, loss_ce: 0.011969, loss_kd: 495.768555
[22:53:37.259] iteration 21120 : loss : 113.649597, loss_ce: 0.022487, loss_kd: 565.847229
[22:53:42.866] iteration 21130 : loss : 108.094131, loss_ce: 0.012311, loss_kd: 538.070374
[22:53:48.458] iteration 21140 : loss : 92.663651, loss_ce: 0.009666, loss_kd: 460.956573
[22:53:54.071] iteration 21150 : loss : 149.976700, loss_ce: 0.013320, loss_kd: 747.455200
[22:53:59.663] iteration 21160 : loss : 196.705658, loss_ce: 0.021180, loss_kd: 981.137817
[22:54:05.263] iteration 21170 : loss : 181.172974, loss_ce: 0.014961, loss_kd: 903.497620
[22:54:10.861] iteration 21180 : loss : 111.464653, loss_ce: 0.013100, loss_kd: 554.934021
[22:54:16.467] iteration 21190 : loss : 109.807549, loss_ce: 0.017841, loss_kd: 546.638184
[22:54:22.059] iteration 21200 : loss : 108.226639, loss_ce: 0.013691, loss_kd: 538.706909
[22:54:27.668] iteration 21210 : loss : 117.007271, loss_ce: 0.010851, loss_kd: 582.628784
[22:54:33.259] iteration 21220 : loss : 93.982857, loss_ce: 0.013676, loss_kd: 467.531952
[22:54:38.863] iteration 21230 : loss : 117.299988, loss_ce: 0.008555, loss_kd: 584.134949
[22:54:44.456] iteration 21240 : loss : 132.948044, loss_ce: 0.013234, loss_kd: 662.342896
[22:54:50.058] iteration 21250 : loss : 158.133072, loss_ce: 0.020187, loss_kd: 788.298645
[22:54:55.654] iteration 21260 : loss : 146.970612, loss_ce: 0.014607, loss_kd: 732.465759
[22:55:01.251] iteration 21270 : loss : 106.506210, loss_ce: 0.013814, loss_kd: 530.171997
[22:55:06.851] iteration 21280 : loss : 136.160645, loss_ce: 0.011017, loss_kd: 678.425598
[22:55:12.460] iteration 21290 : loss : 103.812325, loss_ce: 0.015115, loss_kd: 516.659180
[22:55:18.062] iteration 21300 : loss : 112.722298, loss_ce: 0.022750, loss_kd: 561.184692
[22:55:23.674] iteration 21310 : loss : 112.940048, loss_ce: 0.015045, loss_kd: 562.280762
[22:55:29.267] iteration 21320 : loss : 118.692986, loss_ce: 0.017641, loss_kd: 591.074890
[22:55:34.882] iteration 21330 : loss : 123.947701, loss_ce: 0.015237, loss_kd: 617.324402
[22:55:40.486] iteration 21340 : loss : 103.786461, loss_ce: 0.013543, loss_kd: 516.530334
[22:55:46.100] iteration 21350 : loss : 110.400253, loss_ce: 0.018296, loss_kd: 549.648132
[22:55:51.711] iteration 21360 : loss : 154.025925, loss_ce: 0.016076, loss_kd: 767.684937
[22:55:57.309] iteration 21370 : loss : 155.089142, loss_ce: 0.014078, loss_kd: 773.074402
[22:56:02.914] iteration 21380 : loss : 129.048981, loss_ce: 0.012221, loss_kd: 642.828491
[22:56:08.528] iteration 21390 : loss : 127.705132, loss_ce: 0.015744, loss_kd: 636.127136
[22:56:14.129] iteration 21400 : loss : 132.883957, loss_ce: 0.009648, loss_kd: 662.044861
[22:56:19.751] iteration 21410 : loss : 136.581421, loss_ce: 0.019339, loss_kd: 680.521851
[22:56:25.357] iteration 21420 : loss : 127.787010, loss_ce: 0.017627, loss_kd: 636.514771
[22:56:30.970] iteration 21430 : loss : 166.717728, loss_ce: 0.008529, loss_kd: 831.234131
[22:56:36.569] iteration 21440 : loss : 161.185364, loss_ce: 0.014938, loss_kd: 803.537781
[22:56:42.179] iteration 21450 : loss : 120.382164, loss_ce: 0.011109, loss_kd: 599.590698
[22:56:47.778] iteration 21460 : loss : 119.408096, loss_ce: 0.009968, loss_kd: 594.659302
[22:56:53.397] iteration 21470 : loss : 137.342392, loss_ce: 0.020756, loss_kd: 684.311279
[22:56:59.005] iteration 21480 : loss : 113.276276, loss_ce: 0.024417, loss_kd: 563.973999
[22:57:04.615] iteration 21490 : loss : 137.273193, loss_ce: 0.017371, loss_kd: 683.965515
[22:57:10.220] iteration 21500 : loss : 137.824783, loss_ce: 0.016867, loss_kd: 686.734619
[22:57:15.826] iteration 21510 : loss : 122.916649, loss_ce: 0.016564, loss_kd: 612.201294
[22:57:21.432] iteration 21520 : loss : 97.990669, loss_ce: 0.012911, loss_kd: 487.587585
[22:57:27.035] iteration 21530 : loss : 139.343811, loss_ce: 0.012795, loss_kd: 694.336975
[22:57:32.629] iteration 21540 : loss : 94.628906, loss_ce: 0.011665, loss_kd: 470.756042
[22:57:38.229] iteration 21550 : loss : 101.544312, loss_ce: 0.015908, loss_kd: 505.332520
[22:57:43.832] iteration 21560 : loss : 127.776917, loss_ce: 0.014648, loss_kd: 636.521362
[22:57:49.439] iteration 21570 : loss : 128.341370, loss_ce: 0.020342, loss_kd: 639.338379
[22:57:55.041] iteration 21580 : loss : 132.464279, loss_ce: 0.020260, loss_kd: 659.921387
[22:58:00.667] iteration 21590 : loss : 157.307236, loss_ce: 0.021707, loss_kd: 784.137756
[22:58:06.267] iteration 21600 : loss : 102.585793, loss_ce: 0.025019, loss_kd: 510.500885
[22:58:11.875] iteration 21610 : loss : 142.989716, loss_ce: 0.016356, loss_kd: 712.583008
[22:58:17.473] iteration 21620 : loss : 136.039093, loss_ce: 0.017960, loss_kd: 677.820679
[22:58:23.077] iteration 21630 : loss : 131.276550, loss_ce: 0.011857, loss_kd: 654.001953
[22:58:28.669] iteration 21640 : loss : 117.915649, loss_ce: 0.024649, loss_kd: 587.174133
[22:58:34.276] iteration 21650 : loss : 96.293274, loss_ce: 0.012140, loss_kd: 479.041840
[22:58:39.876] iteration 21660 : loss : 110.691292, loss_ce: 0.016062, loss_kd: 551.043091
[22:58:45.479] iteration 21670 : loss : 141.952972, loss_ce: 0.017693, loss_kd: 707.391418
[22:58:51.073] iteration 21680 : loss : 134.052734, loss_ce: 0.013743, loss_kd: 667.923584
[22:58:56.679] iteration 21690 : loss : 113.397102, loss_ce: 0.020112, loss_kd: 564.592712
[22:59:02.283] iteration 21700 : loss : 135.188522, loss_ce: 0.014282, loss_kd: 673.575928
[22:59:07.904] iteration 21710 : loss : 102.671066, loss_ce: 0.010481, loss_kd: 510.950928
[22:59:13.509] iteration 21720 : loss : 114.970146, loss_ce: 0.024837, loss_kd: 572.436768
[22:59:19.128] iteration 21730 : loss : 113.240242, loss_ce: 0.014101, loss_kd: 563.850037
[22:59:24.730] iteration 21740 : loss : 105.366524, loss_ce: 0.020676, loss_kd: 524.423462
[22:59:30.339] iteration 21750 : loss : 111.045303, loss_ce: 0.009237, loss_kd: 552.875244
[22:59:35.932] iteration 21760 : loss : 73.235565, loss_ce: 0.013307, loss_kd: 363.816437
[22:59:41.541] iteration 21770 : loss : 135.615738, loss_ce: 0.011592, loss_kd: 675.674561
[22:59:47.139] iteration 21780 : loss : 98.285942, loss_ce: 0.015043, loss_kd: 489.052734
[22:59:52.751] iteration 21790 : loss : 127.391525, loss_ce: 0.008407, loss_kd: 634.535278
[22:59:58.343] iteration 21800 : loss : 116.742958, loss_ce: 0.025430, loss_kd: 581.333435
[23:00:03.970] iteration 21810 : loss : 146.207382, loss_ce: 0.010665, loss_kd: 728.641113
[23:00:09.571] iteration 21820 : loss : 172.602798, loss_ce: 0.018749, loss_kd: 860.600708
[23:00:15.191] iteration 21830 : loss : 114.085823, loss_ce: 0.012877, loss_kd: 568.086792
[23:00:20.779] iteration 21840 : loss : 149.992371, loss_ce: 0.015782, loss_kd: 747.582458
[23:00:26.391] iteration 21850 : loss : 136.656296, loss_ce: 0.022191, loss_kd: 680.890503
[23:00:31.993] iteration 21860 : loss : 123.889793, loss_ce: 0.017697, loss_kd: 617.075317
[23:00:37.603] iteration 21870 : loss : 111.927139, loss_ce: 0.026082, loss_kd: 557.255493
[23:00:43.198] iteration 21880 : loss : 107.906197, loss_ce: 0.013030, loss_kd: 537.202454
[23:00:44.658] Running TPGM constraint optimization after epoch 21
[23:05:30.918] iteration 21890 : loss : 166.636734, loss_ce: 0.014246, loss_kd: 830.835327
[23:05:36.443] iteration 21900 : loss : 120.124329, loss_ce: 0.015895, loss_kd: 598.232666
[23:05:41.980] iteration 21910 : loss : 123.622047, loss_ce: 0.015462, loss_kd: 615.718262
[23:05:47.510] iteration 21920 : loss : 128.157486, loss_ce: 0.017023, loss_kd: 638.418274
[23:05:53.053] iteration 21930 : loss : 113.888466, loss_ce: 0.020202, loss_kd: 567.034058
[23:05:58.586] iteration 21940 : loss : 141.540100, loss_ce: 0.011009, loss_kd: 705.270142
[23:06:04.138] iteration 21950 : loss : 109.833710, loss_ce: 0.018902, loss_kd: 546.777588
[23:06:09.689] iteration 21960 : loss : 102.726440, loss_ce: 0.015851, loss_kd: 511.250763
[23:06:15.242] iteration 21970 : loss : 108.987976, loss_ce: 0.013416, loss_kd: 542.575073
[23:06:20.795] iteration 21980 : loss : 129.052689, loss_ce: 0.012067, loss_kd: 642.858582
[23:06:26.354] iteration 21990 : loss : 107.314445, loss_ce: 0.012886, loss_kd: 534.195557
[23:06:31.906] iteration 22000 : loss : 116.915871, loss_ce: 0.015303, loss_kd: 582.196411
[23:06:37.480] iteration 22010 : loss : 139.018600, loss_ce: 0.014390, loss_kd: 692.729065
[23:06:43.048] iteration 22020 : loss : 123.737267, loss_ce: 0.011493, loss_kd: 616.327515
[23:06:48.621] iteration 22030 : loss : 114.393829, loss_ce: 0.026431, loss_kd: 569.552795
[23:06:54.192] iteration 22040 : loss : 159.007858, loss_ce: 0.016344, loss_kd: 792.654846
[23:06:59.769] iteration 22050 : loss : 150.339310, loss_ce: 0.013848, loss_kd: 749.309753
[23:07:05.336] iteration 22060 : loss : 145.920242, loss_ce: 0.010323, loss_kd: 727.219299
[23:07:10.909] iteration 22070 : loss : 125.451958, loss_ce: 0.010217, loss_kd: 624.911987
[23:07:16.496] iteration 22080 : loss : 138.496262, loss_ce: 0.017671, loss_kd: 690.091675
[23:07:22.087] iteration 22090 : loss : 113.003349, loss_ce: 0.008889, loss_kd: 562.688599
[23:07:27.660] iteration 22100 : loss : 109.895096, loss_ce: 0.010185, loss_kd: 547.139954
[23:07:33.251] iteration 22110 : loss : 105.229713, loss_ce: 0.016627, loss_kd: 523.739319
[23:07:38.824] iteration 22120 : loss : 116.882851, loss_ce: 0.012556, loss_kd: 582.055603
[23:07:44.417] iteration 22130 : loss : 118.604713, loss_ce: 0.018742, loss_kd: 590.624939
[23:07:49.995] iteration 22140 : loss : 113.259697, loss_ce: 0.035398, loss_kd: 563.881165
[23:07:55.590] iteration 22150 : loss : 140.679733, loss_ce: 0.010718, loss_kd: 701.041565
[23:08:01.178] iteration 22160 : loss : 105.541008, loss_ce: 0.017252, loss_kd: 525.343628
[23:08:06.764] iteration 22170 : loss : 129.733353, loss_ce: 0.020135, loss_kd: 646.327454
[23:08:12.343] iteration 22180 : loss : 94.106651, loss_ce: 0.010357, loss_kd: 468.116669
[23:08:17.945] iteration 22190 : loss : 127.585716, loss_ce: 0.019827, loss_kd: 635.562927
[23:08:23.542] iteration 22200 : loss : 151.266052, loss_ce: 0.016106, loss_kd: 753.921936
[23:08:29.146] iteration 22210 : loss : 128.647247, loss_ce: 0.014549, loss_kd: 640.876526
[23:08:34.733] iteration 22220 : loss : 135.331619, loss_ce: 0.019264, loss_kd: 674.282593
[23:08:40.334] iteration 22230 : loss : 134.751175, loss_ce: 0.025932, loss_kd: 671.334229
[23:08:45.926] iteration 22240 : loss : 108.022575, loss_ce: 0.017309, loss_kd: 537.707581
[23:08:51.534] iteration 22250 : loss : 108.091316, loss_ce: 0.020396, loss_kd: 538.041138
[23:08:57.138] iteration 22260 : loss : 112.198753, loss_ce: 0.009596, loss_kd: 558.648071
[23:09:02.752] iteration 22270 : loss : 166.869659, loss_ce: 0.015245, loss_kd: 831.962280
[23:09:08.352] iteration 22280 : loss : 161.396790, loss_ce: 0.017770, loss_kd: 804.582764
[23:09:13.959] iteration 22290 : loss : 130.477844, loss_ce: 0.014765, loss_kd: 650.018433
[23:09:19.553] iteration 22300 : loss : 142.730896, loss_ce: 0.016338, loss_kd: 711.299194
[23:09:25.151] iteration 22310 : loss : 119.848122, loss_ce: 0.012920, loss_kd: 596.895813
[23:09:30.740] iteration 22320 : loss : 119.014961, loss_ce: 0.014781, loss_kd: 592.638916
[23:09:36.340] iteration 22330 : loss : 124.799088, loss_ce: 0.012216, loss_kd: 621.621399
[23:09:41.931] iteration 22340 : loss : 104.742805, loss_ce: 0.008921, loss_kd: 521.325928
[23:09:47.533] iteration 22350 : loss : 112.814148, loss_ce: 0.012703, loss_kd: 561.645752
[23:09:53.129] iteration 22360 : loss : 114.364410, loss_ce: 0.012541, loss_kd: 569.410278
[23:09:58.732] iteration 22370 : loss : 98.482574, loss_ce: 0.013582, loss_kd: 490.010559
[23:10:04.323] iteration 22380 : loss : 139.359787, loss_ce: 0.018341, loss_kd: 694.396423
[23:10:09.924] iteration 22390 : loss : 101.656052, loss_ce: 0.018840, loss_kd: 505.927094
[23:10:15.515] iteration 22400 : loss : 95.088417, loss_ce: 0.019167, loss_kd: 473.034515
[23:10:21.119] iteration 22410 : loss : 125.418762, loss_ce: 0.023362, loss_kd: 624.713989
[23:10:26.715] iteration 22420 : loss : 139.614532, loss_ce: 0.014053, loss_kd: 695.688171
[23:10:32.317] iteration 22430 : loss : 114.269028, loss_ce: 0.025898, loss_kd: 568.929932
[23:10:37.913] iteration 22440 : loss : 149.160034, loss_ce: 0.014006, loss_kd: 743.388916
[23:10:43.508] iteration 22450 : loss : 162.354355, loss_ce: 0.016996, loss_kd: 809.400085
[23:10:49.102] iteration 22460 : loss : 191.999420, loss_ce: 0.013862, loss_kd: 957.564819
[23:10:54.706] iteration 22470 : loss : 115.442734, loss_ce: 0.012423, loss_kd: 574.806763
[23:11:00.299] iteration 22480 : loss : 173.646606, loss_ce: 0.013760, loss_kd: 865.810120
[23:11:05.901] iteration 22490 : loss : 126.186966, loss_ce: 0.020494, loss_kd: 628.567505
[23:11:11.498] iteration 22500 : loss : 108.081604, loss_ce: 0.021186, loss_kd: 538.036072
[23:11:17.101] iteration 22510 : loss : 138.611450, loss_ce: 0.018534, loss_kd: 690.656555
[23:11:22.693] iteration 22520 : loss : 131.152130, loss_ce: 0.018751, loss_kd: 653.363525
[23:11:28.293] iteration 22530 : loss : 109.473953, loss_ce: 0.019837, loss_kd: 544.958130
[23:11:33.886] iteration 22540 : loss : 107.602661, loss_ce: 0.010355, loss_kd: 535.651611
[23:11:39.486] iteration 22550 : loss : 104.029503, loss_ce: 0.014676, loss_kd: 517.764160
[23:11:45.087] iteration 22560 : loss : 120.091125, loss_ce: 0.018038, loss_kd: 598.077393
[23:11:50.685] iteration 22570 : loss : 121.138519, loss_ce: 0.016940, loss_kd: 603.266785
[23:11:56.280] iteration 22580 : loss : 120.095535, loss_ce: 0.017798, loss_kd: 598.087891
[23:12:01.882] iteration 22590 : loss : 114.787125, loss_ce: 0.016762, loss_kd: 571.547058
[23:12:07.473] iteration 22600 : loss : 109.238358, loss_ce: 0.014677, loss_kd: 543.784119
[23:12:13.078] iteration 22610 : loss : 92.961403, loss_ce: 0.022418, loss_kd: 462.409790
[23:12:18.678] iteration 22620 : loss : 131.641922, loss_ce: 0.025626, loss_kd: 655.829895
[23:12:24.286] iteration 22630 : loss : 89.036530, loss_ce: 0.013044, loss_kd: 442.794556
[23:12:29.881] iteration 22640 : loss : 137.361847, loss_ce: 0.006852, loss_kd: 684.395081
[23:12:35.481] iteration 22650 : loss : 187.288544, loss_ce: 0.014535, loss_kd: 934.027710
[23:12:41.079] iteration 22660 : loss : 121.463646, loss_ce: 0.023983, loss_kd: 604.923096
[23:12:46.680] iteration 22670 : loss : 167.542770, loss_ce: 0.014226, loss_kd: 835.307373
[23:12:52.274] iteration 22680 : loss : 132.980225, loss_ce: 0.013243, loss_kd: 662.507202
[23:12:57.877] iteration 22690 : loss : 155.400848, loss_ce: 0.017488, loss_kd: 774.590027
[23:13:03.469] iteration 22700 : loss : 99.973671, loss_ce: 0.018300, loss_kd: 497.488495
[23:13:09.072] iteration 22710 : loss : 143.931686, loss_ce: 0.018038, loss_kd: 717.247192
[23:13:14.666] iteration 22720 : loss : 112.201965, loss_ce: 0.011163, loss_kd: 558.601440
[23:13:20.267] iteration 22730 : loss : 121.106621, loss_ce: 0.013187, loss_kd: 603.141724
[23:13:25.861] iteration 22740 : loss : 91.403488, loss_ce: 0.019761, loss_kd: 454.647644
[23:13:31.467] iteration 22750 : loss : 110.722496, loss_ce: 0.015033, loss_kd: 551.206238
[23:13:37.061] iteration 22760 : loss : 119.214279, loss_ce: 0.017726, loss_kd: 593.678223
[23:13:42.661] iteration 22770 : loss : 202.008728, loss_ce: 0.011267, loss_kd: 1007.614929
[23:13:48.254] iteration 22780 : loss : 102.736603, loss_ce: 0.018027, loss_kd: 511.308594
[23:13:53.852] iteration 22790 : loss : 128.859848, loss_ce: 0.017709, loss_kd: 641.902405
[23:13:59.448] iteration 22800 : loss : 97.405785, loss_ce: 0.011358, loss_kd: 484.652466
[23:14:05.049] iteration 22810 : loss : 97.228210, loss_ce: 0.017493, loss_kd: 483.754822
[23:14:10.646] iteration 22820 : loss : 95.300964, loss_ce: 0.018617, loss_kd: 474.098969
[23:14:16.244] iteration 22830 : loss : 114.073082, loss_ce: 0.020313, loss_kd: 567.980591
[23:14:21.837] iteration 22840 : loss : 139.922226, loss_ce: 0.010509, loss_kd: 697.225403
[23:14:27.440] iteration 22850 : loss : 147.055618, loss_ce: 0.021804, loss_kd: 732.885132
[23:14:33.032] iteration 22860 : loss : 168.985352, loss_ce: 0.019297, loss_kd: 842.582031
[23:14:38.636] iteration 22870 : loss : 175.328766, loss_ce: 0.009102, loss_kd: 874.266174
[23:14:44.234] iteration 22880 : loss : 135.543976, loss_ce: 0.010432, loss_kd: 675.308105
[23:14:49.834] iteration 22890 : loss : 148.702209, loss_ce: 0.010803, loss_kd: 741.104492
[23:14:55.429] iteration 22900 : loss : 118.280273, loss_ce: 0.016788, loss_kd: 588.993530
[23:15:01.030] iteration 22910 : loss : 113.516846, loss_ce: 0.015746, loss_kd: 565.200989
[23:15:06.628] iteration 22920 : loss : 121.688187, loss_ce: 0.012807, loss_kd: 606.046387
[23:15:23.855] iteration 22930 : loss : 118.411400, loss_ce: 0.017180, loss_kd: 589.703064
[23:15:29.395] iteration 22940 : loss : 118.274872, loss_ce: 0.022854, loss_kd: 588.977905
[23:15:34.950] iteration 22950 : loss : 105.586411, loss_ce: 0.017434, loss_kd: 525.539185
[23:15:40.501] iteration 22960 : loss : 129.524338, loss_ce: 0.010952, loss_kd: 645.234863
[23:15:46.060] iteration 22970 : loss : 114.042480, loss_ce: 0.018502, loss_kd: 567.837524
[23:15:51.616] iteration 22980 : loss : 125.528252, loss_ce: 0.017734, loss_kd: 625.272827
[23:15:57.179] iteration 22990 : loss : 106.084152, loss_ce: 0.012787, loss_kd: 528.026123
[23:16:02.741] iteration 23000 : loss : 124.221603, loss_ce: 0.012172, loss_kd: 618.720276
[23:16:08.317] iteration 23010 : loss : 140.387634, loss_ce: 0.014309, loss_kd: 699.602783
[23:16:13.881] iteration 23020 : loss : 101.450142, loss_ce: 0.026364, loss_kd: 504.866913
[23:16:19.460] iteration 23030 : loss : 108.481758, loss_ce: 0.020885, loss_kd: 540.030640
[23:16:25.024] iteration 23040 : loss : 107.372322, loss_ce: 0.014740, loss_kd: 534.476746
[23:16:30.603] iteration 23050 : loss : 83.542244, loss_ce: 0.021571, loss_kd: 415.349304
[23:16:36.177] iteration 23060 : loss : 82.869858, loss_ce: 0.014179, loss_kd: 411.973145
[23:16:41.760] iteration 23070 : loss : 105.398903, loss_ce: 0.007600, loss_kd: 524.615112
[23:16:47.329] iteration 23080 : loss : 108.164467, loss_ce: 0.011586, loss_kd: 538.446594
[23:16:52.918] iteration 23090 : loss : 97.512108, loss_ce: 0.012329, loss_kd: 485.195038
[23:16:58.504] iteration 23100 : loss : 139.442215, loss_ce: 0.016980, loss_kd: 694.805603
[23:17:04.104] iteration 23110 : loss : 119.925499, loss_ce: 0.017421, loss_kd: 597.213257
[23:17:09.686] iteration 23120 : loss : 131.153351, loss_ce: 0.016188, loss_kd: 653.406128
[23:17:15.275] iteration 23130 : loss : 122.351570, loss_ce: 0.014559, loss_kd: 609.385498
[23:17:20.854] iteration 23140 : loss : 148.999619, loss_ce: 0.017234, loss_kd: 742.644043
[23:17:26.440] iteration 23150 : loss : 142.138824, loss_ce: 0.017295, loss_kd: 708.338989
[23:17:32.027] iteration 23160 : loss : 160.287582, loss_ce: 0.013672, loss_kd: 799.060913
[23:17:37.616] iteration 23170 : loss : 112.043449, loss_ce: 0.014161, loss_kd: 557.859375
[23:17:43.200] iteration 23180 : loss : 116.967857, loss_ce: 0.014642, loss_kd: 582.466187
[23:17:48.797] iteration 23190 : loss : 99.394707, loss_ce: 0.012220, loss_kd: 494.604034
[23:17:54.375] iteration 23200 : loss : 129.230209, loss_ce: 0.016729, loss_kd: 643.758301
[23:17:59.972] iteration 23210 : loss : 88.654556, loss_ce: 0.019136, loss_kd: 440.907227
[23:18:05.554] iteration 23220 : loss : 140.385422, loss_ce: 0.013814, loss_kd: 699.557617
[23:18:11.156] iteration 23230 : loss : 146.788483, loss_ce: 0.016783, loss_kd: 731.521729
[23:18:16.745] iteration 23240 : loss : 125.724731, loss_ce: 0.012526, loss_kd: 626.206909
[23:18:22.348] iteration 23250 : loss : 159.950470, loss_ce: 0.019449, loss_kd: 797.360046
[23:18:27.935] iteration 23260 : loss : 152.623810, loss_ce: 0.016745, loss_kd: 760.704895
[23:18:33.540] iteration 23270 : loss : 156.643005, loss_ce: 0.020192, loss_kd: 780.786926
[23:18:39.132] iteration 23280 : loss : 117.585442, loss_ce: 0.017769, loss_kd: 585.561768
[23:18:44.736] iteration 23290 : loss : 119.394760, loss_ce: 0.016876, loss_kd: 594.551941
[23:18:50.344] iteration 23300 : loss : 131.218307, loss_ce: 0.014362, loss_kd: 653.711060
[23:18:55.943] iteration 23310 : loss : 111.646156, loss_ce: 0.012222, loss_kd: 555.842163
[23:19:01.536] iteration 23320 : loss : 119.156654, loss_ce: 0.016089, loss_kd: 593.378723
[23:19:07.136] iteration 23330 : loss : 111.912834, loss_ce: 0.029317, loss_kd: 557.175903
[23:19:12.728] iteration 23340 : loss : 86.775795, loss_ce: 0.015736, loss_kd: 431.489136
[23:19:18.333] iteration 23350 : loss : 86.353806, loss_ce: 0.022352, loss_kd: 429.386688
[23:19:23.925] iteration 23360 : loss : 107.542824, loss_ce: 0.015287, loss_kd: 535.304565
[23:19:29.530] iteration 23370 : loss : 119.403259, loss_ce: 0.017814, loss_kd: 594.617859
[23:19:35.129] iteration 23380 : loss : 107.696609, loss_ce: 0.015617, loss_kd: 536.080078
[23:19:40.735] iteration 23390 : loss : 117.779716, loss_ce: 0.021955, loss_kd: 586.459229
[23:19:46.324] iteration 23400 : loss : 152.444992, loss_ce: 0.017177, loss_kd: 759.860352
[23:19:51.931] iteration 23410 : loss : 66.023605, loss_ce: 0.017998, loss_kd: 327.721405
[23:19:57.520] iteration 23420 : loss : 130.166519, loss_ce: 0.014509, loss_kd: 648.430420
[23:20:03.125] iteration 23430 : loss : 122.493500, loss_ce: 0.015519, loss_kd: 610.096619
[23:20:08.719] iteration 23440 : loss : 140.089249, loss_ce: 0.021310, loss_kd: 698.054810
[23:20:14.323] iteration 23450 : loss : 81.972206, loss_ce: 0.015305, loss_kd: 407.441193
[23:20:19.920] iteration 23460 : loss : 103.212494, loss_ce: 0.020168, loss_kd: 513.713501
[23:20:25.523] iteration 23470 : loss : 110.422493, loss_ce: 0.017818, loss_kd: 549.741699
[23:20:31.123] iteration 23480 : loss : 123.496201, loss_ce: 0.016726, loss_kd: 615.044312
[23:20:36.725] iteration 23490 : loss : 133.118820, loss_ce: 0.013985, loss_kd: 663.189941
[23:20:42.324] iteration 23500 : loss : 101.022194, loss_ce: 0.020358, loss_kd: 502.718658
[23:20:47.926] iteration 23510 : loss : 102.990082, loss_ce: 0.015665, loss_kd: 512.575684
[23:20:53.514] iteration 23520 : loss : 128.401291, loss_ce: 0.012687, loss_kd: 639.603088
[23:20:59.115] iteration 23530 : loss : 132.604416, loss_ce: 0.012290, loss_kd: 660.648438
[23:21:04.711] iteration 23540 : loss : 140.451721, loss_ce: 0.016491, loss_kd: 699.880554
[23:21:10.316] iteration 23550 : loss : 138.465744, loss_ce: 0.015837, loss_kd: 689.956238
[23:21:15.914] iteration 23560 : loss : 134.211121, loss_ce: 0.015273, loss_kd: 668.666809
[23:21:21.511] iteration 23570 : loss : 167.476486, loss_ce: 0.016617, loss_kd: 834.989502
[23:21:27.101] iteration 23580 : loss : 140.932785, loss_ce: 0.017881, loss_kd: 702.252258
[23:21:32.705] iteration 23590 : loss : 119.548920, loss_ce: 0.019136, loss_kd: 595.359131
[23:21:38.301] iteration 23600 : loss : 102.827736, loss_ce: 0.018373, loss_kd: 511.749878
[23:21:43.905] iteration 23610 : loss : 106.553467, loss_ce: 0.018549, loss_kd: 530.336426
[23:21:49.496] iteration 23620 : loss : 117.603325, loss_ce: 0.013738, loss_kd: 585.612427
[23:21:55.099] iteration 23630 : loss : 106.563660, loss_ce: 0.020945, loss_kd: 530.423584
[23:22:00.693] iteration 23640 : loss : 139.146347, loss_ce: 0.015426, loss_kd: 693.315430
[23:22:06.294] iteration 23650 : loss : 133.027496, loss_ce: 0.022840, loss_kd: 662.708618
[23:22:11.887] iteration 23660 : loss : 140.878311, loss_ce: 0.017541, loss_kd: 702.008423
[23:22:17.490] iteration 23670 : loss : 118.034096, loss_ce: 0.017582, loss_kd: 587.805298
[23:22:23.084] iteration 23680 : loss : 141.188049, loss_ce: 0.019975, loss_kd: 703.507202
[23:22:28.692] iteration 23690 : loss : 109.709190, loss_ce: 0.014033, loss_kd: 546.184143
[23:22:34.286] iteration 23700 : loss : 109.634293, loss_ce: 0.014014, loss_kd: 545.802612
[23:22:39.891] iteration 23710 : loss : 110.123283, loss_ce: 0.012120, loss_kd: 548.226624
[23:22:45.483] iteration 23720 : loss : 148.168289, loss_ce: 0.013893, loss_kd: 738.438110
[23:22:51.086] iteration 23730 : loss : 102.573463, loss_ce: 0.017185, loss_kd: 510.462830
[23:22:56.677] iteration 23740 : loss : 110.859734, loss_ce: 0.018884, loss_kd: 551.929077
[23:23:02.278] iteration 23750 : loss : 119.376831, loss_ce: 0.021401, loss_kd: 594.499207
[23:23:07.874] iteration 23760 : loss : 120.350327, loss_ce: 0.017738, loss_kd: 599.332825
[23:23:13.474] iteration 23770 : loss : 166.760071, loss_ce: 0.015257, loss_kd: 831.396973
[23:23:19.069] iteration 23780 : loss : 114.039093, loss_ce: 0.015906, loss_kd: 567.815369
[23:23:24.674] iteration 23790 : loss : 122.445328, loss_ce: 0.012030, loss_kd: 609.831421
[23:23:30.265] iteration 23800 : loss : 112.273026, loss_ce: 0.019157, loss_kd: 558.950562
[23:23:35.873] iteration 23810 : loss : 116.331169, loss_ce: 0.009150, loss_kd: 579.302551
[23:23:41.469] iteration 23820 : loss : 130.139496, loss_ce: 0.010832, loss_kd: 648.333557
[23:23:47.069] iteration 23830 : loss : 128.914124, loss_ce: 0.012503, loss_kd: 642.189209
[23:23:52.666] iteration 23840 : loss : 131.815384, loss_ce: 0.020536, loss_kd: 656.670532
[23:23:58.267] iteration 23850 : loss : 95.486656, loss_ce: 0.015599, loss_kd: 475.048828
[23:24:03.858] iteration 23860 : loss : 123.243599, loss_ce: 0.013667, loss_kd: 613.835571
[23:24:09.458] iteration 23870 : loss : 95.797508, loss_ce: 0.020048, loss_kd: 476.629486
[23:24:15.053] iteration 23880 : loss : 93.467010, loss_ce: 0.013596, loss_kd: 464.939728
[23:24:20.654] iteration 23890 : loss : 109.875771, loss_ce: 0.012328, loss_kd: 546.997253
[23:24:26.251] iteration 23900 : loss : 133.050064, loss_ce: 0.014994, loss_kd: 662.892944
[23:24:31.857] iteration 23910 : loss : 99.043480, loss_ce: 0.013307, loss_kd: 492.847046
[23:24:37.450] iteration 23920 : loss : 107.474380, loss_ce: 0.015851, loss_kd: 534.928955
[23:24:43.051] iteration 23930 : loss : 119.793602, loss_ce: 0.015492, loss_kd: 596.549988
[23:24:48.645] iteration 23940 : loss : 121.976158, loss_ce: 0.011019, loss_kd: 607.463623
[23:24:54.248] iteration 23950 : loss : 113.331207, loss_ce: 0.030318, loss_kd: 564.259827
[23:24:59.845] iteration 23960 : loss : 132.236282, loss_ce: 0.015242, loss_kd: 658.794189
[23:25:03.616] Running TPGM constraint optimization after epoch 23
[23:30:05.076] iteration 23970 : loss : 94.339462, loss_ce: 0.012534, loss_kd: 469.273987
[23:30:10.596] iteration 23980 : loss : 123.380699, loss_ce: 0.009937, loss_kd: 614.513733
[23:30:16.134] iteration 23990 : loss : 125.233231, loss_ce: 0.013329, loss_kd: 623.797119
[23:30:21.665] iteration 24000 : loss : 119.120590, loss_ce: 0.018986, loss_kd: 593.258423
[23:30:27.236] iteration 24010 : loss : 138.927887, loss_ce: 0.018067, loss_kd: 692.267273
[23:30:32.776] iteration 24020 : loss : 117.214516, loss_ce: 0.013217, loss_kd: 583.712402
[23:30:38.324] iteration 24030 : loss : 121.827087, loss_ce: 0.012757, loss_kd: 606.707336
[23:30:43.865] iteration 24040 : loss : 113.319969, loss_ce: 0.010547, loss_kd: 564.201904
[23:30:49.419] iteration 24050 : loss : 117.256310, loss_ce: 0.021527, loss_kd: 583.907532
[23:30:54.962] iteration 24060 : loss : 117.585373, loss_ce: 0.010053, loss_kd: 585.564636
[23:31:00.524] iteration 24070 : loss : 164.002365, loss_ce: 0.024125, loss_kd: 817.630371
[23:31:06.073] iteration 24080 : loss : 108.045914, loss_ce: 0.018132, loss_kd: 537.858887
[23:31:11.630] iteration 24090 : loss : 140.242249, loss_ce: 0.010573, loss_kd: 698.827087
[23:31:17.180] iteration 24100 : loss : 110.662292, loss_ce: 0.014069, loss_kd: 550.926086
[23:31:22.742] iteration 24110 : loss : 94.510109, loss_ce: 0.010804, loss_kd: 470.129822
[23:31:28.298] iteration 24120 : loss : 110.234062, loss_ce: 0.015315, loss_kd: 548.756165
[23:31:33.866] iteration 24130 : loss : 129.754639, loss_ce: 0.015300, loss_kd: 646.372009
[23:31:39.423] iteration 24140 : loss : 114.902252, loss_ce: 0.017076, loss_kd: 572.121460
[23:31:44.997] iteration 24150 : loss : 131.790146, loss_ce: 0.024184, loss_kd: 656.596252
[23:31:50.563] iteration 24160 : loss : 136.466721, loss_ce: 0.017120, loss_kd: 679.921814
[23:31:56.136] iteration 24170 : loss : 105.935005, loss_ce: 0.014960, loss_kd: 527.266174
[23:32:01.699] iteration 24180 : loss : 94.958115, loss_ce: 0.017036, loss_kd: 472.403503
[23:32:07.276] iteration 24190 : loss : 112.206322, loss_ce: 0.014618, loss_kd: 558.674683
[23:32:12.839] iteration 24200 : loss : 122.300797, loss_ce: 0.013155, loss_kd: 609.128601
[23:32:18.425] iteration 24210 : loss : 119.227844, loss_ce: 0.013215, loss_kd: 593.786255
[23:32:23.989] iteration 24220 : loss : 112.576401, loss_ce: 0.020314, loss_kd: 560.454895
[23:32:29.573] iteration 24230 : loss : 124.590858, loss_ce: 0.010169, loss_kd: 620.581421
[23:32:35.141] iteration 24240 : loss : 127.814629, loss_ce: 0.016158, loss_kd: 636.661987
[23:32:40.723] iteration 24250 : loss : 100.849174, loss_ce: 0.015145, loss_kd: 501.864563
[23:32:46.296] iteration 24260 : loss : 124.197617, loss_ce: 0.008828, loss_kd: 618.598450
[23:32:51.877] iteration 24270 : loss : 125.864502, loss_ce: 0.024321, loss_kd: 626.885498
[23:32:57.456] iteration 24280 : loss : 88.713959, loss_ce: 0.020717, loss_kd: 441.116882
[23:33:03.043] iteration 24290 : loss : 108.915054, loss_ce: 0.019717, loss_kd: 542.183960
[23:33:08.623] iteration 24300 : loss : 96.605759, loss_ce: 0.011403, loss_kd: 480.618835
[23:33:14.227] iteration 24310 : loss : 136.864777, loss_ce: 0.019665, loss_kd: 681.939636
[23:33:19.808] iteration 24320 : loss : 92.060089, loss_ce: 0.010687, loss_kd: 457.944336
[23:33:25.400] iteration 24330 : loss : 103.895874, loss_ce: 0.014011, loss_kd: 517.090088
[23:33:30.978] iteration 24340 : loss : 128.659363, loss_ce: 0.006196, loss_kd: 640.879517
[23:33:36.567] iteration 24350 : loss : 122.432243, loss_ce: 0.017240, loss_kd: 609.777588
[23:33:42.156] iteration 24360 : loss : 133.454926, loss_ce: 0.015531, loss_kd: 664.911377
[23:33:47.750] iteration 24370 : loss : 180.658463, loss_ce: 0.013372, loss_kd: 900.907471
[23:33:53.329] iteration 24380 : loss : 123.891724, loss_ce: 0.020493, loss_kd: 617.056458
[23:33:58.922] iteration 24390 : loss : 108.762711, loss_ce: 0.015045, loss_kd: 541.427734
[23:34:04.498] iteration 24400 : loss : 100.614098, loss_ce: 0.017587, loss_kd: 500.670227
[23:34:10.100] iteration 24410 : loss : 98.388962, loss_ce: 0.013618, loss_kd: 489.550201
[23:34:15.688] iteration 24420 : loss : 113.894539, loss_ce: 0.023123, loss_kd: 567.089355
[23:34:21.283] iteration 24430 : loss : 103.961906, loss_ce: 0.014584, loss_kd: 517.477173
[23:34:26.866] iteration 24440 : loss : 118.625015, loss_ce: 0.014602, loss_kd: 590.750854
[23:34:32.469] iteration 24450 : loss : 112.735298, loss_ce: 0.012419, loss_kd: 561.272278
[23:34:38.056] iteration 24460 : loss : 125.853836, loss_ce: 0.011346, loss_kd: 626.907532
[23:34:43.659] iteration 24470 : loss : 99.717697, loss_ce: 0.014713, loss_kd: 496.203827
[23:34:49.254] iteration 24480 : loss : 110.607498, loss_ce: 0.011825, loss_kd: 550.688416
[23:34:54.854] iteration 24490 : loss : 96.220543, loss_ce: 0.018960, loss_kd: 478.682007
[23:35:00.447] iteration 24500 : loss : 103.269341, loss_ce: 0.015894, loss_kd: 513.933105
[23:35:06.058] iteration 24510 : loss : 123.639824, loss_ce: 0.008379, loss_kd: 615.775879
[23:35:11.648] iteration 24520 : loss : 160.686264, loss_ce: 0.018968, loss_kd: 801.041321
[23:35:17.255] iteration 24530 : loss : 195.706482, loss_ce: 0.012828, loss_kd: 976.159546
[23:35:22.845] iteration 24540 : loss : 123.673546, loss_ce: 0.008522, loss_kd: 616.011841
[23:35:28.442] iteration 24550 : loss : 118.917267, loss_ce: 0.010871, loss_kd: 592.239075
[23:35:34.035] iteration 24560 : loss : 171.631287, loss_ce: 0.012128, loss_kd: 855.789856
[23:35:39.645] iteration 24570 : loss : 99.072556, loss_ce: 0.013688, loss_kd: 493.027069
[23:35:45.237] iteration 24580 : loss : 122.791801, loss_ce: 0.018938, loss_kd: 611.575500
[23:35:50.845] iteration 24590 : loss : 114.659004, loss_ce: 0.015718, loss_kd: 570.908020
[23:35:56.438] iteration 24600 : loss : 102.881927, loss_ce: 0.013533, loss_kd: 512.046143
[23:36:02.040] iteration 24610 : loss : 97.874832, loss_ce: 0.022773, loss_kd: 486.975891
[23:36:07.639] iteration 24620 : loss : 90.450623, loss_ce: 0.015262, loss_kd: 449.896545
[23:36:13.244] iteration 24630 : loss : 129.955322, loss_ce: 0.013979, loss_kd: 647.403992
[23:36:18.837] iteration 24640 : loss : 100.874886, loss_ce: 0.011509, loss_kd: 501.971954
[23:36:24.434] iteration 24650 : loss : 115.302582, loss_ce: 0.012923, loss_kd: 574.088928
[23:36:30.032] iteration 24660 : loss : 112.555733, loss_ce: 0.014849, loss_kd: 560.411987
[23:36:35.635] iteration 24670 : loss : 107.087379, loss_ce: 0.015990, loss_kd: 533.043457
[23:36:41.225] iteration 24680 : loss : 137.263153, loss_ce: 0.020007, loss_kd: 683.892761
[23:36:46.830] iteration 24690 : loss : 132.349594, loss_ce: 0.014166, loss_kd: 659.342957
[23:36:52.421] iteration 24700 : loss : 111.589928, loss_ce: 0.017222, loss_kd: 555.590332
[23:36:58.030] iteration 24710 : loss : 123.891068, loss_ce: 0.011906, loss_kd: 617.106445
[23:37:03.623] iteration 24720 : loss : 93.180984, loss_ce: 0.018788, loss_kd: 463.540833
[23:37:09.230] iteration 24730 : loss : 144.158096, loss_ce: 0.012561, loss_kd: 718.406860
[23:37:14.816] iteration 24740 : loss : 136.789047, loss_ce: 0.015717, loss_kd: 681.564758
[23:37:20.425] iteration 24750 : loss : 131.380615, loss_ce: 0.010678, loss_kd: 654.517822
[23:37:26.025] iteration 24760 : loss : 124.775589, loss_ce: 0.010625, loss_kd: 621.521423
[23:37:31.631] iteration 24770 : loss : 92.146172, loss_ce: 0.014765, loss_kd: 458.371002
[23:37:37.226] iteration 24780 : loss : 154.257187, loss_ce: 0.010410, loss_kd: 768.885986
[23:37:42.831] iteration 24790 : loss : 112.283806, loss_ce: 0.021575, loss_kd: 559.022339
[23:37:48.426] iteration 24800 : loss : 127.456253, loss_ce: 0.010393, loss_kd: 634.889526
[23:37:54.028] iteration 24810 : loss : 112.716736, loss_ce: 0.020467, loss_kd: 561.203247
[23:37:59.619] iteration 24820 : loss : 110.484161, loss_ce: 0.009855, loss_kd: 550.049622
[23:38:05.222] iteration 24830 : loss : 97.580009, loss_ce: 0.017074, loss_kd: 485.515076
[23:38:10.812] iteration 24840 : loss : 121.027863, loss_ce: 0.018280, loss_kd: 602.703186
[23:38:16.412] iteration 24850 : loss : 123.078438, loss_ce: 0.025107, loss_kd: 612.973633
[23:38:22.006] iteration 24860 : loss : 128.233978, loss_ce: 0.012966, loss_kd: 638.769958
[23:38:27.610] iteration 24870 : loss : 128.859604, loss_ce: 0.010663, loss_kd: 641.926758
[23:38:33.204] iteration 24880 : loss : 102.907143, loss_ce: 0.016298, loss_kd: 512.146423
[23:38:38.809] iteration 24890 : loss : 131.047226, loss_ce: 0.016653, loss_kd: 652.859009
[23:38:44.397] iteration 24900 : loss : 94.927155, loss_ce: 0.017846, loss_kd: 472.241608
[23:38:50.002] iteration 24910 : loss : 102.532784, loss_ce: 0.014995, loss_kd: 510.252380
[23:38:55.603] iteration 24920 : loss : 105.967964, loss_ce: 0.022499, loss_kd: 527.447998
[23:39:01.211] iteration 24930 : loss : 109.494331, loss_ce: 0.013246, loss_kd: 545.095337
[23:39:06.800] iteration 24940 : loss : 117.402397, loss_ce: 0.017927, loss_kd: 584.617615
[23:39:12.401] iteration 24950 : loss : 104.430359, loss_ce: 0.015385, loss_kd: 519.720764
[23:39:17.995] iteration 24960 : loss : 111.153107, loss_ce: 0.021562, loss_kd: 553.358887
[23:39:23.597] iteration 24970 : loss : 102.293152, loss_ce: 0.016525, loss_kd: 509.031250
[23:39:29.185] iteration 24980 : loss : 107.560318, loss_ce: 0.018620, loss_kd: 535.405396
[23:39:34.784] iteration 24990 : loss : 97.190048, loss_ce: 0.013705, loss_kd: 483.566101
[23:39:40.382] iteration 25000 : loss : 125.931252, loss_ce: 0.025347, loss_kd: 627.267578
[23:39:56.816] iteration 25010 : loss : 123.657722, loss_ce: 0.020443, loss_kd: 615.918762
[23:40:02.349] iteration 25020 : loss : 136.170624, loss_ce: 0.013782, loss_kd: 678.475220
[23:40:07.900] iteration 25030 : loss : 113.398232, loss_ce: 0.012418, loss_kd: 564.597107
[23:40:13.440] iteration 25040 : loss : 110.236542, loss_ce: 0.023013, loss_kd: 548.755920
[23:40:18.995] iteration 25050 : loss : 132.955978, loss_ce: 0.014033, loss_kd: 662.424194
[23:40:24.544] iteration 25060 : loss : 133.480957, loss_ce: 0.021643, loss_kd: 665.019165
[23:40:30.105] iteration 25070 : loss : 78.411369, loss_ce: 0.014092, loss_kd: 389.672150
[23:40:35.658] iteration 25080 : loss : 78.798836, loss_ce: 0.018005, loss_kd: 391.648254
[23:40:41.224] iteration 25090 : loss : 102.751320, loss_ce: 0.015689, loss_kd: 511.352325
[23:40:46.784] iteration 25100 : loss : 110.019798, loss_ce: 0.014692, loss_kd: 547.676270
[23:40:52.364] iteration 25110 : loss : 124.871643, loss_ce: 0.022156, loss_kd: 621.950073
[23:40:57.921] iteration 25120 : loss : 126.253136, loss_ce: 0.030272, loss_kd: 628.873047
[23:41:03.495] iteration 25130 : loss : 130.752960, loss_ce: 0.012702, loss_kd: 651.408508
[23:41:09.064] iteration 25140 : loss : 136.422882, loss_ce: 0.019807, loss_kd: 679.749512
[23:41:14.637] iteration 25150 : loss : 128.260635, loss_ce: 0.020268, loss_kd: 638.897278
[23:41:20.203] iteration 25160 : loss : 96.946373, loss_ce: 0.019198, loss_kd: 482.353668
[23:41:25.782] iteration 25170 : loss : 101.190857, loss_ce: 0.022978, loss_kd: 503.584442
[23:41:31.355] iteration 25180 : loss : 125.374336, loss_ce: 0.015086, loss_kd: 624.515076
[23:41:36.932] iteration 25190 : loss : 131.145935, loss_ce: 0.016180, loss_kd: 653.332825
[23:41:42.502] iteration 25200 : loss : 131.895660, loss_ce: 0.015844, loss_kd: 657.121826
[23:41:48.086] iteration 25210 : loss : 109.527847, loss_ce: 0.024240, loss_kd: 545.252075
[23:41:53.658] iteration 25220 : loss : 95.782562, loss_ce: 0.014511, loss_kd: 476.572968
[23:41:59.239] iteration 25230 : loss : 107.119316, loss_ce: 0.013932, loss_kd: 533.196594
[23:42:04.813] iteration 25240 : loss : 109.102158, loss_ce: 0.013961, loss_kd: 543.136169
[23:42:10.415] iteration 25250 : loss : 110.305077, loss_ce: 0.021823, loss_kd: 549.109985
[23:42:15.986] iteration 25260 : loss : 123.068832, loss_ce: 0.007947, loss_kd: 612.976624
[23:42:21.569] iteration 25270 : loss : 98.786629, loss_ce: 0.014295, loss_kd: 491.509094
[23:42:27.136] iteration 25280 : loss : 81.517929, loss_ce: 0.018022, loss_kd: 405.192688
[23:42:32.727] iteration 25290 : loss : 156.236908, loss_ce: 0.013819, loss_kd: 778.805298
[23:42:38.305] iteration 25300 : loss : 119.494698, loss_ce: 0.022483, loss_kd: 595.079529
[23:42:43.894] iteration 25310 : loss : 83.299843, loss_ce: 0.010149, loss_kd: 414.134491
[23:42:49.465] iteration 25320 : loss : 90.428192, loss_ce: 0.025134, loss_kd: 449.736084
[23:42:55.054] iteration 25330 : loss : 106.739342, loss_ce: 0.010666, loss_kd: 531.277466
[23:43:00.634] iteration 25340 : loss : 95.417923, loss_ce: 0.013929, loss_kd: 474.745850
[23:43:06.228] iteration 25350 : loss : 132.225723, loss_ce: 0.017074, loss_kd: 658.741272
[23:43:11.807] iteration 25360 : loss : 138.799759, loss_ce: 0.018655, loss_kd: 691.622070
[23:43:17.394] iteration 25370 : loss : 161.595612, loss_ce: 0.025089, loss_kd: 805.583740
[23:43:22.974] iteration 25380 : loss : 139.562958, loss_ce: 0.013258, loss_kd: 695.418213
[23:43:28.562] iteration 25390 : loss : 117.576981, loss_ce: 0.018818, loss_kd: 585.480591
[23:43:34.137] iteration 25400 : loss : 86.588608, loss_ce: 0.017438, loss_kd: 430.561584
[23:43:39.724] iteration 25410 : loss : 115.459763, loss_ce: 0.014210, loss_kd: 574.924988
[23:43:45.302] iteration 25420 : loss : 77.134430, loss_ce: 0.010256, loss_kd: 383.278992
[23:43:50.889] iteration 25430 : loss : 112.594055, loss_ce: 0.012367, loss_kd: 560.590820
[23:43:56.466] iteration 25440 : loss : 117.862328, loss_ce: 0.015754, loss_kd: 586.933350
[23:44:02.054] iteration 25450 : loss : 119.052170, loss_ce: 0.012744, loss_kd: 592.877930
[23:44:07.632] iteration 25460 : loss : 87.906303, loss_ce: 0.028454, loss_kd: 437.131226
[23:44:13.218] iteration 25470 : loss : 118.881523, loss_ce: 0.016827, loss_kd: 592.014221
[23:44:18.796] iteration 25480 : loss : 98.623856, loss_ce: 0.019676, loss_kd: 490.698425
[23:44:24.376] iteration 25490 : loss : 93.040123, loss_ce: 0.022576, loss_kd: 462.793274
[23:44:29.961] iteration 25500 : loss : 117.511131, loss_ce: 0.026132, loss_kd: 585.157715
[23:44:35.551] iteration 25510 : loss : 105.854630, loss_ce: 0.013735, loss_kd: 526.887146
[23:44:41.141] iteration 25520 : loss : 113.518990, loss_ce: 0.021532, loss_kd: 565.230286
[23:44:46.735] iteration 25530 : loss : 106.936699, loss_ce: 0.016399, loss_kd: 532.307312
[23:44:52.314] iteration 25540 : loss : 112.043259, loss_ce: 0.011618, loss_kd: 557.858459
[23:44:57.899] iteration 25550 : loss : 109.467308, loss_ce: 0.015980, loss_kd: 544.950623
[23:45:03.477] iteration 25560 : loss : 138.409866, loss_ce: 0.010735, loss_kd: 689.631348
[23:45:09.067] iteration 25570 : loss : 107.262421, loss_ce: 0.019280, loss_kd: 533.890259
[23:45:14.651] iteration 25580 : loss : 109.231544, loss_ce: 0.013251, loss_kd: 543.756958
[23:45:20.256] iteration 25590 : loss : 115.536118, loss_ce: 0.024933, loss_kd: 575.286987
[23:45:25.836] iteration 25600 : loss : 115.604691, loss_ce: 0.022613, loss_kd: 575.671387
[23:45:31.427] iteration 25610 : loss : 159.999054, loss_ce: 0.017033, loss_kd: 797.601929
[23:45:37.004] iteration 25620 : loss : 116.274422, loss_ce: 0.008682, loss_kd: 579.013428
[23:45:42.593] iteration 25630 : loss : 107.777702, loss_ce: 0.019677, loss_kd: 536.520081
[23:45:48.179] iteration 25640 : loss : 119.587090, loss_ce: 0.023809, loss_kd: 595.567078
[23:45:53.768] iteration 25650 : loss : 129.335983, loss_ce: 0.010516, loss_kd: 644.258057
[23:45:59.349] iteration 25660 : loss : 95.309799, loss_ce: 0.010556, loss_kd: 474.198822
[23:46:04.938] iteration 25670 : loss : 126.966812, loss_ce: 0.014839, loss_kd: 632.468506
[23:46:10.518] iteration 25680 : loss : 133.596878, loss_ce: 0.010110, loss_kd: 665.618896
[23:46:16.109] iteration 25690 : loss : 133.863876, loss_ce: 0.015126, loss_kd: 666.951050
[23:46:21.701] iteration 25700 : loss : 128.080902, loss_ce: 0.022248, loss_kd: 638.004150
[23:46:27.301] iteration 25710 : loss : 103.753899, loss_ce: 0.018103, loss_kd: 516.376343
[23:46:32.889] iteration 25720 : loss : 102.837769, loss_ce: 0.016972, loss_kd: 511.829376
[23:46:38.492] iteration 25730 : loss : 116.362206, loss_ce: 0.020387, loss_kd: 579.444824
[23:46:44.071] iteration 25740 : loss : 119.782936, loss_ce: 0.019446, loss_kd: 596.494080
[23:46:49.666] iteration 25750 : loss : 112.440674, loss_ce: 0.025061, loss_kd: 559.841797
[23:46:55.257] iteration 25760 : loss : 108.344414, loss_ce: 0.021932, loss_kd: 539.304016
[23:47:00.858] iteration 25770 : loss : 104.441368, loss_ce: 0.013630, loss_kd: 519.857300
[23:47:06.450] iteration 25780 : loss : 146.369598, loss_ce: 0.015109, loss_kd: 729.492676
[23:47:12.059] iteration 25790 : loss : 123.744659, loss_ce: 0.013976, loss_kd: 616.349548
[23:47:17.651] iteration 25800 : loss : 97.801750, loss_ce: 0.011003, loss_kd: 486.633484
[23:47:23.252] iteration 25810 : loss : 126.233986, loss_ce: 0.014288, loss_kd: 628.762512
[23:47:28.849] iteration 25820 : loss : 107.278931, loss_ce: 0.013838, loss_kd: 533.993347
[23:47:34.459] iteration 25830 : loss : 88.087280, loss_ce: 0.020546, loss_kd: 438.054108
[23:47:40.044] iteration 25840 : loss : 94.466866, loss_ce: 0.010652, loss_kd: 469.939301
[23:47:45.654] iteration 25850 : loss : 109.980705, loss_ce: 0.019663, loss_kd: 547.486023
[23:47:51.245] iteration 25860 : loss : 117.764000, loss_ce: 0.015000, loss_kd: 586.458252
[23:47:56.847] iteration 25870 : loss : 115.891045, loss_ce: 0.024937, loss_kd: 577.062805
[23:48:02.445] iteration 25880 : loss : 100.803566, loss_ce: 0.014583, loss_kd: 501.628510
[23:48:08.047] iteration 25890 : loss : 102.700119, loss_ce: 0.027751, loss_kd: 511.122162
[23:48:13.639] iteration 25900 : loss : 83.895912, loss_ce: 0.016486, loss_kd: 417.127594
[23:48:19.256] iteration 25910 : loss : 101.514008, loss_ce: 0.014759, loss_kd: 505.180939
[23:48:24.861] iteration 25920 : loss : 118.029099, loss_ce: 0.025087, loss_kd: 587.756104
[23:48:30.468] iteration 25930 : loss : 130.292755, loss_ce: 0.011942, loss_kd: 649.083740
[23:48:36.066] iteration 25940 : loss : 112.767647, loss_ce: 0.012109, loss_kd: 561.462769
[23:48:41.674] iteration 25950 : loss : 105.733543, loss_ce: 0.012804, loss_kd: 526.260681
[23:48:47.267] iteration 25960 : loss : 90.334114, loss_ce: 0.030710, loss_kd: 449.290161
[23:48:52.872] iteration 25970 : loss : 113.226486, loss_ce: 0.010475, loss_kd: 563.793091
[23:48:58.471] iteration 25980 : loss : 92.503540, loss_ce: 0.018397, loss_kd: 460.146149
[23:49:04.066] iteration 25990 : loss : 93.602013, loss_ce: 0.013141, loss_kd: 465.642822
[23:49:09.662] iteration 26000 : loss : 137.917419, loss_ce: 0.015915, loss_kd: 687.177185
[23:49:15.268] iteration 26010 : loss : 134.073090, loss_ce: 0.019568, loss_kd: 667.986328
[23:49:20.860] iteration 26020 : loss : 139.237671, loss_ce: 0.019533, loss_kd: 693.833984
[23:49:26.463] iteration 26030 : loss : 113.889206, loss_ce: 0.013797, loss_kd: 567.075378
[23:49:32.061] iteration 26040 : loss : 89.197159, loss_ce: 0.012290, loss_kd: 443.636169
[23:49:37.372] iteration 26050 : loss : 92.727066, loss_ce: 0.018440, loss_kd: 461.235260
[23:49:38.047] save model to ./debug_fixed_tpgm\continual_surgical_tpgm_stage1_epoch_24.pth
[23:49:38.050] Running TPGM constraint optimization after epoch 25
[23:54:34.141] iteration 26060 : loss : 122.049751, loss_ce: 0.026579, loss_kd: 607.845032
[23:54:39.666] iteration 26070 : loss : 108.749611, loss_ce: 0.021770, loss_kd: 541.357849
[23:54:45.190] iteration 26080 : loss : 117.910378, loss_ce: 0.011800, loss_kd: 587.145203
[23:54:50.726] iteration 26090 : loss : 111.027802, loss_ce: 0.013011, loss_kd: 552.798157
[23:54:56.254] iteration 26100 : loss : 96.223137, loss_ce: 0.019215, loss_kd: 478.694733
[23:55:01.794] iteration 26110 : loss : 109.600700, loss_ce: 0.024445, loss_kd: 545.609436
[23:55:07.324] iteration 26120 : loss : 115.795517, loss_ce: 0.016939, loss_kd: 576.608398
[23:55:12.870] iteration 26130 : loss : 110.992935, loss_ce: 0.012808, loss_kd: 552.539062
[23:55:18.410] iteration 26140 : loss : 159.409760, loss_ce: 0.020445, loss_kd: 794.670715
[23:55:23.962] iteration 26150 : loss : 103.254219, loss_ce: 0.013210, loss_kd: 513.907959
[23:55:29.509] iteration 26160 : loss : 93.269035, loss_ce: 0.011658, loss_kd: 463.970978
[23:55:35.063] iteration 26170 : loss : 104.154655, loss_ce: 0.019656, loss_kd: 518.386536
[23:55:40.618] iteration 26180 : loss : 112.020187, loss_ce: 0.027630, loss_kd: 557.725159
[23:55:46.181] iteration 26190 : loss : 97.249382, loss_ce: 0.016718, loss_kd: 483.881958
[23:55:51.737] iteration 26200 : loss : 125.491669, loss_ce: 0.024830, loss_kd: 625.124878
[23:55:57.306] iteration 26210 : loss : 104.619484, loss_ce: 0.010426, loss_kd: 520.722900
[23:56:02.865] iteration 26220 : loss : 97.793442, loss_ce: 0.010574, loss_kd: 486.616669
[23:56:08.434] iteration 26230 : loss : 111.267212, loss_ce: 0.022918, loss_kd: 553.929749
[23:56:14.001] iteration 26240 : loss : 102.978783, loss_ce: 0.030389, loss_kd: 512.526917
[23:56:19.578] iteration 26250 : loss : 106.347679, loss_ce: 0.017751, loss_kd: 529.333374
[23:56:25.155] iteration 26260 : loss : 80.801010, loss_ce: 0.023188, loss_kd: 401.640869
[23:56:30.728] iteration 26270 : loss : 102.019791, loss_ce: 0.020383, loss_kd: 507.778870
[23:56:36.303] iteration 26280 : loss : 117.875816, loss_ce: 0.014571, loss_kd: 586.953613
[23:56:41.897] iteration 26290 : loss : 99.509811, loss_ce: 0.012684, loss_kd: 495.143982
[23:56:47.471] iteration 26300 : loss : 109.311035, loss_ce: 0.013462, loss_kd: 544.127747
[23:56:53.057] iteration 26310 : loss : 119.611946, loss_ce: 0.024388, loss_kd: 595.664673
[23:56:58.637] iteration 26320 : loss : 98.919792, loss_ce: 0.011957, loss_kd: 492.241333
[23:57:04.233] iteration 26330 : loss : 133.688126, loss_ce: 0.021166, loss_kd: 666.046204
[23:57:09.807] iteration 26340 : loss : 109.635826, loss_ce: 0.010773, loss_kd: 545.807190
[23:57:15.404] iteration 26350 : loss : 116.757416, loss_ce: 0.010572, loss_kd: 581.413391
[23:57:20.985] iteration 26360 : loss : 158.969086, loss_ce: 0.013645, loss_kd: 792.431335
[23:57:26.578] iteration 26370 : loss : 111.634750, loss_ce: 0.017111, loss_kd: 555.781799
[23:57:32.166] iteration 26380 : loss : 109.037376, loss_ce: 0.014967, loss_kd: 542.822815
[23:57:37.765] iteration 26390 : loss : 95.497902, loss_ce: 0.012502, loss_kd: 475.111816
[23:57:43.356] iteration 26400 : loss : 135.895508, loss_ce: 0.020771, loss_kd: 677.054626
[23:57:48.962] iteration 26410 : loss : 100.125572, loss_ce: 0.012646, loss_kd: 498.221313
[23:57:54.560] iteration 26420 : loss : 117.908478, loss_ce: 0.010477, loss_kd: 587.152283
[23:58:00.168] iteration 26430 : loss : 86.213448, loss_ce: 0.011179, loss_kd: 428.699646
[23:58:05.753] iteration 26440 : loss : 111.429565, loss_ce: 0.007895, loss_kd: 554.744385
[23:58:11.360] iteration 26450 : loss : 180.031433, loss_ce: 0.012141, loss_kd: 897.739624
[23:58:16.955] iteration 26460 : loss : 134.044861, loss_ce: 0.020085, loss_kd: 667.877502
[23:58:22.561] iteration 26470 : loss : 178.936249, loss_ce: 0.013626, loss_kd: 892.302795
[23:58:28.163] iteration 26480 : loss : 116.104729, loss_ce: 0.013888, loss_kd: 578.159485
[23:58:33.768] iteration 26490 : loss : 95.160904, loss_ce: 0.011570, loss_kd: 473.460938
[23:58:39.358] iteration 26500 : loss : 96.922539, loss_ce: 0.013909, loss_kd: 482.263672
[23:58:44.966] iteration 26510 : loss : 121.756302, loss_ce: 0.018682, loss_kd: 606.365479
[23:58:50.557] iteration 26520 : loss : 113.897682, loss_ce: 0.015213, loss_kd: 567.087830
[23:58:56.165] iteration 26530 : loss : 133.074203, loss_ce: 0.017657, loss_kd: 662.991272
[23:59:01.769] iteration 26540 : loss : 115.453957, loss_ce: 0.015045, loss_kd: 574.864197
[23:59:07.375] iteration 26550 : loss : 110.824944, loss_ce: 0.013599, loss_kd: 551.735779
[23:59:12.971] iteration 26560 : loss : 84.556244, loss_ce: 0.018095, loss_kd: 420.433807
[23:59:18.578] iteration 26570 : loss : 172.162201, loss_ce: 0.015000, loss_kd: 858.381042
[23:59:24.184] iteration 26580 : loss : 119.028961, loss_ce: 0.012557, loss_kd: 592.770447
[23:59:29.797] iteration 26590 : loss : 118.213463, loss_ce: 0.012635, loss_kd: 588.652527
[23:59:35.404] iteration 26600 : loss : 106.852806, loss_ce: 0.015487, loss_kd: 531.856201
[23:59:41.012] iteration 26610 : loss : 118.937759, loss_ce: 0.009687, loss_kd: 592.313171
[23:59:46.619] iteration 26620 : loss : 100.134758, loss_ce: 0.020864, loss_kd: 498.303040
[23:59:52.227] iteration 26630 : loss : 91.971909, loss_ce: 0.018487, loss_kd: 457.445007
[23:59:57.824] iteration 26640 : loss : 108.742271, loss_ce: 0.006958, loss_kd: 541.376038
[00:00:03.429] iteration 26650 : loss : 114.019081, loss_ce: 0.014440, loss_kd: 567.700867
[00:00:09.029] iteration 26660 : loss : 100.753990, loss_ce: 0.010426, loss_kd: 501.467651
[00:00:14.647] iteration 26670 : loss : 109.931618, loss_ce: 0.008818, loss_kd: 547.299805
[00:00:20.261] iteration 26680 : loss : 105.989861, loss_ce: 0.018621, loss_kd: 527.556335
[00:00:25.877] iteration 26690 : loss : 128.165543, loss_ce: 0.021476, loss_kd: 638.438354
[00:00:31.477] iteration 26700 : loss : 112.660225, loss_ce: 0.017839, loss_kd: 560.936523
[00:00:37.086] iteration 26710 : loss : 112.418503, loss_ce: 0.015982, loss_kd: 559.710876
[00:00:42.685] iteration 26720 : loss : 96.088074, loss_ce: 0.017841, loss_kd: 478.060120
[00:00:48.293] iteration 26730 : loss : 126.401527, loss_ce: 0.013215, loss_kd: 629.667358
[00:00:53.898] iteration 26740 : loss : 126.946037, loss_ce: 0.018106, loss_kd: 632.322144
[00:00:59.518] iteration 26750 : loss : 93.417755, loss_ce: 0.012065, loss_kd: 464.708466
[00:01:05.119] iteration 26760 : loss : 117.668701, loss_ce: 0.015091, loss_kd: 585.978821
[00:01:10.731] iteration 26770 : loss : 107.300591, loss_ce: 0.014673, loss_kd: 534.152893
[00:01:16.330] iteration 26780 : loss : 100.774063, loss_ce: 0.015176, loss_kd: 501.519165
[00:01:21.940] iteration 26790 : loss : 110.932480, loss_ce: 0.015682, loss_kd: 552.275635
[00:01:27.538] iteration 26800 : loss : 84.534477, loss_ce: 0.018286, loss_kd: 420.289886
[00:01:33.141] iteration 26810 : loss : 119.432129, loss_ce: 0.023426, loss_kd: 594.763733
[00:01:38.741] iteration 26820 : loss : 126.726616, loss_ce: 0.018516, loss_kd: 631.260010
[00:01:44.350] iteration 26830 : loss : 148.886917, loss_ce: 0.019489, loss_kd: 742.089783
[00:01:49.950] iteration 26840 : loss : 95.351830, loss_ce: 0.010114, loss_kd: 474.395691
[00:01:55.577] iteration 26850 : loss : 111.973534, loss_ce: 0.025605, loss_kd: 557.486328
[00:02:01.183] iteration 26860 : loss : 105.307686, loss_ce: 0.014700, loss_kd: 524.110840
[00:02:06.792] iteration 26870 : loss : 88.473389, loss_ce: 0.015091, loss_kd: 439.955688
[00:02:12.392] iteration 26880 : loss : 135.638718, loss_ce: 0.019311, loss_kd: 675.828186
[00:02:18.007] iteration 26890 : loss : 118.091179, loss_ce: 0.012809, loss_kd: 588.128296
[00:02:23.625] iteration 26900 : loss : 126.807495, loss_ce: 0.020120, loss_kd: 631.640076
[00:02:29.246] iteration 26910 : loss : 101.571663, loss_ce: 0.017373, loss_kd: 505.494690
[00:02:34.854] iteration 26920 : loss : 119.000702, loss_ce: 0.012551, loss_kd: 592.592773
[00:02:40.476] iteration 26930 : loss : 101.923111, loss_ce: 0.020998, loss_kd: 507.229004
[00:02:46.087] iteration 26940 : loss : 146.124466, loss_ce: 0.015711, loss_kd: 728.275757
[00:02:51.710] iteration 26950 : loss : 113.777191, loss_ce: 0.019538, loss_kd: 566.503296
[00:02:57.315] iteration 26960 : loss : 114.622475, loss_ce: 0.010698, loss_kd: 570.749695
[00:03:02.931] iteration 26970 : loss : 105.877235, loss_ce: 0.008948, loss_kd: 527.032593
[00:03:08.534] iteration 26980 : loss : 124.160454, loss_ce: 0.010730, loss_kd: 618.409180
[00:03:14.164] iteration 26990 : loss : 80.051743, loss_ce: 0.014315, loss_kd: 397.895081
[00:03:19.772] iteration 27000 : loss : 118.000305, loss_ce: 0.008321, loss_kd: 587.584229
[00:03:25.386] iteration 27010 : loss : 168.332382, loss_ce: 0.027057, loss_kd: 839.282471
[00:03:30.986] iteration 27020 : loss : 174.478409, loss_ce: 0.012003, loss_kd: 870.025818
[00:03:36.597] iteration 27030 : loss : 138.335403, loss_ce: 0.018307, loss_kd: 689.278320
[00:03:42.204] iteration 27040 : loss : 122.155075, loss_ce: 0.011400, loss_kd: 608.444946
[00:03:47.826] iteration 27050 : loss : 96.235764, loss_ce: 0.014396, loss_kd: 478.812531
[00:03:53.437] iteration 27060 : loss : 97.235985, loss_ce: 0.018817, loss_kd: 483.811737
[00:03:59.052] iteration 27070 : loss : 98.004562, loss_ce: 0.015791, loss_kd: 487.645447
[00:04:04.654] iteration 27080 : loss : 99.316757, loss_ce: 0.024765, loss_kd: 494.214478
[00:04:10.281] iteration 27090 : loss : 119.165100, loss_ce: 0.013316, loss_kd: 593.507690
[00:04:27.277] iteration 27100 : loss : 127.609764, loss_ce: 0.015597, loss_kd: 635.717896
[00:04:32.827] iteration 27110 : loss : 107.326828, loss_ce: 0.014627, loss_kd: 534.273743
[00:04:38.370] iteration 27120 : loss : 113.050705, loss_ce: 0.014287, loss_kd: 562.876404
[00:04:43.939] iteration 27130 : loss : 120.332535, loss_ce: 0.017563, loss_kd: 599.313660
[00:04:49.498] iteration 27140 : loss : 95.461639, loss_ce: 0.016254, loss_kd: 474.922058
[00:04:55.063] iteration 27150 : loss : 98.309357, loss_ce: 0.011370, loss_kd: 489.123291
[00:05:00.631] iteration 27160 : loss : 91.241287, loss_ce: 0.019756, loss_kd: 453.821259
[00:05:06.204] iteration 27170 : loss : 123.871498, loss_ce: 0.015611, loss_kd: 616.972656
[00:05:11.770] iteration 27180 : loss : 98.478394, loss_ce: 0.012117, loss_kd: 490.041107
[00:05:17.350] iteration 27190 : loss : 110.347534, loss_ce: 0.013150, loss_kd: 549.335022
[00:05:22.919] iteration 27200 : loss : 107.178726, loss_ce: 0.013060, loss_kd: 533.526489
[00:05:28.512] iteration 27210 : loss : 109.194427, loss_ce: 0.015888, loss_kd: 543.597168
[00:05:34.087] iteration 27220 : loss : 103.334564, loss_ce: 0.014014, loss_kd: 514.313782
[00:05:39.678] iteration 27230 : loss : 90.431969, loss_ce: 0.009669, loss_kd: 449.799225
[00:05:45.255] iteration 27240 : loss : 107.754738, loss_ce: 0.024708, loss_kd: 536.372192
[00:05:50.842] iteration 27250 : loss : 67.873116, loss_ce: 0.014809, loss_kd: 336.988312
[00:05:56.434] iteration 27260 : loss : 124.384712, loss_ce: 0.013311, loss_kd: 619.545288
[00:06:02.026] iteration 27270 : loss : 117.282784, loss_ce: 0.012454, loss_kd: 584.033325
[00:06:07.616] iteration 27280 : loss : 107.346252, loss_ce: 0.013903, loss_kd: 534.365601
[00:06:13.216] iteration 27290 : loss : 121.330750, loss_ce: 0.017302, loss_kd: 604.273499
[00:06:18.805] iteration 27300 : loss : 106.871880, loss_ce: 0.009776, loss_kd: 532.030151
[00:06:24.416] iteration 27310 : loss : 120.294670, loss_ce: 0.012460, loss_kd: 599.122864
[00:06:30.012] iteration 27320 : loss : 118.135353, loss_ce: 0.014483, loss_kd: 588.272827
[00:06:35.624] iteration 27330 : loss : 108.566689, loss_ce: 0.010996, loss_kd: 540.514771
[00:06:41.218] iteration 27340 : loss : 118.305481, loss_ce: 0.020122, loss_kd: 589.132935
[00:06:46.829] iteration 27350 : loss : 113.963554, loss_ce: 0.034358, loss_kd: 567.415710
[00:06:52.432] iteration 27360 : loss : 132.066910, loss_ce: 0.008822, loss_kd: 657.992737
[00:06:58.037] iteration 27370 : loss : 128.136261, loss_ce: 0.019006, loss_kd: 638.328857
[00:07:03.630] iteration 27380 : loss : 106.250229, loss_ce: 0.023185, loss_kd: 528.893555
[00:07:09.239] iteration 27390 : loss : 95.220177, loss_ce: 0.009607, loss_kd: 473.696106
[00:07:14.834] iteration 27400 : loss : 121.066177, loss_ce: 0.017528, loss_kd: 602.960938
[00:07:20.441] iteration 27410 : loss : 121.390068, loss_ce: 0.013690, loss_kd: 604.563782
[00:07:26.038] iteration 27420 : loss : 91.654907, loss_ce: 0.012614, loss_kd: 455.927979
[00:07:31.641] iteration 27430 : loss : 130.077652, loss_ce: 0.017586, loss_kd: 648.024902
[00:07:37.247] iteration 27440 : loss : 127.282127, loss_ce: 0.026149, loss_kd: 634.002991
[00:07:42.865] iteration 27450 : loss : 113.558975, loss_ce: 0.019994, loss_kd: 565.411987
[00:07:48.474] iteration 27460 : loss : 140.355209, loss_ce: 0.018643, loss_kd: 699.374023
[00:07:54.084] iteration 27470 : loss : 106.322273, loss_ce: 0.009494, loss_kd: 529.265869
[00:07:59.684] iteration 27480 : loss : 114.998840, loss_ce: 0.016798, loss_kd: 572.603149
[00:08:05.294] iteration 27490 : loss : 109.400360, loss_ce: 0.022786, loss_kd: 544.603271
[00:08:10.886] iteration 27500 : loss : 105.460655, loss_ce: 0.014829, loss_kd: 524.928345
[00:08:16.496] iteration 27510 : loss : 126.679115, loss_ce: 0.014832, loss_kd: 631.025085
[00:08:22.086] iteration 27520 : loss : 124.631699, loss_ce: 0.012477, loss_kd: 620.813110
[00:08:27.692] iteration 27530 : loss : 121.298096, loss_ce: 0.016370, loss_kd: 604.069519
[00:08:33.291] iteration 27540 : loss : 111.547104, loss_ce: 0.009948, loss_kd: 555.369385
[00:08:38.895] iteration 27550 : loss : 110.783493, loss_ce: 0.008227, loss_kd: 551.538330
[00:08:44.493] iteration 27560 : loss : 92.348862, loss_ce: 0.012458, loss_kd: 459.339142
[00:08:50.097] iteration 27570 : loss : 111.382103, loss_ce: 0.011965, loss_kd: 554.514221
[00:08:55.688] iteration 27580 : loss : 97.263306, loss_ce: 0.012837, loss_kd: 483.939941
[00:09:01.298] iteration 27590 : loss : 136.103180, loss_ce: 0.023604, loss_kd: 678.122803
[00:09:06.898] iteration 27600 : loss : 109.808617, loss_ce: 0.019247, loss_kd: 546.698792
[00:09:12.518] iteration 27610 : loss : 100.158760, loss_ce: 0.021570, loss_kd: 498.377777
[00:09:18.119] iteration 27620 : loss : 111.554977, loss_ce: 0.023650, loss_kd: 555.414185
[00:09:23.736] iteration 27630 : loss : 113.294914, loss_ce: 0.014023, loss_kd: 564.091064
[00:09:29.341] iteration 27640 : loss : 121.789131, loss_ce: 0.026957, loss_kd: 606.532349
[00:09:34.957] iteration 27650 : loss : 124.565239, loss_ce: 0.012181, loss_kd: 620.453552
[00:09:40.551] iteration 27660 : loss : 92.641533, loss_ce: 0.017594, loss_kd: 460.845642
[00:09:46.151] iteration 27670 : loss : 95.915649, loss_ce: 0.014734, loss_kd: 477.153168
[00:09:51.749] iteration 27680 : loss : 97.406296, loss_ce: 0.012988, loss_kd: 484.625427
[00:09:57.357] iteration 27690 : loss : 135.000961, loss_ce: 0.011118, loss_kd: 672.607361
[00:10:02.953] iteration 27700 : loss : 118.990822, loss_ce: 0.019755, loss_kd: 592.584229
[00:10:08.577] iteration 27710 : loss : 111.897156, loss_ce: 0.024777, loss_kd: 557.108948
[00:10:14.181] iteration 27720 : loss : 102.453018, loss_ce: 0.018734, loss_kd: 509.858429
[00:10:19.787] iteration 27730 : loss : 120.893745, loss_ce: 0.017676, loss_kd: 602.071289
[00:10:25.379] iteration 27740 : loss : 97.131821, loss_ce: 0.018821, loss_kd: 483.265045
[00:10:30.985] iteration 27750 : loss : 113.222969, loss_ce: 0.011066, loss_kd: 563.745667
[00:10:36.588] iteration 27760 : loss : 125.228561, loss_ce: 0.012607, loss_kd: 623.783081
[00:10:42.196] iteration 27770 : loss : 119.860619, loss_ce: 0.018507, loss_kd: 596.925903
[00:10:47.796] iteration 27780 : loss : 122.926498, loss_ce: 0.017630, loss_kd: 612.209656
[00:10:53.417] iteration 27790 : loss : 93.409409, loss_ce: 0.017901, loss_kd: 464.677307
[00:10:59.026] iteration 27800 : loss : 110.836899, loss_ce: 0.018745, loss_kd: 551.776733
[00:11:04.648] iteration 27810 : loss : 89.377029, loss_ce: 0.015620, loss_kd: 444.476501
[00:11:10.242] iteration 27820 : loss : 121.869690, loss_ce: 0.023292, loss_kd: 606.949036
[00:11:15.869] iteration 27830 : loss : 105.677086, loss_ce: 0.025345, loss_kd: 526.018860
[00:11:21.488] iteration 27840 : loss : 98.695282, loss_ce: 0.014132, loss_kd: 491.078552
[00:11:27.102] iteration 27850 : loss : 101.334465, loss_ce: 0.007145, loss_kd: 504.264709
[00:11:32.701] iteration 27860 : loss : 109.818680, loss_ce: 0.012295, loss_kd: 546.690796
[00:11:38.302] iteration 27870 : loss : 102.155350, loss_ce: 0.022897, loss_kd: 508.379517
[00:11:43.895] iteration 27880 : loss : 102.919800, loss_ce: 0.017628, loss_kd: 512.195984
[00:11:49.496] iteration 27890 : loss : 88.765770, loss_ce: 0.013521, loss_kd: 441.441223
[00:11:55.099] iteration 27900 : loss : 117.956436, loss_ce: 0.014377, loss_kd: 587.385254
[00:12:00.719] iteration 27910 : loss : 115.172348, loss_ce: 0.016445, loss_kd: 573.506531
[00:12:06.317] iteration 27920 : loss : 132.363556, loss_ce: 0.017054, loss_kd: 659.419373
[00:12:11.920] iteration 27930 : loss : 91.611290, loss_ce: 0.011486, loss_kd: 455.647400
[00:12:17.516] iteration 27940 : loss : 106.147087, loss_ce: 0.014145, loss_kd: 528.345154
[00:12:23.132] iteration 27950 : loss : 95.876038, loss_ce: 0.018297, loss_kd: 477.020111
[00:12:28.748] iteration 27960 : loss : 106.331909, loss_ce: 0.011363, loss_kd: 529.288574
[00:12:34.363] iteration 27970 : loss : 157.538696, loss_ce: 0.016768, loss_kd: 785.305054
[00:12:39.959] iteration 27980 : loss : 158.981491, loss_ce: 0.012585, loss_kd: 792.478760
[00:12:45.585] iteration 27990 : loss : 109.666611, loss_ce: 0.019281, loss_kd: 545.974731
[00:12:51.193] iteration 28000 : loss : 102.610153, loss_ce: 0.020524, loss_kd: 510.664764
[00:12:56.813] iteration 28010 : loss : 105.452774, loss_ce: 0.011917, loss_kd: 524.890930
[00:13:02.422] iteration 28020 : loss : 99.794456, loss_ce: 0.014501, loss_kd: 496.601349
[00:13:08.035] iteration 28030 : loss : 138.242294, loss_ce: 0.019887, loss_kd: 688.808533
[00:13:13.634] iteration 28040 : loss : 93.148140, loss_ce: 0.020000, loss_kd: 463.363037
[00:13:19.255] iteration 28050 : loss : 74.928795, loss_ce: 0.010070, loss_kd: 372.256775
[00:13:24.868] iteration 28060 : loss : 98.593369, loss_ce: 0.022542, loss_kd: 490.581360
[00:13:30.481] iteration 28070 : loss : 124.363991, loss_ce: 0.018302, loss_kd: 619.474854
[00:13:36.079] iteration 28080 : loss : 151.051483, loss_ce: 0.009263, loss_kd: 752.889526
[00:13:41.687] iteration 28090 : loss : 94.373589, loss_ce: 0.010204, loss_kd: 469.495575
[00:13:47.285] iteration 28100 : loss : 89.757973, loss_ce: 0.010755, loss_kd: 446.388977
[00:13:52.896] iteration 28110 : loss : 107.546410, loss_ce: 0.016884, loss_kd: 535.332336
[00:13:58.495] iteration 28120 : loss : 138.667435, loss_ce: 0.018477, loss_kd: 690.973999
[00:14:04.120] iteration 28130 : loss : 142.590332, loss_ce: 0.011566, loss_kd: 710.594421
[00:14:06.729] Running TPGM constraint optimization after epoch 27
[00:18:52.087] iteration 28140 : loss : 119.425034, loss_ce: 0.017660, loss_kd: 594.774353
[00:18:57.618] iteration 28150 : loss : 106.451347, loss_ce: 0.026666, loss_kd: 529.867554
[00:19:03.150] iteration 28160 : loss : 96.810539, loss_ce: 0.017752, loss_kd: 481.684570
[00:19:08.689] iteration 28170 : loss : 121.500008, loss_ce: 0.009774, loss_kd: 605.137207
[00:19:14.217] iteration 28180 : loss : 109.797020, loss_ce: 0.020254, loss_kd: 546.611511
[00:19:19.756] iteration 28190 : loss : 109.049332, loss_ce: 0.016917, loss_kd: 542.883057
[00:19:25.293] iteration 28200 : loss : 81.000748, loss_ce: 0.013146, loss_kd: 402.604126
[00:19:30.845] iteration 28210 : loss : 100.445656, loss_ce: 0.013135, loss_kd: 499.837067
[00:19:36.383] iteration 28220 : loss : 117.687874, loss_ce: 0.016522, loss_kd: 586.104370
[00:19:41.938] iteration 28230 : loss : 82.642418, loss_ce: 0.029204, loss_kd: 410.830750
[00:19:47.492] iteration 28240 : loss : 96.774765, loss_ce: 0.019387, loss_kd: 481.517242
[00:19:53.049] iteration 28250 : loss : 104.330734, loss_ce: 0.012998, loss_kd: 519.271484
[00:19:58.610] iteration 28260 : loss : 83.837570, loss_ce: 0.023802, loss_kd: 416.841919
[00:20:04.180] iteration 28270 : loss : 85.650482, loss_ce: 0.013316, loss_kd: 425.884277
[00:20:09.736] iteration 28280 : loss : 99.483521, loss_ce: 0.008531, loss_kd: 495.028046
[00:20:15.308] iteration 28290 : loss : 84.584679, loss_ce: 0.012010, loss_kd: 420.546875
[00:20:20.871] iteration 28300 : loss : 113.437691, loss_ce: 0.010749, loss_kd: 564.850891
[00:20:26.457] iteration 28310 : loss : 93.140793, loss_ce: 0.015326, loss_kd: 463.308411
[00:20:32.028] iteration 28320 : loss : 80.537674, loss_ce: 0.013455, loss_kd: 400.303680
[00:20:37.605] iteration 28330 : loss : 131.661621, loss_ce: 0.017529, loss_kd: 655.926636
[00:20:43.175] iteration 28340 : loss : 107.933151, loss_ce: 0.014984, loss_kd: 537.310120
[00:20:48.749] iteration 28350 : loss : 125.667229, loss_ce: 0.019964, loss_kd: 625.987549
[00:20:54.325] iteration 28360 : loss : 104.433212, loss_ce: 0.017672, loss_kd: 519.814575
[00:20:59.920] iteration 28370 : loss : 107.375847, loss_ce: 0.015798, loss_kd: 534.499512
[00:21:05.491] iteration 28380 : loss : 122.956940, loss_ce: 0.012733, loss_kd: 612.442566
[00:21:11.076] iteration 28390 : loss : 119.383339, loss_ce: 0.014691, loss_kd: 594.562500
[00:21:16.649] iteration 28400 : loss : 92.701744, loss_ce: 0.011310, loss_kd: 461.152863
[00:21:22.248] iteration 28410 : loss : 85.469177, loss_ce: 0.018686, loss_kd: 424.955444
[00:21:27.826] iteration 28420 : loss : 82.241898, loss_ce: 0.019415, loss_kd: 408.849396
[00:21:33.418] iteration 28430 : loss : 101.174026, loss_ce: 0.014716, loss_kd: 503.518768
[00:21:39.000] iteration 28440 : loss : 106.829643, loss_ce: 0.017303, loss_kd: 531.768982
[00:21:44.592] iteration 28450 : loss : 102.868492, loss_ce: 0.014284, loss_kd: 511.946045
[00:21:50.177] iteration 28460 : loss : 108.065742, loss_ce: 0.017746, loss_kd: 537.950134
[00:21:55.777] iteration 28470 : loss : 96.437004, loss_ce: 0.017316, loss_kd: 479.784515
[00:22:01.360] iteration 28480 : loss : 106.687889, loss_ce: 0.018027, loss_kd: 531.029236
[00:22:06.957] iteration 28490 : loss : 110.931931, loss_ce: 0.014334, loss_kd: 552.310669
[00:22:12.552] iteration 28500 : loss : 144.790100, loss_ce: 0.014929, loss_kd: 721.545105
[00:22:18.157] iteration 28510 : loss : 98.758949, loss_ce: 0.014677, loss_kd: 491.418213
[00:22:23.750] iteration 28520 : loss : 84.932693, loss_ce: 0.012009, loss_kd: 422.281769
[00:22:29.357] iteration 28530 : loss : 94.471855, loss_ce: 0.017638, loss_kd: 469.963135
[00:22:34.956] iteration 28540 : loss : 81.749023, loss_ce: 0.025566, loss_kd: 406.356506
[00:22:40.555] iteration 28550 : loss : 102.056229, loss_ce: 0.016191, loss_kd: 507.900421
[00:22:46.154] iteration 28560 : loss : 80.817619, loss_ce: 0.021120, loss_kd: 401.711578
[00:22:51.759] iteration 28570 : loss : 104.553291, loss_ce: 0.014620, loss_kd: 520.363525
[00:22:57.351] iteration 28580 : loss : 102.841385, loss_ce: 0.022477, loss_kd: 511.817352
[00:23:02.958] iteration 28590 : loss : 87.230293, loss_ce: 0.012598, loss_kd: 433.771484
[00:23:08.556] iteration 28600 : loss : 100.929932, loss_ce: 0.021965, loss_kd: 502.230469
[00:23:14.161] iteration 28610 : loss : 97.222305, loss_ce: 0.012976, loss_kd: 483.775177
[00:23:19.747] iteration 28620 : loss : 68.578827, loss_ce: 0.016009, loss_kd: 340.518433
[00:23:25.352] iteration 28630 : loss : 114.417969, loss_ce: 0.014784, loss_kd: 569.689636
[00:23:30.942] iteration 28640 : loss : 128.017593, loss_ce: 0.015704, loss_kd: 637.722412
[00:23:36.552] iteration 28650 : loss : 95.691864, loss_ce: 0.016290, loss_kd: 476.095276
[00:23:42.147] iteration 28660 : loss : 76.778503, loss_ce: 0.013565, loss_kd: 381.477936
[00:23:47.754] iteration 28670 : loss : 114.148193, loss_ce: 0.018855, loss_kd: 568.408203
[00:23:53.347] iteration 28680 : loss : 108.525162, loss_ce: 0.019230, loss_kd: 540.267273
[00:23:58.948] iteration 28690 : loss : 135.198639, loss_ce: 0.016511, loss_kd: 673.553040
[00:24:04.550] iteration 28700 : loss : 119.221313, loss_ce: 0.015810, loss_kd: 593.708008
[00:24:10.149] iteration 28710 : loss : 84.530640, loss_ce: 0.022214, loss_kd: 420.270538
[00:24:15.746] iteration 28720 : loss : 122.409782, loss_ce: 0.015123, loss_kd: 609.686890
[00:24:21.352] iteration 28730 : loss : 124.044304, loss_ce: 0.012503, loss_kd: 617.811829
[00:24:26.943] iteration 28740 : loss : 89.734444, loss_ce: 0.010064, loss_kd: 446.324463
[00:24:32.542] iteration 28750 : loss : 105.598953, loss_ce: 0.014852, loss_kd: 525.634155
[00:24:38.137] iteration 28760 : loss : 128.638092, loss_ce: 0.021114, loss_kd: 640.789612
[00:24:43.746] iteration 28770 : loss : 117.777885, loss_ce: 0.008982, loss_kd: 586.503479
[00:24:49.336] iteration 28780 : loss : 107.851341, loss_ce: 0.016653, loss_kd: 536.861267
[00:24:54.941] iteration 28790 : loss : 117.330406, loss_ce: 0.015290, loss_kd: 584.247864
[00:25:00.537] iteration 28800 : loss : 98.142288, loss_ce: 0.020723, loss_kd: 488.307343
[00:25:06.141] iteration 28810 : loss : 113.172394, loss_ce: 0.017990, loss_kd: 563.483154
[00:25:11.737] iteration 28820 : loss : 93.311302, loss_ce: 0.019232, loss_kd: 464.147705
[00:25:17.346] iteration 28830 : loss : 106.557007, loss_ce: 0.013256, loss_kd: 530.392639
[00:25:22.940] iteration 28840 : loss : 104.754013, loss_ce: 0.022283, loss_kd: 521.385559
[00:25:28.540] iteration 28850 : loss : 122.395088, loss_ce: 0.014744, loss_kd: 609.593323
[00:25:34.133] iteration 28860 : loss : 113.692101, loss_ce: 0.018082, loss_kd: 566.045715
[00:25:39.731] iteration 28870 : loss : 102.567383, loss_ce: 0.014467, loss_kd: 510.464691
[00:25:45.326] iteration 28880 : loss : 102.539413, loss_ce: 0.019415, loss_kd: 510.329407
[00:25:50.938] iteration 28890 : loss : 119.263809, loss_ce: 0.018794, loss_kd: 593.897644
[00:25:56.535] iteration 28900 : loss : 156.586060, loss_ce: 0.015330, loss_kd: 780.563293
[00:26:02.143] iteration 28910 : loss : 104.252121, loss_ce: 0.014787, loss_kd: 518.914551
[00:26:07.742] iteration 28920 : loss : 95.203972, loss_ce: 0.010189, loss_kd: 473.655212
[00:26:13.348] iteration 28930 : loss : 103.829681, loss_ce: 0.011686, loss_kd: 516.784241
[00:26:18.940] iteration 28940 : loss : 99.917297, loss_ce: 0.015069, loss_kd: 497.199402
[00:26:24.543] iteration 28950 : loss : 108.459137, loss_ce: 0.019182, loss_kd: 539.941223
[00:26:30.131] iteration 28960 : loss : 135.334778, loss_ce: 0.020880, loss_kd: 674.306213
[00:26:35.753] iteration 28970 : loss : 95.691574, loss_ce: 0.017594, loss_kd: 476.055145
[00:26:41.345] iteration 28980 : loss : 112.247734, loss_ce: 0.015897, loss_kd: 558.853149
[00:26:46.959] iteration 28990 : loss : 109.005760, loss_ce: 0.015260, loss_kd: 542.655762
[00:26:52.562] iteration 29000 : loss : 100.858704, loss_ce: 0.009974, loss_kd: 501.914917
[00:26:58.196] iteration 29010 : loss : 99.925842, loss_ce: 0.019009, loss_kd: 497.225952
[00:27:03.793] iteration 29020 : loss : 96.380066, loss_ce: 0.008712, loss_kd: 479.533905
[00:27:09.412] iteration 29030 : loss : 128.072586, loss_ce: 0.011542, loss_kd: 637.997803
[00:27:15.010] iteration 29040 : loss : 88.631630, loss_ce: 0.010883, loss_kd: 440.801117
[00:27:20.629] iteration 29050 : loss : 98.102242, loss_ce: 0.020468, loss_kd: 488.115540
[00:27:26.224] iteration 29060 : loss : 77.754669, loss_ce: 0.015183, loss_kd: 386.391571
[00:27:31.833] iteration 29070 : loss : 114.769745, loss_ce: 0.013589, loss_kd: 571.465576
[00:27:37.429] iteration 29080 : loss : 80.624763, loss_ce: 0.019338, loss_kd: 400.773804
[00:27:43.031] iteration 29090 : loss : 110.766632, loss_ce: 0.016206, loss_kd: 551.465698
[00:27:48.630] iteration 29100 : loss : 110.994263, loss_ce: 0.011276, loss_kd: 552.616577
[00:27:54.242] iteration 29110 : loss : 107.919464, loss_ce: 0.014327, loss_kd: 537.252258
[00:27:59.833] iteration 29120 : loss : 111.194466, loss_ce: 0.014599, loss_kd: 553.602722
[00:28:05.441] iteration 29130 : loss : 105.862885, loss_ce: 0.017146, loss_kd: 526.870300
[00:28:11.042] iteration 29140 : loss : 109.442581, loss_ce: 0.012841, loss_kd: 544.814270
[00:28:16.641] iteration 29150 : loss : 126.708336, loss_ce: 0.013837, loss_kd: 631.128052
[00:28:22.241] iteration 29160 : loss : 158.977005, loss_ce: 0.027144, loss_kd: 792.477905
[00:28:27.858] iteration 29170 : loss : 79.234085, loss_ce: 0.014283, loss_kd: 393.797180
[00:28:44.043] iteration 29180 : loss : 79.960236, loss_ce: 0.012806, loss_kd: 397.381836
[00:28:49.593] iteration 29190 : loss : 97.855957, loss_ce: 0.009539, loss_kd: 486.893738
[00:28:55.136] iteration 29200 : loss : 116.912193, loss_ce: 0.016184, loss_kd: 582.206726
[00:29:00.701] iteration 29210 : loss : 111.384598, loss_ce: 0.018870, loss_kd: 554.572083
[00:29:06.256] iteration 29220 : loss : 106.427650, loss_ce: 0.018953, loss_kd: 529.771729
[00:29:11.820] iteration 29230 : loss : 124.006683, loss_ce: 0.012259, loss_kd: 617.681641
[00:29:17.385] iteration 29240 : loss : 119.831848, loss_ce: 0.010997, loss_kd: 596.742920
[00:29:22.954] iteration 29250 : loss : 83.967079, loss_ce: 0.009656, loss_kd: 417.425842
[00:29:28.524] iteration 29260 : loss : 154.843582, loss_ce: 0.026242, loss_kd: 771.843933
[00:29:34.102] iteration 29270 : loss : 133.306488, loss_ce: 0.010519, loss_kd: 664.153748
[00:29:39.673] iteration 29280 : loss : 183.079071, loss_ce: 0.030357, loss_kd: 912.999023
[00:29:45.262] iteration 29290 : loss : 123.858330, loss_ce: 0.021331, loss_kd: 616.924805
[00:29:50.832] iteration 29300 : loss : 97.500298, loss_ce: 0.011353, loss_kd: 485.131348
[00:29:56.421] iteration 29310 : loss : 123.690475, loss_ce: 0.014454, loss_kd: 616.065674
[00:30:02.000] iteration 29320 : loss : 106.212616, loss_ce: 0.011344, loss_kd: 528.649780
[00:30:07.592] iteration 29330 : loss : 110.140953, loss_ce: 0.016774, loss_kd: 548.280151
[00:30:13.173] iteration 29340 : loss : 91.013000, loss_ce: 0.014584, loss_kd: 452.671265
[00:30:18.775] iteration 29350 : loss : 106.978813, loss_ce: 0.017971, loss_kd: 532.492920
[00:30:24.368] iteration 29360 : loss : 118.337708, loss_ce: 0.025646, loss_kd: 589.344238
[00:30:29.970] iteration 29370 : loss : 88.965637, loss_ce: 0.015787, loss_kd: 442.449615
[00:30:35.562] iteration 29380 : loss : 94.159103, loss_ce: 0.013137, loss_kd: 468.402161
[00:30:41.169] iteration 29390 : loss : 102.200607, loss_ce: 0.015925, loss_kd: 508.632568
[00:30:46.767] iteration 29400 : loss : 111.305023, loss_ce: 0.014354, loss_kd: 554.175659
[00:30:52.371] iteration 29410 : loss : 98.338745, loss_ce: 0.011167, loss_kd: 489.342499
[00:30:57.964] iteration 29420 : loss : 102.158035, loss_ce: 0.012614, loss_kd: 508.446045
[00:31:03.565] iteration 29430 : loss : 102.250328, loss_ce: 0.020728, loss_kd: 508.831787
[00:31:09.155] iteration 29440 : loss : 105.265656, loss_ce: 0.008792, loss_kd: 523.974426
[00:31:14.760] iteration 29450 : loss : 76.737732, loss_ce: 0.017979, loss_kd: 381.286041
[00:31:20.365] iteration 29460 : loss : 83.957542, loss_ce: 0.012944, loss_kd: 417.421692
[00:31:25.967] iteration 29470 : loss : 114.339615, loss_ce: 0.010530, loss_kd: 569.311584
[00:31:31.567] iteration 29480 : loss : 112.599899, loss_ce: 0.023532, loss_kd: 560.588562
[00:31:37.173] iteration 29490 : loss : 88.359856, loss_ce: 0.019036, loss_kd: 439.357788
[00:31:42.763] iteration 29500 : loss : 110.522354, loss_ce: 0.022319, loss_kd: 550.222717
[00:31:48.368] iteration 29510 : loss : 105.991241, loss_ce: 0.011973, loss_kd: 527.533203
[00:31:53.964] iteration 29520 : loss : 91.353638, loss_ce: 0.018094, loss_kd: 454.405426
[00:31:59.566] iteration 29530 : loss : 96.234741, loss_ce: 0.010049, loss_kd: 478.824554
[00:32:05.161] iteration 29540 : loss : 91.630234, loss_ce: 0.015378, loss_kd: 455.774353
[00:32:10.767] iteration 29550 : loss : 114.072739, loss_ce: 0.007491, loss_kd: 567.964722
[00:32:16.357] iteration 29560 : loss : 129.718033, loss_ce: 0.018104, loss_kd: 646.199341
[00:32:21.960] iteration 29570 : loss : 89.248131, loss_ce: 0.013522, loss_kd: 443.884583
[00:32:27.563] iteration 29580 : loss : 156.736374, loss_ce: 0.013188, loss_kd: 781.292603
[00:32:33.167] iteration 29590 : loss : 105.065475, loss_ce: 0.022151, loss_kd: 522.925537
[00:32:38.756] iteration 29600 : loss : 82.107803, loss_ce: 0.015401, loss_kd: 408.168579
[00:32:44.359] iteration 29610 : loss : 106.806900, loss_ce: 0.017190, loss_kd: 531.660461
[00:32:49.947] iteration 29620 : loss : 88.894318, loss_ce: 0.013333, loss_kd: 442.105469
[00:32:55.547] iteration 29630 : loss : 99.443542, loss_ce: 0.024662, loss_kd: 494.841583
[00:33:01.145] iteration 29640 : loss : 108.789330, loss_ce: 0.015688, loss_kd: 541.617554
[00:33:06.751] iteration 29650 : loss : 97.233978, loss_ce: 0.014076, loss_kd: 483.801453
[00:33:12.349] iteration 29660 : loss : 104.040825, loss_ce: 0.013372, loss_kd: 517.804443
[00:33:17.951] iteration 29670 : loss : 81.245979, loss_ce: 0.009270, loss_kd: 403.888672
[00:33:23.551] iteration 29680 : loss : 122.415253, loss_ce: 0.013514, loss_kd: 609.707764
[00:33:29.157] iteration 29690 : loss : 117.521873, loss_ce: 0.010945, loss_kd: 585.266113
[00:33:34.748] iteration 29700 : loss : 99.341484, loss_ce: 0.020326, loss_kd: 494.279633
[00:33:40.362] iteration 29710 : loss : 115.739029, loss_ce: 0.014904, loss_kd: 576.288696
[00:33:45.951] iteration 29720 : loss : 94.142227, loss_ce: 0.006861, loss_kd: 468.305695
[00:33:51.551] iteration 29730 : loss : 79.793808, loss_ce: 0.016655, loss_kd: 396.608429
[00:33:57.150] iteration 29740 : loss : 129.974625, loss_ce: 0.016845, loss_kd: 647.499573
[00:34:02.755] iteration 29750 : loss : 131.471237, loss_ce: 0.008972, loss_kd: 655.003357
[00:34:08.355] iteration 29760 : loss : 131.677704, loss_ce: 0.010849, loss_kd: 656.056946
[00:34:13.972] iteration 29770 : loss : 125.840164, loss_ce: 0.012049, loss_kd: 626.847595
[00:34:19.571] iteration 29780 : loss : 111.669075, loss_ce: 0.015179, loss_kd: 556.014099
[00:34:25.181] iteration 29790 : loss : 82.414581, loss_ce: 0.019073, loss_kd: 409.698090
[00:34:30.781] iteration 29800 : loss : 87.941147, loss_ce: 0.016301, loss_kd: 437.324341
[00:34:36.389] iteration 29810 : loss : 113.432602, loss_ce: 0.012420, loss_kd: 564.807312
[00:34:41.995] iteration 29820 : loss : 96.573700, loss_ce: 0.020704, loss_kd: 480.485748
[00:34:47.597] iteration 29830 : loss : 81.228592, loss_ce: 0.015443, loss_kd: 403.796356
[00:34:53.195] iteration 29840 : loss : 114.313019, loss_ce: 0.012313, loss_kd: 569.211304
[00:34:58.797] iteration 29850 : loss : 88.736748, loss_ce: 0.009453, loss_kd: 441.283783
[00:35:04.394] iteration 29860 : loss : 90.711632, loss_ce: 0.012048, loss_kd: 451.156586
[00:35:09.998] iteration 29870 : loss : 102.285751, loss_ce: 0.014834, loss_kd: 509.075165
[00:35:15.588] iteration 29880 : loss : 119.458961, loss_ce: 0.018543, loss_kd: 594.879028
[00:35:21.187] iteration 29890 : loss : 92.583099, loss_ce: 0.016519, loss_kd: 460.515228
[00:35:26.789] iteration 29900 : loss : 104.349945, loss_ce: 0.014399, loss_kd: 519.366699
[00:35:32.397] iteration 29910 : loss : 121.813980, loss_ce: 0.018999, loss_kd: 606.718384
[00:35:37.994] iteration 29920 : loss : 122.814857, loss_ce: 0.013436, loss_kd: 611.723999
[00:35:43.602] iteration 29930 : loss : 84.811867, loss_ce: 0.018554, loss_kd: 421.714966
[00:35:49.195] iteration 29940 : loss : 107.998413, loss_ce: 0.013221, loss_kd: 537.613770
[00:35:54.803] iteration 29950 : loss : 99.753670, loss_ce: 0.018648, loss_kd: 496.389343
[00:36:00.391] iteration 29960 : loss : 92.520340, loss_ce: 0.010521, loss_kd: 460.212799
[00:36:05.991] iteration 29970 : loss : 114.621307, loss_ce: 0.009851, loss_kd: 570.779053
[00:36:11.595] iteration 29980 : loss : 81.983986, loss_ce: 0.014128, loss_kd: 407.564087
[00:36:17.216] iteration 29990 : loss : 81.442902, loss_ce: 0.013668, loss_kd: 404.801819
[00:36:22.814] iteration 30000 : loss : 123.286041, loss_ce: 0.019815, loss_kd: 614.032959
[00:36:28.429] iteration 30010 : loss : 140.444794, loss_ce: 0.010583, loss_kd: 699.816650
[00:36:34.031] iteration 30020 : loss : 89.132011, loss_ce: 0.020997, loss_kd: 443.275391
[00:36:39.648] iteration 30030 : loss : 96.791443, loss_ce: 0.009756, loss_kd: 481.600250
[00:36:45.239] iteration 30040 : loss : 101.965813, loss_ce: 0.016978, loss_kd: 507.465912
[00:36:50.858] iteration 30050 : loss : 78.370895, loss_ce: 0.014369, loss_kd: 389.466003
[00:36:56.469] iteration 30060 : loss : 115.579971, loss_ce: 0.023106, loss_kd: 575.513428
[00:37:02.084] iteration 30070 : loss : 95.803215, loss_ce: 0.012511, loss_kd: 476.626190
[00:37:07.688] iteration 30080 : loss : 107.412224, loss_ce: 0.010662, loss_kd: 534.710754
[00:37:13.287] iteration 30090 : loss : 96.298195, loss_ce: 0.016437, loss_kd: 479.101807
[00:37:18.887] iteration 30100 : loss : 134.216156, loss_ce: 0.015784, loss_kd: 668.707886
[00:37:24.495] iteration 30110 : loss : 99.354401, loss_ce: 0.024197, loss_kd: 494.348480
[00:37:30.091] iteration 30120 : loss : 81.827332, loss_ce: 0.016622, loss_kd: 406.742310
[00:37:35.703] iteration 30130 : loss : 103.883469, loss_ce: 0.020881, loss_kd: 517.028931
[00:37:41.303] iteration 30140 : loss : 124.943756, loss_ce: 0.012630, loss_kd: 622.343689
[00:37:46.928] iteration 30150 : loss : 99.944656, loss_ce: 0.016955, loss_kd: 497.342743
[00:37:52.531] iteration 30160 : loss : 93.839203, loss_ce: 0.015699, loss_kd: 466.767212
[00:37:58.141] iteration 30170 : loss : 102.093185, loss_ce: 0.020703, loss_kd: 508.057800
[00:38:03.742] iteration 30180 : loss : 91.363182, loss_ce: 0.013908, loss_kd: 454.384918
[00:38:09.342] iteration 30190 : loss : 115.120972, loss_ce: 0.015268, loss_kd: 573.252197
[00:38:14.945] iteration 30200 : loss : 101.840744, loss_ce: 0.013750, loss_kd: 506.843719
[00:38:20.557] iteration 30210 : loss : 105.466888, loss_ce: 0.026810, loss_kd: 524.939941
[00:38:25.369] Running TPGM constraint optimization after epoch 29
[00:43:18.458] iteration 30220 : loss : 103.477432, loss_ce: 0.021807, loss_kd: 515.026001
[00:43:23.988] iteration 30230 : loss : 96.479454, loss_ce: 0.014399, loss_kd: 480.034088
[00:43:29.512] iteration 30240 : loss : 109.213974, loss_ce: 0.013193, loss_kd: 543.669678
[00:43:35.048] iteration 30250 : loss : 107.592003, loss_ce: 0.024737, loss_kd: 535.548828
[00:43:40.574] iteration 30260 : loss : 119.410637, loss_ce: 0.012683, loss_kd: 594.731750
[00:43:46.115] iteration 30270 : loss : 127.376060, loss_ce: 0.022207, loss_kd: 634.487793
[00:43:51.646] iteration 30280 : loss : 100.626633, loss_ce: 0.016694, loss_kd: 500.734924
[00:43:57.189] iteration 30290 : loss : 89.934120, loss_ce: 0.017937, loss_kd: 447.325470
[00:44:02.728] iteration 30300 : loss : 113.036690, loss_ce: 0.016458, loss_kd: 562.810303
[00:44:08.279] iteration 30310 : loss : 84.085846, loss_ce: 0.014847, loss_kd: 418.002655
[00:44:13.822] iteration 30320 : loss : 116.397202, loss_ce: 0.020258, loss_kd: 579.597473
[00:44:19.376] iteration 30330 : loss : 81.654442, loss_ce: 0.027960, loss_kd: 405.899323
[00:44:24.929] iteration 30340 : loss : 98.187340, loss_ce: 0.013983, loss_kd: 488.586060
[00:44:30.488] iteration 30350 : loss : 109.040947, loss_ce: 0.018419, loss_kd: 542.858093
[00:44:36.039] iteration 30360 : loss : 120.614777, loss_ce: 0.017842, loss_kd: 600.683533
[00:44:41.599] iteration 30370 : loss : 106.662140, loss_ce: 0.019078, loss_kd: 530.952332
[00:44:47.160] iteration 30380 : loss : 109.183533, loss_ce: 0.028633, loss_kd: 543.544373
[00:44:52.725] iteration 30390 : loss : 111.327522, loss_ce: 0.015421, loss_kd: 554.293945
[00:44:58.279] iteration 30400 : loss : 115.841972, loss_ce: 0.016949, loss_kd: 576.811829
[00:45:03.855] iteration 30410 : loss : 131.036331, loss_ce: 0.017677, loss_kd: 652.828674
[00:45:09.414] iteration 30420 : loss : 78.685524, loss_ce: 0.024717, loss_kd: 391.022217
[00:45:14.985] iteration 30430 : loss : 114.666176, loss_ce: 0.014084, loss_kd: 570.998718
[00:45:20.548] iteration 30440 : loss : 89.108093, loss_ce: 0.015373, loss_kd: 443.144348
[00:45:26.129] iteration 30450 : loss : 109.810684, loss_ce: 0.013885, loss_kd: 546.679504
[00:45:31.699] iteration 30460 : loss : 97.993599, loss_ce: 0.022210, loss_kd: 487.576965
[00:45:37.284] iteration 30470 : loss : 102.998856, loss_ce: 0.009121, loss_kd: 512.651855
[00:45:42.858] iteration 30480 : loss : 110.734291, loss_ce: 0.013137, loss_kd: 551.279480
[00:45:48.447] iteration 30490 : loss : 80.767700, loss_ce: 0.015259, loss_kd: 401.458679
[00:45:54.022] iteration 30500 : loss : 96.346184, loss_ce: 0.012817, loss_kd: 479.360352
[00:45:59.612] iteration 30510 : loss : 71.565262, loss_ce: 0.021953, loss_kd: 355.437866
[00:46:05.184] iteration 30520 : loss : 79.902061, loss_ce: 0.008348, loss_kd: 397.163086
[00:46:10.785] iteration 30530 : loss : 108.174423, loss_ce: 0.024200, loss_kd: 538.485718
[00:46:16.367] iteration 30540 : loss : 111.911285, loss_ce: 0.009484, loss_kd: 557.147278
[00:46:21.961] iteration 30550 : loss : 85.847458, loss_ce: 0.013438, loss_kd: 426.901886
[00:46:27.541] iteration 30560 : loss : 115.852791, loss_ce: 0.017650, loss_kd: 576.881042
[00:46:33.129] iteration 30570 : loss : 139.836868, loss_ce: 0.020400, loss_kd: 696.798401
[00:46:38.708] iteration 30580 : loss : 98.209671, loss_ce: 0.019409, loss_kd: 488.661774
[00:46:44.300] iteration 30590 : loss : 102.459763, loss_ce: 0.012170, loss_kd: 509.933136
[00:46:49.890] iteration 30600 : loss : 105.940475, loss_ce: 0.018464, loss_kd: 527.308411
[00:46:55.490] iteration 30610 : loss : 97.205940, loss_ce: 0.015379, loss_kd: 483.640564
[00:47:01.078] iteration 30620 : loss : 85.473625, loss_ce: 0.013900, loss_kd: 424.999176
[00:47:06.686] iteration 30630 : loss : 124.413742, loss_ce: 0.011654, loss_kd: 619.666016
[00:47:12.275] iteration 30640 : loss : 91.696754, loss_ce: 0.011423, loss_kd: 456.118164
[00:47:17.875] iteration 30650 : loss : 103.990364, loss_ce: 0.018480, loss_kd: 517.574463
[00:47:23.470] iteration 30660 : loss : 84.693687, loss_ce: 0.013036, loss_kd: 421.100372
[00:47:29.075] iteration 30670 : loss : 84.454758, loss_ce: 0.024176, loss_kd: 419.899658
[00:47:34.667] iteration 30680 : loss : 84.919189, loss_ce: 0.014841, loss_kd: 422.202393
[00:47:40.271] iteration 30690 : loss : 88.448135, loss_ce: 0.020148, loss_kd: 439.843994
[00:47:45.853] iteration 30700 : loss : 77.507835, loss_ce: 0.023843, loss_kd: 385.142639
[00:47:51.462] iteration 30710 : loss : 105.859016, loss_ce: 0.029377, loss_kd: 526.881592
[00:47:57.061] iteration 30720 : loss : 84.729622, loss_ce: 0.013658, loss_kd: 421.271088
[00:48:02.666] iteration 30730 : loss : 104.027031, loss_ce: 0.020954, loss_kd: 517.781616
[00:48:08.264] iteration 30740 : loss : 103.315689, loss_ce: 0.014813, loss_kd: 514.202576
[00:48:13.871] iteration 30750 : loss : 96.120583, loss_ce: 0.008813, loss_kd: 478.261047
[00:48:19.472] iteration 30760 : loss : 94.611115, loss_ce: 0.015874, loss_kd: 470.675415
[00:48:25.071] iteration 30770 : loss : 101.311821, loss_ce: 0.009774, loss_kd: 504.162476
[00:48:30.670] iteration 30780 : loss : 118.688499, loss_ce: 0.018708, loss_kd: 591.046631
[00:48:36.279] iteration 30790 : loss : 88.691078, loss_ce: 0.014330, loss_kd: 441.050446
[00:48:41.871] iteration 30800 : loss : 120.005447, loss_ce: 0.028314, loss_kd: 597.643311
[00:48:47.476] iteration 30810 : loss : 115.047554, loss_ce: 0.023411, loss_kd: 572.878723
[00:48:53.077] iteration 30820 : loss : 149.792221, loss_ce: 0.016400, loss_kd: 746.572876
[00:48:58.686] iteration 30830 : loss : 106.792000, loss_ce: 0.008205, loss_kd: 531.587952
[00:49:04.284] iteration 30840 : loss : 120.725197, loss_ce: 0.020718, loss_kd: 601.280212
[00:49:09.888] iteration 30850 : loss : 96.745186, loss_ce: 0.024651, loss_kd: 481.363556
[00:49:15.486] iteration 30860 : loss : 92.626266, loss_ce: 0.010754, loss_kd: 460.686462
[00:49:21.086] iteration 30870 : loss : 89.106926, loss_ce: 0.011173, loss_kd: 443.197144
[00:49:26.685] iteration 30880 : loss : 135.394638, loss_ce: 0.015384, loss_kd: 674.609741
[00:49:32.289] iteration 30890 : loss : 93.517517, loss_ce: 0.014012, loss_kd: 465.212982
[00:49:37.877] iteration 30900 : loss : 117.047630, loss_ce: 0.011532, loss_kd: 582.882263
[00:49:43.484] iteration 30910 : loss : 93.731056, loss_ce: 0.020452, loss_kd: 466.269989
[00:49:49.082] iteration 30920 : loss : 121.131477, loss_ce: 0.018835, loss_kd: 603.269653
[00:49:54.699] iteration 30930 : loss : 96.734085, loss_ce: 0.017309, loss_kd: 481.315186
[00:50:00.315] iteration 30940 : loss : 132.629654, loss_ce: 0.019207, loss_kd: 660.775757
[00:50:05.927] iteration 30950 : loss : 125.282608, loss_ce: 0.021258, loss_kd: 623.987000
[00:50:11.522] iteration 30960 : loss : 83.571983, loss_ce: 0.022036, loss_kd: 415.517761
[00:50:17.139] iteration 30970 : loss : 93.897026, loss_ce: 0.018405, loss_kd: 467.093414
[00:50:22.735] iteration 30980 : loss : 85.411407, loss_ce: 0.012223, loss_kd: 424.725616
[00:50:28.359] iteration 30990 : loss : 128.514496, loss_ce: 0.015983, loss_kd: 640.215149
[00:50:33.965] iteration 31000 : loss : 84.209435, loss_ce: 0.014033, loss_kd: 418.692932
[00:50:39.584] iteration 31010 : loss : 96.875542, loss_ce: 0.011451, loss_kd: 481.994598
[00:50:45.186] iteration 31020 : loss : 102.997803, loss_ce: 0.013736, loss_kd: 512.594482
[00:50:50.800] iteration 31030 : loss : 105.199814, loss_ce: 0.013426, loss_kd: 523.591858
[00:50:56.401] iteration 31040 : loss : 91.924942, loss_ce: 0.018089, loss_kd: 457.258575
[00:51:02.028] iteration 31050 : loss : 79.083626, loss_ce: 0.009288, loss_kd: 393.044312
[00:51:07.637] iteration 31060 : loss : 107.793159, loss_ce: 0.017533, loss_kd: 536.570740
[00:51:13.247] iteration 31070 : loss : 104.701660, loss_ce: 0.014747, loss_kd: 521.138794
[00:51:18.841] iteration 31080 : loss : 109.793243, loss_ce: 0.022154, loss_kd: 546.586914
[00:51:24.468] iteration 31090 : loss : 83.969910, loss_ce: 0.012611, loss_kd: 417.469910
[00:51:30.079] iteration 31100 : loss : 98.517311, loss_ce: 0.026833, loss_kd: 490.217407
[00:51:35.708] iteration 31110 : loss : 86.488213, loss_ce: 0.016041, loss_kd: 430.100220
[00:51:41.318] iteration 31120 : loss : 103.754425, loss_ce: 0.014322, loss_kd: 516.391602
[00:51:46.929] iteration 31130 : loss : 109.726158, loss_ce: 0.022565, loss_kd: 546.251953
[00:51:52.534] iteration 31140 : loss : 106.534195, loss_ce: 0.012215, loss_kd: 530.298157
[00:51:58.154] iteration 31150 : loss : 95.898659, loss_ce: 0.012579, loss_kd: 477.147827
[00:52:03.771] iteration 31160 : loss : 91.815094, loss_ce: 0.013874, loss_kd: 456.672424
[00:52:09.386] iteration 31170 : loss : 87.712082, loss_ce: 0.030957, loss_kd: 436.183655
[00:52:14.995] iteration 31180 : loss : 122.661850, loss_ce: 0.011193, loss_kd: 610.969055
[00:52:20.619] iteration 31190 : loss : 130.589554, loss_ce: 0.017105, loss_kd: 650.579590
[00:52:26.227] iteration 31200 : loss : 91.186722, loss_ce: 0.012677, loss_kd: 453.575439
[00:52:31.846] iteration 31210 : loss : 127.336159, loss_ce: 0.013076, loss_kd: 634.311096
[00:52:37.463] iteration 31220 : loss : 140.602402, loss_ce: 0.021297, loss_kd: 700.643860
[00:52:43.089] iteration 31230 : loss : 108.901001, loss_ce: 0.019856, loss_kd: 542.159668
[00:52:48.695] iteration 31240 : loss : 96.997124, loss_ce: 0.015099, loss_kd: 482.609528
[00:52:54.319] iteration 31250 : loss : 85.825813, loss_ce: 0.011575, loss_kd: 426.799744
[00:52:59.633] iteration 31260 : loss : 81.549850, loss_ce: 0.019861, loss_kd: 405.350037
[00:53:00.389] save model to ./debug_fixed_tpgm\continual_surgical_tpgm_stage1_epoch_29.pth
[00:53:00.389] Applying final TPGM projection
[00:53:00.571] save final model to ./debug_fixed_tpgm\continual_surgical_tpgm_stage1_final.pth
