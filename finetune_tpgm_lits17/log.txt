[17:11:35.040] Namespace(root_path='./datasets/lits17/train_npz', dataset='lits17', list_dir='./lists/lits17', num_classes=3, model_num_classes=9, output_dir='./finetune_tpgm_lits17', max_iterations=10000, max_epochs=20, batch_size=16, n_gpu=1, deterministic=1, base_lr=0.0001, img_size=224, seed=1234, cfg='configs/finetune.yaml', pretrained_path='./\\finetune_tpgm_kits23_debug/finetuned_final.pth', data_fraction=0.2, freeze_layers=0, opts=None, zip=False, cache_mode='part', resume=None, accumulation_steps=None, use_checkpoint=False, amp_opt_level='O1', tag=None, eval=False, throughput=False, tpgm_norm_mode='l2', tpgm_lr=0.01, tpgm_iters=100, tpgm_exclude=[], tpgm_frequency=2, tpgm_start_epoch=10, disable_tpgm=False, gpu_id=1)
[17:11:35.046] --- Training on dataset: LITS17 ---
[17:11:35.046] Using 2968/14843 samples for finetuning
[17:11:35.046] Using 50/14843 samples for TPGM
[17:11:35.047] TPGM enabled: True
[17:12:38.722] Namespace(root_path='./datasets/lits17/train_npz', dataset='lits17', list_dir='./lists/lits17', num_classes=3, model_num_classes=9, output_dir='./finetune_tpgm_lits17', max_iterations=10000, max_epochs=20, batch_size=32, n_gpu=1, deterministic=1, base_lr=0.0001, img_size=224, seed=1234, cfg='configs/finetune.yaml', pretrained_path='./\\finetune_tpgm_kits23_debug/finetuned_final.pth', data_fraction=0.7, freeze_layers=0, opts=None, zip=False, cache_mode='part', resume=None, accumulation_steps=None, use_checkpoint=False, amp_opt_level='O1', tag=None, eval=False, throughput=False, tpgm_norm_mode='l2', tpgm_lr=0.01, tpgm_iters=100, tpgm_exclude=[], tpgm_frequency=2, tpgm_start_epoch=10, disable_tpgm=False, gpu_id=1)
[17:12:38.726] --- Training on dataset: LITS17 ---
[17:12:38.726] Using 10390/14843 samples for finetuning
[17:12:38.726] Using 50/14843 samples for TPGM
[17:12:38.726] TPGM enabled: True
[17:12:48.446] 325 iterations per epoch
[17:13:03.011] Epoch 0, Iter 10: loss=0.2018, ce=0.0750, dice=0.2864, grad_norm=1.203550
[17:13:07.209] Epoch 0, Iter 20: loss=0.3107, ce=0.0167, dice=0.5068, grad_norm=0.522883
[17:13:11.470] Epoch 0, Iter 30: loss=0.2479, ce=0.0123, dice=0.4049, grad_norm=0.761192
[17:13:15.668] Epoch 0, Iter 40: loss=0.0730, ce=0.0193, dice=0.1087, grad_norm=0.556455
[17:13:19.883] Epoch 0, Iter 50: loss=0.2162, ce=0.0078, dice=0.3551, grad_norm=0.148555
[17:13:24.090] Epoch 0, Iter 60: loss=0.1071, ce=0.0119, dice=0.1706, grad_norm=2.891429
[17:13:28.303] Epoch 0, Iter 70: loss=0.2129, ce=0.0081, dice=0.3494, grad_norm=0.150522
[17:13:32.524] Epoch 0, Iter 80: loss=0.1068, ce=0.0150, dice=0.1679, grad_norm=1.231871
[17:13:36.754] Epoch 0, Iter 90: loss=0.0984, ce=0.0136, dice=0.1549, grad_norm=0.730307
[17:13:40.962] Epoch 0, Iter 100: loss=0.0970, ce=0.0105, dice=0.1546, grad_norm=5.310227
[17:13:45.185] Epoch 0, Iter 110: loss=0.0846, ce=0.0141, dice=0.1316, grad_norm=0.455572
[17:13:49.404] Epoch 0, Iter 120: loss=0.0664, ce=0.0112, dice=0.1032, grad_norm=0.279787
[17:13:53.623] Epoch 0, Iter 130: loss=0.0317, ce=0.0024, dice=0.0512, grad_norm=0.261454
[17:13:57.839] Epoch 0, Iter 140: loss=0.0574, ce=0.0129, dice=0.0870, grad_norm=0.565903
[17:14:02.070] Epoch 0, Iter 150: loss=0.0478, ce=0.0108, dice=0.0724, grad_norm=0.219221
[17:14:06.287] Epoch 0, Iter 160: loss=0.0369, ce=0.0073, dice=0.0566, grad_norm=0.262951
[17:14:10.524] Epoch 0, Iter 170: loss=0.0397, ce=0.0093, dice=0.0600, grad_norm=0.202801
[17:14:14.754] Epoch 0, Iter 180: loss=0.0740, ce=0.0040, dice=0.1206, grad_norm=3.331516
[17:14:18.997] Epoch 0, Iter 190: loss=0.0637, ce=0.0135, dice=0.0971, grad_norm=1.072197
[17:14:23.219] Epoch 0, Iter 200: loss=0.0954, ce=0.0085, dice=0.1534, grad_norm=1.297077
[17:14:27.454] Epoch 0, Iter 210: loss=0.0500, ce=0.0092, dice=0.0772, grad_norm=0.550221
[17:14:31.680] Epoch 0, Iter 220: loss=0.0348, ce=0.0056, dice=0.0542, grad_norm=0.962247
[17:14:35.913] Epoch 0, Iter 230: loss=0.0448, ce=0.0073, dice=0.0697, grad_norm=0.285486
[17:14:40.138] Epoch 0, Iter 240: loss=0.0377, ce=0.0069, dice=0.0582, grad_norm=0.664666
[17:14:44.365] Epoch 0, Iter 250: loss=0.2157, ce=0.0085, dice=0.3539, grad_norm=0.107417
[17:14:48.587] Epoch 0, Iter 260: loss=0.0473, ce=0.0063, dice=0.0747, grad_norm=0.358450
[17:14:52.827] Epoch 0, Iter 270: loss=0.0236, ce=0.0043, dice=0.0365, grad_norm=0.134584
[17:14:57.048] Epoch 0, Iter 280: loss=0.0405, ce=0.0099, dice=0.0610, grad_norm=0.146132
[17:15:01.289] Epoch 0, Iter 290: loss=0.0246, ce=0.0052, dice=0.0375, grad_norm=0.144361
[17:15:05.515] Epoch 0, Iter 300: loss=0.1479, ce=0.0072, dice=0.2417, grad_norm=0.913145
[17:15:09.754] Epoch 0, Iter 310: loss=0.0462, ce=0.0037, dice=0.0746, grad_norm=0.295742
[17:15:13.978] Epoch 0, Iter 320: loss=0.1505, ce=0.0077, dice=0.2456, grad_norm=4.925289
[17:15:16.578] Epoch 0: Avg Loss=0.1010, CE=0.0135, Dice=0.1593
[17:15:28.612] Epoch 1, Iter 330: loss=0.0342, ce=0.0055, dice=0.0534, grad_norm=0.404287
[17:15:32.829] Epoch 1, Iter 340: loss=0.0322, ce=0.0071, dice=0.0490, grad_norm=0.267704
[17:15:37.056] Epoch 1, Iter 350: loss=0.0352, ce=0.0028, dice=0.0568, grad_norm=0.425403
[17:15:41.266] Epoch 1, Iter 360: loss=0.0532, ce=0.0071, dice=0.0839, grad_norm=0.795970
[17:15:45.515] Epoch 1, Iter 370: loss=0.0457, ce=0.0052, dice=0.0726, grad_norm=1.309570
[17:15:49.739] Epoch 1, Iter 380: loss=0.0798, ce=0.0040, dice=0.1303, grad_norm=0.776618
[17:15:54.003] Epoch 1, Iter 390: loss=0.0282, ce=0.0084, dice=0.0413, grad_norm=0.071337
[17:15:58.246] Epoch 1, Iter 400: loss=0.0348, ce=0.0114, dice=0.0504, grad_norm=0.204160
[17:16:02.561] Epoch 1, Iter 410: loss=0.0372, ce=0.0056, dice=0.0582, grad_norm=0.196801
[17:16:06.784] Epoch 1, Iter 420: loss=0.0297, ce=0.0062, dice=0.0453, grad_norm=0.126155
[17:16:11.001] Epoch 1, Iter 430: loss=0.0354, ce=0.0062, dice=0.0549, grad_norm=0.501155
[17:16:15.224] Epoch 1, Iter 440: loss=0.0458, ce=0.0097, dice=0.0700, grad_norm=0.375660
[17:16:19.473] Epoch 1, Iter 450: loss=0.0275, ce=0.0072, dice=0.0409, grad_norm=0.180332
[17:16:23.692] Epoch 1, Iter 460: loss=0.0544, ce=0.0056, dice=0.0869, grad_norm=0.752133
[17:16:27.923] Epoch 1, Iter 470: loss=0.0518, ce=0.0048, dice=0.0831, grad_norm=0.258451
[17:16:32.130] Epoch 1, Iter 480: loss=0.0398, ce=0.0056, dice=0.0626, grad_norm=0.328454
[17:16:36.357] Epoch 1, Iter 490: loss=0.0442, ce=0.0050, dice=0.0703, grad_norm=0.251192
[17:16:40.581] Epoch 1, Iter 500: loss=0.0316, ce=0.0082, dice=0.0473, grad_norm=0.515587
[17:16:44.808] Epoch 1, Iter 510: loss=0.0460, ce=0.0035, dice=0.0743, grad_norm=0.634486
[17:16:49.026] Epoch 1, Iter 520: loss=0.0405, ce=0.0068, dice=0.0629, grad_norm=0.759284
[17:16:53.257] Epoch 1, Iter 530: loss=0.0396, ce=0.0079, dice=0.0607, grad_norm=0.429283
[17:16:57.477] Epoch 1, Iter 540: loss=0.1487, ce=0.0052, dice=0.2444, grad_norm=0.845467
[17:17:01.714] Epoch 1, Iter 550: loss=0.0280, ce=0.0050, dice=0.0434, grad_norm=0.626515
[17:17:05.929] Epoch 1, Iter 560: loss=0.0398, ce=0.0061, dice=0.0623, grad_norm=0.371216
[17:17:10.166] Epoch 1, Iter 570: loss=0.0270, ce=0.0064, dice=0.0408, grad_norm=0.595208
[17:17:14.390] Epoch 1, Iter 580: loss=0.0418, ce=0.0157, dice=0.0592, grad_norm=0.206139
[17:17:18.627] Epoch 1, Iter 590: loss=0.0792, ce=0.0052, dice=0.1285, grad_norm=0.752118
[17:17:22.858] Epoch 1, Iter 600: loss=0.1360, ce=0.0080, dice=0.2213, grad_norm=1.678454
[17:17:27.093] Epoch 1, Iter 610: loss=0.0323, ce=0.0060, dice=0.0498, grad_norm=0.180843
[17:17:31.320] Epoch 1, Iter 620: loss=0.0312, ce=0.0061, dice=0.0479, grad_norm=0.181980
[17:17:35.557] Epoch 1, Iter 630: loss=0.0326, ce=0.0071, dice=0.0496, grad_norm=0.156728
[17:17:39.783] Epoch 1, Iter 640: loss=0.0627, ce=0.0050, dice=0.1011, grad_norm=0.532514
[17:17:43.881] Epoch 1, Iter 650: loss=0.0562, ce=0.0066, dice=0.0893, grad_norm=0.278865
[17:17:44.531] Epoch 1: Avg Loss=0.0653, CE=0.0060, Dice=0.1049
[17:17:59.096] Epoch 2, Iter 660: loss=0.0288, ce=0.0062, dice=0.0438, grad_norm=0.162429
[17:18:03.321] Epoch 2, Iter 670: loss=0.0282, ce=0.0043, dice=0.0441, grad_norm=0.229042
[17:18:07.531] Epoch 2, Iter 680: loss=0.0798, ce=0.0058, dice=0.1291, grad_norm=0.541552
[17:18:11.762] Epoch 2, Iter 690: loss=0.0384, ce=0.0098, dice=0.0576, grad_norm=0.197847
[17:18:15.973] Epoch 2, Iter 700: loss=0.0432, ce=0.0035, dice=0.0696, grad_norm=0.660612
[17:18:20.207] Epoch 2, Iter 710: loss=0.0284, ce=0.0072, dice=0.0426, grad_norm=0.090523
[17:18:24.444] Epoch 2, Iter 720: loss=0.0421, ce=0.0063, dice=0.0659, grad_norm=0.191812
[17:18:28.673] Epoch 2, Iter 730: loss=0.2175, ce=0.0109, dice=0.3552, grad_norm=0.045937
[17:18:32.904] Epoch 2, Iter 740: loss=0.0603, ce=0.0040, dice=0.0978, grad_norm=0.171324
[17:18:37.137] Epoch 2, Iter 750: loss=0.0125, ce=0.0029, dice=0.0189, grad_norm=0.056656
[17:18:41.365] Epoch 2, Iter 760: loss=0.0262, ce=0.0062, dice=0.0395, grad_norm=0.113616
[17:18:45.589] Epoch 2, Iter 770: loss=0.0536, ce=0.0061, dice=0.0853, grad_norm=0.319403
[17:18:49.808] Epoch 2, Iter 780: loss=0.0208, ce=0.0052, dice=0.0312, grad_norm=0.120589
[17:18:54.043] Epoch 2, Iter 790: loss=0.0268, ce=0.0033, dice=0.0424, grad_norm=0.204257
[17:18:58.266] Epoch 2, Iter 800: loss=0.0279, ce=0.0026, dice=0.0448, grad_norm=0.225236
[17:19:02.503] Epoch 2, Iter 810: loss=0.0343, ce=0.0129, dice=0.0486, grad_norm=0.087440
[17:19:06.719] Epoch 2, Iter 820: loss=0.0405, ce=0.0082, dice=0.0621, grad_norm=0.341714
[17:19:10.949] Epoch 2, Iter 830: loss=0.0267, ce=0.0032, dice=0.0423, grad_norm=0.167224
[17:19:15.177] Epoch 2, Iter 840: loss=0.0258, ce=0.0033, dice=0.0407, grad_norm=0.372659
[17:19:19.409] Epoch 2, Iter 850: loss=0.0482, ce=0.0033, dice=0.0781, grad_norm=0.364930
[17:19:23.639] Epoch 2, Iter 860: loss=0.0294, ce=0.0078, dice=0.0438, grad_norm=0.350367
[17:19:27.874] Epoch 2, Iter 870: loss=0.1196, ce=0.0046, dice=0.1963, grad_norm=1.301299
[17:19:32.105] Epoch 2, Iter 880: loss=0.0374, ce=0.0054, dice=0.0587, grad_norm=0.475724
[17:19:36.340] Epoch 2, Iter 890: loss=0.0429, ce=0.0050, dice=0.0682, grad_norm=0.353195
[17:19:40.569] Epoch 2, Iter 900: loss=0.0508, ce=0.0062, dice=0.0806, grad_norm=0.340298
[17:19:44.805] Epoch 2, Iter 910: loss=0.0388, ce=0.0042, dice=0.0618, grad_norm=0.934929
[17:19:49.038] Epoch 2, Iter 920: loss=0.0445, ce=0.0045, dice=0.0712, grad_norm=0.203630
[17:19:53.273] Epoch 2, Iter 930: loss=0.0437, ce=0.0057, dice=0.0691, grad_norm=0.338836
[17:19:57.506] Epoch 2, Iter 940: loss=0.0366, ce=0.0056, dice=0.0572, grad_norm=0.526640
[17:20:01.742] Epoch 2, Iter 950: loss=0.0393, ce=0.0024, dice=0.0639, grad_norm=0.229391
[17:20:05.976] Epoch 2, Iter 960: loss=0.0312, ce=0.0065, dice=0.0477, grad_norm=0.290118
[17:20:10.213] Epoch 2, Iter 970: loss=0.0249, ce=0.0051, dice=0.0382, grad_norm=0.220456
[17:20:12.824] Epoch 2: Avg Loss=0.0562, CE=0.0055, Dice=0.0901
[17:20:24.720] Epoch 3, Iter 980: loss=0.0292, ce=0.0048, dice=0.0454, grad_norm=0.235330
[17:20:28.945] Epoch 3, Iter 990: loss=0.0317, ce=0.0055, dice=0.0491, grad_norm=0.331457
[17:20:33.162] Epoch 3, Iter 1000: loss=0.1205, ce=0.0034, dice=0.1985, grad_norm=1.729209
[17:20:37.403] Epoch 3, Iter 1010: loss=0.1133, ce=0.0027, dice=0.1871, grad_norm=1.166886
[17:20:41.625] Epoch 3, Iter 1020: loss=0.0255, ce=0.0060, dice=0.0385, grad_norm=0.118104
[17:20:45.877] Epoch 3, Iter 1030: loss=0.0454, ce=0.0075, dice=0.0706, grad_norm=0.246500
[17:20:50.099] Epoch 3, Iter 1040: loss=0.0529, ce=0.0035, dice=0.0858, grad_norm=1.346614
[17:20:54.335] Epoch 3, Iter 1050: loss=0.0324, ce=0.0038, dice=0.0514, grad_norm=0.597242
[17:20:58.552] Epoch 3, Iter 1060: loss=0.0358, ce=0.0030, dice=0.0578, grad_norm=0.141066
[17:21:02.785] Epoch 3, Iter 1070: loss=0.0334, ce=0.0057, dice=0.0518, grad_norm=0.284000
[17:21:07.014] Epoch 3, Iter 1080: loss=0.0386, ce=0.0034, dice=0.0621, grad_norm=0.177040
[17:21:11.251] Epoch 3, Iter 1090: loss=0.0308, ce=0.0051, dice=0.0479, grad_norm=0.236611
[17:21:15.473] Epoch 3, Iter 1100: loss=0.0467, ce=0.0045, dice=0.0748, grad_norm=0.435932
[17:21:19.705] Epoch 3, Iter 1110: loss=0.0302, ce=0.0033, dice=0.0481, grad_norm=0.231882
[17:21:23.937] Epoch 3, Iter 1120: loss=0.0196, ce=0.0031, dice=0.0306, grad_norm=0.112010
[17:21:28.171] Epoch 3, Iter 1130: loss=0.0217, ce=0.0039, dice=0.0336, grad_norm=0.137680
[17:21:32.405] Epoch 3, Iter 1140: loss=0.0220, ce=0.0061, dice=0.0326, grad_norm=0.095409
[17:21:36.653] Epoch 3, Iter 1150: loss=0.0372, ce=0.0061, dice=0.0579, grad_norm=0.327737
[17:21:40.878] Epoch 3, Iter 1160: loss=0.0204, ce=0.0074, dice=0.0290, grad_norm=0.141155
[17:21:45.125] Epoch 3, Iter 1170: loss=0.0484, ce=0.0076, dice=0.0756, grad_norm=0.223621
[17:21:49.360] Epoch 3, Iter 1180: loss=0.0283, ce=0.0068, dice=0.0426, grad_norm=0.198727
[17:21:53.610] Epoch 3, Iter 1190: loss=0.0441, ce=0.0071, dice=0.0687, grad_norm=0.295769
[17:21:57.847] Epoch 3, Iter 1200: loss=0.0397, ce=0.0050, dice=0.0628, grad_norm=0.453813
[17:22:02.087] Epoch 3, Iter 1210: loss=0.0663, ce=0.0036, dice=0.1080, grad_norm=0.987526
[17:22:06.322] Epoch 3, Iter 1220: loss=0.0304, ce=0.0040, dice=0.0479, grad_norm=0.152603
[17:22:10.560] Epoch 3, Iter 1230: loss=0.0298, ce=0.0042, dice=0.0469, grad_norm=0.136877
[17:22:14.793] Epoch 3, Iter 1240: loss=0.0262, ce=0.0084, dice=0.0380, grad_norm=0.320491
[17:22:19.039] Epoch 3, Iter 1250: loss=0.0204, ce=0.0025, dice=0.0323, grad_norm=0.112246
[17:22:23.273] Epoch 3, Iter 1260: loss=0.0213, ce=0.0050, dice=0.0323, grad_norm=0.113738
[17:22:27.514] Epoch 3, Iter 1270: loss=0.0214, ce=0.0058, dice=0.0318, grad_norm=0.091175
[17:22:31.745] Epoch 3, Iter 1280: loss=0.0501, ce=0.0080, dice=0.0781, grad_norm=0.281250
[17:22:35.999] Epoch 3, Iter 1290: loss=0.0668, ce=0.0099, dice=0.1047, grad_norm=1.001966
[17:22:40.085] Epoch 3, Iter 1300: loss=0.2092, ce=0.0067, dice=0.3442, grad_norm=0.186676
[17:22:40.687] Epoch 3: Avg Loss=0.0532, CE=0.0050, Dice=0.0854
[17:22:54.780] Epoch 4, Iter 1310: loss=0.0539, ce=0.0043, dice=0.0870, grad_norm=0.242770
[17:22:59.000] Epoch 4, Iter 1320: loss=0.0566, ce=0.0039, dice=0.0918, grad_norm=0.437892
[17:23:03.241] Epoch 4, Iter 1330: loss=0.0256, ce=0.0075, dice=0.0376, grad_norm=0.112926
[17:23:07.472] Epoch 4, Iter 1340: loss=0.1505, ce=0.0020, dice=0.2495, grad_norm=3.898930
[17:23:11.719] Epoch 4, Iter 1350: loss=0.0686, ce=0.0044, dice=0.1114, grad_norm=0.294754
[17:23:15.945] Epoch 4, Iter 1360: loss=0.0533, ce=0.0047, dice=0.0857, grad_norm=0.477419
[17:23:20.184] Epoch 4, Iter 1370: loss=0.0211, ce=0.0079, dice=0.0298, grad_norm=0.086245
[17:23:24.418] Epoch 4, Iter 1380: loss=0.0541, ce=0.0048, dice=0.0870, grad_norm=0.360771
[17:23:28.648] Epoch 4, Iter 1390: loss=0.0387, ce=0.0043, dice=0.0616, grad_norm=0.113690
[17:23:32.884] Epoch 4, Iter 1400: loss=0.2131, ce=0.0074, dice=0.3503, grad_norm=0.071588
[17:23:37.148] Epoch 4, Iter 1410: loss=0.0257, ce=0.0018, dice=0.0417, grad_norm=0.262331
[17:23:41.387] Epoch 4, Iter 1420: loss=0.0260, ce=0.0049, dice=0.0400, grad_norm=0.117752
[17:23:45.633] Epoch 4, Iter 1430: loss=0.0274, ce=0.0035, dice=0.0433, grad_norm=0.172790
[17:23:49.851] Epoch 4, Iter 1440: loss=0.0769, ce=0.0059, dice=0.1241, grad_norm=0.489973
[17:23:54.090] Epoch 4, Iter 1450: loss=0.0255, ce=0.0061, dice=0.0385, grad_norm=0.199809
[17:23:58.321] Epoch 4, Iter 1460: loss=0.0167, ce=0.0056, dice=0.0240, grad_norm=0.126511
[17:24:02.554] Epoch 4, Iter 1470: loss=0.0318, ce=0.0036, dice=0.0506, grad_norm=0.271114
[17:24:06.785] Epoch 4, Iter 1480: loss=0.0349, ce=0.0045, dice=0.0553, grad_norm=0.177232
[17:24:11.023] Epoch 4, Iter 1490: loss=0.0183, ce=0.0065, dice=0.0261, grad_norm=0.114399
[17:24:15.250] Epoch 4, Iter 1500: loss=0.0464, ce=0.0059, dice=0.0733, grad_norm=0.334424
[17:24:19.486] Epoch 4, Iter 1510: loss=0.0688, ce=0.0055, dice=0.1110, grad_norm=5.044186
[17:24:23.714] Epoch 4, Iter 1520: loss=0.0165, ce=0.0042, dice=0.0247, grad_norm=0.110135
[17:24:27.962] Epoch 4, Iter 1530: loss=0.0570, ce=0.0062, dice=0.0908, grad_norm=0.334889
[17:24:32.197] Epoch 4, Iter 1540: loss=0.0210, ce=0.0075, dice=0.0301, grad_norm=0.088650
[17:24:36.445] Epoch 4, Iter 1550: loss=0.0610, ce=0.0064, dice=0.0974, grad_norm=0.437603
[17:24:40.678] Epoch 4, Iter 1560: loss=0.0222, ce=0.0019, dice=0.0358, grad_norm=0.140294
[17:24:44.924] Epoch 4, Iter 1570: loss=0.0718, ce=0.0029, dice=0.1178, grad_norm=0.566358
[17:24:49.167] Epoch 4, Iter 1580: loss=0.0484, ce=0.0034, dice=0.0784, grad_norm=0.292715
[17:24:53.408] Epoch 4, Iter 1590: loss=0.0637, ce=0.0072, dice=0.1013, grad_norm=0.398167
[17:24:57.645] Epoch 4, Iter 1600: loss=0.0678, ce=0.0048, dice=0.1098, grad_norm=2.777505
[17:25:01.895] Epoch 4, Iter 1610: loss=0.0376, ce=0.0063, dice=0.0585, grad_norm=0.128340
[17:25:06.218] Epoch 4, Iter 1620: loss=0.0209, ce=0.0049, dice=0.0315, grad_norm=0.050052
[17:25:08.834] Epoch 4: Avg Loss=0.0499, CE=0.0047, Dice=0.0800
[17:25:21.038] Epoch 5, Iter 1630: loss=0.0253, ce=0.0049, dice=0.0389, grad_norm=0.062008
[17:25:25.260] Epoch 5, Iter 1640: loss=0.0218, ce=0.0039, dice=0.0337, grad_norm=0.087241
[17:25:29.489] Epoch 5, Iter 1650: loss=0.0271, ce=0.0053, dice=0.0416, grad_norm=0.263039
[17:25:33.711] Epoch 5, Iter 1660: loss=0.0381, ce=0.0077, dice=0.0584, grad_norm=0.299804
[17:25:37.992] Epoch 5, Iter 1670: loss=0.0213, ce=0.0052, dice=0.0320, grad_norm=0.077783
[17:25:42.220] Epoch 5, Iter 1680: loss=0.0363, ce=0.0084, dice=0.0548, grad_norm=0.226175
[17:25:46.463] Epoch 5, Iter 1690: loss=0.0278, ce=0.0079, dice=0.0411, grad_norm=0.175947
[17:25:50.698] Epoch 5, Iter 1700: loss=0.0178, ce=0.0019, dice=0.0284, grad_norm=0.156021
[17:25:54.934] Epoch 5, Iter 1710: loss=0.0347, ce=0.0029, dice=0.0560, grad_norm=0.168326
[17:25:59.171] Epoch 5, Iter 1720: loss=0.0410, ce=0.0049, dice=0.0651, grad_norm=0.258066
[17:26:03.413] Epoch 5, Iter 1730: loss=0.0170, ce=0.0035, dice=0.0260, grad_norm=0.056868
[17:26:07.651] Epoch 5, Iter 1740: loss=0.2079, ce=0.0030, dice=0.3446, grad_norm=0.049637
[17:26:11.919] Epoch 5, Iter 1750: loss=0.0186, ce=0.0015, dice=0.0301, grad_norm=0.231813
[17:26:16.162] Epoch 5, Iter 1760: loss=0.0258, ce=0.0038, dice=0.0404, grad_norm=0.140146
[17:26:20.402] Epoch 5, Iter 1770: loss=0.0347, ce=0.0063, dice=0.0536, grad_norm=0.140942
[17:26:24.634] Epoch 5, Iter 1780: loss=0.0414, ce=0.0033, dice=0.0668, grad_norm=0.413208
[17:26:28.880] Epoch 5, Iter 1790: loss=0.0276, ce=0.0045, dice=0.0430, grad_norm=0.171746
[17:26:33.108] Epoch 5, Iter 1800: loss=0.0430, ce=0.0044, dice=0.0688, grad_norm=0.210201
[17:26:37.349] Epoch 5, Iter 1810: loss=0.0196, ce=0.0047, dice=0.0296, grad_norm=0.143797
[17:26:41.581] Epoch 5, Iter 1820: loss=0.0278, ce=0.0047, dice=0.0432, grad_norm=0.205782
[17:26:45.834] Epoch 5, Iter 1830: loss=0.0163, ce=0.0046, dice=0.0241, grad_norm=0.117849
[17:26:50.072] Epoch 5, Iter 1840: loss=0.2091, ce=0.0037, dice=0.3459, grad_norm=0.067577
[17:26:54.311] Epoch 5, Iter 1850: loss=0.0249, ce=0.0069, dice=0.0368, grad_norm=0.184951
[17:26:58.539] Epoch 5, Iter 1860: loss=0.0267, ce=0.0045, dice=0.0415, grad_norm=0.127122
[17:27:02.779] Epoch 5, Iter 1870: loss=0.0801, ce=0.0038, dice=0.1310, grad_norm=0.759250
[17:27:07.005] Epoch 5, Iter 1880: loss=0.0216, ce=0.0056, dice=0.0323, grad_norm=0.095102
[17:27:11.253] Epoch 5, Iter 1890: loss=0.0229, ce=0.0059, dice=0.0343, grad_norm=0.096927
[17:27:15.493] Epoch 5, Iter 1900: loss=0.0287, ce=0.0053, dice=0.0444, grad_norm=0.121958
[17:27:19.744] Epoch 5, Iter 1910: loss=0.1264, ce=0.0025, dice=0.2090, grad_norm=2.005113
[17:27:23.990] Epoch 5, Iter 1920: loss=0.0228, ce=0.0073, dice=0.0332, grad_norm=0.120079
[17:27:28.258] Epoch 5, Iter 1930: loss=0.0471, ce=0.0024, dice=0.0768, grad_norm=0.510837
[17:27:32.491] Epoch 5, Iter 1940: loss=0.0476, ce=0.0034, dice=0.0771, grad_norm=0.236754
[17:27:36.595] Epoch 5, Iter 1950: loss=0.0744, ce=0.0051, dice=0.1206, grad_norm=0.583798
[17:27:37.205] Epoch 5: Avg Loss=0.0470, CE=0.0045, Dice=0.0753
[17:27:51.490] Epoch 6, Iter 1960: loss=0.0365, ce=0.0042, dice=0.0581, grad_norm=0.297665
[17:27:55.718] Epoch 6, Iter 1970: loss=0.0336, ce=0.0035, dice=0.0537, grad_norm=0.201940
[17:27:59.988] Epoch 6, Iter 1980: loss=0.0230, ce=0.0057, dice=0.0345, grad_norm=0.114685
[17:28:04.253] Epoch 6, Iter 1990: loss=0.0520, ce=0.0056, dice=0.0829, grad_norm=0.608303
[17:28:08.484] Epoch 6, Iter 2000: loss=0.0506, ce=0.0069, dice=0.0798, grad_norm=0.216391
[17:28:12.727] Epoch 6, Iter 2010: loss=0.0681, ce=0.0025, dice=0.1118, grad_norm=0.575403
[17:28:16.970] Epoch 6, Iter 2020: loss=0.0427, ce=0.0025, dice=0.0695, grad_norm=0.640746
[17:28:21.209] Epoch 6, Iter 2030: loss=0.0377, ce=0.0054, dice=0.0593, grad_norm=0.472162
[17:28:25.426] Epoch 6, Iter 2040: loss=0.0356, ce=0.0037, dice=0.0569, grad_norm=0.202761
[17:28:29.660] Epoch 6, Iter 2050: loss=0.0416, ce=0.0021, dice=0.0680, grad_norm=0.703037
[17:28:33.886] Epoch 6, Iter 2060: loss=0.0230, ce=0.0087, dice=0.0325, grad_norm=0.080868
[17:28:38.130] Epoch 6, Iter 2070: loss=0.0278, ce=0.0041, dice=0.0436, grad_norm=0.153635
[17:28:42.356] Epoch 6, Iter 2080: loss=0.0361, ce=0.0035, dice=0.0578, grad_norm=0.195825
[17:28:46.602] Epoch 6, Iter 2090: loss=0.0253, ce=0.0037, dice=0.0398, grad_norm=0.090824
[17:28:50.829] Epoch 6, Iter 2100: loss=0.0239, ce=0.0035, dice=0.0375, grad_norm=0.101708
[17:28:55.072] Epoch 6, Iter 2110: loss=0.0291, ce=0.0070, dice=0.0439, grad_norm=0.110025
[17:28:59.302] Epoch 6, Iter 2120: loss=0.0298, ce=0.0021, dice=0.0482, grad_norm=0.313312
[17:29:03.549] Epoch 6, Iter 2130: loss=0.0347, ce=0.0089, dice=0.0519, grad_norm=0.207048
[17:29:07.779] Epoch 6, Iter 2140: loss=0.0606, ce=0.0071, dice=0.0963, grad_norm=0.609413
[17:29:12.024] Epoch 6, Iter 2150: loss=0.0275, ce=0.0033, dice=0.0437, grad_norm=0.279439
[17:29:16.262] Epoch 6, Iter 2160: loss=0.0218, ce=0.0021, dice=0.0349, grad_norm=0.061194
[17:29:20.503] Epoch 6, Iter 2170: loss=0.0331, ce=0.0023, dice=0.0537, grad_norm=0.151956
[17:29:24.751] Epoch 6, Iter 2180: loss=0.0448, ce=0.0071, dice=0.0698, grad_norm=0.176785
[17:29:29.015] Epoch 6, Iter 2190: loss=0.0355, ce=0.0037, dice=0.0567, grad_norm=0.353973
[17:29:33.259] Epoch 6, Iter 2200: loss=0.0156, ce=0.0030, dice=0.0241, grad_norm=0.110063
[17:29:37.510] Epoch 6, Iter 2210: loss=0.0299, ce=0.0030, dice=0.0479, grad_norm=0.168315
[17:29:41.747] Epoch 6, Iter 2220: loss=0.0536, ce=0.0048, dice=0.0860, grad_norm=0.199978
[17:29:45.989] Epoch 6, Iter 2230: loss=0.0680, ce=0.0047, dice=0.1102, grad_norm=0.425191
[17:29:50.229] Epoch 6, Iter 2240: loss=0.0268, ce=0.0039, dice=0.0421, grad_norm=0.157366
[17:29:54.480] Epoch 6, Iter 2250: loss=0.0184, ce=0.0039, dice=0.0281, grad_norm=0.092378
[17:29:58.709] Epoch 6, Iter 2260: loss=0.0224, ce=0.0031, dice=0.0353, grad_norm=0.176365
[17:30:02.953] Epoch 6, Iter 2270: loss=0.0190, ce=0.0033, dice=0.0294, grad_norm=0.101743
[17:30:05.565] Epoch 6: Avg Loss=0.0500, CE=0.0045, Dice=0.0804
[17:30:17.551] Epoch 7, Iter 2280: loss=0.0278, ce=0.0043, dice=0.0434, grad_norm=0.136100
[17:30:21.792] Epoch 7, Iter 2290: loss=0.1899, ce=0.0025, dice=0.3148, grad_norm=0.962522
[17:30:26.017] Epoch 7, Iter 2300: loss=0.0556, ce=0.0036, dice=0.0902, grad_norm=0.293976
[17:30:30.285] Epoch 7, Iter 2310: loss=0.0326, ce=0.0060, dice=0.0503, grad_norm=0.178380
[17:30:34.521] Epoch 7, Iter 2320: loss=0.0273, ce=0.0046, dice=0.0425, grad_norm=0.123868
[17:30:38.754] Epoch 7, Iter 2330: loss=0.0459, ce=0.0017, dice=0.0753, grad_norm=0.156022
[17:30:42.988] Epoch 7, Iter 2340: loss=0.1893, ce=0.0019, dice=0.3141, grad_norm=1.327955
[17:30:47.233] Epoch 7, Iter 2350: loss=0.2057, ce=0.0035, dice=0.3405, grad_norm=0.015602
[17:30:51.466] Epoch 7, Iter 2360: loss=0.0312, ce=0.0023, dice=0.0504, grad_norm=0.782426
[17:30:55.707] Epoch 7, Iter 2370: loss=0.0604, ce=0.0049, dice=0.0974, grad_norm=0.513911
[17:30:59.938] Epoch 7, Iter 2380: loss=0.0533, ce=0.0054, dice=0.0851, grad_norm=0.472605
[17:31:04.196] Epoch 7, Iter 2390: loss=0.2149, ce=0.0030, dice=0.3562, grad_norm=0.469823
[17:31:08.429] Epoch 7, Iter 2400: loss=0.0229, ce=0.0049, dice=0.0349, grad_norm=0.102317
[17:31:12.669] Epoch 7, Iter 2410: loss=0.0812, ce=0.0060, dice=0.1313, grad_norm=0.464985
[17:31:16.906] Epoch 7, Iter 2420: loss=0.0370, ce=0.0033, dice=0.0595, grad_norm=0.176741
[17:31:21.206] Epoch 7, Iter 2430: loss=0.0310, ce=0.0035, dice=0.0494, grad_norm=0.166956
[17:31:25.468] Epoch 7, Iter 2440: loss=0.0228, ce=0.0058, dice=0.0341, grad_norm=0.157932
[17:31:29.726] Epoch 7, Iter 2450: loss=0.0231, ce=0.0048, dice=0.0353, grad_norm=0.078249
[17:31:33.966] Epoch 7, Iter 2460: loss=0.0306, ce=0.0031, dice=0.0490, grad_norm=0.129140
[17:31:38.216] Epoch 7, Iter 2470: loss=0.0140, ce=0.0028, dice=0.0215, grad_norm=0.088701
[17:31:42.456] Epoch 7, Iter 2480: loss=0.2101, ce=0.0045, dice=0.3471, grad_norm=0.041672
[17:31:46.702] Epoch 7, Iter 2490: loss=0.0298, ce=0.0040, dice=0.0469, grad_norm=0.246644
[17:31:50.940] Epoch 7, Iter 2500: loss=0.0194, ce=0.0039, dice=0.0298, grad_norm=0.147256
[17:31:55.191] Epoch 7, Iter 2510: loss=0.0259, ce=0.0046, dice=0.0401, grad_norm=0.130632
[17:31:59.429] Epoch 7, Iter 2520: loss=0.0244, ce=0.0059, dice=0.0367, grad_norm=0.071831
[17:32:03.683] Epoch 7, Iter 2530: loss=0.0259, ce=0.0056, dice=0.0395, grad_norm=0.081494
[17:32:07.926] Epoch 7, Iter 2540: loss=0.0245, ce=0.0065, dice=0.0365, grad_norm=0.149797
[17:32:12.172] Epoch 7, Iter 2550: loss=0.0361, ce=0.0037, dice=0.0577, grad_norm=0.241522
[17:32:16.413] Epoch 7, Iter 2560: loss=0.0572, ce=0.0032, dice=0.0932, grad_norm=1.201805
[17:32:20.659] Epoch 7, Iter 2570: loss=0.0195, ce=0.0036, dice=0.0300, grad_norm=0.146471
[17:32:24.899] Epoch 7, Iter 2580: loss=0.0207, ce=0.0052, dice=0.0309, grad_norm=0.078366
[17:32:29.154] Epoch 7, Iter 2590: loss=0.0543, ce=0.0076, dice=0.0855, grad_norm=0.875245
[17:32:33.258] Epoch 7, Iter 2600: loss=0.0314, ce=0.0035, dice=0.0500, grad_norm=0.110112
[17:32:33.918] Epoch 7: Avg Loss=0.0459, CE=0.0041, Dice=0.0737
[17:32:48.620] Epoch 8, Iter 2610: loss=0.0682, ce=0.0022, dice=0.1122, grad_norm=0.188797
[17:32:52.857] Epoch 8, Iter 2620: loss=0.0252, ce=0.0088, dice=0.0362, grad_norm=0.064275
[17:32:57.096] Epoch 8, Iter 2630: loss=0.0381, ce=0.0032, dice=0.0613, grad_norm=0.566813
[17:33:01.336] Epoch 8, Iter 2640: loss=0.0311, ce=0.0049, dice=0.0486, grad_norm=0.116559
[17:33:05.580] Epoch 8, Iter 2650: loss=0.0347, ce=0.0020, dice=0.0565, grad_norm=0.161699
[17:33:09.813] Epoch 8, Iter 2660: loss=0.0235, ce=0.0048, dice=0.0360, grad_norm=0.071745
[17:33:14.056] Epoch 8, Iter 2670: loss=0.0258, ce=0.0047, dice=0.0400, grad_norm=0.177756
[17:33:18.296] Epoch 8, Iter 2680: loss=0.0233, ce=0.0051, dice=0.0354, grad_norm=0.183158
[17:33:22.542] Epoch 8, Iter 2690: loss=0.0410, ce=0.0047, dice=0.0652, grad_norm=0.233359
[17:33:26.776] Epoch 8, Iter 2700: loss=0.0235, ce=0.0052, dice=0.0357, grad_norm=0.104757
[17:33:31.017] Epoch 8, Iter 2710: loss=0.0274, ce=0.0059, dice=0.0417, grad_norm=0.066735
[17:33:35.251] Epoch 8, Iter 2720: loss=0.0181, ce=0.0047, dice=0.0270, grad_norm=0.201878
[17:33:39.499] Epoch 8, Iter 2730: loss=0.2076, ce=0.0018, dice=0.3448, grad_norm=0.050119
[17:33:43.740] Epoch 8, Iter 2740: loss=0.0536, ce=0.0021, dice=0.0880, grad_norm=1.807812
[17:33:47.992] Epoch 8, Iter 2750: loss=0.0321, ce=0.0033, dice=0.0513, grad_norm=0.140762
[17:33:52.231] Epoch 8, Iter 2760: loss=0.0207, ce=0.0050, dice=0.0312, grad_norm=0.109600
[17:33:56.481] Epoch 8, Iter 2770: loss=0.0191, ce=0.0052, dice=0.0283, grad_norm=0.155440
[17:34:00.722] Epoch 8, Iter 2780: loss=0.0312, ce=0.0087, dice=0.0462, grad_norm=0.082664
[17:34:04.971] Epoch 8, Iter 2790: loss=0.0179, ce=0.0051, dice=0.0264, grad_norm=0.091555
[17:34:09.211] Epoch 8, Iter 2800: loss=0.0343, ce=0.0025, dice=0.0555, grad_norm=0.132015
[17:34:13.453] Epoch 8, Iter 2810: loss=0.0442, ce=0.0065, dice=0.0693, grad_norm=0.408586
[17:34:17.693] Epoch 8, Iter 2820: loss=0.0555, ce=0.0033, dice=0.0902, grad_norm=0.270214
[17:34:22.030] Epoch 8, Iter 2830: loss=0.2060, ce=0.0009, dice=0.3426, grad_norm=0.167354
[17:34:26.268] Epoch 8, Iter 2840: loss=0.0326, ce=0.0051, dice=0.0509, grad_norm=0.267406
[17:34:30.515] Epoch 8, Iter 2850: loss=0.0345, ce=0.0066, dice=0.0530, grad_norm=0.125126
[17:34:34.758] Epoch 8, Iter 2860: loss=0.0242, ce=0.0041, dice=0.0376, grad_norm=0.110951
[17:34:39.010] Epoch 8, Iter 2870: loss=0.0351, ce=0.0030, dice=0.0566, grad_norm=0.196009
[17:34:43.247] Epoch 8, Iter 2880: loss=0.0388, ce=0.0023, dice=0.0631, grad_norm=0.262988
[17:34:47.502] Epoch 8, Iter 2890: loss=0.0135, ce=0.0040, dice=0.0199, grad_norm=0.080822
[17:34:51.741] Epoch 8, Iter 2900: loss=0.0168, ce=0.0030, dice=0.0260, grad_norm=0.094052
[17:34:55.981] Epoch 8, Iter 2910: loss=0.0528, ce=0.0046, dice=0.0850, grad_norm=0.490399
[17:35:00.227] Epoch 8, Iter 2920: loss=0.0431, ce=0.0027, dice=0.0701, grad_norm=0.132382
[17:35:02.862] Epoch 8: Avg Loss=0.0437, CE=0.0040, Dice=0.0702
[17:35:15.448] Epoch 9, Iter 2930: loss=0.0657, ce=0.0017, dice=0.1084, grad_norm=0.757303
[17:35:19.702] Epoch 9, Iter 2940: loss=0.0250, ce=0.0054, dice=0.0381, grad_norm=0.087157
[17:35:23.930] Epoch 9, Iter 2950: loss=0.0249, ce=0.0035, dice=0.0392, grad_norm=0.100674
[17:35:28.156] Epoch 9, Iter 2960: loss=0.0704, ce=0.0068, dice=0.1129, grad_norm=0.799336
[17:35:32.389] Epoch 9, Iter 2970: loss=0.0243, ce=0.0027, dice=0.0386, grad_norm=0.069402
[17:35:36.623] Epoch 9, Iter 2980: loss=0.0299, ce=0.0026, dice=0.0480, grad_norm=0.199979
[17:35:40.863] Epoch 9, Iter 2990: loss=0.0370, ce=0.0061, dice=0.0576, grad_norm=0.288665
[17:35:45.099] Epoch 9, Iter 3000: loss=0.0600, ce=0.0038, dice=0.0974, grad_norm=0.363011
[17:35:49.349] Epoch 9, Iter 3010: loss=0.0207, ce=0.0041, dice=0.0318, grad_norm=0.205146
[17:35:53.584] Epoch 9, Iter 3020: loss=0.0219, ce=0.0033, dice=0.0344, grad_norm=0.109076
[17:35:57.830] Epoch 9, Iter 3030: loss=0.0200, ce=0.0051, dice=0.0299, grad_norm=0.116447
[17:36:02.063] Epoch 9, Iter 3040: loss=0.0240, ce=0.0042, dice=0.0372, grad_norm=0.094407
[17:36:06.310] Epoch 9, Iter 3050: loss=0.0784, ce=0.0040, dice=0.1281, grad_norm=0.337906
[17:36:10.548] Epoch 9, Iter 3060: loss=0.0412, ce=0.0055, dice=0.0649, grad_norm=0.369823
[17:36:14.789] Epoch 9, Iter 3070: loss=0.0288, ce=0.0049, dice=0.0448, grad_norm=0.118003
[17:36:19.023] Epoch 9, Iter 3080: loss=0.0199, ce=0.0059, dice=0.0292, grad_norm=0.074395
[17:36:23.271] Epoch 9, Iter 3090: loss=0.0438, ce=0.0047, dice=0.0699, grad_norm=0.282286
[17:36:27.506] Epoch 9, Iter 3100: loss=0.2072, ce=0.0027, dice=0.3435, grad_norm=0.048033
[17:36:31.759] Epoch 9, Iter 3110: loss=0.0215, ce=0.0051, dice=0.0325, grad_norm=0.093360
[17:36:35.993] Epoch 9, Iter 3120: loss=0.0204, ce=0.0040, dice=0.0312, grad_norm=0.099006
[17:36:40.245] Epoch 9, Iter 3130: loss=0.0237, ce=0.0040, dice=0.0368, grad_norm=0.151009
[17:36:44.489] Epoch 9, Iter 3140: loss=0.0228, ce=0.0028, dice=0.0362, grad_norm=0.072581
[17:36:48.733] Epoch 9, Iter 3150: loss=0.0249, ce=0.0041, dice=0.0387, grad_norm=0.109460
[17:36:52.975] Epoch 9, Iter 3160: loss=0.0178, ce=0.0045, dice=0.0266, grad_norm=0.099797
[17:36:57.216] Epoch 9, Iter 3170: loss=0.0620, ce=0.0029, dice=0.1014, grad_norm=0.446730
[17:37:01.444] Epoch 9, Iter 3180: loss=0.0365, ce=0.0039, dice=0.0582, grad_norm=0.155627
[17:37:05.683] Epoch 9, Iter 3190: loss=0.0524, ce=0.0020, dice=0.0859, grad_norm=0.371341
[17:37:09.917] Epoch 9, Iter 3200: loss=0.0510, ce=0.0019, dice=0.0838, grad_norm=0.642653
[17:37:14.163] Epoch 9, Iter 3210: loss=0.0193, ce=0.0028, dice=0.0304, grad_norm=0.150126
[17:37:18.400] Epoch 9, Iter 3220: loss=0.2059, ce=0.0021, dice=0.3417, grad_norm=0.026780
[17:37:22.647] Epoch 9, Iter 3230: loss=0.0312, ce=0.0017, dice=0.0509, grad_norm=0.240153
[17:37:26.881] Epoch 9, Iter 3240: loss=0.0241, ce=0.0041, dice=0.0374, grad_norm=0.156055
[17:37:30.985] Epoch 9, Iter 3250: loss=0.0300, ce=0.0050, dice=0.0466, grad_norm=0.244746
[17:37:31.601] Epoch 9: Avg Loss=0.0412, CE=0.0038, Dice=0.0662
[17:37:31.691] save model to ./finetune_tpgm_lits17\finetuned_epoch_9.pth
[17:37:45.735] Epoch 10, Iter 3260: loss=0.0273, ce=0.0048, dice=0.0423, grad_norm=0.132975
[17:37:49.966] Epoch 10, Iter 3270: loss=0.2065, ce=0.0023, dice=0.3426, grad_norm=0.030098
[17:37:54.196] Epoch 10, Iter 3280: loss=0.0242, ce=0.0036, dice=0.0380, grad_norm=0.100692
[17:37:58.434] Epoch 10, Iter 3290: loss=0.0125, ce=0.0009, dice=0.0201, grad_norm=0.062143
[17:38:02.663] Epoch 10, Iter 3300: loss=0.0293, ce=0.0030, dice=0.0469, grad_norm=0.189684
[17:38:06.901] Epoch 10, Iter 3310: loss=0.0337, ce=0.0049, dice=0.0528, grad_norm=0.109894
[17:38:11.138] Epoch 10, Iter 3320: loss=0.0440, ce=0.0015, dice=0.0723, grad_norm=0.263561
[17:38:15.384] Epoch 10, Iter 3330: loss=0.0471, ce=0.0042, dice=0.0757, grad_norm=0.140768
[17:38:19.616] Epoch 10, Iter 3340: loss=0.0492, ce=0.0039, dice=0.0794, grad_norm=0.506568
[17:38:23.861] Epoch 10, Iter 3350: loss=0.0229, ce=0.0048, dice=0.0350, grad_norm=0.053298
[17:38:28.091] Epoch 10, Iter 3360: loss=0.0211, ce=0.0053, dice=0.0316, grad_norm=0.100181
[17:38:32.334] Epoch 10, Iter 3370: loss=0.0200, ce=0.0031, dice=0.0313, grad_norm=0.098246
[17:38:36.556] Epoch 10, Iter 3380: loss=0.0240, ce=0.0007, dice=0.0396, grad_norm=0.147863
[17:38:40.795] Epoch 10, Iter 3390: loss=0.0899, ce=0.0024, dice=0.1482, grad_norm=1.053363
[17:38:45.032] Epoch 10, Iter 3400: loss=0.0223, ce=0.0056, dice=0.0335, grad_norm=0.127404
[17:38:49.275] Epoch 10, Iter 3410: loss=0.0246, ce=0.0048, dice=0.0379, grad_norm=0.057571
[17:38:53.504] Epoch 10, Iter 3420: loss=0.0291, ce=0.0022, dice=0.0471, grad_norm=0.264196
[17:38:57.762] Epoch 10, Iter 3430: loss=0.0395, ce=0.0028, dice=0.0640, grad_norm=0.533892
[17:39:01.990] Epoch 10, Iter 3440: loss=0.0185, ce=0.0052, dice=0.0273, grad_norm=0.085532
[17:39:06.226] Epoch 10, Iter 3450: loss=0.0299, ce=0.0047, dice=0.0468, grad_norm=0.268781
[17:39:10.459] Epoch 10, Iter 3460: loss=0.0158, ce=0.0061, dice=0.0222, grad_norm=0.086443
[17:39:14.703] Epoch 10, Iter 3470: loss=0.0409, ce=0.0053, dice=0.0647, grad_norm=0.303322
[17:39:18.934] Epoch 10, Iter 3480: loss=0.2087, ce=0.0035, dice=0.3454, grad_norm=0.118525
[17:39:23.171] Epoch 10, Iter 3490: loss=0.0410, ce=0.0038, dice=0.0658, grad_norm=0.554927
[17:39:27.405] Epoch 10, Iter 3500: loss=0.2094, ce=0.0030, dice=0.3470, grad_norm=0.084606
[17:39:31.643] Epoch 10, Iter 3510: loss=0.0248, ce=0.0036, dice=0.0390, grad_norm=0.088874
[17:39:35.892] Epoch 10, Iter 3520: loss=0.0325, ce=0.0036, dice=0.0518, grad_norm=0.130885
[17:39:40.139] Epoch 10, Iter 3530: loss=0.0409, ce=0.0041, dice=0.0655, grad_norm=0.219807
[17:39:44.369] Epoch 10, Iter 3540: loss=0.0211, ce=0.0033, dice=0.0329, grad_norm=0.112292
[17:39:48.616] Epoch 10, Iter 3550: loss=0.0287, ce=0.0016, dice=0.0467, grad_norm=0.120362
[17:39:52.853] Epoch 10, Iter 3560: loss=0.0940, ce=0.0033, dice=0.1545, grad_norm=1.282024
[17:39:57.110] Epoch 10, Iter 3570: loss=0.0316, ce=0.0035, dice=0.0503, grad_norm=0.187994
[17:39:59.661] Epoch 10: Avg Loss=0.0437, CE=0.0038, Dice=0.0702
[17:40:11.756] Epoch 11, Iter 3580: loss=0.0421, ce=0.0038, dice=0.0677, grad_norm=0.307902
[17:40:16.006] Epoch 11, Iter 3590: loss=0.0213, ce=0.0059, dice=0.0316, grad_norm=0.085402
[17:40:20.233] Epoch 11, Iter 3600: loss=0.0470, ce=0.0027, dice=0.0766, grad_norm=0.544394
[17:40:24.465] Epoch 11, Iter 3610: loss=0.0869, ce=0.0015, dice=0.1439, grad_norm=0.721128
[17:40:28.709] Epoch 11, Iter 3620: loss=0.0251, ce=0.0030, dice=0.0398, grad_norm=0.156445
[17:40:32.949] Epoch 11, Iter 3630: loss=0.0422, ce=0.0055, dice=0.0667, grad_norm=0.164396
[17:40:37.179] Epoch 11, Iter 3640: loss=0.0493, ce=0.0045, dice=0.0791, grad_norm=0.192540
[17:40:41.427] Epoch 11, Iter 3650: loss=0.0260, ce=0.0049, dice=0.0400, grad_norm=0.071016
[17:40:45.658] Epoch 11, Iter 3660: loss=0.0446, ce=0.0032, dice=0.0722, grad_norm=1.723621
[17:40:49.898] Epoch 11, Iter 3670: loss=0.0220, ce=0.0027, dice=0.0348, grad_norm=0.117387
[17:40:54.127] Epoch 11, Iter 3680: loss=0.0682, ce=0.0030, dice=0.1118, grad_norm=0.790979
[17:40:58.370] Epoch 11, Iter 3690: loss=0.0296, ce=0.0026, dice=0.0476, grad_norm=0.131736
[17:41:02.610] Epoch 11, Iter 3700: loss=0.0227, ce=0.0048, dice=0.0347, grad_norm=0.185376
[17:41:06.852] Epoch 11, Iter 3710: loss=0.0189, ce=0.0019, dice=0.0303, grad_norm=0.143874
[17:41:11.079] Epoch 11, Iter 3720: loss=0.0343, ce=0.0027, dice=0.0554, grad_norm=0.314323
[17:41:15.319] Epoch 11, Iter 3730: loss=0.0286, ce=0.0044, dice=0.0448, grad_norm=0.195429
[17:41:19.543] Epoch 11, Iter 3740: loss=0.0232, ce=0.0038, dice=0.0361, grad_norm=0.074366
[17:41:23.788] Epoch 11, Iter 3750: loss=0.0307, ce=0.0044, dice=0.0482, grad_norm=0.158979
[17:41:28.021] Epoch 11, Iter 3760: loss=0.0347, ce=0.0044, dice=0.0550, grad_norm=0.145658
[17:41:32.270] Epoch 11, Iter 3770: loss=0.0923, ce=0.0017, dice=0.1527, grad_norm=1.660713
[17:41:36.507] Epoch 11, Iter 3780: loss=0.0225, ce=0.0029, dice=0.0356, grad_norm=0.069552
[17:41:40.755] Epoch 11, Iter 3790: loss=0.0199, ce=0.0071, dice=0.0285, grad_norm=0.087980
[17:41:44.992] Epoch 11, Iter 3800: loss=0.0239, ce=0.0035, dice=0.0375, grad_norm=0.086718
[17:41:49.248] Epoch 11, Iter 3810: loss=0.0232, ce=0.0031, dice=0.0365, grad_norm=0.219816
[17:41:53.494] Epoch 11, Iter 3820: loss=0.0186, ce=0.0061, dice=0.0270, grad_norm=0.054926
[17:41:57.740] Epoch 11, Iter 3830: loss=0.0152, ce=0.0033, dice=0.0232, grad_norm=0.060905
[17:42:01.978] Epoch 11, Iter 3840: loss=0.0342, ce=0.0021, dice=0.0556, grad_norm=0.317600
[17:42:06.231] Epoch 11, Iter 3850: loss=0.0221, ce=0.0051, dice=0.0333, grad_norm=0.071944
[17:42:10.478] Epoch 11, Iter 3860: loss=0.2067, ce=0.0028, dice=0.3426, grad_norm=0.032109
[17:42:14.724] Epoch 11, Iter 3870: loss=0.0408, ce=0.0035, dice=0.0656, grad_norm=0.159852
[17:42:18.964] Epoch 11, Iter 3880: loss=0.0268, ce=0.0020, dice=0.0433, grad_norm=0.218818
[17:42:23.214] Epoch 11, Iter 3890: loss=0.0148, ce=0.0030, dice=0.0227, grad_norm=0.093335
[17:42:27.331] Epoch 11, Iter 3900: loss=0.0263, ce=0.0023, dice=0.0423, grad_norm=0.071627
[17:42:27.924] Epoch 11: Avg Loss=0.0417, CE=0.0038, Dice=0.0670
[17:51:52.623] Epoch 12, Iter 3910: loss=0.0227, ce=0.0042, dice=0.0351, grad_norm=0.072841
[17:51:56.819] Epoch 12, Iter 3920: loss=0.0298, ce=0.0019, dice=0.0483, grad_norm=0.259904
[17:52:01.031] Epoch 12, Iter 3930: loss=0.0478, ce=0.0036, dice=0.0772, grad_norm=0.459702
[17:52:05.241] Epoch 12, Iter 3940: loss=0.0190, ce=0.0030, dice=0.0297, grad_norm=0.091508
[17:52:09.463] Epoch 12, Iter 3950: loss=0.0208, ce=0.0029, dice=0.0327, grad_norm=0.094105
[17:52:13.671] Epoch 12, Iter 3960: loss=0.0232, ce=0.0058, dice=0.0347, grad_norm=0.080460
[17:52:17.888] Epoch 12, Iter 3970: loss=0.0131, ce=0.0034, dice=0.0196, grad_norm=0.062237
[17:52:22.101] Epoch 12, Iter 3980: loss=0.0193, ce=0.0032, dice=0.0301, grad_norm=0.044242
[17:52:26.317] Epoch 12, Iter 3990: loss=0.0243, ce=0.0045, dice=0.0375, grad_norm=0.085777
[17:52:30.532] Epoch 12, Iter 4000: loss=0.0186, ce=0.0037, dice=0.0286, grad_norm=0.079025
[17:52:34.755] Epoch 12, Iter 4010: loss=0.0478, ce=0.0030, dice=0.0776, grad_norm=0.289540
[17:52:38.971] Epoch 12, Iter 4020: loss=0.0292, ce=0.0018, dice=0.0474, grad_norm=0.153295
[17:52:43.197] Epoch 12, Iter 4030: loss=0.0255, ce=0.0034, dice=0.0402, grad_norm=0.272441
[17:52:47.414] Epoch 12, Iter 4040: loss=0.0221, ce=0.0035, dice=0.0344, grad_norm=0.152633
[17:52:51.640] Epoch 12, Iter 4050: loss=0.0757, ce=0.0049, dice=0.1228, grad_norm=0.356836
[17:52:55.861] Epoch 12, Iter 4060: loss=0.0367, ce=0.0042, dice=0.0583, grad_norm=0.151782
[17:53:00.082] Epoch 12, Iter 4070: loss=0.0136, ce=0.0032, dice=0.0205, grad_norm=0.073081
[17:53:04.304] Epoch 12, Iter 4080: loss=0.0231, ce=0.0065, dice=0.0342, grad_norm=0.062935
[17:53:08.532] Epoch 12, Iter 4090: loss=0.0386, ce=0.0043, dice=0.0615, grad_norm=1.548906
[17:53:12.744] Epoch 12, Iter 4100: loss=0.2058, ce=0.0023, dice=0.3415, grad_norm=0.028049
[17:53:16.976] Epoch 12, Iter 4110: loss=0.0256, ce=0.0035, dice=0.0403, grad_norm=0.098843
[17:53:21.209] Epoch 12, Iter 4120: loss=0.0421, ce=0.0028, dice=0.0683, grad_norm=0.317959
[17:53:25.442] Epoch 12, Iter 4130: loss=0.1798, ce=0.0029, dice=0.2977, grad_norm=1.807892
[17:53:29.673] Epoch 12, Iter 4140: loss=0.0303, ce=0.0027, dice=0.0487, grad_norm=0.145913
[17:53:33.909] Epoch 12, Iter 4150: loss=0.0129, ce=0.0024, dice=0.0200, grad_norm=0.055420
[17:53:38.142] Epoch 12, Iter 4160: loss=0.0242, ce=0.0018, dice=0.0392, grad_norm=0.149831
[17:53:42.371] Epoch 12, Iter 4170: loss=0.0228, ce=0.0034, dice=0.0358, grad_norm=0.135637
[17:53:46.672] Epoch 12, Iter 4180: loss=0.0215, ce=0.0044, dice=0.0329, grad_norm=0.060634
[17:53:50.913] Epoch 12, Iter 4190: loss=0.0438, ce=0.0044, dice=0.0701, grad_norm=0.129195
[17:53:55.142] Epoch 12, Iter 4200: loss=0.0576, ce=0.0037, dice=0.0935, grad_norm=0.576309
[17:53:59.377] Epoch 12, Iter 4210: loss=0.0191, ce=0.0038, dice=0.0292, grad_norm=0.048786
[17:54:03.599] Epoch 12, Iter 4220: loss=0.0248, ce=0.0043, dice=0.0384, grad_norm=0.065492
[17:54:06.148] Epoch 12: Avg Loss=0.0415, CE=0.0036, Dice=0.0667
[17:54:18.118] Epoch 13, Iter 4230: loss=0.0256, ce=0.0017, dice=0.0415, grad_norm=0.248016
[17:54:22.334] Epoch 13, Iter 4240: loss=0.0257, ce=0.0047, dice=0.0398, grad_norm=0.088319
[17:54:26.563] Epoch 13, Iter 4250: loss=0.0259, ce=0.0035, dice=0.0408, grad_norm=0.375863
[17:54:30.777] Epoch 13, Iter 4260: loss=0.0461, ce=0.0015, dice=0.0759, grad_norm=0.496523
[17:54:35.007] Epoch 13, Iter 4270: loss=0.0253, ce=0.0026, dice=0.0404, grad_norm=0.129219
[17:54:39.231] Epoch 13, Iter 4280: loss=0.0326, ce=0.0032, dice=0.0522, grad_norm=0.120422
[17:54:43.463] Epoch 13, Iter 4290: loss=0.0509, ce=0.0034, dice=0.0825, grad_norm=0.353764
[17:54:47.688] Epoch 13, Iter 4300: loss=0.0737, ce=0.0022, dice=0.1213, grad_norm=0.533944
[17:54:51.922] Epoch 13, Iter 4310: loss=0.0153, ce=0.0048, dice=0.0224, grad_norm=0.070383
[17:54:56.141] Epoch 13, Iter 4320: loss=0.0232, ce=0.0036, dice=0.0363, grad_norm=0.123416
[17:55:00.370] Epoch 13, Iter 4330: loss=0.0232, ce=0.0039, dice=0.0360, grad_norm=0.131247
[17:55:04.591] Epoch 13, Iter 4340: loss=0.0177, ce=0.0043, dice=0.0267, grad_norm=0.117032
[17:55:08.823] Epoch 13, Iter 4350: loss=0.0439, ce=0.0021, dice=0.0719, grad_norm=0.904407
[17:55:13.042] Epoch 13, Iter 4360: loss=0.0844, ce=0.0033, dice=0.1384, grad_norm=0.206137
[17:55:17.277] Epoch 13, Iter 4370: loss=0.0279, ce=0.0069, dice=0.0418, grad_norm=0.094397
[17:55:21.501] Epoch 13, Iter 4380: loss=0.0304, ce=0.0032, dice=0.0485, grad_norm=0.094737
[17:55:25.734] Epoch 13, Iter 4390: loss=0.0150, ce=0.0037, dice=0.0226, grad_norm=0.116733
[17:55:29.972] Epoch 13, Iter 4400: loss=0.0273, ce=0.0092, dice=0.0393, grad_norm=0.044498
[17:55:34.207] Epoch 13, Iter 4410: loss=0.0220, ce=0.0051, dice=0.0334, grad_norm=0.201649
[17:55:38.433] Epoch 13, Iter 4420: loss=0.0230, ce=0.0011, dice=0.0376, grad_norm=0.151224
[17:55:42.665] Epoch 13, Iter 4430: loss=0.0200, ce=0.0026, dice=0.0315, grad_norm=0.103738
[17:55:46.896] Epoch 13, Iter 4440: loss=0.0184, ce=0.0040, dice=0.0279, grad_norm=0.040723
[17:55:51.134] Epoch 13, Iter 4450: loss=0.0813, ce=0.0014, dice=0.1345, grad_norm=1.036123
[17:55:55.363] Epoch 13, Iter 4460: loss=0.0493, ce=0.0028, dice=0.0802, grad_norm=0.734860
[17:55:59.600] Epoch 13, Iter 4470: loss=0.0341, ce=0.0051, dice=0.0535, grad_norm=0.216689
[17:56:03.835] Epoch 13, Iter 4480: loss=0.0262, ce=0.0015, dice=0.0427, grad_norm=0.279467
[17:56:08.070] Epoch 13, Iter 4490: loss=0.0297, ce=0.0040, dice=0.0468, grad_norm=0.107749
[17:56:12.300] Epoch 13, Iter 4500: loss=0.2057, ce=0.0022, dice=0.3414, grad_norm=0.050367
[17:56:16.535] Epoch 13, Iter 4510: loss=0.0233, ce=0.0021, dice=0.0374, grad_norm=0.109362
[17:56:20.767] Epoch 13, Iter 4520: loss=0.0255, ce=0.0027, dice=0.0407, grad_norm=0.167629
[17:56:25.019] Epoch 13, Iter 4530: loss=0.0247, ce=0.0065, dice=0.0369, grad_norm=0.099376
[17:56:29.276] Epoch 13, Iter 4540: loss=0.0215, ce=0.0013, dice=0.0349, grad_norm=0.253812
[17:56:33.381] Epoch 13, Iter 4550: loss=0.0227, ce=0.0041, dice=0.0351, grad_norm=0.110248
[17:56:33.942] Epoch 13: Avg Loss=0.0377, CE=0.0035, Dice=0.0604
[18:05:58.574] Epoch 14, Iter 4560: loss=0.0751, ce=0.0018, dice=0.1240, grad_norm=0.943241
[18:06:02.780] Epoch 14, Iter 4570: loss=0.0248, ce=0.0030, dice=0.0394, grad_norm=0.163774
[18:06:06.982] Epoch 14, Iter 4580: loss=0.0199, ce=0.0053, dice=0.0296, grad_norm=0.085304
[18:06:11.200] Epoch 14, Iter 4590: loss=0.0358, ce=0.0039, dice=0.0570, grad_norm=0.214328
[18:06:15.402] Epoch 14, Iter 4600: loss=0.0137, ce=0.0037, dice=0.0204, grad_norm=0.067765
[18:06:19.623] Epoch 14, Iter 4610: loss=0.0205, ce=0.0033, dice=0.0320, grad_norm=0.051686
[18:06:23.840] Epoch 14, Iter 4620: loss=0.0255, ce=0.0010, dice=0.0419, grad_norm=0.434288
[18:06:28.062] Epoch 14, Iter 4630: loss=0.0228, ce=0.0037, dice=0.0356, grad_norm=0.146157
[18:06:32.276] Epoch 14, Iter 4640: loss=0.0203, ce=0.0017, dice=0.0327, grad_norm=0.146227
[18:06:36.499] Epoch 14, Iter 4650: loss=0.0372, ce=0.0047, dice=0.0588, grad_norm=0.464582
[18:06:40.711] Epoch 14, Iter 4660: loss=0.0214, ce=0.0074, dice=0.0306, grad_norm=0.060204
[18:06:44.940] Epoch 14, Iter 4670: loss=0.0264, ce=0.0020, dice=0.0427, grad_norm=0.164380
[18:06:49.157] Epoch 14, Iter 4680: loss=0.0206, ce=0.0040, dice=0.0317, grad_norm=0.066013
[18:06:53.390] Epoch 14, Iter 4690: loss=0.0389, ce=0.0033, dice=0.0627, grad_norm=0.095247
[18:06:57.605] Epoch 14, Iter 4700: loss=0.0299, ce=0.0063, dice=0.0456, grad_norm=0.090910
[18:07:01.845] Epoch 14, Iter 4710: loss=0.0113, ce=0.0037, dice=0.0163, grad_norm=0.042942
[18:07:06.052] Epoch 14, Iter 4720: loss=0.2063, ce=0.0013, dice=0.3430, grad_norm=0.044339
[18:07:10.277] Epoch 14, Iter 4730: loss=0.0234, ce=0.0027, dice=0.0372, grad_norm=0.176986
[18:07:14.493] Epoch 14, Iter 4740: loss=0.0157, ce=0.0025, dice=0.0245, grad_norm=0.076886
[18:07:18.715] Epoch 14, Iter 4750: loss=0.0297, ce=0.0041, dice=0.0467, grad_norm=0.118647
[18:07:22.928] Epoch 14, Iter 4760: loss=0.0127, ce=0.0021, dice=0.0198, grad_norm=0.031415
[18:07:27.155] Epoch 14, Iter 4770: loss=0.0219, ce=0.0039, dice=0.0339, grad_norm=0.195681
[18:07:31.374] Epoch 14, Iter 4780: loss=0.2071, ce=0.0030, dice=0.3431, grad_norm=0.032386
[18:07:35.597] Epoch 14, Iter 4790: loss=0.0278, ce=0.0016, dice=0.0453, grad_norm=0.607140
[18:07:39.810] Epoch 14, Iter 4800: loss=0.0553, ce=0.0038, dice=0.0896, grad_norm=0.404657
[18:07:44.040] Epoch 14, Iter 4810: loss=0.0187, ce=0.0034, dice=0.0289, grad_norm=0.086716
[18:07:48.255] Epoch 14, Iter 4820: loss=0.0256, ce=0.0025, dice=0.0410, grad_norm=0.111363
[18:07:52.487] Epoch 14, Iter 4830: loss=0.0165, ce=0.0045, dice=0.0244, grad_norm=0.100628
[18:07:56.711] Epoch 14, Iter 4840: loss=0.0453, ce=0.0072, dice=0.0707, grad_norm=0.289775
[18:08:00.940] Epoch 14, Iter 4850: loss=0.0387, ce=0.0014, dice=0.0635, grad_norm=0.476949
[18:08:05.163] Epoch 14, Iter 4860: loss=0.0184, ce=0.0019, dice=0.0294, grad_norm=0.191687
[18:08:09.388] Epoch 14, Iter 4870: loss=0.0144, ce=0.0004, dice=0.0237, grad_norm=0.116732
[18:08:11.920] Epoch 14: Avg Loss=0.0429, CE=0.0035, Dice=0.0692
[18:08:23.649] Epoch 15, Iter 4880: loss=0.0721, ce=0.0020, dice=0.1189, grad_norm=1.762792
[18:08:27.860] Epoch 15, Iter 4890: loss=0.0302, ce=0.0035, dice=0.0480, grad_norm=0.110970
[18:08:32.067] Epoch 15, Iter 4900: loss=0.0154, ce=0.0026, dice=0.0239, grad_norm=0.053139
[18:08:36.285] Epoch 15, Iter 4910: loss=0.0300, ce=0.0030, dice=0.0480, grad_norm=0.107008
[18:08:40.499] Epoch 15, Iter 4920: loss=0.0336, ce=0.0040, dice=0.0533, grad_norm=0.111593
[18:08:44.719] Epoch 15, Iter 4930: loss=0.2063, ce=0.0026, dice=0.3422, grad_norm=0.030423
[18:08:48.928] Epoch 15, Iter 4940: loss=0.0279, ce=0.0023, dice=0.0451, grad_norm=0.109532
[18:08:53.153] Epoch 15, Iter 4950: loss=0.0177, ce=0.0043, dice=0.0266, grad_norm=0.051619
[18:08:57.374] Epoch 15, Iter 4960: loss=0.0247, ce=0.0043, dice=0.0384, grad_norm=0.133692
[18:09:01.593] Epoch 15, Iter 4970: loss=0.0167, ce=0.0036, dice=0.0254, grad_norm=0.081719
[18:09:05.810] Epoch 15, Iter 4980: loss=0.0332, ce=0.0024, dice=0.0538, grad_norm=0.773677
[18:09:10.040] Epoch 15, Iter 4990: loss=0.0435, ce=0.0024, dice=0.0709, grad_norm=0.263181
[18:09:14.255] Epoch 15, Iter 5000: loss=0.0394, ce=0.0033, dice=0.0634, grad_norm=0.221901
[18:09:18.488] Epoch 15, Iter 5010: loss=0.0223, ce=0.0020, dice=0.0359, grad_norm=0.142156
[18:09:22.711] Epoch 15, Iter 5020: loss=0.0476, ce=0.0022, dice=0.0779, grad_norm=0.531966
[18:09:26.939] Epoch 15, Iter 5030: loss=0.0426, ce=0.0047, dice=0.0678, grad_norm=0.172590
[18:09:31.157] Epoch 15, Iter 5040: loss=0.1113, ce=0.0060, dice=0.1815, grad_norm=0.438734
[18:09:35.391] Epoch 15, Iter 5050: loss=0.0274, ce=0.0029, dice=0.0437, grad_norm=0.139796
[18:09:39.610] Epoch 15, Iter 5060: loss=0.0291, ce=0.0045, dice=0.0455, grad_norm=0.105656
[18:09:43.843] Epoch 15, Iter 5070: loss=0.0184, ce=0.0055, dice=0.0269, grad_norm=0.055558
[18:09:48.058] Epoch 15, Iter 5080: loss=0.0232, ce=0.0061, dice=0.0347, grad_norm=0.068144
[18:09:52.288] Epoch 15, Iter 5090: loss=0.0185, ce=0.0030, dice=0.0288, grad_norm=0.084902
[18:09:56.513] Epoch 15, Iter 5100: loss=0.0253, ce=0.0030, dice=0.0401, grad_norm=0.122747
[18:10:00.744] Epoch 15, Iter 5110: loss=0.0175, ce=0.0043, dice=0.0263, grad_norm=0.045422
[18:10:04.970] Epoch 15, Iter 5120: loss=0.0212, ce=0.0037, dice=0.0329, grad_norm=0.051355
[18:10:09.198] Epoch 15, Iter 5130: loss=0.0210, ce=0.0049, dice=0.0318, grad_norm=0.047852
[18:10:13.422] Epoch 15, Iter 5140: loss=0.0437, ce=0.0028, dice=0.0710, grad_norm=0.481707
[18:10:17.652] Epoch 15, Iter 5150: loss=0.0293, ce=0.0032, dice=0.0466, grad_norm=0.282673
[18:10:21.870] Epoch 15, Iter 5160: loss=0.0127, ce=0.0033, dice=0.0191, grad_norm=0.106556
[18:10:26.110] Epoch 15, Iter 5170: loss=0.0266, ce=0.0019, dice=0.0430, grad_norm=0.092021
[18:10:30.329] Epoch 15, Iter 5180: loss=0.0275, ce=0.0041, dice=0.0430, grad_norm=0.130852
[18:10:34.585] Epoch 15, Iter 5190: loss=0.0236, ce=0.0064, dice=0.0350, grad_norm=0.076429
[18:10:38.675] Epoch 15, Iter 5200: loss=0.0269, ce=0.0094, dice=0.0385, grad_norm=0.087604
[18:10:39.241] Epoch 15: Avg Loss=0.0391, CE=0.0035, Dice=0.0629
[18:20:18.499] Epoch 16, Iter 5210: loss=0.0135, ce=0.0043, dice=0.0196, grad_norm=0.042610
[18:20:22.696] Epoch 16, Iter 5220: loss=0.0326, ce=0.0030, dice=0.0523, grad_norm=0.185953
[18:20:26.903] Epoch 16, Iter 5230: loss=0.0479, ce=0.0030, dice=0.0778, grad_norm=0.258727
[18:20:31.104] Epoch 16, Iter 5240: loss=0.0397, ce=0.0041, dice=0.0634, grad_norm=0.240419
[18:20:35.318] Epoch 16, Iter 5250: loss=0.0337, ce=0.0035, dice=0.0538, grad_norm=0.109795
[18:20:39.526] Epoch 16, Iter 5260: loss=0.0316, ce=0.0064, dice=0.0484, grad_norm=0.121387
[18:20:43.740] Epoch 16, Iter 5270: loss=0.2073, ce=0.0032, dice=0.3435, grad_norm=0.079961
[18:20:47.941] Epoch 16, Iter 5280: loss=0.0227, ce=0.0040, dice=0.0352, grad_norm=0.130025
[18:20:52.153] Epoch 16, Iter 5290: loss=0.0462, ce=0.0048, dice=0.0738, grad_norm=0.147023
[18:20:56.362] Epoch 16, Iter 5300: loss=0.0297, ce=0.0050, dice=0.0463, grad_norm=0.211582
[18:21:00.577] Epoch 16, Iter 5310: loss=0.0139, ce=0.0016, dice=0.0221, grad_norm=0.075962
[18:21:04.791] Epoch 16, Iter 5320: loss=0.0316, ce=0.0030, dice=0.0507, grad_norm=0.178032
[18:21:09.013] Epoch 16, Iter 5330: loss=0.0341, ce=0.0036, dice=0.0544, grad_norm=0.160468
[18:21:13.221] Epoch 16, Iter 5340: loss=0.0144, ce=0.0034, dice=0.0218, grad_norm=0.075790
[18:21:17.445] Epoch 16, Iter 5350: loss=0.0160, ce=0.0043, dice=0.0237, grad_norm=0.068602
[18:21:21.663] Epoch 16, Iter 5360: loss=0.0317, ce=0.0025, dice=0.0512, grad_norm=0.086508
[18:21:25.877] Epoch 16, Iter 5370: loss=0.0234, ce=0.0043, dice=0.0362, grad_norm=0.080905
[18:21:30.087] Epoch 16, Iter 5380: loss=0.0218, ce=0.0060, dice=0.0322, grad_norm=0.051408
[18:21:34.305] Epoch 16, Iter 5390: loss=0.0464, ce=0.0036, dice=0.0750, grad_norm=0.194522
[18:21:38.520] Epoch 16, Iter 5400: loss=0.0383, ce=0.0056, dice=0.0602, grad_norm=0.240786
[18:21:42.742] Epoch 16, Iter 5410: loss=0.0236, ce=0.0035, dice=0.0370, grad_norm=0.242738
[18:21:46.957] Epoch 16, Iter 5420: loss=0.0567, ce=0.0049, dice=0.0911, grad_norm=0.306429
[18:21:51.181] Epoch 16, Iter 5430: loss=0.0136, ce=0.0044, dice=0.0197, grad_norm=0.032371
[18:21:55.400] Epoch 16, Iter 5440: loss=0.0154, ce=0.0024, dice=0.0241, grad_norm=0.054984
[18:21:59.624] Epoch 16, Iter 5450: loss=0.0358, ce=0.0035, dice=0.0573, grad_norm=0.119703
[18:22:03.839] Epoch 16, Iter 5460: loss=0.2027, ce=0.0017, dice=0.3366, grad_norm=0.255409
[18:22:08.070] Epoch 16, Iter 5470: loss=0.0246, ce=0.0051, dice=0.0376, grad_norm=0.060780
[18:22:12.281] Epoch 16, Iter 5480: loss=0.0438, ce=0.0043, dice=0.0701, grad_norm=0.182432
[18:22:16.508] Epoch 16, Iter 5490: loss=0.0278, ce=0.0023, dice=0.0448, grad_norm=0.118370
[18:22:20.727] Epoch 16, Iter 5500: loss=0.0348, ce=0.0016, dice=0.0570, grad_norm=0.177367
[18:22:24.949] Epoch 16, Iter 5510: loss=0.0159, ce=0.0019, dice=0.0252, grad_norm=0.102272
[18:22:29.164] Epoch 16, Iter 5520: loss=0.0194, ce=0.0036, dice=0.0299, grad_norm=0.056861
[18:22:31.772] Epoch 16: Avg Loss=0.0420, CE=0.0034, Dice=0.0677
[18:22:43.780] Epoch 17, Iter 5530: loss=0.0198, ce=0.0035, dice=0.0307, grad_norm=0.061271
[18:22:47.987] Epoch 17, Iter 5540: loss=0.0127, ce=0.0019, dice=0.0200, grad_norm=0.110485
[18:22:52.208] Epoch 17, Iter 5550: loss=0.0254, ce=0.0030, dice=0.0404, grad_norm=0.181045
[18:22:56.421] Epoch 17, Iter 5560: loss=0.0195, ce=0.0045, dice=0.0294, grad_norm=0.080326
[18:23:00.637] Epoch 17, Iter 5570: loss=0.0458, ce=0.0071, dice=0.0716, grad_norm=0.156822
[18:23:04.853] Epoch 17, Iter 5580: loss=0.0222, ce=0.0027, dice=0.0352, grad_norm=0.150640
[18:23:09.076] Epoch 17, Iter 5590: loss=0.0471, ce=0.0045, dice=0.0755, grad_norm=0.171230
[18:23:13.292] Epoch 17, Iter 5600: loss=0.0161, ce=0.0019, dice=0.0255, grad_norm=0.164292
[18:23:17.517] Epoch 17, Iter 5610: loss=0.0189, ce=0.0033, dice=0.0293, grad_norm=0.074523
[18:23:21.733] Epoch 17, Iter 5620: loss=0.0211, ce=0.0017, dice=0.0340, grad_norm=0.096157
[18:23:25.954] Epoch 17, Iter 5630: loss=0.0290, ce=0.0042, dice=0.0455, grad_norm=0.130460
[18:23:30.163] Epoch 17, Iter 5640: loss=0.0382, ce=0.0061, dice=0.0595, grad_norm=0.099629
[18:23:34.390] Epoch 17, Iter 5650: loss=0.0324, ce=0.0020, dice=0.0526, grad_norm=0.136311
[18:23:38.609] Epoch 17, Iter 5660: loss=0.0470, ce=0.0050, dice=0.0751, grad_norm=0.739316
[18:23:42.835] Epoch 17, Iter 5670: loss=0.0308, ce=0.0029, dice=0.0494, grad_norm=0.163924
[18:23:47.055] Epoch 17, Iter 5680: loss=0.0184, ce=0.0039, dice=0.0281, grad_norm=0.103201
[18:23:51.288] Epoch 17, Iter 5690: loss=0.0363, ce=0.0036, dice=0.0581, grad_norm=0.134560
[18:23:55.507] Epoch 17, Iter 5700: loss=0.0189, ce=0.0065, dice=0.0272, grad_norm=0.103575
[18:23:59.735] Epoch 17, Iter 5710: loss=0.0214, ce=0.0035, dice=0.0333, grad_norm=0.079864
[18:24:03.955] Epoch 17, Iter 5720: loss=0.0369, ce=0.0025, dice=0.0598, grad_norm=0.930448
[18:24:08.187] Epoch 17, Iter 5730: loss=0.0193, ce=0.0066, dice=0.0279, grad_norm=0.101646
[18:24:12.410] Epoch 17, Iter 5740: loss=0.0313, ce=0.0029, dice=0.0502, grad_norm=0.110258
[18:24:16.639] Epoch 17, Iter 5750: loss=0.0197, ce=0.0047, dice=0.0297, grad_norm=0.119463
[18:24:20.859] Epoch 17, Iter 5760: loss=0.0430, ce=0.0035, dice=0.0693, grad_norm=0.287737
[18:24:25.105] Epoch 17, Iter 5770: loss=0.0394, ce=0.0018, dice=0.0645, grad_norm=0.241597
[18:24:29.325] Epoch 17, Iter 5780: loss=0.0224, ce=0.0047, dice=0.0342, grad_norm=0.102378
[18:24:33.555] Epoch 17, Iter 5790: loss=0.0317, ce=0.0035, dice=0.0505, grad_norm=0.215122
[18:24:37.768] Epoch 17, Iter 5800: loss=0.0502, ce=0.0020, dice=0.0823, grad_norm=0.382893
[18:24:42.004] Epoch 17, Iter 5810: loss=0.0763, ce=0.0032, dice=0.1250, grad_norm=1.216585
[18:24:46.229] Epoch 17, Iter 5820: loss=0.0249, ce=0.0054, dice=0.0379, grad_norm=0.167473
[18:24:50.463] Epoch 17, Iter 5830: loss=0.1010, ce=0.0044, dice=0.1654, grad_norm=0.920308
[18:24:54.688] Epoch 17, Iter 5840: loss=0.0312, ce=0.0033, dice=0.0499, grad_norm=0.228468
[18:24:58.784] Epoch 17, Iter 5850: loss=0.0186, ce=0.0019, dice=0.0297, grad_norm=0.214645
[18:24:59.400] Epoch 17: Avg Loss=0.0377, CE=0.0034, Dice=0.0605
[18:34:34.842] Epoch 18, Iter 5860: loss=0.0250, ce=0.0033, dice=0.0395, grad_norm=0.394276
[18:34:39.050] Epoch 18, Iter 5870: loss=0.0192, ce=0.0051, dice=0.0287, grad_norm=0.050585
[18:34:43.254] Epoch 18, Iter 5880: loss=0.0220, ce=0.0032, dice=0.0346, grad_norm=0.365423
[18:34:47.476] Epoch 18, Iter 5890: loss=0.1593, ce=0.0022, dice=0.2640, grad_norm=2.972983
[18:34:51.677] Epoch 18, Iter 5900: loss=0.0284, ce=0.0028, dice=0.0455, grad_norm=0.244223
[18:34:55.889] Epoch 18, Iter 5910: loss=0.0376, ce=0.0013, dice=0.0618, grad_norm=0.366430
[18:35:00.096] Epoch 18, Iter 5920: loss=0.0190, ce=0.0033, dice=0.0294, grad_norm=0.070353
[18:35:04.317] Epoch 18, Iter 5930: loss=0.0218, ce=0.0041, dice=0.0335, grad_norm=0.087706
[18:35:08.532] Epoch 18, Iter 5940: loss=0.0134, ce=0.0032, dice=0.0201, grad_norm=0.095245
[18:35:12.752] Epoch 18, Iter 5950: loss=0.0408, ce=0.0014, dice=0.0671, grad_norm=0.149052
[18:35:16.970] Epoch 18, Iter 5960: loss=0.0135, ce=0.0012, dice=0.0217, grad_norm=0.114989
[18:35:21.196] Epoch 18, Iter 5970: loss=0.0212, ce=0.0062, dice=0.0313, grad_norm=0.067786
[18:35:25.408] Epoch 18, Iter 5980: loss=0.0267, ce=0.0041, dice=0.0418, grad_norm=0.105593
[18:35:29.632] Epoch 18, Iter 5990: loss=0.0181, ce=0.0030, dice=0.0282, grad_norm=0.069474
[18:35:33.844] Epoch 18, Iter 6000: loss=0.0214, ce=0.0040, dice=0.0331, grad_norm=0.069161
[18:35:38.070] Epoch 18, Iter 6010: loss=0.0892, ce=0.0009, dice=0.1480, grad_norm=1.025121
[18:35:42.275] Epoch 18, Iter 6020: loss=0.0959, ce=0.0033, dice=0.1577, grad_norm=0.591510
[18:35:46.500] Epoch 18, Iter 6030: loss=0.0315, ce=0.0052, dice=0.0490, grad_norm=0.162156
[18:35:50.717] Epoch 18, Iter 6040: loss=0.0211, ce=0.0034, dice=0.0329, grad_norm=0.107669
[18:35:54.940] Epoch 18, Iter 6050: loss=0.0110, ce=0.0037, dice=0.0159, grad_norm=0.036002
[18:35:59.150] Epoch 18, Iter 6060: loss=0.0408, ce=0.0045, dice=0.0650, grad_norm=0.405946
[18:36:03.377] Epoch 18, Iter 6070: loss=0.0220, ce=0.0032, dice=0.0346, grad_norm=0.120608
[18:36:07.599] Epoch 18, Iter 6080: loss=0.0216, ce=0.0023, dice=0.0345, grad_norm=0.141642
[18:36:11.823] Epoch 18, Iter 6090: loss=0.0282, ce=0.0028, dice=0.0452, grad_norm=0.328334
[18:36:16.043] Epoch 18, Iter 6100: loss=0.0143, ce=0.0033, dice=0.0216, grad_norm=0.047895
[18:36:20.275] Epoch 18, Iter 6110: loss=0.0298, ce=0.0028, dice=0.0477, grad_norm=0.150929
[18:36:24.488] Epoch 18, Iter 6120: loss=0.0214, ce=0.0031, dice=0.0337, grad_norm=0.055495
[18:36:28.720] Epoch 18, Iter 6130: loss=0.0217, ce=0.0030, dice=0.0341, grad_norm=0.070997
[18:36:32.940] Epoch 18, Iter 6140: loss=0.0211, ce=0.0030, dice=0.0331, grad_norm=0.156558
[18:36:37.168] Epoch 18, Iter 6150: loss=0.0162, ce=0.0027, dice=0.0251, grad_norm=0.080818
[18:36:41.390] Epoch 18, Iter 6160: loss=0.0293, ce=0.0015, dice=0.0478, grad_norm=0.164891
[18:36:45.611] Epoch 18, Iter 6170: loss=0.0239, ce=0.0046, dice=0.0368, grad_norm=0.077338
[18:36:48.209] Epoch 18: Avg Loss=0.0401, CE=0.0034, Dice=0.0645
[18:37:00.138] Epoch 19, Iter 6180: loss=0.2070, ce=0.0014, dice=0.3440, grad_norm=0.056446
[18:37:04.358] Epoch 19, Iter 6190: loss=0.0158, ce=0.0043, dice=0.0234, grad_norm=0.058532
[18:37:08.558] Epoch 19, Iter 6200: loss=0.0218, ce=0.0054, dice=0.0327, grad_norm=0.084447
[18:37:12.779] Epoch 19, Iter 6210: loss=0.0336, ce=0.0027, dice=0.0541, grad_norm=0.244833
[18:37:16.998] Epoch 19, Iter 6220: loss=0.0205, ce=0.0058, dice=0.0304, grad_norm=0.065316
[18:37:21.219] Epoch 19, Iter 6230: loss=0.0197, ce=0.0050, dice=0.0295, grad_norm=0.052433
[18:37:25.430] Epoch 19, Iter 6240: loss=0.0455, ce=0.0059, dice=0.0718, grad_norm=0.203619
[18:37:29.653] Epoch 19, Iter 6250: loss=0.0373, ce=0.0036, dice=0.0598, grad_norm=0.167483
[18:37:33.868] Epoch 19, Iter 6260: loss=0.0327, ce=0.0031, dice=0.0525, grad_norm=0.190483
[18:37:38.091] Epoch 19, Iter 6270: loss=0.0208, ce=0.0028, dice=0.0328, grad_norm=0.071980
[18:37:42.298] Epoch 19, Iter 6280: loss=0.0153, ce=0.0033, dice=0.0233, grad_norm=0.094095
[18:37:46.525] Epoch 19, Iter 6290: loss=0.0314, ce=0.0028, dice=0.0505, grad_norm=0.196336
[18:37:50.745] Epoch 19, Iter 6300: loss=0.0270, ce=0.0044, dice=0.0421, grad_norm=0.131925
[18:37:54.965] Epoch 19, Iter 6310: loss=0.0178, ce=0.0047, dice=0.0265, grad_norm=0.055842
[18:37:59.184] Epoch 19, Iter 6320: loss=0.0224, ce=0.0019, dice=0.0360, grad_norm=0.175365
[18:38:03.414] Epoch 19, Iter 6330: loss=0.0287, ce=0.0021, dice=0.0464, grad_norm=0.279341
[18:38:07.630] Epoch 19, Iter 6340: loss=0.0198, ce=0.0038, dice=0.0304, grad_norm=0.083647
[18:38:11.856] Epoch 19, Iter 6350: loss=0.1477, ce=0.0029, dice=0.2442, grad_norm=4.628413
[18:38:16.078] Epoch 19, Iter 6360: loss=0.0190, ce=0.0054, dice=0.0280, grad_norm=0.067019
[18:38:20.307] Epoch 19, Iter 6370: loss=0.0173, ce=0.0046, dice=0.0258, grad_norm=0.075198
[18:38:24.535] Epoch 19, Iter 6380: loss=0.0258, ce=0.0016, dice=0.0419, grad_norm=0.104599
[18:38:28.757] Epoch 19, Iter 6390: loss=0.0189, ce=0.0054, dice=0.0278, grad_norm=0.102720
[18:38:32.973] Epoch 19, Iter 6400: loss=0.0351, ce=0.0021, dice=0.0570, grad_norm=0.263121
[18:38:37.209] Epoch 19, Iter 6410: loss=0.0181, ce=0.0037, dice=0.0278, grad_norm=0.061446
[18:38:41.429] Epoch 19, Iter 6420: loss=0.0204, ce=0.0029, dice=0.0321, grad_norm=0.123032
[18:38:45.654] Epoch 19, Iter 6430: loss=0.0184, ce=0.0049, dice=0.0275, grad_norm=0.119134
[18:38:49.879] Epoch 19, Iter 6440: loss=0.0256, ce=0.0031, dice=0.0407, grad_norm=0.186461
[18:38:54.111] Epoch 19, Iter 6450: loss=0.0318, ce=0.0067, dice=0.0485, grad_norm=0.175982
[18:38:58.335] Epoch 19, Iter 6460: loss=0.0226, ce=0.0023, dice=0.0362, grad_norm=0.186391
[18:39:02.559] Epoch 19, Iter 6470: loss=0.0226, ce=0.0008, dice=0.0371, grad_norm=0.503911
[18:39:06.788] Epoch 19, Iter 6480: loss=0.0301, ce=0.0030, dice=0.0482, grad_norm=0.511479
[18:39:11.024] Epoch 19, Iter 6490: loss=0.0371, ce=0.0021, dice=0.0604, grad_norm=0.112552
[18:39:15.110] Epoch 19, Iter 6500: loss=0.0880, ce=0.0029, dice=0.1448, grad_norm=0.755702
[18:39:15.723] Epoch 19: Avg Loss=0.0390, CE=0.0034, Dice=0.0628
[18:48:30.979] save model to ./finetune_tpgm_lits17\finetuned_epoch_19.pth
[18:48:31.138] save final model to ./finetune_tpgm_lits17\finetuned_final.pth
