[00:32:37.040] Namespace(root_path='./datasets/lits17/train_npz', dataset='lits17', list_dir='./lists/lits17', num_classes=3, model_num_classes=9, output_dir='./finetune_tpgm_surgical_lits17', max_iterations=10000, max_epochs=25, batch_size=24, n_gpu=1, deterministic=1, base_lr=0.0005, img_size=224, seed=1234, cfg='configs/finetune.yaml', pretrained_path='./finetune_tpgm_kits23_debug/finetuned_final.pth', data_fraction=0.7, freeze_layers=0, opts=None, zip=False, cache_mode='part', resume=None, accumulation_steps=None, use_checkpoint=False, amp_opt_level='O1', tag=None, eval=False, throughput=False, tpgm_norm_mode='l2', tpgm_lr=0.01, tpgm_iters=100, tpgm_exclude=[], tpgm_frequency=3, tpgm_start_epoch=8, disable_tpgm=False, auto_tune='RGN', gradient_batches=5, surgical_frequency=4, surgical_start_epoch=5, gpu_id=1)
[00:32:37.045] --- Combined TPGM + Surgical Fine-tuning on dataset: LITS17 ---
[00:32:37.045] Using 10390/14843 samples for finetuning
[00:32:37.045] Using 50/14843 samples for TPGM
[00:32:37.045] TPGM enabled: True
[00:32:37.045] Surgical tuning method: RGN
[00:32:48.530] 433 iterations per epoch
[00:33:03.441] Epoch 0, Iter 10: loss=0.2508, ce=0.0192, dice=0.4053, grad_norm=1.582542
[00:33:06.585] Epoch 0, Iter 20: loss=0.2244, ce=0.0125, dice=0.3656, grad_norm=1.199422
[00:33:09.801] Epoch 0, Iter 30: loss=0.0683, ce=0.0208, dice=0.1000, grad_norm=1.291842
[00:33:12.932] Epoch 0, Iter 40: loss=0.2346, ce=0.0103, dice=0.3842, grad_norm=0.673991
[00:33:16.073] Epoch 0, Iter 50: loss=0.1834, ce=0.0133, dice=0.2968, grad_norm=0.980991
[00:33:19.207] Epoch 0, Iter 60: loss=0.2176, ce=0.0249, dice=0.3461, grad_norm=0.730561
[00:33:22.362] Epoch 0, Iter 70: loss=0.1260, ce=0.0111, dice=0.2026, grad_norm=0.809066
[00:33:25.498] Epoch 0, Iter 80: loss=0.2431, ce=0.0169, dice=0.3939, grad_norm=0.592532
[00:33:28.650] Epoch 0, Iter 90: loss=0.1463, ce=0.0162, dice=0.2330, grad_norm=0.631053
[00:33:31.794] Epoch 0, Iter 100: loss=0.0925, ce=0.0107, dice=0.1469, grad_norm=0.415194
[00:33:34.941] Epoch 0, Iter 110: loss=0.0879, ce=0.0186, dice=0.1341, grad_norm=0.890461
[00:33:38.084] Epoch 0, Iter 120: loss=0.1078, ce=0.0160, dice=0.1691, grad_norm=0.556454
[00:33:41.243] Epoch 0, Iter 130: loss=0.1238, ce=0.0170, dice=0.1949, grad_norm=2.736730
[00:33:44.430] Epoch 0, Iter 140: loss=0.1659, ce=0.0191, dice=0.2638, grad_norm=1.219064
[00:33:47.595] Epoch 0, Iter 150: loss=0.1401, ce=0.0231, dice=0.2181, grad_norm=1.368200
[00:33:50.741] Epoch 0, Iter 160: loss=0.1289, ce=0.0178, dice=0.2030, grad_norm=0.664357
[00:33:53.903] Epoch 0, Iter 170: loss=0.1052, ce=0.0168, dice=0.1641, grad_norm=0.682828
[00:33:57.045] Epoch 0, Iter 180: loss=0.1595, ce=0.0047, dice=0.2626, grad_norm=1.191496
[00:34:00.207] Epoch 0, Iter 190: loss=0.0349, ce=0.0094, dice=0.0520, grad_norm=0.122942
[00:34:03.356] Epoch 0, Iter 200: loss=0.0604, ce=0.0100, dice=0.0941, grad_norm=2.033869
[00:34:06.511] Epoch 0, Iter 210: loss=0.0469, ce=0.0123, dice=0.0700, grad_norm=0.546605
[00:34:09.657] Epoch 0, Iter 220: loss=0.1909, ce=0.0133, dice=0.3092, grad_norm=2.244832
[00:34:12.816] Epoch 0, Iter 230: loss=0.0667, ce=0.0150, dice=0.1011, grad_norm=0.701654
[00:34:15.972] Epoch 0, Iter 240: loss=0.0292, ce=0.0041, dice=0.0460, grad_norm=0.474711
[00:34:19.131] Epoch 0, Iter 250: loss=0.0810, ce=0.0253, dice=0.1180, grad_norm=0.803577
[00:34:22.280] Epoch 0, Iter 260: loss=0.0735, ce=0.0101, dice=0.1157, grad_norm=0.424649
[00:34:25.453] Epoch 0, Iter 270: loss=0.1203, ce=0.0265, dice=0.1829, grad_norm=0.883507
[00:34:28.600] Epoch 0, Iter 280: loss=0.2383, ce=0.0184, dice=0.3849, grad_norm=0.292087
[00:34:31.761] Epoch 0, Iter 290: loss=0.1123, ce=0.0123, dice=0.1789, grad_norm=1.322895
[00:34:34.925] Epoch 0, Iter 300: loss=0.0881, ce=0.0072, dice=0.1420, grad_norm=0.605525
[00:34:38.106] Epoch 0, Iter 310: loss=0.0494, ce=0.0079, dice=0.0771, grad_norm=0.566804
[00:34:41.267] Epoch 0, Iter 320: loss=0.0566, ce=0.0113, dice=0.0868, grad_norm=0.661509
[00:34:44.442] Epoch 0, Iter 330: loss=0.2241, ce=0.0039, dice=0.3708, grad_norm=0.308388
[00:34:47.600] Epoch 0, Iter 340: loss=0.1457, ce=0.0229, dice=0.2276, grad_norm=0.553294
[00:34:50.783] Epoch 0, Iter 350: loss=0.0835, ce=0.0094, dice=0.1329, grad_norm=0.547326
[00:34:53.944] Epoch 0, Iter 360: loss=0.0607, ce=0.0156, dice=0.0908, grad_norm=0.424703
[00:34:57.105] Epoch 0, Iter 370: loss=0.0705, ce=0.0066, dice=0.1130, grad_norm=0.572519
[00:35:00.252] Epoch 0, Iter 380: loss=0.0990, ce=0.0063, dice=0.1608, grad_norm=1.243396
[00:35:03.405] Epoch 0, Iter 390: loss=0.0809, ce=0.0085, dice=0.1293, grad_norm=1.671187
[00:35:06.572] Epoch 0, Iter 400: loss=0.2001, ce=0.0245, dice=0.3171, grad_norm=1.574789
[00:35:09.841] Epoch 0, Iter 410: loss=0.1115, ce=0.0257, dice=0.1687, grad_norm=0.371386
[00:35:12.996] Epoch 0, Iter 420: loss=0.1375, ce=0.0157, dice=0.2187, grad_norm=1.477567
[00:35:16.155] Epoch 0, Iter 430: loss=0.1141, ce=0.0266, dice=0.1724, grad_norm=1.511532
[00:35:17.701] Epoch 0: Avg Loss=0.1379, CE=0.0169, Dice=0.2185
[00:35:30.898] Epoch 1, Iter 440: loss=0.0354, ce=0.0045, dice=0.0559, grad_norm=0.264779
[00:35:34.057] Epoch 1, Iter 450: loss=0.0610, ce=0.0177, dice=0.0899, grad_norm=0.709178
[00:35:37.223] Epoch 1, Iter 460: loss=0.1161, ce=0.0199, dice=0.1803, grad_norm=0.606027
[00:35:40.387] Epoch 1, Iter 470: loss=0.2271, ce=0.0203, dice=0.3649, grad_norm=0.169058
[00:35:43.532] Epoch 1, Iter 480: loss=0.1389, ce=0.0133, dice=0.2227, grad_norm=1.576782
[00:35:46.700] Epoch 1, Iter 490: loss=0.0405, ce=0.0023, dice=0.0659, grad_norm=0.556323
[00:35:49.857] Epoch 1, Iter 500: loss=0.0283, ce=0.0100, dice=0.0404, grad_norm=0.105043
[00:35:53.026] Epoch 1, Iter 510: loss=0.0765, ce=0.0203, dice=0.1139, grad_norm=0.342268
[00:35:56.187] Epoch 1, Iter 520: loss=0.0349, ce=0.0091, dice=0.0521, grad_norm=0.313977
[00:35:59.353] Epoch 1, Iter 530: loss=0.0782, ce=0.0125, dice=0.1220, grad_norm=0.719023
[00:36:02.501] Epoch 1, Iter 540: loss=0.0762, ce=0.0076, dice=0.1219, grad_norm=0.195535
[00:36:05.670] Epoch 1, Iter 550: loss=0.0455, ce=0.0109, dice=0.0686, grad_norm=0.140325
[00:36:08.835] Epoch 1, Iter 560: loss=0.0423, ce=0.0086, dice=0.0648, grad_norm=0.159106
[00:36:12.009] Epoch 1, Iter 570: loss=0.2222, ce=0.0102, dice=0.3636, grad_norm=1.113012
[00:36:15.170] Epoch 1, Iter 580: loss=0.0877, ce=0.0078, dice=0.1410, grad_norm=0.936192
[00:36:18.333] Epoch 1, Iter 590: loss=0.0862, ce=0.0143, dice=0.1342, grad_norm=0.974616
[00:36:21.484] Epoch 1, Iter 600: loss=0.0505, ce=0.0106, dice=0.0770, grad_norm=0.455309
[00:36:24.652] Epoch 1, Iter 610: loss=0.0527, ce=0.0152, dice=0.0777, grad_norm=0.272328
[00:36:27.833] Epoch 1, Iter 620: loss=0.0578, ce=0.0033, dice=0.0941, grad_norm=1.714933
[00:36:31.004] Epoch 1, Iter 630: loss=0.1725, ce=0.0349, dice=0.2642, grad_norm=1.408051
[00:36:34.170] Epoch 1, Iter 640: loss=0.2219, ce=0.0124, dice=0.3615, grad_norm=0.121974
[00:36:37.332] Epoch 1, Iter 650: loss=0.0790, ce=0.0117, dice=0.1239, grad_norm=0.426757
[00:36:40.490] Epoch 1, Iter 660: loss=0.0695, ce=0.0047, dice=0.1127, grad_norm=1.020693
[00:36:43.656] Epoch 1, Iter 670: loss=0.0486, ce=0.0098, dice=0.0745, grad_norm=0.645342
[00:36:46.827] Epoch 1, Iter 680: loss=0.0892, ce=0.0077, dice=0.1435, grad_norm=0.838802
[00:36:49.992] Epoch 1, Iter 690: loss=0.1297, ce=0.0080, dice=0.2108, grad_norm=2.322313
[00:36:53.162] Epoch 1, Iter 700: loss=0.0678, ce=0.0092, dice=0.1068, grad_norm=0.952764
[00:36:56.331] Epoch 1, Iter 710: loss=0.1076, ce=0.0067, dice=0.1749, grad_norm=0.699470
[00:36:59.491] Epoch 1, Iter 720: loss=0.2139, ce=0.0246, dice=0.3402, grad_norm=1.064283
[00:37:02.657] Epoch 1, Iter 730: loss=0.0496, ce=0.0082, dice=0.0772, grad_norm=0.355692
[00:37:05.830] Epoch 1, Iter 740: loss=0.0442, ce=0.0075, dice=0.0687, grad_norm=0.240937
[00:37:09.018] Epoch 1, Iter 750: loss=0.0819, ce=0.0102, dice=0.1296, grad_norm=1.351348
[00:37:12.185] Epoch 1, Iter 760: loss=0.0859, ce=0.0173, dice=0.1317, grad_norm=0.944420
[00:37:15.359] Epoch 1, Iter 770: loss=0.0452, ce=0.0057, dice=0.0716, grad_norm=0.396475
[00:37:18.511] Epoch 1, Iter 780: loss=0.0486, ce=0.0055, dice=0.0773, grad_norm=1.212367
[00:37:21.692] Epoch 1, Iter 790: loss=0.0297, ce=0.0060, dice=0.0454, grad_norm=0.179492
[00:37:24.868] Epoch 1, Iter 800: loss=0.1008, ce=0.0206, dice=0.1542, grad_norm=1.374421
[00:37:28.056] Epoch 1, Iter 810: loss=0.0857, ce=0.0053, dice=0.1392, grad_norm=1.537535
[00:37:31.221] Epoch 1, Iter 820: loss=0.0979, ce=0.0081, dice=0.1578, grad_norm=2.036930
[00:37:34.387] Epoch 1, Iter 830: loss=0.0595, ce=0.0120, dice=0.0912, grad_norm=1.267595
[00:37:37.544] Epoch 1, Iter 840: loss=0.1170, ce=0.0093, dice=0.1888, grad_norm=1.980423
[00:37:40.720] Epoch 1, Iter 850: loss=0.0915, ce=0.0089, dice=0.1465, grad_norm=1.051378
[00:37:43.882] Epoch 1, Iter 860: loss=0.1174, ce=0.0070, dice=0.1911, grad_norm=1.305739
[00:37:46.407] Epoch 1: Avg Loss=0.1057, CE=0.0108, Dice=0.1691
[00:37:58.717] Epoch 2, Iter 870: loss=0.1276, ce=0.0050, dice=0.2093, grad_norm=0.410431
[00:38:01.878] Epoch 2, Iter 880: loss=0.0939, ce=0.0096, dice=0.1501, grad_norm=0.760984
[00:38:05.036] Epoch 2, Iter 890: loss=0.0642, ce=0.0102, dice=0.1003, grad_norm=0.241312
[00:38:08.192] Epoch 2, Iter 900: loss=0.0368, ce=0.0080, dice=0.0560, grad_norm=0.170927
[00:38:11.365] Epoch 2, Iter 910: loss=0.0367, ce=0.0075, dice=0.0561, grad_norm=0.187734
[00:38:14.540] Epoch 2, Iter 920: loss=0.1347, ce=0.0092, dice=0.2184, grad_norm=1.058315
[00:38:17.720] Epoch 2, Iter 930: loss=0.0508, ce=0.0061, dice=0.0806, grad_norm=0.590769
[00:38:20.886] Epoch 2, Iter 940: loss=0.2094, ce=0.0080, dice=0.3437, grad_norm=0.206082
[00:38:24.051] Epoch 2, Iter 950: loss=0.0475, ce=0.0077, dice=0.0740, grad_norm=0.213075
[00:38:27.203] Epoch 2, Iter 960: loss=0.0514, ce=0.0120, dice=0.0777, grad_norm=0.449433
[00:38:30.368] Epoch 2, Iter 970: loss=0.1102, ce=0.0073, dice=0.1788, grad_norm=0.966413
[00:38:33.536] Epoch 2, Iter 980: loss=0.0736, ce=0.0092, dice=0.1166, grad_norm=0.471540
[00:38:36.702] Epoch 2, Iter 990: loss=0.0509, ce=0.0068, dice=0.0804, grad_norm=0.382400
[00:38:39.860] Epoch 2, Iter 1000: loss=0.0413, ce=0.0069, dice=0.0642, grad_norm=0.642640
[00:38:43.030] Epoch 2, Iter 1010: loss=0.0632, ce=0.0067, dice=0.1008, grad_norm=0.494647
[00:38:46.180] Epoch 2, Iter 1020: loss=0.0367, ce=0.0070, dice=0.0566, grad_norm=0.201379
[00:38:49.352] Epoch 2, Iter 1030: loss=0.2120, ce=0.0070, dice=0.3486, grad_norm=0.059451
[00:38:52.519] Epoch 2, Iter 1040: loss=0.1318, ce=0.0068, dice=0.2151, grad_norm=2.372053
[00:38:55.694] Epoch 2, Iter 1050: loss=0.0507, ce=0.0213, dice=0.0703, grad_norm=0.568432
[00:38:58.859] Epoch 2, Iter 1060: loss=0.0593, ce=0.0185, dice=0.0865, grad_norm=0.341230
[00:39:02.035] Epoch 2, Iter 1070: loss=0.0649, ce=0.0098, dice=0.1016, grad_norm=0.346162
[00:39:05.195] Epoch 2, Iter 1080: loss=0.0348, ce=0.0107, dice=0.0508, grad_norm=0.156230
[00:39:08.370] Epoch 2, Iter 1090: loss=0.0465, ce=0.0068, dice=0.0729, grad_norm=1.171277
[00:39:11.524] Epoch 2, Iter 1100: loss=0.0347, ce=0.0127, dice=0.0494, grad_norm=0.536351
[00:39:14.695] Epoch 2, Iter 1110: loss=0.0779, ce=0.0120, dice=0.1218, grad_norm=0.375482
[00:39:17.860] Epoch 2, Iter 1120: loss=0.0373, ce=0.0123, dice=0.0540, grad_norm=0.200357
[00:39:21.025] Epoch 2, Iter 1130: loss=0.0372, ce=0.0066, dice=0.0575, grad_norm=0.194520
[00:39:24.177] Epoch 2, Iter 1140: loss=0.0356, ce=0.0042, dice=0.0565, grad_norm=0.642065
[00:39:27.350] Epoch 2, Iter 1150: loss=0.0389, ce=0.0094, dice=0.0586, grad_norm=0.195629
[00:39:30.513] Epoch 2, Iter 1160: loss=0.0477, ce=0.0197, dice=0.0664, grad_norm=0.472173
[00:39:33.686] Epoch 2, Iter 1170: loss=0.1289, ce=0.0070, dice=0.2102, grad_norm=1.449481
[00:39:36.847] Epoch 2, Iter 1180: loss=0.1051, ce=0.0150, dice=0.1651, grad_norm=0.953553
[00:39:40.011] Epoch 2, Iter 1190: loss=0.0297, ce=0.0101, dice=0.0428, grad_norm=0.214323
[00:39:43.172] Epoch 2, Iter 1200: loss=0.1986, ce=0.0082, dice=0.3255, grad_norm=0.772929
[00:39:46.339] Epoch 2, Iter 1210: loss=0.2060, ce=0.0013, dice=0.3425, grad_norm=0.039423
[00:39:49.506] Epoch 2, Iter 1220: loss=0.0444, ce=0.0072, dice=0.0692, grad_norm=0.252283
[00:39:52.680] Epoch 2, Iter 1230: loss=0.1064, ce=0.0057, dice=0.1736, grad_norm=0.221116
[00:39:55.846] Epoch 2, Iter 1240: loss=0.2102, ce=0.0073, dice=0.3455, grad_norm=0.283065
[00:39:59.009] Epoch 2, Iter 1250: loss=0.1593, ce=0.0059, dice=0.2615, grad_norm=0.529395
[00:40:02.170] Epoch 2, Iter 1260: loss=0.0632, ce=0.0095, dice=0.0990, grad_norm=3.950480
[00:40:05.339] Epoch 2, Iter 1270: loss=0.0380, ce=0.0119, dice=0.0553, grad_norm=0.137828
[00:40:08.507] Epoch 2, Iter 1280: loss=0.0423, ce=0.0140, dice=0.0611, grad_norm=0.119047
[00:40:11.685] Epoch 2, Iter 1290: loss=0.0997, ce=0.0095, dice=0.1598, grad_norm=0.760478
[00:40:15.119] Epoch 2: Avg Loss=0.0915, CE=0.0088, Dice=0.1467
[00:40:26.318] Epoch 3, Iter 1300: loss=0.1852, ce=0.0110, dice=0.3013, grad_norm=1.073360
[00:40:29.470] Epoch 3, Iter 1310: loss=0.0543, ce=0.0142, dice=0.0809, grad_norm=0.216907
[00:40:32.624] Epoch 3, Iter 1320: loss=0.0885, ce=0.0237, dice=0.1317, grad_norm=0.263180
[00:40:35.793] Epoch 3, Iter 1330: loss=0.0820, ce=0.0110, dice=0.1293, grad_norm=0.553464
[00:40:38.951] Epoch 3, Iter 1340: loss=0.0265, ce=0.0058, dice=0.0403, grad_norm=0.254982
[00:40:42.118] Epoch 3, Iter 1350: loss=0.0321, ce=0.0064, dice=0.0493, grad_norm=0.309092
[00:40:45.281] Epoch 3, Iter 1360: loss=0.0595, ce=0.0081, dice=0.0938, grad_norm=0.631455
[00:40:48.453] Epoch 3, Iter 1370: loss=0.2200, ce=0.0122, dice=0.3585, grad_norm=0.116192
[00:40:51.610] Epoch 3, Iter 1380: loss=0.0526, ce=0.0199, dice=0.0744, grad_norm=0.292134
[00:40:54.784] Epoch 3, Iter 1390: loss=0.0807, ce=0.0106, dice=0.1274, grad_norm=0.382859
[00:40:57.948] Epoch 3, Iter 1400: loss=0.1458, ce=0.0092, dice=0.2369, grad_norm=0.909970
[00:41:01.136] Epoch 3, Iter 1410: loss=0.0259, ce=0.0097, dice=0.0368, grad_norm=0.198735
[00:41:04.300] Epoch 3, Iter 1420: loss=0.2117, ce=0.0056, dice=0.3491, grad_norm=1.531968
[00:41:07.480] Epoch 3, Iter 1430: loss=0.0285, ce=0.0053, dice=0.0440, grad_norm=0.210629
[00:41:10.638] Epoch 3, Iter 1440: loss=0.0497, ce=0.0090, dice=0.0769, grad_norm=0.349494
[00:41:13.809] Epoch 3, Iter 1450: loss=0.0333, ce=0.0109, dice=0.0483, grad_norm=0.181382
[00:41:16.977] Epoch 3, Iter 1460: loss=0.0819, ce=0.0245, dice=0.1202, grad_norm=1.183277
[00:41:20.161] Epoch 3, Iter 1470: loss=0.0302, ce=0.0079, dice=0.0451, grad_norm=0.120132
[00:41:23.328] Epoch 3, Iter 1480: loss=0.0428, ce=0.0072, dice=0.0666, grad_norm=0.303562
[00:41:26.498] Epoch 3, Iter 1490: loss=0.0337, ce=0.0026, dice=0.0544, grad_norm=0.200111
[00:41:29.661] Epoch 3, Iter 1500: loss=0.2103, ce=0.0055, dice=0.3469, grad_norm=0.045444
[00:41:32.837] Epoch 3, Iter 1510: loss=0.0578, ce=0.0152, dice=0.0862, grad_norm=0.457470
[00:41:36.006] Epoch 3, Iter 1520: loss=0.0329, ce=0.0096, dice=0.0484, grad_norm=0.154587
[00:41:39.184] Epoch 3, Iter 1530: loss=0.0939, ce=0.0084, dice=0.1510, grad_norm=1.096554
[00:41:42.337] Epoch 3, Iter 1540: loss=0.0730, ce=0.0097, dice=0.1153, grad_norm=0.681708
[00:41:45.501] Epoch 3, Iter 1550: loss=0.0786, ce=0.0061, dice=0.1270, grad_norm=0.519386
[00:41:48.653] Epoch 3, Iter 1560: loss=0.0367, ce=0.0051, dice=0.0578, grad_norm=0.508217
[00:41:51.819] Epoch 3, Iter 1570: loss=0.0704, ce=0.0055, dice=0.1137, grad_norm=0.798443
[00:41:54.981] Epoch 3, Iter 1580: loss=0.2144, ce=0.0062, dice=0.3532, grad_norm=0.180730
[00:41:58.153] Epoch 3, Iter 1590: loss=0.2017, ce=0.0074, dice=0.3312, grad_norm=0.369974
[00:42:01.319] Epoch 3, Iter 1600: loss=0.2109, ce=0.0069, dice=0.3468, grad_norm=0.036931
[00:42:04.495] Epoch 3, Iter 1610: loss=0.1321, ce=0.0033, dice=0.2179, grad_norm=4.911667
[00:42:07.664] Epoch 3, Iter 1620: loss=0.2156, ce=0.0057, dice=0.3555, grad_norm=0.192967
[00:42:10.934] Epoch 3, Iter 1630: loss=0.1257, ce=0.0056, dice=0.2057, grad_norm=0.919084
[00:42:14.107] Epoch 3, Iter 1640: loss=0.0416, ce=0.0059, dice=0.0653, grad_norm=0.451060
[00:42:17.281] Epoch 3, Iter 1650: loss=0.1821, ce=0.0156, dice=0.2930, grad_norm=2.225178
[00:42:20.451] Epoch 3, Iter 1660: loss=0.2194, ce=0.0097, dice=0.3591, grad_norm=0.259502
[00:42:23.613] Epoch 3, Iter 1670: loss=0.0450, ce=0.0055, dice=0.0713, grad_norm=0.235679
[00:42:26.775] Epoch 3, Iter 1680: loss=0.1387, ce=0.0085, dice=0.2255, grad_norm=0.889710
[00:42:29.952] Epoch 3, Iter 1690: loss=0.0723, ce=0.0034, dice=0.1181, grad_norm=0.676925
[00:42:33.126] Epoch 3, Iter 1700: loss=0.0285, ce=0.0022, dice=0.0460, grad_norm=0.607130
[00:42:36.308] Epoch 3, Iter 1710: loss=0.0471, ce=0.0072, dice=0.0736, grad_norm=0.367651
[00:42:39.475] Epoch 3, Iter 1720: loss=0.0344, ce=0.0126, dice=0.0489, grad_norm=0.175305
[00:42:42.652] Epoch 3, Iter 1730: loss=0.0659, ce=0.0123, dice=0.1016, grad_norm=0.539138
[00:42:43.878] Epoch 3: Avg Loss=0.0917, CE=0.0097, Dice=0.1464
[00:42:57.291] Epoch 4, Iter 1740: loss=0.0449, ce=0.0111, dice=0.0674, grad_norm=0.272992
[00:43:00.448] Epoch 4, Iter 1750: loss=0.0364, ce=0.0087, dice=0.0548, grad_norm=0.119613
[00:43:03.593] Epoch 4, Iter 1760: loss=0.0320, ce=0.0058, dice=0.0495, grad_norm=0.197049
[00:43:06.747] Epoch 4, Iter 1770: loss=0.0414, ce=0.0108, dice=0.0619, grad_norm=0.322429
[00:43:09.896] Epoch 4, Iter 1780: loss=0.0609, ce=0.0067, dice=0.0971, grad_norm=0.420066
[00:43:13.048] Epoch 4, Iter 1790: loss=0.0583, ce=0.0334, dice=0.0750, grad_norm=0.595128
[00:43:16.194] Epoch 4, Iter 1800: loss=0.0516, ce=0.0122, dice=0.0779, grad_norm=0.068527
[00:43:19.351] Epoch 4, Iter 1810: loss=0.0385, ce=0.0083, dice=0.0585, grad_norm=0.123434
[00:43:22.490] Epoch 4, Iter 1820: loss=0.0547, ce=0.0087, dice=0.0854, grad_norm=0.187002
[00:43:25.649] Epoch 4, Iter 1830: loss=0.0582, ce=0.0069, dice=0.0924, grad_norm=0.452995
[00:43:28.807] Epoch 4, Iter 1840: loss=0.2087, ce=0.0022, dice=0.3464, grad_norm=0.330533
[00:43:31.977] Epoch 4, Iter 1850: loss=0.0739, ce=0.0035, dice=0.1208, grad_norm=1.190019
[00:43:35.138] Epoch 4, Iter 1860: loss=0.0699, ce=0.0090, dice=0.1105, grad_norm=0.216708
[00:43:38.306] Epoch 4, Iter 1870: loss=0.1865, ce=0.0027, dice=0.3090, grad_norm=0.728880
[00:43:41.456] Epoch 4, Iter 1880: loss=0.2098, ce=0.0043, dice=0.3469, grad_norm=0.111393
[00:43:44.616] Epoch 4, Iter 1890: loss=0.0850, ce=0.0093, dice=0.1356, grad_norm=0.402624
[00:43:47.759] Epoch 4, Iter 1900: loss=0.0429, ce=0.0054, dice=0.0678, grad_norm=0.242058
[00:43:50.923] Epoch 4, Iter 1910: loss=0.0427, ce=0.0061, dice=0.0672, grad_norm=0.286942
[00:43:54.091] Epoch 4, Iter 1920: loss=0.0687, ce=0.0095, dice=0.1082, grad_norm=0.630699
[00:43:57.254] Epoch 4, Iter 1930: loss=0.0372, ce=0.0100, dice=0.0553, grad_norm=0.171525
[00:44:00.412] Epoch 4, Iter 1940: loss=0.0378, ce=0.0079, dice=0.0577, grad_norm=0.428894
[00:44:03.576] Epoch 4, Iter 1950: loss=0.0494, ce=0.0072, dice=0.0776, grad_norm=0.169291
[00:44:06.723] Epoch 4, Iter 1960: loss=0.0577, ce=0.0102, dice=0.0894, grad_norm=0.215162
[00:44:09.905] Epoch 4, Iter 1970: loss=0.1447, ce=0.0073, dice=0.2363, grad_norm=0.428033
[00:44:13.059] Epoch 4, Iter 1980: loss=0.0418, ce=0.0066, dice=0.0653, grad_norm=0.351523
[00:44:16.231] Epoch 4, Iter 1990: loss=0.0345, ce=0.0099, dice=0.0509, grad_norm=0.178082
[00:44:19.389] Epoch 4, Iter 2000: loss=0.0883, ce=0.0090, dice=0.1411, grad_norm=0.681879
[00:44:22.569] Epoch 4, Iter 2010: loss=0.0679, ce=0.0059, dice=0.1093, grad_norm=0.878185
[00:44:25.731] Epoch 4, Iter 2020: loss=0.1138, ce=0.0183, dice=0.1775, grad_norm=1.236463
[00:44:28.905] Epoch 4, Iter 2030: loss=0.0851, ce=0.0099, dice=0.1351, grad_norm=1.004527
[00:44:32.065] Epoch 4, Iter 2040: loss=0.2286, ce=0.0023, dice=0.3795, grad_norm=0.478062
[00:44:35.234] Epoch 4, Iter 2050: loss=0.2136, ce=0.0038, dice=0.3535, grad_norm=0.150086
[00:44:38.384] Epoch 4, Iter 2060: loss=0.0515, ce=0.0049, dice=0.0825, grad_norm=0.715093
[00:44:41.548] Epoch 4, Iter 2070: loss=0.0324, ce=0.0034, dice=0.0518, grad_norm=0.191484
[00:44:44.706] Epoch 4, Iter 2080: loss=0.0529, ce=0.0043, dice=0.0854, grad_norm=0.932135
[00:44:47.883] Epoch 4, Iter 2090: loss=0.0367, ce=0.0028, dice=0.0593, grad_norm=0.253247
[00:44:51.051] Epoch 4, Iter 2100: loss=0.1823, ce=0.0044, dice=0.3008, grad_norm=0.497986
[00:44:54.242] Epoch 4, Iter 2110: loss=0.0780, ce=0.0035, dice=0.1276, grad_norm=0.266610
[00:44:57.398] Epoch 4, Iter 2120: loss=0.0452, ce=0.0025, dice=0.0737, grad_norm=0.353895
[00:45:00.570] Epoch 4, Iter 2130: loss=0.2068, ce=0.0058, dice=0.3408, grad_norm=0.199899
[00:45:03.717] Epoch 4, Iter 2140: loss=0.0942, ce=0.0111, dice=0.1497, grad_norm=1.554556
[00:45:06.884] Epoch 4, Iter 2150: loss=0.0354, ce=0.0047, dice=0.0559, grad_norm=0.134356
[00:45:10.051] Epoch 4, Iter 2160: loss=0.1787, ce=0.0041, dice=0.2950, grad_norm=0.669524
[00:45:12.202] Epoch 4: Avg Loss=0.0805, CE=0.0078, Dice=0.1290
[00:45:24.480] Epoch 5, Iter 2170: loss=0.0285, ce=0.0054, dice=0.0440, grad_norm=0.213228
[00:45:27.620] Epoch 5, Iter 2180: loss=0.0842, ce=0.0112, dice=0.1329, grad_norm=0.555931
[00:45:30.779] Epoch 5, Iter 2190: loss=0.0461, ce=0.0064, dice=0.0726, grad_norm=0.384159
[00:45:33.923] Epoch 5, Iter 2200: loss=0.0303, ce=0.0089, dice=0.0445, grad_norm=0.206830
[00:45:37.091] Epoch 5, Iter 2210: loss=0.0758, ce=0.0078, dice=0.1212, grad_norm=6.672824
[00:45:40.252] Epoch 5, Iter 2220: loss=0.0409, ce=0.0057, dice=0.0644, grad_norm=0.173859
[00:45:43.402] Epoch 5, Iter 2230: loss=0.0218, ce=0.0077, dice=0.0312, grad_norm=0.057937
[00:45:46.542] Epoch 5, Iter 2240: loss=0.2132, ce=0.0066, dice=0.3509, grad_norm=0.053627
[00:45:49.698] Epoch 5, Iter 2250: loss=0.1303, ce=0.0122, dice=0.2091, grad_norm=1.621613
[00:45:52.831] Epoch 5, Iter 2260: loss=0.0807, ce=0.0046, dice=0.1314, grad_norm=1.166248
[00:45:56.002] Epoch 5, Iter 2270: loss=0.0753, ce=0.0076, dice=0.1205, grad_norm=0.893875
[00:45:59.145] Epoch 5, Iter 2280: loss=0.0748, ce=0.0069, dice=0.1201, grad_norm=0.377779
[00:46:02.301] Epoch 5, Iter 2290: loss=0.2084, ce=0.0053, dice=0.3437, grad_norm=0.087075
[00:46:05.439] Epoch 5, Iter 2300: loss=0.0486, ce=0.0075, dice=0.0760, grad_norm=0.280767
[00:46:08.588] Epoch 5, Iter 2310: loss=0.0561, ce=0.0061, dice=0.0894, grad_norm=0.944260
[00:46:11.733] Epoch 5, Iter 2320: loss=0.1267, ce=0.0079, dice=0.2058, grad_norm=0.908142
[00:46:14.885] Epoch 5, Iter 2330: loss=0.0860, ce=0.0071, dice=0.1386, grad_norm=0.952977
[00:46:18.040] Epoch 5, Iter 2340: loss=0.0493, ce=0.0156, dice=0.0717, grad_norm=0.337481
[00:46:21.210] Epoch 5, Iter 2350: loss=0.0310, ce=0.0040, dice=0.0490, grad_norm=0.148626
[00:46:24.367] Epoch 5, Iter 2360: loss=0.0488, ce=0.0090, dice=0.0753, grad_norm=0.771332
[00:46:27.551] Epoch 5, Iter 2370: loss=0.0391, ce=0.0043, dice=0.0623, grad_norm=0.133660
[00:46:30.709] Epoch 5, Iter 2380: loss=0.0321, ce=0.0146, dice=0.0437, grad_norm=0.154268
[00:46:33.895] Epoch 5, Iter 2390: loss=0.0214, ce=0.0061, dice=0.0317, grad_norm=0.096525
[00:46:37.068] Epoch 5, Iter 2400: loss=0.0481, ce=0.0074, dice=0.0753, grad_norm=0.602768
[00:46:40.250] Epoch 5, Iter 2410: loss=0.0300, ce=0.0052, dice=0.0466, grad_norm=0.146554
[00:46:43.432] Epoch 5, Iter 2420: loss=0.1961, ce=0.0084, dice=0.3213, grad_norm=0.486084
[00:46:46.613] Epoch 5, Iter 2430: loss=0.2084, ce=0.0039, dice=0.3447, grad_norm=0.045419
[00:46:49.784] Epoch 5, Iter 2440: loss=0.0357, ce=0.0061, dice=0.0554, grad_norm=0.346625
[00:46:52.974] Epoch 5, Iter 2450: loss=0.0379, ce=0.0091, dice=0.0572, grad_norm=0.201200
[00:46:56.173] Epoch 5, Iter 2460: loss=0.0370, ce=0.0126, dice=0.0532, grad_norm=0.194444
[00:46:59.352] Epoch 5, Iter 2470: loss=0.1427, ce=0.0088, dice=0.2320, grad_norm=3.314024
[00:47:02.523] Epoch 5, Iter 2480: loss=0.0455, ce=0.0043, dice=0.0730, grad_norm=0.595330
[00:47:05.702] Epoch 5, Iter 2490: loss=0.0312, ce=0.0096, dice=0.0456, grad_norm=0.188543
[00:47:08.888] Epoch 5, Iter 2500: loss=0.0239, ce=0.0034, dice=0.0375, grad_norm=0.202002
[00:47:12.103] Epoch 5, Iter 2510: loss=0.0771, ce=0.0031, dice=0.1264, grad_norm=0.233145
[00:47:15.289] Epoch 5, Iter 2520: loss=0.0793, ce=0.0036, dice=0.1297, grad_norm=0.919421
[00:47:18.494] Epoch 5, Iter 2530: loss=0.1020, ce=0.0106, dice=0.1629, grad_norm=0.556021
[00:47:21.662] Epoch 5, Iter 2540: loss=0.0331, ce=0.0085, dice=0.0494, grad_norm=0.129642
[00:47:24.838] Epoch 5, Iter 2550: loss=0.1493, ce=0.0025, dice=0.2472, grad_norm=0.619086
[00:47:27.999] Epoch 5, Iter 2560: loss=0.0620, ce=0.0030, dice=0.1013, grad_norm=0.754147
[00:47:31.180] Epoch 5, Iter 2570: loss=0.1060, ce=0.0076, dice=0.1716, grad_norm=0.782526
[00:47:34.357] Epoch 5, Iter 2580: loss=0.0966, ce=0.0060, dice=0.1569, grad_norm=0.539661
[00:47:37.566] Epoch 5, Iter 2590: loss=0.0725, ce=0.0054, dice=0.1172, grad_norm=0.418705
[00:47:40.748] Epoch 5: Avg Loss=0.0777, CE=0.0072, Dice=0.1247
[00:47:53.292] Epoch 6, Iter 2600: loss=0.0526, ce=0.0082, dice=0.0822, grad_norm=0.448047
[00:47:56.459] Epoch 6, Iter 2610: loss=0.0614, ce=0.0159, dice=0.0917, grad_norm=1.028080
[00:47:59.611] Epoch 6, Iter 2620: loss=0.0455, ce=0.0091, dice=0.0698, grad_norm=0.551597
[00:48:02.790] Epoch 6, Iter 2630: loss=0.1099, ce=0.0107, dice=0.1759, grad_norm=1.106226
[00:48:05.964] Epoch 6, Iter 2640: loss=0.0370, ce=0.0086, dice=0.0560, grad_norm=0.182288
[00:48:09.152] Epoch 6, Iter 2650: loss=0.0734, ce=0.0054, dice=0.1187, grad_norm=0.808932
[00:48:12.347] Epoch 6, Iter 2660: loss=0.0401, ce=0.0064, dice=0.0626, grad_norm=0.126644
[00:48:15.507] Epoch 6, Iter 2670: loss=0.0247, ce=0.0085, dice=0.0355, grad_norm=0.224891
[00:48:18.667] Epoch 6, Iter 2680: loss=0.0640, ce=0.0098, dice=0.1002, grad_norm=0.637267
[00:48:21.847] Epoch 6, Iter 2690: loss=0.0488, ce=0.0051, dice=0.0780, grad_norm=0.588200
[00:48:25.012] Epoch 6, Iter 2700: loss=0.0401, ce=0.0082, dice=0.0613, grad_norm=0.237803
[00:48:28.177] Epoch 6, Iter 2710: loss=0.0593, ce=0.0123, dice=0.0906, grad_norm=0.421546
[00:48:31.338] Epoch 6, Iter 2720: loss=0.0319, ce=0.0078, dice=0.0480, grad_norm=0.134189
[00:48:34.506] Epoch 6, Iter 2730: loss=0.1531, ce=0.0041, dice=0.2525, grad_norm=1.087379
[00:48:37.665] Epoch 6, Iter 2740: loss=0.0296, ce=0.0072, dice=0.0445, grad_norm=0.125841
[00:48:40.843] Epoch 6, Iter 2750: loss=0.0746, ce=0.0104, dice=0.1174, grad_norm=0.463040
[00:48:44.012] Epoch 6, Iter 2760: loss=0.0275, ce=0.0062, dice=0.0417, grad_norm=0.168269
[00:48:47.176] Epoch 6, Iter 2770: loss=0.0601, ce=0.0130, dice=0.0916, grad_norm=0.340811
[00:48:50.325] Epoch 6, Iter 2780: loss=0.0570, ce=0.0099, dice=0.0884, grad_norm=0.218613
[00:48:53.491] Epoch 6, Iter 2790: loss=0.0321, ce=0.0100, dice=0.0468, grad_norm=0.099852
[00:48:56.642] Epoch 6, Iter 2800: loss=0.0253, ce=0.0050, dice=0.0389, grad_norm=0.108443
[00:48:59.809] Epoch 6, Iter 2810: loss=0.0469, ce=0.0075, dice=0.0732, grad_norm=0.143487
[00:49:02.981] Epoch 6, Iter 2820: loss=0.0625, ce=0.0047, dice=0.1010, grad_norm=0.363612
[00:49:06.145] Epoch 6, Iter 2830: loss=0.0298, ce=0.0037, dice=0.0473, grad_norm=0.255123
[00:49:09.406] Epoch 6, Iter 2840: loss=0.2087, ce=0.0057, dice=0.3440, grad_norm=0.069305
[00:49:12.575] Epoch 6, Iter 2850: loss=0.0713, ce=0.0100, dice=0.1122, grad_norm=0.324392
[00:49:15.749] Epoch 6, Iter 2860: loss=0.0542, ce=0.0037, dice=0.0879, grad_norm=0.281289
[00:49:18.930] Epoch 6, Iter 2870: loss=0.0371, ce=0.0085, dice=0.0561, grad_norm=0.218108
[00:49:22.092] Epoch 6, Iter 2880: loss=0.2134, ce=0.0060, dice=0.3517, grad_norm=0.083278
[00:49:25.258] Epoch 6, Iter 2890: loss=0.0512, ce=0.0079, dice=0.0801, grad_norm=0.768395
[00:49:28.408] Epoch 6, Iter 2900: loss=0.0682, ce=0.0100, dice=0.1070, grad_norm=0.252252
[00:49:31.562] Epoch 6, Iter 2910: loss=0.0378, ce=0.0074, dice=0.0580, grad_norm=1.009085
[00:49:34.715] Epoch 6, Iter 2920: loss=0.0431, ce=0.0058, dice=0.0680, grad_norm=0.296657
[00:49:37.877] Epoch 6, Iter 2930: loss=0.1047, ce=0.0065, dice=0.1702, grad_norm=1.108683
[00:49:41.044] Epoch 6, Iter 2940: loss=0.0606, ce=0.0078, dice=0.0957, grad_norm=0.280270
[00:49:44.209] Epoch 6, Iter 2950: loss=0.0849, ce=0.0135, dice=0.1325, grad_norm=0.623043
[00:49:47.360] Epoch 6, Iter 2960: loss=0.0846, ce=0.0075, dice=0.1360, grad_norm=0.519345
[00:49:50.525] Epoch 6, Iter 2970: loss=0.0381, ce=0.0179, dice=0.0516, grad_norm=0.124801
[00:49:53.675] Epoch 6, Iter 2980: loss=0.0962, ce=0.0050, dice=0.1571, grad_norm=0.659353
[00:49:56.850] Epoch 6, Iter 2990: loss=0.0482, ce=0.0026, dice=0.0786, grad_norm=0.266995
[00:50:00.009] Epoch 6, Iter 3000: loss=0.1338, ce=0.0047, dice=0.2198, grad_norm=1.047440
[00:50:03.166] Epoch 6, Iter 3010: loss=0.0458, ce=0.0081, dice=0.0709, grad_norm=0.187927
[00:50:06.322] Epoch 6, Iter 3020: loss=0.0487, ce=0.0037, dice=0.0786, grad_norm=1.091565
[00:50:09.485] Epoch 6, Iter 3030: loss=0.2110, ce=0.0043, dice=0.3487, grad_norm=0.017079
[00:50:10.368] Epoch 6: Avg Loss=0.0812, CE=0.0073, Dice=0.1305
[00:50:23.653] Epoch 7, Iter 3040: loss=0.0349, ce=0.0090, dice=0.0521, grad_norm=0.381063
[00:50:26.816] Epoch 7, Iter 3050: loss=0.0912, ce=0.0033, dice=0.1498, grad_norm=0.718265
[00:50:29.969] Epoch 7, Iter 3060: loss=0.0932, ce=0.0088, dice=0.1495, grad_norm=0.306836
[00:50:33.127] Epoch 7, Iter 3070: loss=0.0381, ce=0.0058, dice=0.0596, grad_norm=0.190221
[00:50:36.280] Epoch 7, Iter 3080: loss=0.0592, ce=0.0074, dice=0.0937, grad_norm=0.884257
[00:50:39.438] Epoch 7, Iter 3090: loss=0.0285, ce=0.0082, dice=0.0420, grad_norm=0.157590
[00:50:42.587] Epoch 7, Iter 3100: loss=0.0323, ce=0.0085, dice=0.0482, grad_norm=0.086229
[00:50:45.747] Epoch 7, Iter 3110: loss=0.0400, ce=0.0053, dice=0.0632, grad_norm=0.143497
[00:50:48.898] Epoch 7, Iter 3120: loss=0.0232, ce=0.0064, dice=0.0344, grad_norm=0.075912
[00:50:52.056] Epoch 7, Iter 3130: loss=0.0295, ce=0.0060, dice=0.0452, grad_norm=0.245726
[00:50:55.204] Epoch 7, Iter 3140: loss=0.0947, ce=0.0071, dice=0.1530, grad_norm=0.649154
[00:50:58.367] Epoch 7, Iter 3150: loss=0.0511, ce=0.0072, dice=0.0805, grad_norm=0.250019
[00:51:01.517] Epoch 7, Iter 3160: loss=0.0274, ce=0.0071, dice=0.0409, grad_norm=0.098270
[00:51:04.678] Epoch 7, Iter 3170: loss=0.0331, ce=0.0060, dice=0.0511, grad_norm=0.158256
[00:51:07.832] Epoch 7, Iter 3180: loss=0.2183, ce=0.0100, dice=0.3572, grad_norm=0.515659
[00:51:10.993] Epoch 7, Iter 3190: loss=0.1207, ce=0.0349, dice=0.1778, grad_norm=1.968371
[00:51:14.142] Epoch 7, Iter 3200: loss=0.0461, ce=0.0172, dice=0.0654, grad_norm=0.165096
[00:51:17.297] Epoch 7, Iter 3210: loss=0.2131, ce=0.0047, dice=0.3521, grad_norm=0.056440
[00:51:20.453] Epoch 7, Iter 3220: loss=0.0319, ce=0.0073, dice=0.0482, grad_norm=0.244954
[00:51:23.615] Epoch 7, Iter 3230: loss=0.0780, ce=0.0076, dice=0.1248, grad_norm=0.536241
[00:51:26.771] Epoch 7, Iter 3240: loss=0.0320, ce=0.0102, dice=0.0465, grad_norm=0.111646
[00:51:29.933] Epoch 7, Iter 3250: loss=0.2120, ce=0.0056, dice=0.3495, grad_norm=0.042084
[00:51:33.080] Epoch 7, Iter 3260: loss=0.1101, ce=0.0046, dice=0.1805, grad_norm=2.465850
[00:51:36.253] Epoch 7, Iter 3270: loss=0.0616, ce=0.0101, dice=0.0959, grad_norm=1.227266
[00:51:39.415] Epoch 7, Iter 3280: loss=0.0372, ce=0.0020, dice=0.0607, grad_norm=0.543770
[00:51:42.597] Epoch 7, Iter 3290: loss=0.0404, ce=0.0075, dice=0.0624, grad_norm=0.160380
[00:51:45.761] Epoch 7, Iter 3300: loss=0.0554, ce=0.0048, dice=0.0891, grad_norm=0.368401
[00:51:48.934] Epoch 7, Iter 3310: loss=0.1655, ce=0.0081, dice=0.2705, grad_norm=1.238438
[00:51:52.097] Epoch 7, Iter 3320: loss=0.0495, ce=0.0086, dice=0.0767, grad_norm=0.654783
[00:51:55.268] Epoch 7, Iter 3330: loss=0.0619, ce=0.0069, dice=0.0986, grad_norm=1.228879
[00:51:58.416] Epoch 7, Iter 3340: loss=0.0272, ce=0.0053, dice=0.0418, grad_norm=0.099682
[00:52:01.585] Epoch 7, Iter 3350: loss=0.0372, ce=0.0075, dice=0.0570, grad_norm=0.105854
[00:52:04.749] Epoch 7, Iter 3360: loss=0.0243, ce=0.0031, dice=0.0384, grad_norm=0.250005
[00:52:07.918] Epoch 7, Iter 3370: loss=0.0402, ce=0.0050, dice=0.0636, grad_norm=0.284649
[00:52:11.078] Epoch 7, Iter 3380: loss=0.0512, ce=0.0035, dice=0.0829, grad_norm=0.162698
[00:52:14.249] Epoch 7, Iter 3390: loss=0.2094, ce=0.0046, dice=0.3459, grad_norm=0.158645
[00:52:17.415] Epoch 7, Iter 3400: loss=0.0266, ce=0.0087, dice=0.0385, grad_norm=0.083929
[00:52:20.597] Epoch 7, Iter 3410: loss=0.0357, ce=0.0033, dice=0.0572, grad_norm=0.627510
[00:52:23.773] Epoch 7, Iter 3420: loss=0.0682, ce=0.0038, dice=0.1112, grad_norm=1.200543
[00:52:26.937] Epoch 7, Iter 3430: loss=0.0560, ce=0.0046, dice=0.0902, grad_norm=1.066990
[00:52:30.108] Epoch 7, Iter 3440: loss=0.0271, ce=0.0128, dice=0.0367, grad_norm=0.160552
[00:52:33.288] Epoch 7, Iter 3450: loss=0.1516, ce=0.0062, dice=0.2485, grad_norm=0.961038
[00:52:36.451] Epoch 7, Iter 3460: loss=0.0292, ce=0.0044, dice=0.0457, grad_norm=0.182722
[00:52:38.325] Epoch 7: Avg Loss=0.0775, CE=0.0072, Dice=0.1244
[00:52:38.327] 
[EPOCH 9] Calculating RGN weights for surgical fine-tuning...
[00:52:51.526] RGN: Max weight before normalization: 0.011437
[00:52:51.553] 
================================================================================
[00:52:51.553] SURGICAL FINE-TUNING WITH TPGM - RGN METHOD
[00:52:51.553] ================================================================================
[00:52:51.553] Layer Name                                         Weight       Learning Rate  
[00:52:51.553] --------------------------------------------------------------------------------
[00:52:51.554] cswin_unet.stage1.0.attns.1.get_v.bias             1.000000     0.00050000      [ACTIVE]
[00:52:51.554] cswin_unet.stage1.0.attns.0.get_v.bias             0.489927     0.00024496      [ACTIVE]
[00:52:51.554] cswin_unet.stage1_conv_embed.0.weight              0.364318     0.00018216      [ACTIVE]
[00:52:51.554] cswin_unet.stage2.1.attns.0.get_v.bias             0.295645     0.00014782      [ACTIVE]
[00:52:51.554] cswin_unet.stage1.0.proj.bias                      0.294814     0.00014741      [ACTIVE]
[00:52:51.554] cswin_unet.stage2.1.attns.1.get_v.bias             0.274892     0.00013745      [ACTIVE]
[00:52:51.554] cswin_unet.stage1.0.proj.weight                    0.272390     0.00013620      [ACTIVE]
[00:52:51.554] cswin_unet.stage2.0.proj.bias                      0.246448     0.00012322      [ACTIVE]
[00:52:51.554] cswin_unet.stage2.0.attns.1.get_v.bias             0.222705     0.00011135      [ACTIVE]
[00:52:51.554] cswin_unet.stage2.0.attns.0.get_v.bias             0.200919     0.00010046      [ACTIVE]
[00:52:51.554] cswin_unet.output.weight                           0.194394     0.00009720      [ACTIVE]
[00:52:51.554] cswin_unet.concat_linear2.bias                     0.192750     0.00009638      [ACTIVE]
[00:52:51.554] cswin_unet.stage_up1.0.attns.1.get_v.bias          0.188037     0.00009402      [ACTIVE]
[00:52:51.554] cswin_unet.upsample1.out.bias                      0.180784     0.00009039      [ACTIVE]
[00:52:51.554] cswin_unet.stage1.0.mlp.fc2.bias                   0.171832     0.00008592      [ACTIVE]
[00:52:51.554] cswin_unet.upsample1.out.weight                    0.170062     0.00008503      [ACTIVE]
[00:52:51.554] cswin_unet.stage1_conv_embed.2.bias                0.169391     0.00008470      [ACTIVE]
[00:52:51.554] cswin_unet.upsample2.out.weight                    0.168727     0.00008436      [ACTIVE]
[00:52:51.554] cswin_unet.stage1.0.qkv.weight                     0.168499     0.00008425      [ACTIVE]
[00:52:51.555] cswin_unet.stage1.0.mlp.fc2.weight                 0.167449     0.00008372      [ACTIVE]
[00:52:51.555] cswin_unet.concat_linear2.weight                   0.163731     0.00008187      [ACTIVE]
[00:52:51.555] cswin_unet.stage1.0.mlp.fc1.weight                 0.159408     0.00007970      [ACTIVE]
[00:52:51.555] cswin_unet.stage2.1.proj.bias                      0.147575     0.00007379      [ACTIVE]
[00:52:51.555] cswin_unet.concat_linear3.weight                   0.138216     0.00006911      [ACTIVE]
[00:52:51.555] cswin_unet.stage_up1.0.attns.0.get_v.bias          0.137343     0.00006867      [ACTIVE]
[00:52:51.555] cswin_unet.upsample3.out.weight                    0.132668     0.00006633      [ACTIVE]
[00:52:51.555] cswin_unet.merge1.conv.weight                      0.102283     0.00005114      [ACTIVE]
[00:52:51.555] cswin_unet.stage1.0.norm1.weight                   0.100000     0.00005000      [ACTIVE]
[00:52:51.555] cswin_unet.stage1.0.norm1.bias                     0.100000     0.00005000      [ACTIVE]
[00:52:51.555] cswin_unet.stage1.0.norm2.weight                   0.100000     0.00005000      [ACTIVE]
[00:52:51.555] cswin_unet.stage1.0.norm2.bias                     0.100000     0.00005000      [ACTIVE]
[00:52:51.555] cswin_unet.merge1.norm.weight                      0.100000     0.00005000      [ACTIVE]
[00:52:51.555] cswin_unet.merge1.norm.bias                        0.100000     0.00005000      [ACTIVE]
[00:52:51.555] cswin_unet.stage2.0.norm1.weight                   0.100000     0.00005000      [ACTIVE]
[00:52:51.555] cswin_unet.stage2.0.norm1.bias                     0.100000     0.00005000      [ACTIVE]
[00:52:51.555] cswin_unet.stage2.0.norm2.weight                   0.100000     0.00005000      [ACTIVE]
[00:52:51.557] cswin_unet.stage2.0.norm2.bias                     0.100000     0.00005000      [ACTIVE]
[00:52:51.557] cswin_unet.stage2.1.norm1.weight                   0.100000     0.00005000      [ACTIVE]
[00:52:51.557] cswin_unet.stage2.1.norm1.bias                     0.100000     0.00005000      [ACTIVE]
[00:52:51.557] cswin_unet.stage2.1.norm2.weight                   0.100000     0.00005000      [ACTIVE]
[00:52:51.557] cswin_unet.stage2.1.norm2.bias                     0.100000     0.00005000      [ACTIVE]
[00:52:51.557] cswin_unet.merge2.norm.weight                      0.100000     0.00005000      [ACTIVE]
[00:52:51.557] cswin_unet.merge2.norm.bias                        0.100000     0.00005000      [ACTIVE]
[00:52:51.557] cswin_unet.stage3.0.norm1.weight                   0.100000     0.00005000      [ACTIVE]
[00:52:51.557] cswin_unet.stage3.0.norm1.bias                     0.100000     0.00005000      [ACTIVE]
[00:52:51.557] cswin_unet.stage3.0.norm2.weight                   0.100000     0.00005000      [ACTIVE]
[00:52:51.557] cswin_unet.stage3.0.norm2.bias                     0.100000     0.00005000      [ACTIVE]
[00:52:51.557] cswin_unet.stage3.1.norm1.weight                   0.100000     0.00005000      [ACTIVE]
[00:52:51.558] cswin_unet.stage3.1.norm1.bias                     0.100000     0.00005000      [ACTIVE]
[00:52:51.558] cswin_unet.stage3.1.norm2.weight                   0.100000     0.00005000      [ACTIVE]
[00:52:51.558] cswin_unet.stage3.1.norm2.bias                     0.100000     0.00005000      [ACTIVE]
[00:52:51.558] cswin_unet.stage3.2.norm1.weight                   0.100000     0.00005000      [ACTIVE]
[00:52:51.558] cswin_unet.stage3.2.norm1.bias                     0.100000     0.00005000      [ACTIVE]
[00:52:51.558] cswin_unet.stage3.2.norm2.weight                   0.100000     0.00005000      [ACTIVE]
[00:52:51.558] cswin_unet.stage3.2.norm2.bias                     0.100000     0.00005000      [ACTIVE]
[00:52:51.558] cswin_unet.stage3.3.norm1.weight                   0.100000     0.00005000      [ACTIVE]
[00:52:51.558] cswin_unet.stage3.3.norm1.bias                     0.100000     0.00005000      [ACTIVE]
[00:52:51.558] cswin_unet.stage3.3.norm2.weight                   0.100000     0.00005000      [ACTIVE]
[00:52:51.558] cswin_unet.stage3.3.norm2.bias                     0.100000     0.00005000      [ACTIVE]
[00:52:51.558] cswin_unet.stage3.4.norm1.weight                   0.100000     0.00005000      [ACTIVE]
[00:52:51.558] cswin_unet.stage3.4.norm1.bias                     0.100000     0.00005000      [ACTIVE]
[00:52:51.558] cswin_unet.stage3.4.norm2.weight                   0.100000     0.00005000      [ACTIVE]
[00:52:51.559] cswin_unet.stage3.4.norm2.bias                     0.100000     0.00005000      [ACTIVE]
[00:52:51.559] cswin_unet.stage3.5.norm1.weight                   0.100000     0.00005000      [ACTIVE]
[00:52:51.559] cswin_unet.stage3.5.norm1.bias                     0.100000     0.00005000      [ACTIVE]
[00:52:51.559] cswin_unet.stage3.5.norm2.weight                   0.100000     0.00005000      [ACTIVE]
[00:52:51.559] cswin_unet.stage3.5.norm2.bias                     0.100000     0.00005000      [ACTIVE]
[00:52:51.559] cswin_unet.stage3.6.norm1.weight                   0.100000     0.00005000      [ACTIVE]
[00:52:51.559] cswin_unet.stage3.6.norm1.bias                     0.100000     0.00005000      [ACTIVE]
[00:52:51.559] cswin_unet.stage3.6.norm2.weight                   0.100000     0.00005000      [ACTIVE]
[00:52:51.559] cswin_unet.stage3.6.norm2.bias                     0.100000     0.00005000      [ACTIVE]
[00:52:51.559] cswin_unet.stage3.7.norm1.weight                   0.100000     0.00005000      [ACTIVE]
[00:52:51.559] cswin_unet.stage3.7.norm1.bias                     0.100000     0.00005000      [ACTIVE]
[00:52:51.559] cswin_unet.stage3.7.norm2.weight                   0.100000     0.00005000      [ACTIVE]
[00:52:51.559] cswin_unet.stage3.7.norm2.bias                     0.100000     0.00005000      [ACTIVE]
[00:52:51.559] cswin_unet.stage3.8.norm1.weight                   0.100000     0.00005000      [ACTIVE]
[00:52:51.559] cswin_unet.stage3.8.norm1.bias                     0.100000     0.00005000      [ACTIVE]
[00:52:51.559] cswin_unet.stage3.8.norm2.weight                   0.100000     0.00005000      [ACTIVE]
[00:52:51.559] cswin_unet.stage3.8.norm2.bias                     0.100000     0.00005000      [ACTIVE]
[00:52:51.559] cswin_unet.merge3.norm.weight                      0.100000     0.00005000      [ACTIVE]
[00:52:51.560] cswin_unet.merge3.norm.bias                        0.100000     0.00005000      [ACTIVE]
[00:52:51.560] cswin_unet.stage4.0.norm1.weight                   0.100000     0.00005000      [ACTIVE]
[00:52:51.560] cswin_unet.stage4.0.norm1.bias                     0.100000     0.00005000      [ACTIVE]
[00:52:51.560] cswin_unet.stage4.0.norm2.weight                   0.100000     0.00005000      [ACTIVE]
[00:52:51.560] cswin_unet.stage4.0.norm2.bias                     0.100000     0.00005000      [ACTIVE]
[00:52:51.560] cswin_unet.norm.weight                             0.100000     0.00005000      [ACTIVE]
[00:52:51.560] cswin_unet.norm.bias                               0.100000     0.00005000      [ACTIVE]
[00:52:51.560] cswin_unet.stage_up4.0.norm1.weight                0.100000     0.00005000      [ACTIVE]
[00:52:51.560] cswin_unet.stage_up4.0.norm1.bias                  0.100000     0.00005000      [ACTIVE]
[00:52:51.560] cswin_unet.stage_up4.0.norm2.weight                0.100000     0.00005000      [ACTIVE]
[00:52:51.560] cswin_unet.stage_up4.0.norm2.bias                  0.100000     0.00005000      [ACTIVE]
[00:52:51.560] cswin_unet.stage_up3.0.norm1.weight                0.100000     0.00005000      [ACTIVE]
[00:52:51.560] cswin_unet.stage_up3.0.norm1.bias                  0.100000     0.00005000      [ACTIVE]
[00:52:51.560] cswin_unet.stage_up3.0.norm2.weight                0.100000     0.00005000      [ACTIVE]
[00:52:51.560] cswin_unet.stage_up3.0.norm2.bias                  0.100000     0.00005000      [ACTIVE]
[00:52:51.560] cswin_unet.stage_up3.1.norm1.weight                0.100000     0.00005000      [ACTIVE]
[00:52:51.560] cswin_unet.stage_up3.1.norm1.bias                  0.100000     0.00005000      [ACTIVE]
[00:52:51.560] cswin_unet.stage_up3.1.norm2.weight                0.100000     0.00005000      [ACTIVE]
[00:52:51.560] cswin_unet.stage_up3.1.norm2.bias                  0.100000     0.00005000      [ACTIVE]
[00:52:51.560] cswin_unet.stage_up3.2.norm1.weight                0.100000     0.00005000      [ACTIVE]
[00:52:51.560] cswin_unet.stage_up3.2.norm1.bias                  0.100000     0.00005000      [ACTIVE]
[00:52:51.560] cswin_unet.stage_up3.2.norm2.weight                0.100000     0.00005000      [ACTIVE]
[00:52:51.560] cswin_unet.stage_up3.2.norm2.bias                  0.100000     0.00005000      [ACTIVE]
[00:52:51.560] cswin_unet.stage_up3.3.norm1.weight                0.100000     0.00005000      [ACTIVE]
[00:52:51.560] cswin_unet.stage_up3.3.norm1.bias                  0.100000     0.00005000      [ACTIVE]
[00:52:51.560] cswin_unet.stage_up3.3.norm2.weight                0.100000     0.00005000      [ACTIVE]
[00:52:51.560] cswin_unet.stage_up3.3.norm2.bias                  0.100000     0.00005000      [ACTIVE]
[00:52:51.560] cswin_unet.stage_up3.4.norm1.weight                0.100000     0.00005000      [ACTIVE]
[00:52:51.561] cswin_unet.stage_up3.4.norm1.bias                  0.100000     0.00005000      [ACTIVE]
[00:52:51.561] cswin_unet.stage_up3.4.norm2.weight                0.100000     0.00005000      [ACTIVE]
[00:52:51.561] cswin_unet.stage_up3.4.norm2.bias                  0.100000     0.00005000      [ACTIVE]
[00:52:51.561] cswin_unet.stage_up3.5.norm1.weight                0.100000     0.00005000      [ACTIVE]
[00:52:51.561] cswin_unet.stage_up3.5.norm1.bias                  0.100000     0.00005000      [ACTIVE]
[00:52:51.561] cswin_unet.stage_up3.5.norm2.weight                0.100000     0.00005000      [ACTIVE]
[00:52:51.561] cswin_unet.stage_up3.5.norm2.bias                  0.100000     0.00005000      [ACTIVE]
[00:52:51.561] cswin_unet.stage_up3.6.norm1.weight                0.100000     0.00005000      [ACTIVE]
[00:52:51.561] cswin_unet.stage_up3.6.norm1.bias                  0.100000     0.00005000      [ACTIVE]
[00:52:51.561] cswin_unet.stage_up3.6.norm2.weight                0.100000     0.00005000      [ACTIVE]
[00:52:51.561] cswin_unet.stage_up3.6.norm2.bias                  0.100000     0.00005000      [ACTIVE]
[00:52:51.561] cswin_unet.stage_up3.7.norm1.weight                0.100000     0.00005000      [ACTIVE]
[00:52:51.561] cswin_unet.stage_up3.7.norm1.bias                  0.100000     0.00005000      [ACTIVE]
[00:52:51.561] cswin_unet.stage_up3.7.norm2.weight                0.100000     0.00005000      [ACTIVE]
[00:52:51.561] cswin_unet.stage_up3.7.norm2.bias                  0.100000     0.00005000      [ACTIVE]
[00:52:51.561] cswin_unet.stage_up3.8.norm1.weight                0.100000     0.00005000      [ACTIVE]
[00:52:51.561] cswin_unet.stage_up3.8.norm1.bias                  0.100000     0.00005000      [ACTIVE]
[00:52:51.561] cswin_unet.stage_up3.8.norm2.weight                0.100000     0.00005000      [ACTIVE]
[00:52:51.561] cswin_unet.stage_up3.8.norm2.bias                  0.100000     0.00005000      [ACTIVE]
[00:52:51.561] cswin_unet.stage_up2.0.norm1.weight                0.100000     0.00005000      [ACTIVE]
[00:52:51.561] cswin_unet.stage_up2.0.norm1.bias                  0.100000     0.00005000      [ACTIVE]
[00:52:51.561] cswin_unet.stage_up2.0.norm2.weight                0.100000     0.00005000      [ACTIVE]
[00:52:51.561] cswin_unet.stage_up2.0.norm2.bias                  0.100000     0.00005000      [ACTIVE]
[00:52:51.561] cswin_unet.stage_up2.1.norm1.weight                0.100000     0.00005000      [ACTIVE]
[00:52:51.562] cswin_unet.stage_up2.1.norm1.bias                  0.100000     0.00005000      [ACTIVE]
[00:52:51.562] cswin_unet.stage_up2.1.norm2.weight                0.100000     0.00005000      [ACTIVE]
[00:52:51.562] cswin_unet.stage_up2.1.norm2.bias                  0.100000     0.00005000      [ACTIVE]
[00:52:51.562] cswin_unet.stage_up1.0.norm1.weight                0.100000     0.00005000      [ACTIVE]
[00:52:51.562] cswin_unet.stage_up1.0.norm1.bias                  0.100000     0.00005000      [ACTIVE]
[00:52:51.562] cswin_unet.stage_up1.0.norm2.weight                0.100000     0.00005000      [ACTIVE]
[00:52:51.562] cswin_unet.stage_up1.0.norm2.bias                  0.100000     0.00005000      [ACTIVE]
[00:52:51.562] cswin_unet.norm_up.weight                          0.100000     0.00005000      [ACTIVE]
[00:52:51.562] cswin_unet.norm_up.bias                            0.100000     0.00005000      [ACTIVE]
[00:52:51.562] cswin_unet.stage1.0.attns.1.get_v.weight           0.094011     0.00004701      [ACTIVE]
[00:52:51.562] cswin_unet.concat_linear3.bias                     0.091814     0.00004591      [ACTIVE]
[00:52:51.562] cswin_unet.stage2.0.attns.1.get_v.weight           0.087859     0.00004393      [ACTIVE]
[00:52:51.562] cswin_unet.upsample2.out.bias                      0.087593     0.00004380      [ACTIVE]
[00:52:51.562] cswin_unet.stage_up2.1.attns.1.get_v.bias          0.086335     0.00004317      [ACTIVE]
[00:52:51.562] cswin_unet.stage1.0.attns.0.get_v.weight           0.084879     0.00004244      [ACTIVE]
[00:52:51.562] cswin_unet.stage_up2.1.attns.0.get_v.bias          0.076790     0.00003840      [ACTIVE]
[00:52:51.562] cswin_unet.stage2.1.proj.weight                    0.073450     0.00003673      [ACTIVE]
[00:52:51.562] cswin_unet.stage2.0.mlp.fc2.bias                   0.073427     0.00003671      [ACTIVE]
[00:52:51.562] cswin_unet.upsample2.down.weight                   0.073399     0.00003670      [ACTIVE]
[00:52:51.562] cswin_unet.upsample2.encoder.weight                0.070250     0.00003513      [ACTIVE]
[00:52:51.562] cswin_unet.stage2.0.proj.weight                    0.064925     0.00003246      [ACTIVE]
[00:52:51.563] cswin_unet.stage_up1.0.mlp.fc2.weight              0.063435     0.00003172      [ACTIVE]
[00:52:51.563] cswin_unet.stage_up1.0.mlp.fc2.bias                0.062483     0.00003124      [ACTIVE]
[00:52:51.563] cswin_unet.stage2.0.attns.0.get_v.weight           0.060826     0.00003041      [ACTIVE]
[00:52:51.563] cswin_unet.stage2.0.mlp.fc1.weight                 0.059735     0.00002987      [ACTIVE]
[00:52:51.563] cswin_unet.stage2.1.attns.1.get_v.weight           0.059697     0.00002985      [ACTIVE]
[00:52:51.563] cswin_unet.upsample1.down.weight                   0.058346     0.00002917      [ACTIVE]
[00:52:51.563] cswin_unet.stage2.1.mlp.fc2.bias                   0.056386     0.00002819      [ACTIVE]
[00:52:51.563] cswin_unet.stage_up2.0.attns.1.get_v.bias          0.055800     0.00002790      [ACTIVE]
[00:52:51.563] cswin_unet.stage_up1.0.proj.weight                 0.055361     0.00002768      [ACTIVE]
[00:52:51.563] cswin_unet.stage2.1.qkv.weight                     0.054813     0.00002741      [ACTIVE]
[00:52:51.563] cswin_unet.stage2.0.mlp.fc2.weight                 0.052501     0.00002625      [ACTIVE]
[00:52:51.563] cswin_unet.stage_up1.0.proj.bias                   0.052111     0.00002606      [ACTIVE]
[00:52:51.563] cswin_unet.stage2.1.mlp.fc1.weight                 0.052055     0.00002603      [ACTIVE]
[00:52:51.563] cswin_unet.stage_up1.0.qkv.weight                  0.051350     0.00002568      [ACTIVE]
[00:52:51.563] cswin_unet.upsample1.down.bias                     0.050933     0.00002547      [ACTIVE]
[00:52:51.563] cswin_unet.stage_up1.0.mlp.fc1.weight              0.050302     0.00002515      [ACTIVE]
[00:52:51.564] cswin_unet.stage1_conv_embed.2.weight              0.049935     0.00002497      [LOW_LR]
[00:52:51.564] cswin_unet.stage1.0.qkv.bias                       0.049330     0.00002467      [LOW_LR]
[00:52:51.564] cswin_unet.stage_up2.0.attns.0.get_v.bias          0.049147     0.00002457      [LOW_LR]
[00:52:51.564] cswin_unet.upsample3.encoder.weight                0.045552     0.00002278      [LOW_LR]
[00:52:51.564] cswin_unet.stage2.1.attns.0.get_v.weight           0.045012     0.00002251      [LOW_LR]
[00:52:51.564] cswin_unet.upsample2.encoder.bias                  0.043258     0.00002163      [LOW_LR]
[00:52:51.564] cswin_unet.concat_linear4.weight                   0.041815     0.00002091      [LOW_LR]
[00:52:51.564] cswin_unet.stage2.0.qkv.weight                     0.039639     0.00001982      [LOW_LR]
[00:52:51.564] cswin_unet.stage3.0.attns.1.get_v.weight           0.039140     0.00001957      [LOW_LR]
[00:52:51.564] cswin_unet.upsample2.down.bias                     0.033657     0.00001683      [LOW_LR]
[00:52:51.564] cswin_unet.stage3.0.attns.0.get_v.weight           0.032839     0.00001642      [LOW_LR]
[00:52:51.564] cswin_unet.stage3.0.attns.1.get_v.bias             0.032364     0.00001618      [LOW_LR]
[00:52:51.564] cswin_unet.stage_up2.0.attns.0.get_v.weight        0.032349     0.00001617      [LOW_LR]
[00:52:51.564] cswin_unet.stage_up2.0.proj.bias                   0.032040     0.00001602      [LOW_LR]
[00:52:51.564] cswin_unet.stage2.1.mlp.fc2.weight                 0.031611     0.00001581      [LOW_LR]
[00:52:51.564] cswin_unet.merge2.conv.weight                      0.030936     0.00001547      [LOW_LR]
[00:52:51.564] cswin_unet.stage3.0.attns.0.get_v.bias             0.029890     0.00001495      [LOW_LR]
[00:52:51.564] cswin_unet.stage3.1.attns.1.get_v.weight           0.029440     0.00001472      [LOW_LR]
[00:52:51.564] cswin_unet.upsample3.down.weight                   0.028349     0.00001417      [LOW_LR]
[00:52:51.564] cswin_unet.stage3.1.attns.0.get_v.weight           0.028052     0.00001403      [LOW_LR]
[00:52:51.564] cswin_unet.stage1_conv_embed.0.bias                0.027424     0.00001371      [LOW_LR]
[00:52:51.565] cswin_unet.stage_up1.0.attns.0.get_v.weight        0.026576     0.00001329      [LOW_LR]
[00:52:51.565] cswin_unet.stage_up2.0.attns.1.get_v.weight        0.026415     0.00001321      [LOW_LR]
[00:52:51.565] cswin_unet.stage_up1.0.attns.1.get_v.weight        0.026368     0.00001318      [LOW_LR]
[00:52:51.565] cswin_unet.stage3.2.attns.0.get_v.weight           0.024991     0.00001250      [LOW_LR]
[00:52:51.565] cswin_unet.stage3.3.attns.1.get_v.weight           0.024390     0.00001220      [LOW_LR]
[00:52:51.565] cswin_unet.stage_up2.1.proj.bias                   0.023797     0.00001190      [LOW_LR]
[00:52:51.565] cswin_unet.stage3.2.attns.1.get_v.weight           0.022758     0.00001138      [LOW_LR]
[00:52:51.565] cswin_unet.stage3.1.attns.0.get_v.bias             0.021284     0.00001064      [LOW_LR]
[00:52:51.565] cswin_unet.stage2.1.qkv.bias                       0.021080     0.00001054      [LOW_LR]
[00:52:51.565] cswin_unet.stage2.0.qkv.bias                       0.020777     0.00001039      [LOW_LR]
[00:52:51.565] cswin_unet.upsample1.encoder.bias                  0.020588     0.00001029      [LOW_LR]
[00:52:51.565] cswin_unet.stage_up2.1.attns.0.get_v.weight        0.020556     0.00001028      [LOW_LR]
[00:52:51.565] cswin_unet.stage_up2.1.proj.weight                 0.020207     0.00001010      [LOW_LR]
[00:52:51.565] cswin_unet.upsample3.out.bias                      0.018870     0.00000944      [LOW_LR]
[00:52:51.565] cswin_unet.stage_up2.1.qkv.weight                  0.017588     0.00000879      [LOW_LR]
[00:52:51.565] cswin_unet.stage3.0.proj.weight                    0.017429     0.00000871      [LOW_LR]
[00:52:51.565] cswin_unet.stage_up2.0.proj.weight                 0.017290     0.00000865      [LOW_LR]
[00:52:51.565] cswin_unet.stage_up2.0.qkv.weight                  0.016448     0.00000822      [LOW_LR]
[00:52:51.565] cswin_unet.stage_up2.1.attns.1.get_v.weight        0.016345     0.00000817      [LOW_LR]
[00:52:51.566] cswin_unet.stage1.0.mlp.fc1.bias                   0.016268     0.00000813      [LOW_LR]
[00:52:51.566] cswin_unet.stage3.3.attns.0.get_v.weight           0.015699     0.00000785      [LOW_LR]
[00:52:51.566] cswin_unet.stage3.0.proj.bias                      0.015271     0.00000764      [LOW_LR]
[00:52:51.566] cswin_unet.concat_linear4.bias                     0.015182     0.00000759      [LOW_LR]
[00:52:51.566] cswin_unet.stage3.4.attns.1.get_v.weight           0.014854     0.00000743      [LOW_LR]
[00:52:51.566] cswin_unet.stage3.1.proj.weight                    0.014767     0.00000738      [LOW_LR]
[00:52:51.566] cswin_unet.stage3.1.attns.1.get_v.bias             0.013932     0.00000697      [LOW_LR]
[00:52:51.566] cswin_unet.stage3.4.attns.0.get_v.weight           0.013693     0.00000685      [LOW_LR]
[00:52:51.566] cswin_unet.stage3.0.qkv.weight                     0.013670     0.00000684      [LOW_LR]
[00:52:51.566] cswin_unet.stage_up1.0.qkv.bias                    0.013315     0.00000666      [LOW_LR]
[00:52:51.566] cswin_unet.stage_up2.0.mlp.fc2.weight              0.012437     0.00000622      [LOW_LR]
[00:52:51.566] cswin_unet.stage3.4.qkv.weight                     0.011598     0.00000580      [LOW_LR]
[00:52:51.566] cswin_unet.merge1.conv.bias                        0.011592     0.00000580      [LOW_LR]
[00:52:51.566] cswin_unet.stage_up2.1.mlp.fc2.bias                0.011474     0.00000574      [LOW_LR]
[00:52:51.566] cswin_unet.stage3.4.proj.weight                    0.011455     0.00000573      [LOW_LR]
[00:52:51.566] cswin_unet.stage2.0.mlp.fc1.bias                   0.011372     0.00000569      [LOW_LR]
[00:52:51.566] cswin_unet.stage3.5.attns.1.get_v.weight           0.010938     0.00000547      [LOW_LR]
[00:52:51.566] cswin_unet.stage3.2.proj.weight                    0.010931     0.00000547      [LOW_LR]
[00:52:51.566] cswin_unet.stage_up4.0.attns.0.get_v.bias          0.010867     0.00000543      [LOW_LR]
[00:52:51.566] cswin_unet.upsample1.encoder.weight                0.010862     0.00000543      [LOW_LR]
[00:52:51.566] cswin_unet.stage3.5.attns.0.get_v.weight           0.010785     0.00000539      [LOW_LR]
[00:52:51.566] cswin_unet.stage_up2.0.mlp.fc1.weight              0.010461     0.00000523      [LOW_LR]
[00:52:51.566] cswin_unet.stage3.1.qkv.weight                     0.010329     0.00000516      [LOW_LR]
[00:52:51.567] cswin_unet.stage3.1.proj.bias                      0.010323     0.00000516      [LOW_LR]
[00:52:51.567] cswin_unet.stage3.6.attns.1.get_v.weight           0.010296     0.00000515      [LOW_LR]
[00:52:51.567] cswin_unet.stage_up2.0.mlp.fc2.bias                0.010160     0.00000508      [LOW_LR]
[00:52:51.567] cswin_unet.stage3.3.proj.weight                    0.010160     0.00000508      [LOW_LR]
[00:52:51.567] cswin_unet.stage3.2.attns.0.get_v.bias             0.010009     0.00000500      [LOW_LR]
[00:52:51.567] cswin_unet.stage3.0.mlp.fc2.weight                 0.009748     0.00000487      [LOW_LR]
[00:52:51.567] cswin_unet.stage3.3.qkv.weight                     0.009574     0.00000479      [LOW_LR]
[00:52:51.567] cswin_unet.stage3.7.attns.0.get_v.weight           0.009416     0.00000471      [LOW_LR]
[00:52:51.567] cswin_unet.stage3.0.mlp.fc1.weight                 0.009181     0.00000459      [LOW_LR]
[00:52:51.567] cswin_unet.stage3.2.qkv.weight                     0.008799     0.00000440      [LOW_LR]
[00:52:51.567] cswin_unet.stage3.3.attns.1.get_v.bias             0.008649     0.00000432      [LOW_LR]
[00:52:51.567] cswin_unet.stage_up2.1.mlp.fc1.weight              0.008488     0.00000424      [LOW_LR]
[00:52:51.567] cswin_unet.upsample3.down.bias                     0.008391     0.00000420      [LOW_LR]
[00:52:51.567] cswin_unet.stage3.2.proj.bias                      0.008147     0.00000407      [LOW_LR]
[00:52:51.567] cswin_unet.stage2.1.mlp.fc1.bias                   0.008091     0.00000405      [LOW_LR]
[00:52:51.567] cswin_unet.upsample3.encoder.bias                  0.007509     0.00000375      [LOW_LR]
[00:52:51.567] cswin_unet.stage3.5.proj.weight                    0.007367     0.00000368      [LOW_LR]
[00:52:51.567] cswin_unet.stage3.8.attns.0.get_v.weight           0.007358     0.00000368      [LOW_LR]
[00:52:51.567] cswin_unet.stage3.7.attns.1.get_v.weight           0.007297     0.00000365      [LOW_LR]
[00:52:51.567] cswin_unet.stage3.6.attns.0.get_v.weight           0.007295     0.00000365      [LOW_LR]
[00:52:51.567] cswin_unet.stage3.2.attns.1.get_v.bias             0.007278     0.00000364      [LOW_LR]
[00:52:51.567] cswin_unet.stage3.6.proj.weight                    0.006882     0.00000344      [LOW_LR]
[00:52:51.567] cswin_unet.stage3.5.qkv.weight                     0.006861     0.00000343      [LOW_LR]
[00:52:51.567] cswin_unet.stage_up2.1.mlp.fc2.weight              0.006812     0.00000341      [LOW_LR]
[00:52:51.568] cswin_unet.stage_up3.8.attns.1.get_v.bias          0.006623     0.00000331      [LOW_LR]
[00:52:51.568] cswin_unet.stage3.6.qkv.weight                     0.006503     0.00000325      [LOW_LR]
[00:52:51.568] cswin_unet.stage3.2.mlp.fc2.bias                   0.006460     0.00000323      [LOW_LR]
[00:52:51.568] cswin_unet.stage_up3.1.attns.0.get_v.weight        0.006431     0.00000322      [LOW_LR]
[00:52:51.568] cswin_unet.upsample4.out.weight                    0.006327     0.00000316      [LOW_LR]
[00:52:51.568] cswin_unet.stage3.1.mlp.fc2.bias                   0.006312     0.00000316      [LOW_LR]
[00:52:51.568] cswin_unet.stage3.5.attns.0.get_v.bias             0.006289     0.00000314      [LOW_LR]
[00:52:51.568] cswin_unet.stage3.0.mlp.fc2.bias                   0.006248     0.00000312      [LOW_LR]
[00:52:51.568] cswin_unet.stage_up3.0.attns.0.get_v.weight        0.006224     0.00000311      [LOW_LR]
[00:52:51.568] cswin_unet.stage3.3.attns.0.get_v.bias             0.006137     0.00000307      [LOW_LR]
[00:52:51.568] cswin_unet.stage3.4.attns.1.get_v.bias             0.005990     0.00000300      [LOW_LR]
[00:52:51.568] cswin_unet.stage3.8.attns.1.get_v.weight           0.005935     0.00000297      [LOW_LR]
[00:52:51.568] cswin_unet.stage3.3.proj.bias                      0.005836     0.00000292      [LOW_LR]
[00:52:51.568] cswin_unet.upsample4.out.bias                      0.005775     0.00000289      [LOW_LR]
[00:52:51.568] cswin_unet.stage3.8.qkv.weight                     0.005362     0.00000268      [LOW_LR]
[00:52:51.568] cswin_unet.stage3.8.attns.0.get_v.bias             0.005350     0.00000267      [LOW_LR]
[00:52:51.568] cswin_unet.stage_up2.0.qkv.bias                    0.005309     0.00000265      [LOW_LR]
[00:52:51.568] cswin_unet.stage3.0.qkv.bias                       0.005302     0.00000265      [LOW_LR]
[00:52:51.568] cswin_unet.stage_up1.0.mlp.fc1.bias                0.005220     0.00000261      [LOW_LR]
[00:52:51.568] cswin_unet.stage3.4.proj.bias                      0.005143     0.00000257      [LOW_LR]
[00:52:51.568] cswin_unet.stage3.8.attns.1.get_v.bias             0.005115     0.00000256      [LOW_LR]
[00:52:51.568] cswin_unet.stage_up3.8.attns.0.get_v.bias          0.005087     0.00000254      [LOW_LR]
[00:52:51.568] cswin_unet.stage_up3.4.attns.0.get_v.weight        0.005034     0.00000252      [LOW_LR]
[00:52:51.568] cswin_unet.stage3.7.attns.0.get_v.bias             0.005004     0.00000250      [LOW_LR]
[00:52:51.569] cswin_unet.stage3.4.attns.0.get_v.bias             0.004814     0.00000241      [LOW_LR]
[00:52:51.569] cswin_unet.stage3.3.mlp.fc2.bias                   0.004686     0.00000234      [LOW_LR]
[00:52:51.569] cswin_unet.stage_up3.2.attns.0.get_v.weight        0.004664     0.00000233      [LOW_LR]
[00:52:51.569] cswin_unet.stage3.6.attns.1.get_v.bias             0.004645     0.00000232      [LOW_LR]
[00:52:51.569] cswin_unet.stage3.1.mlp.fc2.weight                 0.004552     0.00000228      [LOW_LR]
[00:52:51.569] cswin_unet.stage3.7.proj.weight                    0.004516     0.00000226      [LOW_LR]
[00:52:51.569] cswin_unet.stage_up3.7.attns.0.get_v.weight        0.004429     0.00000221      [LOW_LR]
[00:52:51.569] cswin_unet.stage3.7.qkv.weight                     0.004369     0.00000218      [LOW_LR]
[00:52:51.569] cswin_unet.stage3.1.mlp.fc1.weight                 0.004368     0.00000218      [LOW_LR]
[00:52:51.569] cswin_unet.stage_up2.1.qkv.bias                    0.004360     0.00000218      [LOW_LR]
[00:52:51.569] cswin_unet.stage3.8.proj.weight                    0.004320     0.00000216      [LOW_LR]
[00:52:51.569] cswin_unet.stage_up3.5.attns.0.get_v.weight        0.004287     0.00000214      [LOW_LR]
[00:52:51.569] cswin_unet.stage_up3.8.attns.0.get_v.weight        0.004263     0.00000213      [LOW_LR]
[00:52:51.569] cswin_unet.stage3.2.mlp.fc1.weight                 0.004200     0.00000210      [LOW_LR]
[00:52:51.569] cswin_unet.stage_up3.3.attns.0.get_v.weight        0.004176     0.00000209      [LOW_LR]
[00:52:51.569] cswin_unet.stage_up3.7.attns.0.get_v.bias          0.004122     0.00000206      [LOW_LR]
[00:52:51.569] cswin_unet.stage_up3.1.attns.1.get_v.weight        0.003900     0.00000195      [LOW_LR]
[00:52:51.569] cswin_unet.stage_up3.2.attns.1.get_v.weight        0.003886     0.00000194      [LOW_LR]
[00:52:51.569] cswin_unet.stage_up3.6.attns.0.get_v.weight        0.003851     0.00000193      [LOW_LR]
[00:52:51.569] cswin_unet.stage3.5.proj.bias                      0.003797     0.00000190      [LOW_LR]
[00:52:51.569] cswin_unet.stage_up3.0.attns.1.get_v.weight        0.003729     0.00000186      [LOW_LR]
[00:52:51.569] cswin_unet.stage_up3.5.attns.1.get_v.weight        0.003728     0.00000186      [LOW_LR]
[00:52:51.569] cswin_unet.stage_up3.3.attns.1.get_v.weight        0.003721     0.00000186      [LOW_LR]
[00:52:51.569] cswin_unet.stage_up3.4.attns.1.get_v.weight        0.003699     0.00000185      [LOW_LR]
[00:52:51.569] cswin_unet.stage_up3.6.attns.0.get_v.bias          0.003672     0.00000184      [LOW_LR]
[00:52:51.570] cswin_unet.stage3.4.mlp.fc2.bias                   0.003587     0.00000179      [LOW_LR]
[00:52:51.570] cswin_unet.stage3.6.proj.bias                      0.003535     0.00000177      [LOW_LR]
[00:52:51.570] cswin_unet.stage3.1.qkv.bias                       0.003529     0.00000176      [LOW_LR]
[00:52:51.570] cswin_unet.stage3.6.attns.0.get_v.bias             0.003526     0.00000176      [LOW_LR]
[00:52:51.570] cswin_unet.stage_up3.6.attns.1.get_v.bias          0.003523     0.00000176      [LOW_LR]
[00:52:51.570] cswin_unet.stage_up3.8.attns.1.get_v.weight        0.003513     0.00000176      [LOW_LR]
[00:52:51.570] cswin_unet.stage_up3.5.attns.0.get_v.bias          0.003508     0.00000175      [LOW_LR]
[00:52:51.570] cswin_unet.stage3.2.mlp.fc2.weight                 0.003466     0.00000173      [LOW_LR]
[00:52:51.570] cswin_unet.stage_up3.1.attns.0.get_v.bias          0.003408     0.00000170      [LOW_LR]
[00:52:51.570] cswin_unet.stage3.3.mlp.fc1.weight                 0.003323     0.00000166      [LOW_LR]
[00:52:51.570] cswin_unet.stage3.5.mlp.fc2.bias                   0.003310     0.00000165      [LOW_LR]
[00:52:51.570] cswin_unet.stage3.7.proj.bias                      0.003242     0.00000162      [LOW_LR]
[00:52:51.570] cswin_unet.stage_up3.6.attns.1.get_v.weight        0.003107     0.00000155      [LOW_LR]
[00:52:51.570] cswin_unet.stage3.7.attns.1.get_v.bias             0.003070     0.00000153      [LOW_LR]
[00:52:51.570] cswin_unet.stage_up3.7.proj.bias                   0.003065     0.00000153      [LOW_LR]
[00:52:51.570] cswin_unet.stage3.3.mlp.fc2.weight                 0.003055     0.00000153      [LOW_LR]
[00:52:51.570] cswin_unet.stage_up3.7.attns.1.get_v.bias          0.003018     0.00000151      [LOW_LR]
[00:52:51.570] cswin_unet.stage_up3.8.mlp.fc2.bias                0.002970     0.00000148      [LOW_LR]
[00:52:51.570] cswin_unet.stage_up3.6.proj.bias                   0.002961     0.00000148      [LOW_LR]
[00:52:51.570] cswin_unet.stage_up3.8.proj.bias                   0.002951     0.00000148      [LOW_LR]
[00:52:51.570] cswin_unet.stage3.5.attns.1.get_v.bias             0.002922     0.00000146      [LOW_LR]
[00:52:51.570] cswin_unet.stage_up3.1.proj.weight                 0.002889     0.00000144      [LOW_LR]
[00:52:51.570] cswin_unet.stage3.4.mlp.fc1.weight                 0.002831     0.00000142      [LOW_LR]
[00:52:51.570] cswin_unet.stage_up3.4.proj.bias                   0.002743     0.00000137      [LOW_LR]
[00:52:51.571] cswin_unet.stage_up3.0.attns.0.get_v.bias          0.002624     0.00000131      [LOW_LR]
[00:52:51.571] cswin_unet.stage3.6.mlp.fc2.bias                   0.002604     0.00000130      [LOW_LR]
[00:52:51.571] cswin_unet.stage_up3.7.attns.1.get_v.weight        0.002570     0.00000129      [LOW_LR]
[00:52:51.571] cswin_unet.stage3.7.mlp.fc2.bias                   0.002556     0.00000128      [LOW_LR]
[00:52:51.571] cswin_unet.stage_up3.2.attns.0.get_v.bias          0.002543     0.00000127      [LOW_LR]
[00:52:51.571] cswin_unet.stage_up3.3.proj.weight                 0.002543     0.00000127      [LOW_LR]
[00:52:51.571] cswin_unet.stage_up3.7.mlp.fc2.bias                0.002543     0.00000127      [LOW_LR]
[00:52:51.571] cswin_unet.stage_up3.5.proj.bias                   0.002525     0.00000126      [LOW_LR]
[00:52:51.571] cswin_unet.stage3.8.proj.bias                      0.002485     0.00000124      [LOW_LR]
[00:52:51.572] cswin_unet.stage_up3.2.proj.weight                 0.002465     0.00000123      [LOW_LR]
[00:52:51.572] cswin_unet.stage_up3.5.mlp.fc2.bias                0.002463     0.00000123      [LOW_LR]
[00:52:51.572] cswin_unet.stage_up3.3.attns.1.get_v.bias          0.002453     0.00000123      [LOW_LR]
[00:52:51.572] cswin_unet.stage3.2.qkv.bias                       0.002434     0.00000122      [LOW_LR]
[00:52:51.572] cswin_unet.stage_up3.8.proj.weight                 0.002390     0.00000120      [LOW_LR]
[00:52:51.572] cswin_unet.stage_up3.6.mlp.fc2.bias                0.002381     0.00000119      [LOW_LR]
[00:52:51.572] cswin_unet.stage3.4.mlp.fc2.weight                 0.002379     0.00000119      [LOW_LR]
[00:52:51.572] cswin_unet.stage_up3.4.proj.weight                 0.002326     0.00000116      [LOW_LR]
[00:52:51.572] cswin_unet.stage_up3.4.mlp.fc2.bias                0.002322     0.00000116      [LOW_LR]
[00:52:51.572] cswin_unet.stage_up3.8.qkv.weight                  0.002321     0.00000116      [LOW_LR]
[00:52:51.572] cswin_unet.stage_up3.3.proj.bias                   0.002275     0.00000114      [LOW_LR]
[00:52:51.573] cswin_unet.stage3.8.mlp.fc2.bias                   0.002270     0.00000113      [LOW_LR]
[00:52:51.573] cswin_unet.stage_up3.5.attns.1.get_v.bias          0.002268     0.00000113      [LOW_LR]
[00:52:51.573] cswin_unet.stage_up3.4.attns.1.get_v.bias          0.002254     0.00000113      [LOW_LR]
[00:52:51.573] cswin_unet.stage_up3.2.proj.bias                   0.002244     0.00000112      [LOW_LR]
[00:52:51.573] cswin_unet.stage_up3.7.proj.weight                 0.002196     0.00000110      [LOW_LR]
[00:52:51.573] cswin_unet.stage_up3.6.proj.weight                 0.002187     0.00000109      [LOW_LR]
[00:52:51.573] cswin_unet.stage_up3.3.attns.0.get_v.bias          0.002184     0.00000109      [LOW_LR]
[00:52:51.573] cswin_unet.stage_up3.5.proj.weight                 0.002172     0.00000109      [LOW_LR]
[00:52:51.573] cswin_unet.stage_up3.1.attns.1.get_v.bias          0.002150     0.00000108      [LOW_LR]
[00:52:51.573] cswin_unet.stage_up3.4.attns.0.get_v.bias          0.002144     0.00000107      [LOW_LR]
[00:52:51.573] cswin_unet.stage_up3.2.mlp.fc2.bias                0.002132     0.00000107      [LOW_LR]
[00:52:51.573] cswin_unet.stage_up3.1.proj.bias                   0.002123     0.00000106      [LOW_LR]
[00:52:51.574] cswin_unet.stage_up3.3.mlp.fc2.bias                0.002090     0.00000104      [LOW_LR]
[00:52:51.574] cswin_unet.stage_up3.0.attns.1.get_v.bias          0.001988     0.00000099      [LOW_LR]
[00:52:51.574] cswin_unet.merge2.conv.bias                        0.001977     0.00000099      [LOW_LR]
[00:52:51.574] cswin_unet.stage4.0.attns.0.get_v.bias             0.001975     0.00000099      [LOW_LR]
[00:52:51.574] cswin_unet.stage3.5.mlp.fc1.weight                 0.001896     0.00000095      [LOW_LR]
[00:52:51.574] cswin_unet.stage3.6.mlp.fc1.weight                 0.001873     0.00000094      [LOW_LR]
[00:52:51.574] cswin_unet.stage_up3.3.qkv.weight                  0.001849     0.00000092      [LOW_LR]
[00:52:51.574] cswin_unet.stage_up3.2.attns.1.get_v.bias          0.001838     0.00000092      [LOW_LR]
[00:52:51.574] cswin_unet.stage3.0.mlp.fc1.bias                   0.001760     0.00000088      [LOW_LR]
[00:52:51.574] cswin_unet.stage_up3.6.qkv.weight                  0.001749     0.00000087      [LOW_LR]
[00:52:51.574] cswin_unet.stage_up3.0.proj.weight                 0.001739     0.00000087      [LOW_LR]
[00:52:51.574] cswin_unet.stage_up3.5.qkv.weight                  0.001655     0.00000083      [LOW_LR]
[00:52:51.574] cswin_unet.stage3.5.mlp.fc2.weight                 0.001645     0.00000082      [LOW_LR]
[00:52:51.574] cswin_unet.stage3.3.qkv.bias                       0.001641     0.00000082      [LOW_LR]
[00:52:51.574] cswin_unet.stage_up3.7.qkv.weight                  0.001621     0.00000081      [LOW_LR]
[00:52:51.575] cswin_unet.stage_up3.1.qkv.weight                  0.001619     0.00000081      [LOW_LR]
[00:52:51.575] cswin_unet.stage3.6.mlp.fc2.weight                 0.001617     0.00000081      [LOW_LR]
[00:52:51.575] cswin_unet.stage_up3.4.qkv.weight                  0.001597     0.00000080      [LOW_LR]
[00:52:51.575] cswin_unet.stage3.4.qkv.bias                       0.001549     0.00000077      [LOW_LR]
[00:52:51.575] cswin_unet.stage_up3.2.qkv.weight                  0.001535     0.00000077      [LOW_LR]
[00:52:51.575] cswin_unet.stage_up3.1.mlp.fc2.bias                0.001514     0.00000076      [LOW_LR]
[00:52:51.575] cswin_unet.stage_up2.0.mlp.fc1.bias                0.001477     0.00000074      [LOW_LR]
[00:52:51.575] cswin_unet.stage3.7.mlp.fc1.weight                 0.001403     0.00000070      [LOW_LR]
[00:52:51.575] cswin_unet.stage_up3.0.proj.bias                   0.001378     0.00000069      [LOW_LR]
[00:52:51.575] cswin_unet.stage3.8.qkv.bias                       0.001335     0.00000067      [LOW_LR]
[00:52:51.575] cswin_unet.stage3.6.qkv.bias                       0.001316     0.00000066      [LOW_LR]
[00:52:51.575] cswin_unet.stage3.5.qkv.bias                       0.001298     0.00000065      [LOW_LR]
[00:52:51.575] cswin_unet.stage_up3.0.mlp.fc2.weight              0.001236     0.00000062      [LOW_LR]
[00:52:51.575] cswin_unet.stage3.7.mlp.fc2.weight                 0.001232     0.00000062      [LOW_LR]
[00:52:51.576] cswin_unet.stage_up4.0.attns.0.get_v.weight        0.001217     0.00000061      [LOW_LR]
[00:52:51.576] cswin_unet.stage3.8.mlp.fc1.weight                 0.001199     0.00000060      [LOW_LR]
[00:52:51.576] cswin_unet.stage_up2.1.mlp.fc1.bias                0.001127     0.00000056      [LOW_LR]
[00:52:51.576] cswin_unet.stage_up3.0.qkv.weight                  0.001105     0.00000055      [LOW_LR]
[00:52:51.576] cswin_unet.stage_up3.8.mlp.fc1.weight              0.001093     0.00000055      [LOW_LR]
[00:52:51.576] cswin_unet.stage_up3.7.mlp.fc1.weight              0.000967     0.00000048      [LOW_LR]
[00:52:51.576] cswin_unet.stage3.7.qkv.bias                       0.000966     0.00000048      [LOW_LR]
[00:52:51.576] cswin_unet.stage_up3.0.mlp.fc2.bias                0.000940     0.00000047      [LOW_LR]
[00:52:51.576] cswin_unet.stage_up3.6.mlp.fc2.weight              0.000938     0.00000047      [LOW_LR]
[00:52:51.576] cswin_unet.stage_up3.8.mlp.fc2.weight              0.000931     0.00000047      [LOW_LR]
[00:52:51.576] cswin_unet.stage_up3.6.mlp.fc1.weight              0.000931     0.00000047      [LOW_LR]
[00:52:51.576] cswin_unet.stage_up3.1.mlp.fc2.weight              0.000912     0.00000046      [LOW_LR]
[00:52:51.576] cswin_unet.stage3.8.mlp.fc2.weight                 0.000868     0.00000043      [LOW_LR]
[00:52:51.576] cswin_unet.stage_up3.7.mlp.fc2.weight              0.000839     0.00000042      [LOW_LR]
[00:52:51.576] cswin_unet.stage_up3.2.mlp.fc2.weight              0.000808     0.00000040      [LOW_LR]
[00:52:51.576] cswin_unet.stage_up3.3.mlp.fc2.weight              0.000808     0.00000040      [LOW_LR]
[00:52:51.576] cswin_unet.stage_up3.4.mlp.fc2.weight              0.000805     0.00000040      [LOW_LR]
[00:52:51.576] cswin_unet.stage_up3.0.mlp.fc1.weight              0.000776     0.00000039      [LOW_LR]
[00:52:51.576] cswin_unet.stage_up3.8.qkv.bias                    0.000767     0.00000038      [LOW_LR]
[00:52:51.576] cswin_unet.stage4.0.attns.0.get_v.weight           0.000654     0.00000033      [LOW_LR]
[00:52:51.576] cswin_unet.stage_up3.5.mlp.fc2.weight              0.000646     0.00000032      [LOW_LR]
[00:52:51.576] cswin_unet.stage_up3.4.mlp.fc1.weight              0.000630     0.00000032      [LOW_LR]
[00:52:51.576] cswin_unet.stage_up4.0.proj.bias                   0.000599     0.00000030      [LOW_LR]
[00:52:51.576] cswin_unet.stage_up3.6.qkv.bias                    0.000597     0.00000030      [LOW_LR]
[00:52:51.576] cswin_unet.stage_up3.1.qkv.bias                    0.000562     0.00000028      [LOW_LR]
[00:52:51.576] cswin_unet.stage_up3.1.mlp.fc1.weight              0.000540     0.00000027      [LOW_LR]
[00:52:51.576] cswin_unet.stage3.1.mlp.fc1.bias                   0.000533     0.00000027      [LOW_LR]
[00:52:51.576] cswin_unet.stage_up3.3.mlp.fc1.weight              0.000529     0.00000026      [LOW_LR]
[00:52:51.576] cswin_unet.stage3.2.mlp.fc1.bias                   0.000519     0.00000026      [LOW_LR]
[00:52:51.577] cswin_unet.stage_up3.7.qkv.bias                    0.000516     0.00000026      [LOW_LR]
[00:52:51.577] cswin_unet.stage_up3.2.mlp.fc1.weight              0.000495     0.00000025      [LOW_LR]
[00:52:51.577] cswin_unet.stage_up3.5.mlp.fc1.weight              0.000486     0.00000024      [LOW_LR]
[00:52:51.577] cswin_unet.stage_up3.2.qkv.bias                    0.000472     0.00000024      [LOW_LR]
[00:52:51.577] cswin_unet.stage_up3.0.qkv.bias                    0.000456     0.00000023      [LOW_LR]
[00:52:51.577] cswin_unet.stage_up4.0.mlp.fc1.weight              0.000454     0.00000023      [LOW_LR]
[00:52:51.577] cswin_unet.stage_up3.3.qkv.bias                    0.000450     0.00000022      [LOW_LR]
[00:52:51.577] cswin_unet.stage_up4.0.proj.weight                 0.000448     0.00000022      [LOW_LR]
[00:52:51.577] cswin_unet.stage_up3.5.qkv.bias                    0.000447     0.00000022      [LOW_LR]
[00:52:51.577] cswin_unet.stage_up3.4.qkv.bias                    0.000414     0.00000021      [LOW_LR]
[00:52:51.577] cswin_unet.stage3.3.mlp.fc1.bias                   0.000408     0.00000020      [LOW_LR]
[00:52:51.577] cswin_unet.stage3.4.mlp.fc1.bias                   0.000375     0.00000019      [LOW_LR]
[00:52:51.577] cswin_unet.stage4.0.proj.weight                    0.000293     0.00000015      [LOW_LR]
[00:52:51.577] cswin_unet.stage4.0.mlp.fc1.weight                 0.000281     0.00000014      [LOW_LR]
[00:52:51.577] cswin_unet.stage3.5.mlp.fc1.bias                   0.000248     0.00000012      [LOW_LR]
[00:52:51.577] cswin_unet.stage4.0.mlp.fc2.weight                 0.000248     0.00000012      [LOW_LR]
[00:52:51.577] cswin_unet.stage_up4.0.qkv.weight                  0.000245     0.00000012      [LOW_LR]
[00:52:51.577] cswin_unet.stage3.6.mlp.fc1.bias                   0.000233     0.00000012      [LOW_LR]
[00:52:51.577] cswin_unet.stage_up4.0.mlp.fc2.weight              0.000219     0.00000011      [LOW_LR]
[00:52:51.577] cswin_unet.merge3.conv.weight                      0.000209     0.00000010      [LOW_LR]
[00:52:51.577] cswin_unet.stage_up4.0.mlp.fc2.bias                0.000205     0.00000010      [LOW_LR]
[00:52:51.577] cswin_unet.stage_up4.0.qkv.bias                    0.000175     0.00000009      [LOW_LR]
[00:52:51.577] cswin_unet.stage3.7.mlp.fc1.bias                   0.000174     0.00000009      [LOW_LR]
[00:52:51.577] cswin_unet.stage3.8.mlp.fc1.bias                   0.000160     0.00000008      [LOW_LR]
[00:52:51.578] cswin_unet.stage_up3.8.mlp.fc1.bias                0.000154     0.00000008      [LOW_LR]
[00:52:51.578] cswin_unet.stage4.0.proj.bias                      0.000152     0.00000008      [LOW_LR]
[00:52:51.578] cswin_unet.stage_up3.7.mlp.fc1.bias                0.000138     0.00000007      [LOW_LR]
[00:52:51.578] cswin_unet.stage_up3.6.mlp.fc1.bias                0.000129     0.00000006      [LOW_LR]
[00:52:51.578] cswin_unet.stage_up3.0.mlp.fc1.bias                0.000112     0.00000006      [LOW_LR]
[00:52:51.578] cswin_unet.stage4.0.qkv.weight                     0.000099     0.00000005      [LOW_LR]
[00:52:51.578] cswin_unet.stage_up3.4.mlp.fc1.bias                0.000080     0.00000004      [LOW_LR]
[00:52:51.578] cswin_unet.stage4.0.mlp.fc2.bias                   0.000077     0.00000004      [LOW_LR]
[00:52:51.578] cswin_unet.stage_up3.3.mlp.fc1.bias                0.000067     0.00000003      [LOW_LR]
[00:52:51.578] cswin_unet.stage_up3.5.mlp.fc1.bias                0.000062     0.00000003      [LOW_LR]
[00:52:51.578] cswin_unet.stage_up4.0.mlp.fc1.bias                0.000061     0.00000003      [LOW_LR]
[00:52:51.578] cswin_unet.stage_up3.1.mlp.fc1.bias                0.000060     0.00000003      [LOW_LR]
[00:52:51.578] cswin_unet.stage_up3.2.mlp.fc1.bias                0.000056     0.00000003      [LOW_LR]
[00:52:51.578] cswin_unet.stage4.0.qkv.bias                       0.000047     0.00000002      [LOW_LR]
[00:52:51.578] cswin_unet.stage4.0.mlp.fc1.bias                   0.000039     0.00000002      [LOW_LR]
[00:52:51.578] cswin_unet.upsample4.encoder.weight                0.000026     0.00000001      [LOW_LR]
[00:52:51.578] cswin_unet.upsample4.encoder.bias                  0.000006     0.00000000      [LOW_LR]
[00:52:51.578] cswin_unet.upsample4.down.weight                   0.000006     0.00000000      [LOW_LR]
[00:52:51.578] cswin_unet.upsample4.down.bias                     0.000006     0.00000000      [LOW_LR]
[00:52:51.578] cswin_unet.merge3.conv.bias                        0.000003     0.00000000      [LOW_LR]
[00:52:51.578] --------------------------------------------------------------------------------
[00:52:51.578] Total layers: 463, High LR layers: 169, Low LR layers: 294
[00:52:51.578] ================================================================================

[00:53:04.737] Epoch 8, Iter 3470: loss=0.0567, ce=0.0096, dice=0.0881, grad_norm=0.201982
[00:53:08.349] Epoch 8, Iter 3480: loss=0.0390, ce=0.0045, dice=0.0621, grad_norm=0.172635
[00:53:11.970] Epoch 8, Iter 3490: loss=0.0353, ce=0.0035, dice=0.0565, grad_norm=0.325779
[00:53:15.613] Epoch 8, Iter 3500: loss=0.0269, ce=0.0073, dice=0.0400, grad_norm=0.104334
[00:53:19.233] Epoch 8, Iter 3510: loss=0.0918, ce=0.0133, dice=0.1441, grad_norm=0.619334
[00:53:22.847] Epoch 8, Iter 3520: loss=0.0531, ce=0.0047, dice=0.0853, grad_norm=0.487501
[00:53:26.485] Epoch 8, Iter 3530: loss=0.0392, ce=0.0059, dice=0.0614, grad_norm=0.138486
[00:53:30.071] Epoch 8, Iter 3540: loss=0.0237, ce=0.0046, dice=0.0364, grad_norm=0.066201
[00:53:33.664] Epoch 8, Iter 3550: loss=0.0291, ce=0.0087, dice=0.0426, grad_norm=0.077228
[00:53:37.230] Epoch 8, Iter 3560: loss=0.0489, ce=0.0055, dice=0.0778, grad_norm=0.685823
[00:53:40.842] Epoch 8, Iter 3570: loss=0.0301, ce=0.0058, dice=0.0464, grad_norm=0.422751
[00:53:44.420] Epoch 8, Iter 3580: loss=0.0508, ce=0.0031, dice=0.0826, grad_norm=0.182063
[00:53:48.010] Epoch 8, Iter 3590: loss=0.0244, ce=0.0050, dice=0.0374, grad_norm=0.116419
[00:53:51.608] Epoch 8, Iter 3600: loss=0.0213, ce=0.0057, dice=0.0318, grad_norm=0.140644
[00:53:55.200] Epoch 8, Iter 3610: loss=0.0318, ce=0.0028, dice=0.0512, grad_norm=0.101676
[00:53:58.800] Epoch 8, Iter 3620: loss=0.0228, ce=0.0050, dice=0.0346, grad_norm=0.069439
[00:54:02.408] Epoch 8, Iter 3630: loss=0.1357, ce=0.0071, dice=0.2215, grad_norm=0.241721
[00:54:05.999] Epoch 8, Iter 3640: loss=0.0385, ce=0.0037, dice=0.0617, grad_norm=0.152450
[00:54:09.635] Epoch 8, Iter 3650: loss=0.0264, ce=0.0075, dice=0.0390, grad_norm=0.114488
[00:54:13.219] Epoch 8, Iter 3660: loss=0.2061, ce=0.0047, dice=0.3403, grad_norm=0.032047
[00:54:16.808] Epoch 8, Iter 3670: loss=0.0197, ce=0.0081, dice=0.0274, grad_norm=0.034564
[00:54:20.385] Epoch 8, Iter 3680: loss=0.0605, ce=0.0080, dice=0.0954, grad_norm=0.153867
[00:54:23.974] Epoch 8, Iter 3690: loss=0.0492, ce=0.0039, dice=0.0794, grad_norm=0.608522
[00:54:27.548] Epoch 8, Iter 3700: loss=0.0342, ce=0.0030, dice=0.0550, grad_norm=0.870599
[00:54:31.146] Epoch 8, Iter 3710: loss=0.0250, ce=0.0064, dice=0.0374, grad_norm=0.076608
[00:54:34.756] Epoch 8, Iter 3720: loss=0.0658, ce=0.0044, dice=0.1067, grad_norm=0.709162
[00:54:38.339] Epoch 8, Iter 3730: loss=0.0352, ce=0.0047, dice=0.0555, grad_norm=0.299180
[00:54:41.917] Epoch 8, Iter 3740: loss=0.0337, ce=0.0052, dice=0.0526, grad_norm=0.187944
[00:54:45.508] Epoch 8, Iter 3750: loss=0.0359, ce=0.0034, dice=0.0576, grad_norm=0.543591
[00:54:49.088] Epoch 8, Iter 3760: loss=0.2100, ce=0.0023, dice=0.3484, grad_norm=0.032065
[00:54:52.674] Epoch 8, Iter 3770: loss=0.0491, ce=0.0070, dice=0.0771, grad_norm=0.204547
[00:54:56.270] Epoch 8, Iter 3780: loss=0.0424, ce=0.0036, dice=0.0682, grad_norm=0.262520
[00:54:59.880] Epoch 8, Iter 3790: loss=0.0959, ce=0.0055, dice=0.1561, grad_norm=0.340074
[00:55:03.459] Epoch 8, Iter 3800: loss=0.2091, ce=0.0040, dice=0.3459, grad_norm=0.030516
[00:55:07.058] Epoch 8, Iter 3810: loss=0.0214, ce=0.0022, dice=0.0342, grad_norm=0.125871
[00:55:10.637] Epoch 8, Iter 3820: loss=0.0231, ce=0.0064, dice=0.0342, grad_norm=0.162823
[00:55:14.219] Epoch 8, Iter 3830: loss=0.0384, ce=0.0042, dice=0.0613, grad_norm=0.211046
[00:55:17.800] Epoch 8, Iter 3840: loss=0.1233, ce=0.0054, dice=0.2019, grad_norm=0.198106
[00:55:21.411] Epoch 8, Iter 3850: loss=0.0292, ce=0.0052, dice=0.0452, grad_norm=0.070292
[00:55:24.986] Epoch 8, Iter 3860: loss=0.0479, ce=0.0041, dice=0.0771, grad_norm=0.115834
[00:55:28.571] Epoch 8, Iter 3870: loss=0.0245, ce=0.0031, dice=0.0387, grad_norm=0.245329
[00:55:32.140] Epoch 8, Iter 3880: loss=0.0176, ce=0.0017, dice=0.0282, grad_norm=0.064688
[00:55:35.723] Epoch 8, Iter 3890: loss=0.2057, ce=0.0018, dice=0.3416, grad_norm=0.023782
[00:55:38.796] Epoch 8: Avg Loss=0.0625, CE=0.0055, Dice=0.1005
[00:55:50.190] Epoch 9, Iter 3900: loss=0.0231, ce=0.0065, dice=0.0341, grad_norm=0.096137
[00:55:53.788] Epoch 9, Iter 3910: loss=0.0336, ce=0.0075, dice=0.0509, grad_norm=0.151706
[00:55:57.372] Epoch 9, Iter 3920: loss=0.0332, ce=0.0065, dice=0.0509, grad_norm=0.107528
[00:56:00.959] Epoch 9, Iter 3930: loss=0.0580, ce=0.0056, dice=0.0930, grad_norm=0.166386
[00:56:04.540] Epoch 9, Iter 3940: loss=0.0399, ce=0.0078, dice=0.0614, grad_norm=0.085068
[00:56:08.136] Epoch 9, Iter 3950: loss=0.0153, ce=0.0019, dice=0.0243, grad_norm=0.093163
[00:56:11.723] Epoch 9, Iter 3960: loss=0.0365, ce=0.0089, dice=0.0550, grad_norm=0.225935
[00:56:15.315] Epoch 9, Iter 3970: loss=0.0874, ce=0.0074, dice=0.1408, grad_norm=1.315894
[00:56:18.897] Epoch 9, Iter 3980: loss=0.2084, ce=0.0027, dice=0.3455, grad_norm=0.020037
[00:56:22.490] Epoch 9, Iter 3990: loss=0.0453, ce=0.0028, dice=0.0736, grad_norm=0.167783
[00:56:26.073] Epoch 9, Iter 4000: loss=0.0540, ce=0.0057, dice=0.0863, grad_norm=0.461376
[00:56:29.673] Epoch 9, Iter 4010: loss=0.0769, ce=0.0048, dice=0.1250, grad_norm=0.343476
[00:56:33.396] Epoch 9, Iter 4020: loss=0.0473, ce=0.0055, dice=0.0751, grad_norm=0.190232
[00:56:37.021] Epoch 9, Iter 4030: loss=0.0253, ce=0.0063, dice=0.0379, grad_norm=0.063393
[00:56:40.637] Epoch 9, Iter 4040: loss=0.0837, ce=0.0075, dice=0.1345, grad_norm=0.435008
[00:56:44.263] Epoch 9, Iter 4050: loss=0.0481, ce=0.0066, dice=0.0758, grad_norm=0.101781
[00:56:47.880] Epoch 9, Iter 4060: loss=0.0451, ce=0.0034, dice=0.0729, grad_norm=0.354290
[00:56:51.505] Epoch 9, Iter 4070: loss=0.0270, ce=0.0013, dice=0.0442, grad_norm=0.172750
[00:56:55.115] Epoch 9, Iter 4080: loss=0.0346, ce=0.0036, dice=0.0553, grad_norm=0.311862
[00:56:58.752] Epoch 9, Iter 4090: loss=0.0187, ce=0.0064, dice=0.0269, grad_norm=0.034853
[00:57:02.355] Epoch 9, Iter 4100: loss=0.2098, ce=0.0029, dice=0.3477, grad_norm=0.081902
[00:57:05.987] Epoch 9, Iter 4110: loss=0.0255, ce=0.0065, dice=0.0382, grad_norm=0.064124
[00:57:09.610] Epoch 9, Iter 4120: loss=0.0625, ce=0.0023, dice=0.1026, grad_norm=0.343893
[00:57:13.242] Epoch 9, Iter 4130: loss=0.0312, ce=0.0035, dice=0.0496, grad_norm=0.085071
[00:57:16.872] Epoch 9, Iter 4140: loss=0.0212, ce=0.0047, dice=0.0321, grad_norm=0.112805
[00:57:20.513] Epoch 9, Iter 4150: loss=0.0514, ce=0.0059, dice=0.0817, grad_norm=0.838389
[00:57:24.138] Epoch 9, Iter 4160: loss=0.0233, ce=0.0077, dice=0.0338, grad_norm=0.090576
[00:57:27.788] Epoch 9, Iter 4170: loss=0.0572, ce=0.0034, dice=0.0931, grad_norm=0.230706
[00:57:31.414] Epoch 9, Iter 4180: loss=0.2136, ce=0.0051, dice=0.3526, grad_norm=0.029804
[00:57:35.059] Epoch 9, Iter 4190: loss=0.0618, ce=0.0080, dice=0.0977, grad_norm=1.252324
[00:57:38.688] Epoch 9, Iter 4200: loss=0.0971, ce=0.0081, dice=0.1565, grad_norm=0.496035
[00:57:42.324] Epoch 9, Iter 4210: loss=0.0514, ce=0.0068, dice=0.0811, grad_norm=0.222121
[00:57:45.979] Epoch 9, Iter 4220: loss=0.0662, ce=0.0052, dice=0.1069, grad_norm=0.206935
[00:57:49.622] Epoch 9, Iter 4230: loss=0.2072, ce=0.0021, dice=0.3440, grad_norm=0.019706
[00:57:53.256] Epoch 9, Iter 4240: loss=0.0474, ce=0.0092, dice=0.0728, grad_norm=0.208171
[00:57:56.894] Epoch 9, Iter 4250: loss=0.0648, ce=0.0092, dice=0.1018, grad_norm=0.250950
[00:58:00.525] Epoch 9, Iter 4260: loss=0.2087, ce=0.0016, dice=0.3468, grad_norm=0.062124
[00:58:04.165] Epoch 9, Iter 4270: loss=0.0788, ce=0.0057, dice=0.1274, grad_norm=0.425755
[00:58:07.798] Epoch 9, Iter 4280: loss=0.0252, ce=0.0054, dice=0.0385, grad_norm=0.053900
[00:58:11.424] Epoch 9, Iter 4290: loss=0.0674, ce=0.0076, dice=0.1072, grad_norm=0.258762
[00:58:15.063] Epoch 9, Iter 4300: loss=0.0234, ce=0.0055, dice=0.0353, grad_norm=0.263739
[00:58:18.702] Epoch 9, Iter 4310: loss=0.2068, ce=0.0033, dice=0.3425, grad_norm=0.042072
[00:58:22.332] Epoch 9, Iter 4320: loss=0.1293, ce=0.0048, dice=0.2123, grad_norm=0.660399
[00:58:25.987] Epoch 9, Iter 4330: loss=0.0311, ce=0.0038, dice=0.0494, grad_norm=0.202616
[00:58:26.640] Epoch 9: Avg Loss=0.0616, CE=0.0053, Dice=0.0991
[00:58:26.734] save model to ./finetune_tpgm_surgical_lits17\finetuned_epoch_9.pth
[00:58:41.892] Epoch 10, Iter 4340: loss=0.0168, ce=0.0060, dice=0.0240, grad_norm=0.039114
[00:58:45.491] Epoch 10, Iter 4350: loss=0.1154, ce=0.0071, dice=0.1875, grad_norm=0.853796
[00:58:49.064] Epoch 10, Iter 4360: loss=0.0599, ce=0.0068, dice=0.0954, grad_norm=0.847767
[00:58:52.664] Epoch 10, Iter 4370: loss=0.0337, ce=0.0096, dice=0.0497, grad_norm=0.159012
[00:58:56.262] Epoch 10, Iter 4380: loss=0.0414, ce=0.0025, dice=0.0674, grad_norm=0.717042
[00:58:59.853] Epoch 10, Iter 4390: loss=0.0749, ce=0.0046, dice=0.1217, grad_norm=1.091540
[00:59:03.441] Epoch 10, Iter 4400: loss=0.0619, ce=0.0046, dice=0.1001, grad_norm=1.083067
[00:59:07.046] Epoch 10, Iter 4410: loss=0.0238, ce=0.0071, dice=0.0349, grad_norm=0.053873
[00:59:10.628] Epoch 10, Iter 4420: loss=0.0284, ce=0.0046, dice=0.0443, grad_norm=0.062221
[00:59:14.223] Epoch 10, Iter 4430: loss=0.0368, ce=0.0059, dice=0.0574, grad_norm=0.126085
[00:59:17.820] Epoch 10, Iter 4440: loss=0.1054, ce=0.0040, dice=0.1730, grad_norm=1.964825
[00:59:21.437] Epoch 10, Iter 4450: loss=0.0240, ce=0.0064, dice=0.0358, grad_norm=0.053501
[00:59:25.025] Epoch 10, Iter 4460: loss=0.0583, ce=0.0041, dice=0.0943, grad_norm=1.486678
[00:59:28.625] Epoch 10, Iter 4470: loss=0.2091, ce=0.0028, dice=0.3467, grad_norm=0.084886
[00:59:32.209] Epoch 10, Iter 4480: loss=0.0247, ce=0.0065, dice=0.0368, grad_norm=0.129424
[00:59:35.831] Epoch 10, Iter 4490: loss=0.0498, ce=0.0067, dice=0.0785, grad_norm=0.188042
[00:59:39.430] Epoch 10, Iter 4500: loss=0.0443, ce=0.0047, dice=0.0707, grad_norm=0.124494
[00:59:43.048] Epoch 10, Iter 4510: loss=0.2079, ce=0.0029, dice=0.3447, grad_norm=0.057177
[00:59:46.774] Epoch 10, Iter 4520: loss=0.0417, ce=0.0020, dice=0.0682, grad_norm=0.153240
[00:59:50.395] Epoch 10, Iter 4530: loss=0.0427, ce=0.0060, dice=0.0672, grad_norm=0.235030
[00:59:54.002] Epoch 10, Iter 4540: loss=0.0229, ce=0.0050, dice=0.0349, grad_norm=0.077116
[00:59:57.606] Epoch 10, Iter 4550: loss=0.0341, ce=0.0073, dice=0.0520, grad_norm=0.169843
[01:00:01.213] Epoch 10, Iter 4560: loss=0.0239, ce=0.0014, dice=0.0390, grad_norm=0.150891
[01:00:04.818] Epoch 10, Iter 4570: loss=0.0651, ce=0.0052, dice=0.1050, grad_norm=0.315723
[01:00:08.409] Epoch 10, Iter 4580: loss=0.0223, ce=0.0036, dice=0.0347, grad_norm=0.048435
[01:00:12.020] Epoch 10, Iter 4590: loss=0.2055, ce=0.0028, dice=0.3406, grad_norm=0.060553
[01:00:15.607] Epoch 10, Iter 4600: loss=0.0940, ce=0.0057, dice=0.1529, grad_norm=0.504168
[01:00:19.227] Epoch 10, Iter 4610: loss=0.0209, ce=0.0064, dice=0.0306, grad_norm=0.064611
[01:00:22.819] Epoch 10, Iter 4620: loss=0.0262, ce=0.0087, dice=0.0378, grad_norm=0.066980
[01:00:26.421] Epoch 10, Iter 4630: loss=0.0270, ce=0.0043, dice=0.0420, grad_norm=0.117402
[01:00:30.047] Epoch 10, Iter 4640: loss=0.0247, ce=0.0018, dice=0.0399, grad_norm=0.091213
[01:00:33.657] Epoch 10, Iter 4650: loss=0.0281, ce=0.0062, dice=0.0427, grad_norm=0.084915
[01:00:37.274] Epoch 10, Iter 4660: loss=0.0631, ce=0.0082, dice=0.0997, grad_norm=0.196913
[01:00:40.883] Epoch 10, Iter 4670: loss=0.0176, ce=0.0041, dice=0.0267, grad_norm=0.053779
[01:00:44.472] Epoch 10, Iter 4680: loss=0.0227, ce=0.0029, dice=0.0358, grad_norm=0.070642
[01:00:48.083] Epoch 10, Iter 4690: loss=0.2087, ce=0.0031, dice=0.3458, grad_norm=0.070113
[01:00:51.672] Epoch 10, Iter 4700: loss=0.0328, ce=0.0078, dice=0.0495, grad_norm=0.058859
[01:00:55.274] Epoch 10, Iter 4710: loss=0.2064, ce=0.0030, dice=0.3419, grad_norm=0.014538
[01:00:58.873] Epoch 10, Iter 4720: loss=0.0477, ce=0.0050, dice=0.0762, grad_norm=0.217773
[01:01:02.482] Epoch 10, Iter 4730: loss=0.0182, ce=0.0036, dice=0.0280, grad_norm=0.111150
[01:01:06.078] Epoch 10, Iter 4740: loss=0.0567, ce=0.0083, dice=0.0890, grad_norm=0.200807
[01:01:09.691] Epoch 10, Iter 4750: loss=0.0168, ce=0.0045, dice=0.0251, grad_norm=0.069391
[01:01:13.283] Epoch 10, Iter 4760: loss=0.0597, ce=0.0044, dice=0.0965, grad_norm=0.169342
[01:01:14.926] Epoch 10: Avg Loss=0.0618, CE=0.0051, Dice=0.0996
[01:08:23.797] Epoch 11, Iter 4770: loss=0.2077, ce=0.0022, dice=0.3447, grad_norm=0.017280
[01:08:27.372] Epoch 11, Iter 4780: loss=0.0521, ce=0.0038, dice=0.0842, grad_norm=0.260448
[01:08:30.976] Epoch 11, Iter 4790: loss=0.0279, ce=0.0028, dice=0.0447, grad_norm=0.504425
[01:08:34.569] Epoch 11, Iter 4800: loss=0.0321, ce=0.0045, dice=0.0505, grad_norm=0.178915
[01:08:38.180] Epoch 11, Iter 4810: loss=0.0418, ce=0.0037, dice=0.0673, grad_norm=0.321245
[01:08:41.763] Epoch 11, Iter 4820: loss=0.0294, ce=0.0051, dice=0.0456, grad_norm=0.063858
[01:08:45.361] Epoch 11, Iter 4830: loss=0.0392, ce=0.0087, dice=0.0595, grad_norm=0.137781
[01:08:48.953] Epoch 11, Iter 4840: loss=0.1165, ce=0.0017, dice=0.1931, grad_norm=1.050958
[01:08:52.612] Epoch 11, Iter 4850: loss=0.2061, ce=0.0008, dice=0.3429, grad_norm=0.029145
[01:08:56.235] Epoch 11, Iter 4860: loss=0.0194, ce=0.0058, dice=0.0285, grad_norm=0.060221
[01:08:59.864] Epoch 11, Iter 4870: loss=0.0311, ce=0.0063, dice=0.0476, grad_norm=0.100064
[01:09:03.475] Epoch 11, Iter 4880: loss=0.0222, ce=0.0046, dice=0.0339, grad_norm=0.048259
[01:09:07.125] Epoch 11, Iter 4890: loss=0.0474, ce=0.0025, dice=0.0774, grad_norm=0.791624
[01:09:10.740] Epoch 11, Iter 4900: loss=0.0986, ce=0.0032, dice=0.1621, grad_norm=1.681379
[01:09:14.383] Epoch 11, Iter 4910: loss=0.0343, ce=0.0031, dice=0.0551, grad_norm=0.465373
[01:09:18.009] Epoch 11, Iter 4920: loss=0.0290, ce=0.0055, dice=0.0447, grad_norm=0.093716
[01:09:21.654] Epoch 11, Iter 4930: loss=0.0599, ce=0.0051, dice=0.0965, grad_norm=0.170191
[01:09:25.305] Epoch 11, Iter 4940: loss=0.0215, ce=0.0054, dice=0.0322, grad_norm=0.053829
[01:09:28.924] Epoch 11, Iter 4950: loss=0.0359, ce=0.0028, dice=0.0580, grad_norm=0.199340
[01:09:32.538] Epoch 11, Iter 4960: loss=0.0256, ce=0.0046, dice=0.0396, grad_norm=0.129690
[01:09:36.178] Epoch 11, Iter 4970: loss=0.0280, ce=0.0037, dice=0.0442, grad_norm=0.073323
[01:09:39.792] Epoch 11, Iter 4980: loss=0.0277, ce=0.0077, dice=0.0411, grad_norm=0.062588
[01:09:43.433] Epoch 11, Iter 4990: loss=0.0331, ce=0.0065, dice=0.0508, grad_norm=0.086604
[01:09:47.068] Epoch 11, Iter 5000: loss=0.0218, ce=0.0049, dice=0.0331, grad_norm=0.117535
[01:09:50.716] Epoch 11, Iter 5010: loss=0.2098, ce=0.0024, dice=0.3480, grad_norm=0.047787
[01:09:54.356] Epoch 11, Iter 5020: loss=0.0355, ce=0.0058, dice=0.0553, grad_norm=0.148890
[01:09:57.993] Epoch 11, Iter 5030: loss=0.0180, ce=0.0059, dice=0.0260, grad_norm=0.066490
[01:10:01.628] Epoch 11, Iter 5040: loss=0.0353, ce=0.0047, dice=0.0558, grad_norm=0.419925
[01:10:05.285] Epoch 11, Iter 5050: loss=0.0254, ce=0.0051, dice=0.0390, grad_norm=0.158495
[01:10:08.902] Epoch 11, Iter 5060: loss=0.0435, ce=0.0057, dice=0.0687, grad_norm=0.071108
[01:10:12.554] Epoch 11, Iter 5070: loss=0.0307, ce=0.0036, dice=0.0487, grad_norm=0.363972
[01:10:16.190] Epoch 11, Iter 5080: loss=0.0165, ce=0.0039, dice=0.0249, grad_norm=0.054721
[01:10:19.841] Epoch 11, Iter 5090: loss=0.0236, ce=0.0028, dice=0.0375, grad_norm=0.143596
[01:10:23.482] Epoch 11, Iter 5100: loss=0.2078, ce=0.0047, dice=0.3432, grad_norm=0.036134
[01:10:27.138] Epoch 11, Iter 5110: loss=0.0258, ce=0.0047, dice=0.0399, grad_norm=0.056363
[01:10:30.771] Epoch 11, Iter 5120: loss=0.0170, ce=0.0044, dice=0.0254, grad_norm=0.033122
[01:10:34.411] Epoch 11, Iter 5130: loss=0.0358, ce=0.0035, dice=0.0574, grad_norm=0.482900
[01:10:38.027] Epoch 11, Iter 5140: loss=0.2175, ce=0.0019, dice=0.3613, grad_norm=0.062076
[01:10:41.653] Epoch 11, Iter 5150: loss=0.0373, ce=0.0060, dice=0.0582, grad_norm=0.290651
[01:10:45.269] Epoch 11, Iter 5160: loss=0.0731, ce=0.0061, dice=0.1177, grad_norm=0.432515
[01:10:48.901] Epoch 11, Iter 5170: loss=0.0194, ce=0.0041, dice=0.0295, grad_norm=0.069695
[01:10:52.516] Epoch 11, Iter 5180: loss=0.0858, ce=0.0042, dice=0.1402, grad_norm=0.892129
[01:10:56.121] Epoch 11, Iter 5190: loss=0.0242, ce=0.0043, dice=0.0374, grad_norm=0.101101
[01:10:58.867] Epoch 11: Avg Loss=0.0605, CE=0.0049, Dice=0.0975
[01:10:58.868] 
[EPOCH 13] Calculating RGN weights for surgical fine-tuning...
[01:11:12.561] RGN: Max weight before normalization: 0.002754
[01:11:12.588] 
================================================================================
[01:11:12.588] SURGICAL FINE-TUNING WITH TPGM - RGN METHOD
[01:11:12.588] ================================================================================
[01:11:12.588] Layer Name                                         Weight       Learning Rate  
[01:11:12.588] --------------------------------------------------------------------------------
[01:11:12.588] cswin_unet.stage1.0.attns.1.get_v.bias             1.000000     0.00050000      [ACTIVE]
[01:11:12.588] cswin_unet.stage1.0.attns.0.get_v.bias             0.665869     0.00033293      [ACTIVE]
[01:11:12.588] cswin_unet.output.weight                           0.361151     0.00018058      [ACTIVE]
[01:11:12.588] cswin_unet.stage_up1.0.attns.1.get_v.bias          0.358292     0.00017915      [ACTIVE]
[01:11:12.588] cswin_unet.concat_linear2.weight                   0.354174     0.00017709      [ACTIVE]
[01:11:12.588] cswin_unet.upsample2.out.weight                    0.347926     0.00017396      [ACTIVE]
[01:11:12.588] cswin_unet.concat_linear2.bias                     0.345079     0.00017254      [ACTIVE]
[01:11:12.588] cswin_unet.concat_linear3.weight                   0.331418     0.00016571      [ACTIVE]
[01:11:12.588] cswin_unet.stage1_conv_embed.0.weight              0.325820     0.00016291      [ACTIVE]
[01:11:12.588] cswin_unet.upsample1.out.weight                    0.324358     0.00016218      [ACTIVE]
[01:11:12.588] cswin_unet.upsample1.out.bias                      0.312776     0.00015639      [ACTIVE]
[01:11:12.588] cswin_unet.stage1.0.proj.bias                      0.305506     0.00015275      [ACTIVE]
[01:11:12.588] cswin_unet.upsample3.out.weight                    0.302142     0.00015107      [ACTIVE]
[01:11:12.588] cswin_unet.stage_up1.0.attns.0.get_v.bias          0.275675     0.00013784      [ACTIVE]
[01:11:12.588] cswin_unet.stage1.0.mlp.fc2.bias                   0.262420     0.00013121      [ACTIVE]
[01:11:12.588] cswin_unet.stage2.1.attns.0.get_v.bias             0.236736     0.00011837      [ACTIVE]
[01:11:12.588] cswin_unet.stage1.0.proj.weight                    0.226239     0.00011312      [ACTIVE]
[01:11:12.589] cswin_unet.concat_linear3.bias                     0.225343     0.00011267      [ACTIVE]
[01:11:12.589] cswin_unet.stage2.1.attns.1.get_v.bias             0.217784     0.00010889      [ACTIVE]
[01:11:12.589] cswin_unet.stage2.0.proj.bias                      0.207893     0.00010395      [ACTIVE]
[01:11:12.589] cswin_unet.upsample2.down.weight                   0.207448     0.00010372      [ACTIVE]
[01:11:12.589] cswin_unet.upsample2.encoder.weight                0.204846     0.00010242      [ACTIVE]
[01:11:12.589] cswin_unet.stage1_conv_embed.2.bias                0.189210     0.00009460      [ACTIVE]
[01:11:12.589] cswin_unet.stage1.0.mlp.fc2.weight                 0.182372     0.00009119      [ACTIVE]
[01:11:12.589] cswin_unet.stage_up2.1.attns.1.get_v.bias          0.172662     0.00008633      [ACTIVE]
[01:11:12.589] cswin_unet.stage1.0.mlp.fc1.weight                 0.172081     0.00008604      [ACTIVE]
[01:11:12.589] cswin_unet.stage1.0.qkv.weight                     0.169785     0.00008489      [ACTIVE]
[01:11:12.589] cswin_unet.upsample2.out.bias                      0.167844     0.00008392      [ACTIVE]
[01:11:12.589] cswin_unet.stage_up2.1.attns.0.get_v.bias          0.162055     0.00008103      [ACTIVE]
[01:11:12.589] cswin_unet.stage2.0.attns.1.get_v.bias             0.150693     0.00007535      [ACTIVE]
[01:11:12.589] cswin_unet.upsample2.encoder.bias                  0.149297     0.00007465      [ACTIVE]
[01:11:12.589] cswin_unet.stage2.0.attns.0.get_v.bias             0.142608     0.00007130      [ACTIVE]
[01:11:12.589] cswin_unet.stage_up1.0.mlp.fc2.weight              0.131934     0.00006597      [ACTIVE]
[01:11:12.589] cswin_unet.stage2.1.proj.bias                      0.128806     0.00006440      [ACTIVE]
[01:11:12.589] cswin_unet.stage_up1.0.mlp.fc1.weight              0.120854     0.00006043      [ACTIVE]
[01:11:12.589] cswin_unet.stage_up1.0.qkv.weight                  0.118291     0.00005915      [ACTIVE]
[01:11:12.589] cswin_unet.upsample2.down.bias                     0.116268     0.00005813      [ACTIVE]
[01:11:12.589] cswin_unet.stage_up1.0.proj.weight                 0.113095     0.00005655      [ACTIVE]
[01:11:12.589] cswin_unet.stage_up1.0.mlp.fc2.bias                0.106922     0.00005346      [ACTIVE]
[01:11:12.590] cswin_unet.upsample3.encoder.weight                0.104201     0.00005210      [ACTIVE]
[01:11:12.590] cswin_unet.stage_up2.0.attns.1.get_v.bias          0.103432     0.00005172      [ACTIVE]
[01:11:12.590] cswin_unet.upsample1.down.weight                   0.101083     0.00005054      [ACTIVE]
[01:11:12.590] cswin_unet.stage1.0.norm1.weight                   0.100000     0.00005000      [ACTIVE]
[01:11:12.590] cswin_unet.stage1.0.norm1.bias                     0.100000     0.00005000      [ACTIVE]
[01:11:12.590] cswin_unet.stage1.0.norm2.weight                   0.100000     0.00005000      [ACTIVE]
[01:11:12.590] cswin_unet.stage1.0.norm2.bias                     0.100000     0.00005000      [ACTIVE]
[01:11:12.590] cswin_unet.merge1.norm.weight                      0.100000     0.00005000      [ACTIVE]
[01:11:12.590] cswin_unet.merge1.norm.bias                        0.100000     0.00005000      [ACTIVE]
[01:11:12.590] cswin_unet.stage2.0.norm1.weight                   0.100000     0.00005000      [ACTIVE]
[01:11:12.590] cswin_unet.stage2.0.norm1.bias                     0.100000     0.00005000      [ACTIVE]
[01:11:12.590] cswin_unet.stage2.0.norm2.weight                   0.100000     0.00005000      [ACTIVE]
[01:11:12.590] cswin_unet.stage2.0.norm2.bias                     0.100000     0.00005000      [ACTIVE]
[01:11:12.590] cswin_unet.stage2.1.norm1.weight                   0.100000     0.00005000      [ACTIVE]
[01:11:12.590] cswin_unet.stage2.1.norm1.bias                     0.100000     0.00005000      [ACTIVE]
[01:11:12.590] cswin_unet.stage2.1.norm2.weight                   0.100000     0.00005000      [ACTIVE]
[01:11:12.590] cswin_unet.stage2.1.norm2.bias                     0.100000     0.00005000      [ACTIVE]
[01:11:12.590] cswin_unet.merge2.norm.weight                      0.100000     0.00005000      [ACTIVE]
[01:11:12.590] cswin_unet.merge2.norm.bias                        0.100000     0.00005000      [ACTIVE]
[01:11:12.590] cswin_unet.stage3.0.norm1.weight                   0.100000     0.00005000      [ACTIVE]
[01:11:12.591] cswin_unet.stage3.0.norm1.bias                     0.100000     0.00005000      [ACTIVE]
[01:11:12.591] cswin_unet.stage3.0.norm2.weight                   0.100000     0.00005000      [ACTIVE]
[01:11:12.591] cswin_unet.stage3.0.norm2.bias                     0.100000     0.00005000      [ACTIVE]
[01:11:12.591] cswin_unet.stage3.1.norm1.weight                   0.100000     0.00005000      [ACTIVE]
[01:11:12.591] cswin_unet.stage3.1.norm1.bias                     0.100000     0.00005000      [ACTIVE]
[01:11:12.591] cswin_unet.stage3.1.norm2.weight                   0.100000     0.00005000      [ACTIVE]
[01:11:12.591] cswin_unet.stage3.1.norm2.bias                     0.100000     0.00005000      [ACTIVE]
[01:11:12.591] cswin_unet.stage3.2.norm1.weight                   0.100000     0.00005000      [ACTIVE]
[01:11:12.591] cswin_unet.stage3.2.norm1.bias                     0.100000     0.00005000      [ACTIVE]
[01:11:12.591] cswin_unet.stage3.2.norm2.weight                   0.100000     0.00005000      [ACTIVE]
[01:11:12.591] cswin_unet.stage3.2.norm2.bias                     0.100000     0.00005000      [ACTIVE]
[01:11:12.591] cswin_unet.stage3.3.norm1.weight                   0.100000     0.00005000      [ACTIVE]
[01:11:12.591] cswin_unet.stage3.3.norm1.bias                     0.100000     0.00005000      [ACTIVE]
[01:11:12.591] cswin_unet.stage3.3.norm2.weight                   0.100000     0.00005000      [ACTIVE]
[01:11:12.591] cswin_unet.stage3.3.norm2.bias                     0.100000     0.00005000      [ACTIVE]
[01:11:12.591] cswin_unet.stage3.4.norm1.weight                   0.100000     0.00005000      [ACTIVE]
[01:11:12.591] cswin_unet.stage3.4.norm1.bias                     0.100000     0.00005000      [ACTIVE]
[01:11:12.591] cswin_unet.stage3.4.norm2.weight                   0.100000     0.00005000      [ACTIVE]
[01:11:12.591] cswin_unet.stage3.4.norm2.bias                     0.100000     0.00005000      [ACTIVE]
[01:11:12.591] cswin_unet.stage3.5.norm1.weight                   0.100000     0.00005000      [ACTIVE]
[01:11:12.591] cswin_unet.stage3.5.norm1.bias                     0.100000     0.00005000      [ACTIVE]
[01:11:12.591] cswin_unet.stage3.5.norm2.weight                   0.100000     0.00005000      [ACTIVE]
[01:11:12.592] cswin_unet.stage3.5.norm2.bias                     0.100000     0.00005000      [ACTIVE]
[01:11:12.592] cswin_unet.stage3.6.norm1.weight                   0.100000     0.00005000      [ACTIVE]
[01:11:12.592] cswin_unet.stage3.6.norm1.bias                     0.100000     0.00005000      [ACTIVE]
[01:11:12.592] cswin_unet.stage3.6.norm2.weight                   0.100000     0.00005000      [ACTIVE]
[01:11:12.592] cswin_unet.stage3.6.norm2.bias                     0.100000     0.00005000      [ACTIVE]
[01:11:12.592] cswin_unet.stage3.7.norm1.weight                   0.100000     0.00005000      [ACTIVE]
[01:11:12.592] cswin_unet.stage3.7.norm1.bias                     0.100000     0.00005000      [ACTIVE]
[01:11:12.592] cswin_unet.stage3.7.norm2.weight                   0.100000     0.00005000      [ACTIVE]
[01:11:12.592] cswin_unet.stage3.7.norm2.bias                     0.100000     0.00005000      [ACTIVE]
[01:11:12.592] cswin_unet.stage3.8.norm1.weight                   0.100000     0.00005000      [ACTIVE]
[01:11:12.592] cswin_unet.stage3.8.norm1.bias                     0.100000     0.00005000      [ACTIVE]
[01:11:12.592] cswin_unet.stage3.8.norm2.weight                   0.100000     0.00005000      [ACTIVE]
[01:11:12.592] cswin_unet.stage3.8.norm2.bias                     0.100000     0.00005000      [ACTIVE]
[01:11:12.592] cswin_unet.merge3.norm.weight                      0.100000     0.00005000      [ACTIVE]
[01:11:12.592] cswin_unet.merge3.norm.bias                        0.100000     0.00005000      [ACTIVE]
[01:11:12.592] cswin_unet.stage4.0.norm1.weight                   0.100000     0.00005000      [ACTIVE]
[01:11:12.592] cswin_unet.stage4.0.norm1.bias                     0.100000     0.00005000      [ACTIVE]
[01:11:12.592] cswin_unet.stage4.0.norm2.weight                   0.100000     0.00005000      [ACTIVE]
[01:11:12.592] cswin_unet.stage4.0.norm2.bias                     0.100000     0.00005000      [ACTIVE]
[01:11:12.592] cswin_unet.norm.weight                             0.100000     0.00005000      [ACTIVE]
[01:11:12.592] cswin_unet.norm.bias                               0.100000     0.00005000      [ACTIVE]
[01:11:12.592] cswin_unet.stage_up4.0.norm1.weight                0.100000     0.00005000      [ACTIVE]
[01:11:12.592] cswin_unet.stage_up4.0.norm1.bias                  0.100000     0.00005000      [ACTIVE]
[01:11:12.592] cswin_unet.stage_up4.0.norm2.weight                0.100000     0.00005000      [ACTIVE]
[01:11:12.592] cswin_unet.stage_up4.0.norm2.bias                  0.100000     0.00005000      [ACTIVE]
[01:11:12.593] cswin_unet.stage_up3.0.norm1.weight                0.100000     0.00005000      [ACTIVE]
[01:11:12.593] cswin_unet.stage_up3.0.norm1.bias                  0.100000     0.00005000      [ACTIVE]
[01:11:12.593] cswin_unet.stage_up3.0.norm2.weight                0.100000     0.00005000      [ACTIVE]
[01:11:12.593] cswin_unet.stage_up3.0.norm2.bias                  0.100000     0.00005000      [ACTIVE]
[01:11:12.593] cswin_unet.stage_up3.1.norm1.weight                0.100000     0.00005000      [ACTIVE]
[01:11:12.593] cswin_unet.stage_up3.1.norm1.bias                  0.100000     0.00005000      [ACTIVE]
[01:11:12.593] cswin_unet.stage_up3.1.norm2.weight                0.100000     0.00005000      [ACTIVE]
[01:11:12.593] cswin_unet.stage_up3.1.norm2.bias                  0.100000     0.00005000      [ACTIVE]
[01:11:12.593] cswin_unet.stage_up3.2.norm1.weight                0.100000     0.00005000      [ACTIVE]
[01:11:12.593] cswin_unet.stage_up3.2.norm1.bias                  0.100000     0.00005000      [ACTIVE]
[01:11:12.593] cswin_unet.stage_up3.2.norm2.weight                0.100000     0.00005000      [ACTIVE]
[01:11:12.593] cswin_unet.stage_up3.2.norm2.bias                  0.100000     0.00005000      [ACTIVE]
[01:11:12.593] cswin_unet.stage_up3.3.norm1.weight                0.100000     0.00005000      [ACTIVE]
[01:11:12.593] cswin_unet.stage_up3.3.norm1.bias                  0.100000     0.00005000      [ACTIVE]
[01:11:12.593] cswin_unet.stage_up3.3.norm2.weight                0.100000     0.00005000      [ACTIVE]
[01:11:12.593] cswin_unet.stage_up3.3.norm2.bias                  0.100000     0.00005000      [ACTIVE]
[01:11:12.593] cswin_unet.stage_up3.4.norm1.weight                0.100000     0.00005000      [ACTIVE]
[01:11:12.593] cswin_unet.stage_up3.4.norm1.bias                  0.100000     0.00005000      [ACTIVE]
[01:11:12.593] cswin_unet.stage_up3.4.norm2.weight                0.100000     0.00005000      [ACTIVE]
[01:11:12.593] cswin_unet.stage_up3.4.norm2.bias                  0.100000     0.00005000      [ACTIVE]
[01:11:12.593] cswin_unet.stage_up3.5.norm1.weight                0.100000     0.00005000      [ACTIVE]
[01:11:12.593] cswin_unet.stage_up3.5.norm1.bias                  0.100000     0.00005000      [ACTIVE]
[01:11:12.593] cswin_unet.stage_up3.5.norm2.weight                0.100000     0.00005000      [ACTIVE]
[01:11:12.593] cswin_unet.stage_up3.5.norm2.bias                  0.100000     0.00005000      [ACTIVE]
[01:11:12.593] cswin_unet.stage_up3.6.norm1.weight                0.100000     0.00005000      [ACTIVE]
[01:11:12.593] cswin_unet.stage_up3.6.norm1.bias                  0.100000     0.00005000      [ACTIVE]
[01:11:12.593] cswin_unet.stage_up3.6.norm2.weight                0.100000     0.00005000      [ACTIVE]
[01:11:12.593] cswin_unet.stage_up3.6.norm2.bias                  0.100000     0.00005000      [ACTIVE]
[01:11:12.593] cswin_unet.stage_up3.7.norm1.weight                0.100000     0.00005000      [ACTIVE]
[01:11:12.593] cswin_unet.stage_up3.7.norm1.bias                  0.100000     0.00005000      [ACTIVE]
[01:11:12.593] cswin_unet.stage_up3.7.norm2.weight                0.100000     0.00005000      [ACTIVE]
[01:11:12.593] cswin_unet.stage_up3.7.norm2.bias                  0.100000     0.00005000      [ACTIVE]
[01:11:12.593] cswin_unet.stage_up3.8.norm1.weight                0.100000     0.00005000      [ACTIVE]
[01:11:12.593] cswin_unet.stage_up3.8.norm1.bias                  0.100000     0.00005000      [ACTIVE]
[01:11:12.593] cswin_unet.stage_up3.8.norm2.weight                0.100000     0.00005000      [ACTIVE]
[01:11:12.595] cswin_unet.stage_up3.8.norm2.bias                  0.100000     0.00005000      [ACTIVE]
[01:11:12.595] cswin_unet.stage_up2.0.norm1.weight                0.100000     0.00005000      [ACTIVE]
[01:11:12.595] cswin_unet.stage_up2.0.norm1.bias                  0.100000     0.00005000      [ACTIVE]
[01:11:12.595] cswin_unet.stage_up2.0.norm2.weight                0.100000     0.00005000      [ACTIVE]
[01:11:12.595] cswin_unet.stage_up2.0.norm2.bias                  0.100000     0.00005000      [ACTIVE]
[01:11:12.595] cswin_unet.stage_up2.1.norm1.weight                0.100000     0.00005000      [ACTIVE]
[01:11:12.595] cswin_unet.stage_up2.1.norm1.bias                  0.100000     0.00005000      [ACTIVE]
[01:11:12.595] cswin_unet.stage_up2.1.norm2.weight                0.100000     0.00005000      [ACTIVE]
[01:11:12.595] cswin_unet.stage_up2.1.norm2.bias                  0.100000     0.00005000      [ACTIVE]
[01:11:12.595] cswin_unet.stage_up1.0.norm1.weight                0.100000     0.00005000      [ACTIVE]
[01:11:12.595] cswin_unet.stage_up1.0.norm1.bias                  0.100000     0.00005000      [ACTIVE]
[01:11:12.595] cswin_unet.stage_up1.0.norm2.weight                0.100000     0.00005000      [ACTIVE]
[01:11:12.595] cswin_unet.stage_up1.0.norm2.bias                  0.100000     0.00005000      [ACTIVE]
[01:11:12.595] cswin_unet.norm_up.weight                          0.100000     0.00005000      [ACTIVE]
[01:11:12.595] cswin_unet.norm_up.bias                            0.100000     0.00005000      [ACTIVE]
[01:11:12.595] cswin_unet.stage_up1.0.proj.bias                   0.099543     0.00004977      [ACTIVE]
[01:11:12.595] cswin_unet.stage_up2.0.attns.0.get_v.bias          0.099470     0.00004973      [ACTIVE]
[01:11:12.595] cswin_unet.stage1.0.attns.0.get_v.weight           0.097480     0.00004874      [ACTIVE]
[01:11:12.595] cswin_unet.merge1.conv.weight                      0.093409     0.00004670      [ACTIVE]
[01:11:12.595] cswin_unet.stage1.0.attns.1.get_v.weight           0.087040     0.00004352      [ACTIVE]
[01:11:12.595] cswin_unet.stage1_conv_embed.2.weight              0.086962     0.00004348      [ACTIVE]
[01:11:12.595] cswin_unet.upsample1.down.bias                     0.078257     0.00003913      [ACTIVE]
[01:11:12.595] cswin_unet.upsample3.down.weight                   0.077710     0.00003885      [ACTIVE]
[01:11:12.595] cswin_unet.concat_linear4.weight                   0.077245     0.00003862      [ACTIVE]
[01:11:12.595] cswin_unet.stage2.1.proj.weight                    0.074955     0.00003748      [ACTIVE]
[01:11:12.595] cswin_unet.stage_up2.0.attns.0.get_v.weight        0.072582     0.00003629      [ACTIVE]
[01:11:12.595] cswin_unet.stage_up2.0.proj.bias                   0.068856     0.00003443      [ACTIVE]
[01:11:12.595] cswin_unet.stage_up2.0.attns.1.get_v.weight        0.066259     0.00003313      [ACTIVE]
[01:11:12.595] cswin_unet.stage_up1.0.attns.1.get_v.weight        0.065339     0.00003267      [ACTIVE]
[01:11:12.597] cswin_unet.stage2.0.mlp.fc2.bias                   0.062912     0.00003146      [ACTIVE]
[01:11:12.597] cswin_unet.stage2.0.proj.weight                    0.060992     0.00003050      [ACTIVE]
[01:11:12.597] cswin_unet.stage_up1.0.attns.0.get_v.weight        0.060357     0.00003018      [ACTIVE]
[01:11:12.597] cswin_unet.stage2.0.attns.0.get_v.weight           0.056186     0.00002809      [ACTIVE]
[01:11:12.597] cswin_unet.stage1.0.qkv.bias                       0.055746     0.00002787      [ACTIVE]
[01:11:12.597] cswin_unet.stage2.0.mlp.fc1.weight                 0.052472     0.00002624      [ACTIVE]
[01:11:12.597] cswin_unet.upsample1.encoder.bias                  0.052049     0.00002602      [ACTIVE]
[01:11:12.597] cswin_unet.stage_up2.1.proj.bias                   0.050398     0.00002520      [ACTIVE]
[01:11:12.597] cswin_unet.stage2.0.attns.1.get_v.weight           0.050311     0.00002516      [ACTIVE]
[01:11:12.597] cswin_unet.stage2.1.attns.1.get_v.weight           0.050061     0.00002503      [ACTIVE]
[01:11:12.597] cswin_unet.stage2.1.qkv.weight                     0.049669     0.00002483      [LOW_LR]
[01:11:12.597] cswin_unet.stage2.1.mlp.fc1.weight                 0.047016     0.00002351      [LOW_LR]
[01:11:12.597] cswin_unet.stage_up2.1.proj.weight                 0.045740     0.00002287      [LOW_LR]
[01:11:12.598] cswin_unet.stage2.0.mlp.fc2.weight                 0.045713     0.00002286      [LOW_LR]
[01:11:12.598] cswin_unet.stage2.1.attns.0.get_v.weight           0.044771     0.00002239      [LOW_LR]
[01:11:12.598] cswin_unet.stage_up2.1.attns.0.get_v.weight        0.041979     0.00002099      [LOW_LR]
[01:11:12.598] cswin_unet.stage_up2.0.proj.weight                 0.041787     0.00002089      [LOW_LR]
[01:11:12.598] cswin_unet.stage_up2.1.qkv.weight                  0.040408     0.00002020      [LOW_LR]
[01:11:12.598] cswin_unet.upsample3.out.bias                      0.039984     0.00001999      [LOW_LR]
[01:11:12.598] cswin_unet.stage2.1.mlp.fc2.bias                   0.039612     0.00001981      [LOW_LR]
[01:11:12.598] cswin_unet.stage_up2.1.attns.1.get_v.weight        0.037949     0.00001897      [LOW_LR]
[01:11:12.598] cswin_unet.stage_up2.0.qkv.weight                  0.036487     0.00001824      [LOW_LR]
[01:11:12.598] cswin_unet.stage2.0.qkv.weight                     0.035916     0.00001796      [LOW_LR]
[01:11:12.598] cswin_unet.stage_up2.0.mlp.fc2.weight              0.031134     0.00001557      [LOW_LR]
[01:11:12.598] cswin_unet.stage_up1.0.qkv.bias                    0.029237     0.00001462      [LOW_LR]
[01:11:12.598] cswin_unet.stage_up2.0.mlp.fc1.weight              0.027371     0.00001369      [LOW_LR]
[01:11:12.598] cswin_unet.upsample1.encoder.weight                0.027168     0.00001358      [LOW_LR]
[01:11:12.598] cswin_unet.stage2.1.mlp.fc2.weight                 0.026744     0.00001337      [LOW_LR]
[01:11:12.598] cswin_unet.concat_linear4.bias                     0.024815     0.00001241      [LOW_LR]
[01:11:12.598] cswin_unet.stage_up2.1.mlp.fc2.bias                0.023903     0.00001195      [LOW_LR]
[01:11:12.598] cswin_unet.stage_up2.1.mlp.fc1.weight              0.022636     0.00001132      [LOW_LR]
[01:11:12.598] cswin_unet.stage1.0.mlp.fc1.bias                   0.021231     0.00001062      [LOW_LR]
[01:11:12.598] cswin_unet.stage_up2.0.mlp.fc2.bias                0.020825     0.00001041      [LOW_LR]
[01:11:12.598] cswin_unet.stage_up2.1.mlp.fc2.weight              0.017648     0.00000882      [LOW_LR]
[01:11:12.598] cswin_unet.stage2.1.qkv.bias                       0.017377     0.00000869      [LOW_LR]
[01:11:12.598] cswin_unet.stage2.0.qkv.bias                       0.014877     0.00000744      [LOW_LR]
[01:11:12.598] cswin_unet.upsample3.down.bias                     0.014842     0.00000742      [LOW_LR]
[01:11:12.598] cswin_unet.stage3.0.attns.0.get_v.weight           0.014755     0.00000738      [LOW_LR]
[01:11:12.598] cswin_unet.stage3.1.attns.1.get_v.weight           0.014415     0.00000721      [LOW_LR]
[01:11:12.598] cswin_unet.stage3.1.attns.0.get_v.weight           0.014271     0.00000714      [LOW_LR]
[01:11:12.598] cswin_unet.stage3.2.attns.0.get_v.weight           0.014189     0.00000709      [LOW_LR]
[01:11:12.599] cswin_unet.merge2.conv.weight                      0.013993     0.00000700      [LOW_LR]
[01:11:12.599] cswin_unet.stage3.3.attns.0.get_v.weight           0.013493     0.00000675      [LOW_LR]
[01:11:12.599] cswin_unet.stage3.3.attns.1.get_v.weight           0.012939     0.00000647      [LOW_LR]
[01:11:12.599] cswin_unet.stage3.0.attns.1.get_v.weight           0.012685     0.00000634      [LOW_LR]
[01:11:12.599] cswin_unet.stage3.4.attns.0.get_v.weight           0.011960     0.00000598      [LOW_LR]
[01:11:12.599] cswin_unet.stage3.4.attns.1.get_v.weight           0.011752     0.00000588      [LOW_LR]
[01:11:12.599] cswin_unet.upsample3.encoder.bias                  0.011705     0.00000585      [LOW_LR]
[01:11:12.599] cswin_unet.stage_up3.8.attns.1.get_v.bias          0.011615     0.00000581      [LOW_LR]
[01:11:12.599] cswin_unet.stage3.2.attns.1.get_v.weight           0.011462     0.00000573      [LOW_LR]
[01:11:12.599] cswin_unet.stage3.5.attns.0.get_v.weight           0.011215     0.00000561      [LOW_LR]
[01:11:12.599] cswin_unet.stage3.8.attns.1.get_v.weight           0.010966     0.00000548      [LOW_LR]
[01:11:12.599] cswin_unet.stage3.8.attns.0.get_v.weight           0.010947     0.00000547      [LOW_LR]
[01:11:12.599] cswin_unet.stage_up2.0.qkv.bias                    0.010940     0.00000547      [LOW_LR]
[01:11:12.599] cswin_unet.stage3.6.attns.1.get_v.weight           0.010720     0.00000536      [LOW_LR]
[01:11:12.599] cswin_unet.stage_up1.0.mlp.fc1.bias                0.010695     0.00000535      [LOW_LR]
[01:11:12.599] cswin_unet.stage_up4.0.attns.0.get_v.bias          0.010661     0.00000533      [LOW_LR]
[01:11:12.599] cswin_unet.stage2.0.mlp.fc1.bias                   0.010448     0.00000522      [LOW_LR]
[01:11:12.599] cswin_unet.stage_up3.8.attns.0.get_v.bias          0.010185     0.00000509      [LOW_LR]
[01:11:12.599] cswin_unet.merge1.conv.bias                        0.010063     0.00000503      [LOW_LR]
[01:11:12.599] cswin_unet.upsample4.out.weight                    0.009740     0.00000487      [LOW_LR]
[01:11:12.599] cswin_unet.stage3.6.attns.0.get_v.weight           0.009656     0.00000483      [LOW_LR]
[01:11:12.600] cswin_unet.stage3.0.attns.0.get_v.bias             0.009557     0.00000478      [LOW_LR]
[01:11:12.600] cswin_unet.upsample4.out.bias                      0.009443     0.00000472      [LOW_LR]
[01:11:12.600] cswin_unet.stage_up2.1.qkv.bias                    0.009315     0.00000466      [LOW_LR]
[01:11:12.600] cswin_unet.stage3.0.proj.weight                    0.009251     0.00000463      [LOW_LR]
[01:11:12.600] cswin_unet.stage_up3.1.attns.0.get_v.weight        0.008862     0.00000443      [LOW_LR]
[01:11:12.600] cswin_unet.stage3.5.attns.1.get_v.weight           0.008827     0.00000441      [LOW_LR]
[01:11:12.600] cswin_unet.stage3.7.attns.0.get_v.weight           0.008721     0.00000436      [LOW_LR]
[01:11:12.600] cswin_unet.stage3.8.attns.1.get_v.bias             0.008559     0.00000428      [LOW_LR]
[01:11:12.600] cswin_unet.stage3.3.qkv.weight                     0.008432     0.00000422      [LOW_LR]
[01:11:12.600] cswin_unet.stage3.8.attns.0.get_v.bias             0.008377     0.00000419      [LOW_LR]
[01:11:12.600] cswin_unet.stage3.3.proj.weight                    0.008372     0.00000419      [LOW_LR]
[01:11:12.600] cswin_unet.stage3.1.proj.weight                    0.008338     0.00000417      [LOW_LR]
[01:11:12.600] cswin_unet.stage3.5.attns.0.get_v.bias             0.008205     0.00000410      [LOW_LR]
[01:11:12.600] cswin_unet.stage3.7.attns.1.get_v.weight           0.008153     0.00000408      [LOW_LR]
[01:11:12.600] cswin_unet.stage3.0.attns.1.get_v.bias             0.008030     0.00000401      [LOW_LR]
[01:11:12.600] cswin_unet.stage_up3.7.attns.0.get_v.bias          0.007854     0.00000393      [LOW_LR]
[01:11:12.600] cswin_unet.stage_up3.6.attns.1.get_v.weight        0.007785     0.00000389      [LOW_LR]
[01:11:12.600] cswin_unet.stage_up3.5.attns.1.get_v.weight        0.007769     0.00000388      [LOW_LR]
[01:11:12.600] cswin_unet.stage_up3.2.attns.0.get_v.weight        0.007769     0.00000388      [LOW_LR]
[01:11:12.600] cswin_unet.stage_up3.4.attns.0.get_v.weight        0.007689     0.00000384      [LOW_LR]
[01:11:12.601] cswin_unet.stage_up3.8.attns.1.get_v.weight        0.007634     0.00000382      [LOW_LR]
[01:11:12.601] cswin_unet.stage_up3.8.attns.0.get_v.weight        0.007466     0.00000373      [LOW_LR]
[01:11:12.601] cswin_unet.stage3.1.attns.0.get_v.bias             0.007288     0.00000364      [LOW_LR]
[01:11:12.601] cswin_unet.stage_up3.0.attns.0.get_v.weight        0.007240     0.00000362      [LOW_LR]
[01:11:12.601] cswin_unet.stage_up3.5.attns.0.get_v.bias          0.007230     0.00000362      [LOW_LR]
[01:11:12.601] cswin_unet.stage_up3.7.attns.0.get_v.weight        0.007210     0.00000360      [LOW_LR]
[01:11:12.601] cswin_unet.stage2.1.mlp.fc1.bias                   0.007115     0.00000356      [LOW_LR]
[01:11:12.601] cswin_unet.stage_up3.3.attns.0.get_v.weight        0.007022     0.00000351      [LOW_LR]
[01:11:12.601] cswin_unet.stage3.6.attns.1.get_v.bias             0.006875     0.00000344      [LOW_LR]
[01:11:12.601] cswin_unet.stage_up3.3.attns.1.get_v.weight        0.006821     0.00000341      [LOW_LR]
[01:11:12.601] cswin_unet.stage3.2.proj.weight                    0.006795     0.00000340      [LOW_LR]
[01:11:12.601] cswin_unet.stage_up3.1.attns.1.get_v.weight        0.006761     0.00000338      [LOW_LR]
[01:11:12.601] cswin_unet.stage3.4.proj.weight                    0.006758     0.00000338      [LOW_LR]
[01:11:12.601] cswin_unet.stage_up3.4.attns.1.get_v.weight        0.006537     0.00000327      [LOW_LR]
[01:11:12.601] cswin_unet.stage_up3.2.attns.1.get_v.weight        0.006529     0.00000326      [LOW_LR]
[01:11:12.601] cswin_unet.stage_up3.5.attns.0.get_v.weight        0.006486     0.00000324      [LOW_LR]
[01:11:12.601] cswin_unet.stage3.7.attns.0.get_v.bias             0.006386     0.00000319      [LOW_LR]
[01:11:12.601] cswin_unet.stage_up3.6.attns.0.get_v.bias          0.006287     0.00000314      [LOW_LR]
[01:11:12.601] cswin_unet.stage3.6.attns.0.get_v.bias             0.006169     0.00000308      [LOW_LR]
[01:11:12.601] cswin_unet.stage3.5.proj.weight                    0.006080     0.00000304      [LOW_LR]
[01:11:12.601] cswin_unet.stage_up3.6.attns.0.get_v.weight        0.006040     0.00000302      [LOW_LR]
[01:11:12.601] cswin_unet.stage3.3.attns.1.get_v.bias             0.005935     0.00000297      [LOW_LR]
[01:11:12.601] cswin_unet.stage_up3.6.attns.1.get_v.bias          0.005866     0.00000293      [LOW_LR]
[01:11:12.601] cswin_unet.stage3.6.proj.weight                    0.005728     0.00000286      [LOW_LR]
[01:11:12.602] cswin_unet.stage3.2.attns.0.get_v.bias             0.005724     0.00000286      [LOW_LR]
[01:11:12.602] cswin_unet.stage3.8.proj.weight                    0.005601     0.00000280      [LOW_LR]
[01:11:12.602] cswin_unet.stage3.1.attns.1.get_v.bias             0.005597     0.00000280      [LOW_LR]
[01:11:12.602] cswin_unet.stage3.3.attns.0.get_v.bias             0.005469     0.00000273      [LOW_LR]
[01:11:12.602] cswin_unet.stage3.2.proj.bias                      0.005467     0.00000273      [LOW_LR]
[01:11:12.602] cswin_unet.stage_up3.8.mlp.fc2.bias                0.005412     0.00000271      [LOW_LR]
[01:11:12.602] cswin_unet.stage_up3.7.proj.bias                   0.005393     0.00000270      [LOW_LR]
[01:11:12.602] cswin_unet.stage_up3.8.proj.bias                   0.005389     0.00000269      [LOW_LR]
[01:11:12.602] cswin_unet.stage3.4.qkv.weight                     0.005371     0.00000269      [LOW_LR]
[01:11:12.602] cswin_unet.stage_up3.0.attns.1.get_v.weight        0.005334     0.00000267      [LOW_LR]
[01:11:12.602] cswin_unet.stage3.1.proj.bias                      0.005283     0.00000264      [LOW_LR]
[01:11:12.602] cswin_unet.stage_up3.7.attns.1.get_v.weight        0.005193     0.00000260      [LOW_LR]
[01:11:12.602] cswin_unet.stage3.1.qkv.weight                     0.005187     0.00000259      [LOW_LR]
[01:11:12.602] cswin_unet.stage3.0.proj.bias                      0.005172     0.00000259      [LOW_LR]
[01:11:12.602] cswin_unet.stage3.6.qkv.weight                     0.005144     0.00000257      [LOW_LR]
[01:11:12.602] cswin_unet.stage_up3.6.proj.bias                   0.005127     0.00000256      [LOW_LR]
[01:11:12.602] cswin_unet.stage_up3.1.attns.0.get_v.bias          0.005103     0.00000255      [LOW_LR]
[01:11:12.602] cswin_unet.stage_up3.8.proj.weight                 0.005092     0.00000255      [LOW_LR]
[01:11:12.602] cswin_unet.stage_up3.6.proj.weight                 0.005076     0.00000254      [LOW_LR]
[01:11:12.602] cswin_unet.stage3.7.proj.weight                    0.005055     0.00000253      [LOW_LR]
[01:11:12.602] cswin_unet.stage3.0.qkv.weight                     0.005034     0.00000252      [LOW_LR]
[01:11:12.602] cswin_unet.stage3.5.qkv.weight                     0.005014     0.00000251      [LOW_LR]
[01:11:12.602] cswin_unet.stage3.2.mlp.fc2.bias                   0.004984     0.00000249      [LOW_LR]
[01:11:12.603] cswin_unet.stage3.3.proj.bias                      0.004905     0.00000245      [LOW_LR]
[01:11:12.603] cswin_unet.stage3.4.proj.bias                      0.004861     0.00000243      [LOW_LR]
[01:11:12.603] cswin_unet.stage_up3.3.proj.weight                 0.004839     0.00000242      [LOW_LR]
[01:11:12.603] cswin_unet.stage3.8.qkv.weight                     0.004809     0.00000240      [LOW_LR]
[01:11:12.603] cswin_unet.stage_up3.4.proj.bias                   0.004660     0.00000233      [LOW_LR]
[01:11:12.603] cswin_unet.stage3.4.attns.1.get_v.bias             0.004630     0.00000231      [LOW_LR]
[01:11:12.603] cswin_unet.stage3.6.proj.bias                      0.004608     0.00000230      [LOW_LR]
[01:11:12.603] cswin_unet.stage_up3.1.proj.weight                 0.004539     0.00000227      [LOW_LR]
[01:11:12.603] cswin_unet.stage_up3.4.proj.weight                 0.004515     0.00000226      [LOW_LR]
[01:11:12.603] cswin_unet.stage_up3.7.mlp.fc2.bias                0.004512     0.00000226      [LOW_LR]
[01:11:12.603] cswin_unet.stage_up3.5.proj.bias                   0.004502     0.00000225      [LOW_LR]
[01:11:12.603] cswin_unet.stage_up3.7.attns.1.get_v.bias          0.004466     0.00000223      [LOW_LR]
[01:11:12.603] cswin_unet.stage_up3.3.attns.1.get_v.bias          0.004440     0.00000222      [LOW_LR]
[01:11:12.603] cswin_unet.stage_up3.8.qkv.weight                  0.004426     0.00000221      [LOW_LR]
[01:11:12.603] cswin_unet.stage_up3.5.mlp.fc2.bias                0.004374     0.00000219      [LOW_LR]
[01:11:12.603] cswin_unet.stage_up3.2.attns.0.get_v.bias          0.004310     0.00000216      [LOW_LR]
[01:11:12.603] cswin_unet.stage_up3.7.proj.weight                 0.004310     0.00000215      [LOW_LR]
[01:11:12.604] cswin_unet.stage_up3.5.proj.weight                 0.004297     0.00000215      [LOW_LR]
[01:11:12.604] cswin_unet.stage3.5.proj.bias                      0.004292     0.00000215      [LOW_LR]
[01:11:12.604] cswin_unet.stage_up3.6.mlp.fc2.bias                0.004271     0.00000214      [LOW_LR]
[01:11:12.604] cswin_unet.stage3.0.mlp.fc2.weight                 0.004212     0.00000211      [LOW_LR]
[01:11:12.604] cswin_unet.stage3.7.proj.bias                      0.004209     0.00000210      [LOW_LR]
[01:11:12.604] cswin_unet.stage3.2.qkv.weight                     0.004163     0.00000208      [LOW_LR]
[01:11:12.604] cswin_unet.stage3.3.mlp.fc2.bias                   0.004110     0.00000205      [LOW_LR]
[01:11:12.604] cswin_unet.stage_up3.2.proj.weight                 0.004103     0.00000205      [LOW_LR]
[01:11:12.604] cswin_unet.stage3.7.qkv.weight                     0.004073     0.00000204      [LOW_LR]
[01:11:12.604] cswin_unet.stage_up3.5.attns.1.get_v.bias          0.004002     0.00000200      [LOW_LR]
[01:11:12.604] cswin_unet.stage_up3.4.mlp.fc2.bias                0.003993     0.00000200      [LOW_LR]
[01:11:12.604] cswin_unet.stage3.4.attns.0.get_v.bias             0.003948     0.00000197      [LOW_LR]
[01:11:12.604] cswin_unet.stage3.8.proj.bias                      0.003935     0.00000197      [LOW_LR]
[01:11:12.604] cswin_unet.stage3.2.attns.1.get_v.bias             0.003900     0.00000195      [LOW_LR]
[01:11:12.604] cswin_unet.stage_up3.3.proj.bias                   0.003898     0.00000195      [LOW_LR]
[01:11:12.604] cswin_unet.stage3.7.attns.1.get_v.bias             0.003888     0.00000194      [LOW_LR]
[01:11:12.604] cswin_unet.stage3.5.mlp.fc2.bias                   0.003884     0.00000194      [LOW_LR]
[01:11:12.604] cswin_unet.stage_up3.0.attns.0.get_v.bias          0.003855     0.00000193      [LOW_LR]
[01:11:12.604] cswin_unet.stage_up3.2.proj.bias                   0.003810     0.00000191      [LOW_LR]
[01:11:12.604] cswin_unet.stage3.4.mlp.fc2.bias                   0.003753     0.00000188      [LOW_LR]
[01:11:12.604] cswin_unet.stage3.0.mlp.fc1.weight                 0.003751     0.00000188      [LOW_LR]
[01:11:12.604] cswin_unet.stage_up3.4.attns.1.get_v.bias          0.003718     0.00000186      [LOW_LR]
[01:11:12.604] cswin_unet.stage_up3.2.mlp.fc2.bias                0.003651     0.00000183      [LOW_LR]
[01:11:12.604] cswin_unet.stage_up3.3.mlp.fc2.bias                0.003603     0.00000180      [LOW_LR]
[01:11:12.605] cswin_unet.stage3.5.attns.1.get_v.bias             0.003575     0.00000179      [LOW_LR]
[01:11:12.605] cswin_unet.stage_up2.0.mlp.fc1.bias                0.003545     0.00000177      [LOW_LR]
[01:11:12.605] cswin_unet.stage3.8.mlp.fc2.bias                   0.003543     0.00000177      [LOW_LR]
[01:11:12.605] cswin_unet.stage3.1.mlp.fc2.bias                   0.003516     0.00000176      [LOW_LR]
[01:11:12.605] cswin_unet.stage_up3.1.proj.bias                   0.003486     0.00000174      [LOW_LR]
[01:11:12.605] cswin_unet.stage_up3.6.qkv.weight                  0.003474     0.00000174      [LOW_LR]
[01:11:12.605] cswin_unet.stage_up3.4.attns.0.get_v.bias          0.003473     0.00000174      [LOW_LR]
[01:11:12.605] cswin_unet.stage_up3.3.attns.0.get_v.bias          0.003427     0.00000171      [LOW_LR]
[01:11:12.605] cswin_unet.stage3.6.mlp.fc2.bias                   0.003313     0.00000166      [LOW_LR]
[01:11:12.605] cswin_unet.stage3.7.mlp.fc2.bias                   0.003269     0.00000163      [LOW_LR]
[01:11:12.605] cswin_unet.stage_up3.7.qkv.weight                  0.003178     0.00000159      [LOW_LR]
[01:11:12.605] cswin_unet.stage_up3.1.attns.1.get_v.bias          0.003145     0.00000157      [LOW_LR]
[01:11:12.605] cswin_unet.stage_up3.2.attns.1.get_v.bias          0.003047     0.00000152      [LOW_LR]
[01:11:12.605] cswin_unet.stage_up3.0.attns.1.get_v.bias          0.002895     0.00000145      [LOW_LR]
[01:11:12.605] cswin_unet.stage_up3.4.qkv.weight                  0.002867     0.00000143      [LOW_LR]
[01:11:12.605] cswin_unet.stage_up3.5.qkv.weight                  0.002865     0.00000143      [LOW_LR]
[01:11:12.605] cswin_unet.stage_up3.0.proj.weight                 0.002838     0.00000142      [LOW_LR]
[01:11:12.606] cswin_unet.stage_up2.1.mlp.fc1.bias                0.002807     0.00000140      [LOW_LR]
[01:11:12.606] cswin_unet.stage_up3.3.qkv.weight                  0.002745     0.00000137      [LOW_LR]
[01:11:12.606] cswin_unet.stage3.0.mlp.fc2.bias                   0.002734     0.00000137      [LOW_LR]
[01:11:12.606] cswin_unet.stage_up3.1.mlp.fc2.bias                0.002542     0.00000127      [LOW_LR]
[01:11:12.606] cswin_unet.stage_up3.2.qkv.weight                  0.002504     0.00000125      [LOW_LR]
[01:11:12.606] cswin_unet.stage_up3.1.qkv.weight                  0.002444     0.00000122      [LOW_LR]
[01:11:12.606] cswin_unet.stage3.1.mlp.fc2.weight                 0.002402     0.00000120      [LOW_LR]
[01:11:12.606] cswin_unet.stage3.4.mlp.fc1.weight                 0.002354     0.00000118      [LOW_LR]
[01:11:12.606] cswin_unet.stage3.6.mlp.fc1.weight                 0.002334     0.00000117      [LOW_LR]
[01:11:12.606] cswin_unet.stage_up3.8.mlp.fc1.weight              0.002230     0.00000111      [LOW_LR]
[01:11:12.606] cswin_unet.stage_up3.0.proj.bias                   0.002211     0.00000111      [LOW_LR]
[01:11:12.606] cswin_unet.stage3.2.mlp.fc2.weight                 0.002199     0.00000110      [LOW_LR]
[01:11:12.606] cswin_unet.stage3.3.mlp.fc2.weight                 0.002189     0.00000109      [LOW_LR]
[01:11:12.606] cswin_unet.stage3.4.mlp.fc2.weight                 0.002129     0.00000106      [LOW_LR]
[01:11:12.606] cswin_unet.stage3.8.mlp.fc1.weight                 0.002124     0.00000106      [LOW_LR]
[01:11:12.606] cswin_unet.stage3.3.mlp.fc1.weight                 0.002110     0.00000106      [LOW_LR]
[01:11:12.606] cswin_unet.stage3.1.mlp.fc1.weight                 0.002108     0.00000105      [LOW_LR]
[01:11:12.606] cswin_unet.stage4.0.attns.0.get_v.bias             0.002009     0.00000100      [LOW_LR]
[01:11:12.606] cswin_unet.stage3.6.mlp.fc2.weight                 0.001994     0.00000100      [LOW_LR]
[01:11:12.606] cswin_unet.stage_up3.6.mlp.fc2.weight              0.001971     0.00000099      [LOW_LR]
[01:11:12.607] cswin_unet.stage3.2.mlp.fc1.weight                 0.001963     0.00000098      [LOW_LR]
[01:11:12.607] cswin_unet.stage_up3.0.mlp.fc2.weight              0.001962     0.00000098      [LOW_LR]
[01:11:12.607] cswin_unet.stage_up3.6.mlp.fc1.weight              0.001959     0.00000098      [LOW_LR]
[01:11:12.607] cswin_unet.stage_up3.8.mlp.fc2.weight              0.001951     0.00000098      [LOW_LR]
[01:11:12.607] cswin_unet.stage_up3.7.mlp.fc1.weight              0.001947     0.00000097      [LOW_LR]
[01:11:12.607] cswin_unet.stage3.5.mlp.fc1.weight                 0.001942     0.00000097      [LOW_LR]
[01:11:12.607] cswin_unet.stage3.7.mlp.fc1.weight                 0.001892     0.00000095      [LOW_LR]
[01:11:12.607] cswin_unet.stage3.3.qkv.bias                       0.001769     0.00000088      [LOW_LR]
[01:11:12.607] cswin_unet.stage3.5.mlp.fc2.weight                 0.001736     0.00000087      [LOW_LR]
[01:11:12.607] cswin_unet.stage3.0.qkv.bias                       0.001699     0.00000085      [LOW_LR]
[01:11:12.607] cswin_unet.stage_up3.4.mlp.fc2.weight              0.001647     0.00000082      [LOW_LR]
[01:11:12.607] cswin_unet.stage_up3.7.mlp.fc2.weight              0.001644     0.00000082      [LOW_LR]
[01:11:12.607] cswin_unet.stage3.7.mlp.fc2.weight                 0.001627     0.00000081      [LOW_LR]
[01:11:12.607] cswin_unet.stage3.1.qkv.bias                       0.001578     0.00000079      [LOW_LR]
[01:11:12.607] cswin_unet.stage_up3.1.mlp.fc2.weight              0.001549     0.00000077      [LOW_LR]
[01:11:12.607] cswin_unet.stage_up3.0.mlp.fc2.bias                0.001548     0.00000077      [LOW_LR]
[01:11:12.607] cswin_unet.stage_up3.3.mlp.fc2.weight              0.001517     0.00000076      [LOW_LR]
[01:11:12.607] cswin_unet.stage1_conv_embed.0.bias                0.001517     0.00000076      [LOW_LR]
[01:11:12.607] cswin_unet.stage_up3.2.mlp.fc2.weight              0.001487     0.00000074      [LOW_LR]
[01:11:12.607] cswin_unet.stage3.8.mlp.fc2.weight                 0.001476     0.00000074      [LOW_LR]
[01:11:12.607] cswin_unet.stage_up3.0.qkv.weight                  0.001475     0.00000074      [LOW_LR]
[01:11:12.608] cswin_unet.stage_up3.8.qkv.bias                    0.001432     0.00000072      [LOW_LR]
[01:11:12.608] cswin_unet.stage_up3.4.mlp.fc1.weight              0.001408     0.00000070      [LOW_LR]
[01:11:12.608] cswin_unet.stage_up4.0.attns.0.get_v.weight        0.001365     0.00000068      [LOW_LR]
[01:11:12.608] cswin_unet.stage_up3.5.mlp.fc2.weight              0.001315     0.00000066      [LOW_LR]
[01:11:12.608] cswin_unet.stage_up3.0.mlp.fc1.weight              0.001304     0.00000065      [LOW_LR]
[01:11:12.608] cswin_unet.stage3.6.qkv.bias                       0.001188     0.00000059      [LOW_LR]
[01:11:12.608] cswin_unet.stage_up3.5.mlp.fc1.weight              0.001154     0.00000058      [LOW_LR]
[01:11:12.608] cswin_unet.stage_up3.6.qkv.bias                    0.001130     0.00000056      [LOW_LR]
[01:11:12.608] cswin_unet.stage3.8.qkv.bias                       0.001095     0.00000055      [LOW_LR]
[01:11:12.608] cswin_unet.stage3.2.qkv.bias                       0.001082     0.00000054      [LOW_LR]
[01:11:12.608] cswin_unet.stage3.5.qkv.bias                       0.001080     0.00000054      [LOW_LR]
[01:11:12.608] cswin_unet.stage_up3.2.mlp.fc1.weight              0.001049     0.00000052      [LOW_LR]
[01:11:12.608] cswin_unet.stage3.4.qkv.bias                       0.001022     0.00000051      [LOW_LR]
[01:11:12.608] cswin_unet.stage4.0.attns.0.get_v.weight           0.001014     0.00000051      [LOW_LR]
[01:11:12.608] cswin_unet.stage3.7.qkv.bias                       0.001013     0.00000051      [LOW_LR]
[01:11:12.608] cswin_unet.stage_up3.1.mlp.fc1.weight              0.001003     0.00000050      [LOW_LR]
[01:11:12.608] cswin_unet.stage_up3.3.mlp.fc1.weight              0.001002     0.00000050      [LOW_LR]
[01:11:12.608] cswin_unet.stage_up3.7.qkv.bias                    0.000905     0.00000045      [LOW_LR]
[01:11:12.608] cswin_unet.stage_up3.1.qkv.bias                    0.000857     0.00000043      [LOW_LR]
[01:11:12.608] cswin_unet.stage_up3.5.qkv.bias                    0.000856     0.00000043      [LOW_LR]
[01:11:12.608] cswin_unet.stage_up3.2.qkv.bias                    0.000781     0.00000039      [LOW_LR]
[01:11:12.608] cswin_unet.merge2.conv.bias                        0.000745     0.00000037      [LOW_LR]
[01:11:12.608] cswin_unet.stage_up3.3.qkv.bias                    0.000693     0.00000035      [LOW_LR]
[01:11:12.608] cswin_unet.stage_up4.0.proj.bias                   0.000681     0.00000034      [LOW_LR]
[01:11:12.609] cswin_unet.stage3.0.mlp.fc1.bias                   0.000666     0.00000033      [LOW_LR]
[01:11:12.609] cswin_unet.stage_up3.4.qkv.bias                    0.000647     0.00000032      [LOW_LR]
[01:11:12.609] cswin_unet.stage_up3.0.qkv.bias                    0.000626     0.00000031      [LOW_LR]
[01:11:12.609] cswin_unet.stage_up4.0.proj.weight                 0.000484     0.00000024      [LOW_LR]
[01:11:12.609] cswin_unet.stage_up4.0.mlp.fc1.weight              0.000448     0.00000022      [LOW_LR]
[01:11:12.609] cswin_unet.stage4.0.proj.weight                    0.000396     0.00000020      [LOW_LR]
[01:11:12.609] cswin_unet.stage_up4.0.mlp.fc2.weight              0.000372     0.00000019      [LOW_LR]
[01:11:12.609] cswin_unet.stage_up4.0.mlp.fc2.bias                0.000347     0.00000017      [LOW_LR]
[01:11:12.609] cswin_unet.stage_up3.8.mlp.fc1.bias                0.000313     0.00000016      [LOW_LR]
[01:11:12.609] cswin_unet.stage3.6.mlp.fc1.bias                   0.000292     0.00000015      [LOW_LR]
[01:11:12.609] cswin_unet.stage3.8.mlp.fc1.bias                   0.000289     0.00000014      [LOW_LR]
[01:11:12.609] cswin_unet.stage3.4.mlp.fc1.bias                   0.000278     0.00000014      [LOW_LR]
[01:11:12.609] cswin_unet.stage3.3.mlp.fc1.bias                   0.000267     0.00000013      [LOW_LR]
[01:11:12.609] cswin_unet.stage3.1.mlp.fc1.bias                   0.000259     0.00000013      [LOW_LR]
[01:11:12.609] cswin_unet.stage3.5.mlp.fc1.bias                   0.000256     0.00000013      [LOW_LR]
[01:11:12.609] cswin_unet.stage_up3.7.mlp.fc1.bias                0.000245     0.00000012      [LOW_LR]
[01:11:12.609] cswin_unet.stage_up3.6.mlp.fc1.bias                0.000244     0.00000012      [LOW_LR]
[01:11:12.609] cswin_unet.stage3.2.mlp.fc1.bias                   0.000240     0.00000012      [LOW_LR]
[01:11:12.609] cswin_unet.stage3.7.mlp.fc1.bias                   0.000238     0.00000012      [LOW_LR]
[01:11:12.609] cswin_unet.stage4.0.mlp.fc2.weight                 0.000211     0.00000011      [LOW_LR]
[01:11:12.609] cswin_unet.stage_up3.0.mlp.fc1.bias                0.000198     0.00000010      [LOW_LR]
[01:11:12.609] cswin_unet.stage_up4.0.qkv.weight                  0.000189     0.00000009      [LOW_LR]
[01:11:12.609] cswin_unet.stage4.0.mlp.fc1.weight                 0.000175     0.00000009      [LOW_LR]
[01:11:12.610] cswin_unet.stage_up3.4.mlp.fc1.bias                0.000174     0.00000009      [LOW_LR]
[01:11:12.610] cswin_unet.stage_up4.0.qkv.bias                    0.000147     0.00000007      [LOW_LR]
[01:11:12.610] cswin_unet.stage_up3.5.mlp.fc1.bias                0.000144     0.00000007      [LOW_LR]
[01:11:12.610] cswin_unet.stage4.0.qkv.weight                     0.000139     0.00000007      [LOW_LR]
[01:11:12.610] cswin_unet.merge3.conv.weight                      0.000124     0.00000006      [LOW_LR]
[01:11:12.610] cswin_unet.stage_up3.3.mlp.fc1.bias                0.000121     0.00000006      [LOW_LR]
[01:11:12.610] cswin_unet.stage_up3.2.mlp.fc1.bias                0.000115     0.00000006      [LOW_LR]
[01:11:12.610] cswin_unet.stage_up3.1.mlp.fc1.bias                0.000114     0.00000006      [LOW_LR]
[01:11:12.610] cswin_unet.stage4.0.proj.bias                      0.000112     0.00000006      [LOW_LR]
[01:11:12.610] cswin_unet.stage_up4.0.mlp.fc1.bias                0.000057     0.00000003      [LOW_LR]
[01:11:12.610] cswin_unet.stage4.0.mlp.fc2.bias                   0.000054     0.00000003      [LOW_LR]
[01:11:12.610] cswin_unet.stage4.0.qkv.bias                       0.000049     0.00000002      [LOW_LR]
[01:11:12.610] cswin_unet.upsample4.encoder.weight                0.000043     0.00000002      [LOW_LR]
[01:11:12.610] cswin_unet.stage4.0.mlp.fc1.bias                   0.000022     0.00000001      [LOW_LR]
[01:11:12.610] cswin_unet.upsample4.encoder.bias                  0.000014     0.00000001      [LOW_LR]
[01:11:12.610] cswin_unet.upsample4.down.weight                   0.000011     0.00000001      [LOW_LR]
[01:11:12.610] cswin_unet.upsample4.down.bias                     0.000010     0.00000001      [LOW_LR]
[01:11:12.610] cswin_unet.merge3.conv.bias                        0.000002     0.00000000      [LOW_LR]
[01:11:12.611] --------------------------------------------------------------------------------
[01:11:12.611] Total layers: 463, High LR layers: 180, Low LR layers: 283
[01:11:12.611] ================================================================================

[01:11:25.323] Epoch 12, Iter 5200: loss=0.0270, ce=0.0021, dice=0.0436, grad_norm=0.256060
[01:11:29.000] Epoch 12, Iter 5210: loss=0.0299, ce=0.0089, dice=0.0439, grad_norm=0.075858
[01:11:32.626] Epoch 12, Iter 5220: loss=0.0264, ce=0.0065, dice=0.0397, grad_norm=0.074595
[01:11:36.239] Epoch 12, Iter 5230: loss=0.0396, ce=0.0039, dice=0.0634, grad_norm=0.130895
[01:11:39.842] Epoch 12, Iter 5240: loss=0.0424, ce=0.0066, dice=0.0663, grad_norm=0.136210
[01:11:43.461] Epoch 12, Iter 5250: loss=0.0215, ce=0.0062, dice=0.0317, grad_norm=0.089096
[01:11:47.061] Epoch 12, Iter 5260: loss=0.0393, ce=0.0048, dice=0.0622, grad_norm=0.315721
[01:11:50.692] Epoch 12, Iter 5270: loss=0.2094, ce=0.0038, dice=0.3464, grad_norm=0.056279
[01:11:54.308] Epoch 12, Iter 5280: loss=0.0241, ce=0.0023, dice=0.0387, grad_norm=0.150783
[01:11:57.946] Epoch 12, Iter 5290: loss=0.0711, ce=0.0063, dice=0.1143, grad_norm=0.385977
[01:12:01.561] Epoch 12, Iter 5300: loss=0.0320, ce=0.0051, dice=0.0500, grad_norm=0.334869
[01:12:05.180] Epoch 12, Iter 5310: loss=0.0185, ce=0.0039, dice=0.0282, grad_norm=0.067810
[01:12:08.789] Epoch 12, Iter 5320: loss=0.0444, ce=0.0038, dice=0.0714, grad_norm=0.267157
[01:12:12.407] Epoch 12, Iter 5330: loss=0.0203, ce=0.0027, dice=0.0320, grad_norm=0.130703
[01:12:16.019] Epoch 12, Iter 5340: loss=0.0488, ce=0.0038, dice=0.0788, grad_norm=0.200620
[01:12:19.655] Epoch 12, Iter 5350: loss=0.1739, ce=0.0077, dice=0.2846, grad_norm=3.377294
[01:12:23.290] Epoch 12, Iter 5360: loss=0.0221, ce=0.0033, dice=0.0345, grad_norm=0.137454
[01:12:26.945] Epoch 12, Iter 5370: loss=0.0322, ce=0.0025, dice=0.0520, grad_norm=0.134341
[01:12:30.560] Epoch 12, Iter 5380: loss=0.0177, ce=0.0045, dice=0.0264, grad_norm=0.064790
[01:12:34.277] Epoch 12, Iter 5390: loss=0.0843, ce=0.0038, dice=0.1379, grad_norm=0.249270
[01:12:37.918] Epoch 12, Iter 5400: loss=0.0216, ce=0.0021, dice=0.0345, grad_norm=0.105689
[01:12:41.537] Epoch 12, Iter 5410: loss=0.2044, ce=0.0024, dice=0.3390, grad_norm=0.020424
[01:12:45.164] Epoch 12, Iter 5420: loss=0.0241, ce=0.0044, dice=0.0371, grad_norm=0.069078
[01:12:48.808] Epoch 12, Iter 5430: loss=0.0386, ce=0.0052, dice=0.0608, grad_norm=0.081868
[01:12:52.439] Epoch 12, Iter 5440: loss=0.0303, ce=0.0027, dice=0.0487, grad_norm=0.102210
[01:12:56.074] Epoch 12, Iter 5450: loss=0.0472, ce=0.0059, dice=0.0747, grad_norm=0.133578
[01:12:59.707] Epoch 12, Iter 5460: loss=0.0270, ce=0.0033, dice=0.0427, grad_norm=0.174890
[01:13:03.358] Epoch 12, Iter 5470: loss=0.2127, ce=0.0071, dice=0.3498, grad_norm=0.039033
[01:13:06.986] Epoch 12, Iter 5480: loss=0.0154, ce=0.0052, dice=0.0221, grad_norm=0.067155
[01:13:10.613] Epoch 12, Iter 5490: loss=0.0215, ce=0.0012, dice=0.0351, grad_norm=0.083820
[01:13:14.248] Epoch 12, Iter 5500: loss=0.0383, ce=0.0040, dice=0.0612, grad_norm=0.075649
[01:13:17.892] Epoch 12, Iter 5510: loss=0.0344, ce=0.0044, dice=0.0544, grad_norm=0.112794
[01:13:21.499] Epoch 12, Iter 5520: loss=0.2079, ce=0.0022, dice=0.3451, grad_norm=0.053972
[01:13:25.129] Epoch 12, Iter 5530: loss=0.2083, ce=0.0012, dice=0.3463, grad_norm=0.088918
[01:13:28.752] Epoch 12, Iter 5540: loss=0.0491, ce=0.0051, dice=0.0785, grad_norm=0.440261
[01:13:32.412] Epoch 12, Iter 5550: loss=0.0373, ce=0.0051, dice=0.0588, grad_norm=0.130395
[01:13:36.069] Epoch 12, Iter 5560: loss=0.0476, ce=0.0066, dice=0.0750, grad_norm=0.327191
[01:13:39.707] Epoch 12, Iter 5570: loss=0.0258, ce=0.0068, dice=0.0384, grad_norm=0.049217
[01:13:43.320] Epoch 12, Iter 5580: loss=0.2083, ce=0.0031, dice=0.3451, grad_norm=0.043431
[01:13:46.945] Epoch 12, Iter 5590: loss=0.0334, ce=0.0061, dice=0.0516, grad_norm=0.216998
[01:13:50.566] Epoch 12, Iter 5600: loss=0.0674, ce=0.0069, dice=0.1078, grad_norm=0.373054
[01:13:54.208] Epoch 12, Iter 5610: loss=0.1112, ce=0.0051, dice=0.1820, grad_norm=0.554333
[01:13:57.835] Epoch 12, Iter 5620: loss=0.0439, ce=0.0052, dice=0.0696, grad_norm=0.194982
[01:14:01.694] Epoch 12: Avg Loss=0.0615, CE=0.0048, Dice=0.0993
[01:14:12.957] Epoch 13, Iter 5630: loss=0.1105, ce=0.0062, dice=0.1801, grad_norm=0.761003
[01:14:16.555] Epoch 13, Iter 5640: loss=0.0404, ce=0.0045, dice=0.0644, grad_norm=0.137314
[01:14:20.174] Epoch 13, Iter 5650: loss=0.1622, ce=0.0031, dice=0.2682, grad_norm=1.190030
[01:14:23.789] Epoch 13, Iter 5660: loss=0.0214, ce=0.0039, dice=0.0330, grad_norm=0.117575
[01:14:27.430] Epoch 13, Iter 5670: loss=0.0265, ce=0.0053, dice=0.0405, grad_norm=0.058073
[01:14:31.059] Epoch 13, Iter 5680: loss=0.0207, ce=0.0033, dice=0.0323, grad_norm=0.058766
[01:14:34.708] Epoch 13, Iter 5690: loss=0.0554, ce=0.0087, dice=0.0865, grad_norm=0.215833
[01:14:38.338] Epoch 13, Iter 5700: loss=0.2075, ce=0.0018, dice=0.3446, grad_norm=0.027951
[01:14:41.990] Epoch 13, Iter 5710: loss=0.0235, ce=0.0071, dice=0.0345, grad_norm=0.041684
[01:14:45.604] Epoch 13, Iter 5720: loss=0.0245, ce=0.0019, dice=0.0396, grad_norm=0.234230
[01:14:49.238] Epoch 13, Iter 5730: loss=0.0149, ce=0.0042, dice=0.0221, grad_norm=0.063286
[01:14:52.821] Epoch 13, Iter 5740: loss=0.0447, ce=0.0049, dice=0.0713, grad_norm=0.225594
[01:14:56.418] Epoch 13, Iter 5750: loss=0.0393, ce=0.0082, dice=0.0600, grad_norm=0.171804
[01:15:00.033] Epoch 13, Iter 5760: loss=0.0390, ce=0.0060, dice=0.0611, grad_norm=0.112440
[01:15:03.651] Epoch 13, Iter 5770: loss=0.0336, ce=0.0051, dice=0.0526, grad_norm=0.107373
[01:15:07.325] Epoch 13, Iter 5780: loss=0.0205, ce=0.0034, dice=0.0319, grad_norm=0.067608
[01:15:10.975] Epoch 13, Iter 5790: loss=0.0492, ce=0.0040, dice=0.0793, grad_norm=0.176070
[01:15:14.575] Epoch 13, Iter 5800: loss=0.0710, ce=0.0047, dice=0.1153, grad_norm=0.245988
[01:15:18.208] Epoch 13, Iter 5810: loss=0.0431, ce=0.0054, dice=0.0683, grad_norm=0.492975
[01:15:21.833] Epoch 13, Iter 5820: loss=0.0346, ce=0.0032, dice=0.0555, grad_norm=0.216949
[01:15:25.480] Epoch 13, Iter 5830: loss=0.2099, ce=0.0057, dice=0.3461, grad_norm=0.053145
[01:15:29.086] Epoch 13, Iter 5840: loss=0.1940, ce=0.0009, dice=0.3228, grad_norm=1.018116
[01:15:32.700] Epoch 13, Iter 5850: loss=0.1048, ce=0.0032, dice=0.1725, grad_norm=0.265740
[01:15:36.299] Epoch 13, Iter 5860: loss=0.0420, ce=0.0038, dice=0.0675, grad_norm=0.117872
[01:15:39.919] Epoch 13, Iter 5870: loss=0.0431, ce=0.0033, dice=0.0696, grad_norm=0.184513
[01:15:43.524] Epoch 13, Iter 5880: loss=0.0392, ce=0.0037, dice=0.0629, grad_norm=0.417555
[01:15:47.133] Epoch 13, Iter 5890: loss=0.0278, ce=0.0061, dice=0.0423, grad_norm=0.075703
[01:15:50.745] Epoch 13, Iter 5900: loss=0.0249, ce=0.0045, dice=0.0384, grad_norm=0.064082
[01:15:54.375] Epoch 13, Iter 5910: loss=0.2067, ce=0.0030, dice=0.3426, grad_norm=0.018080
[01:15:58.015] Epoch 13, Iter 5920: loss=0.0202, ce=0.0024, dice=0.0321, grad_norm=0.085231
[01:16:01.653] Epoch 13, Iter 5930: loss=0.0344, ce=0.0031, dice=0.0553, grad_norm=0.104663
[01:16:05.287] Epoch 13, Iter 5940: loss=0.0247, ce=0.0029, dice=0.0393, grad_norm=0.093261
[01:16:08.916] Epoch 13, Iter 5950: loss=0.1092, ce=0.0028, dice=0.1802, grad_norm=0.472213
[01:16:12.542] Epoch 13, Iter 5960: loss=0.0592, ce=0.0043, dice=0.0959, grad_norm=0.207798
[01:16:16.164] Epoch 13, Iter 5970: loss=0.0264, ce=0.0034, dice=0.0417, grad_norm=0.303371
[01:16:19.805] Epoch 13, Iter 5980: loss=0.0512, ce=0.0035, dice=0.0831, grad_norm=0.289463
[01:16:23.441] Epoch 13, Iter 5990: loss=0.0567, ce=0.0032, dice=0.0924, grad_norm=0.323541
[01:16:27.074] Epoch 13, Iter 6000: loss=0.0323, ce=0.0085, dice=0.0482, grad_norm=0.079484
[01:16:30.726] Epoch 13, Iter 6010: loss=0.0208, ce=0.0031, dice=0.0326, grad_norm=0.053512
[01:16:34.359] Epoch 13, Iter 6020: loss=0.0226, ce=0.0048, dice=0.0344, grad_norm=0.068466
[01:16:38.002] Epoch 13, Iter 6030: loss=0.0292, ce=0.0047, dice=0.0455, grad_norm=0.132523
[01:16:41.648] Epoch 13, Iter 6040: loss=0.0206, ce=0.0042, dice=0.0316, grad_norm=0.059494
[01:16:45.293] Epoch 13, Iter 6050: loss=0.0386, ce=0.0069, dice=0.0596, grad_norm=0.104834
[01:16:48.923] Epoch 13, Iter 6060: loss=0.0511, ce=0.0039, dice=0.0826, grad_norm=0.311278
[01:16:50.281] Epoch 13: Avg Loss=0.0585, CE=0.0048, Dice=0.0943
[01:23:58.132] Epoch 14, Iter 6070: loss=0.0297, ce=0.0051, dice=0.0461, grad_norm=0.097698
[01:24:01.757] Epoch 14, Iter 6080: loss=0.0353, ce=0.0029, dice=0.0568, grad_norm=0.321013
[01:24:05.399] Epoch 14, Iter 6090: loss=0.0356, ce=0.0056, dice=0.0556, grad_norm=0.063062
[01:24:09.034] Epoch 14, Iter 6100: loss=0.2086, ce=0.0041, dice=0.3449, grad_norm=0.042632
[01:24:12.639] Epoch 14, Iter 6110: loss=0.0701, ce=0.0089, dice=0.1108, grad_norm=0.480527
[01:24:16.253] Epoch 14, Iter 6120: loss=0.0167, ce=0.0053, dice=0.0244, grad_norm=0.046465
[01:24:19.889] Epoch 14, Iter 6130: loss=0.0250, ce=0.0075, dice=0.0366, grad_norm=0.056831
[01:24:23.507] Epoch 14, Iter 6140: loss=0.2086, ce=0.0038, dice=0.3451, grad_norm=0.033218
[01:24:27.156] Epoch 14, Iter 6150: loss=0.0253, ce=0.0121, dice=0.0341, grad_norm=0.065285
[01:24:30.774] Epoch 14, Iter 6160: loss=0.0206, ce=0.0035, dice=0.0321, grad_norm=0.058668
[01:24:34.420] Epoch 14, Iter 6170: loss=0.0281, ce=0.0063, dice=0.0427, grad_norm=0.068939
[01:24:38.034] Epoch 14, Iter 6180: loss=0.0169, ce=0.0049, dice=0.0249, grad_norm=0.057561
[01:24:41.677] Epoch 14, Iter 6190: loss=0.0250, ce=0.0043, dice=0.0389, grad_norm=0.162749
[01:24:45.315] Epoch 14, Iter 6200: loss=0.0712, ce=0.0021, dice=0.1173, grad_norm=0.236559
[01:24:48.958] Epoch 14, Iter 6210: loss=0.0514, ce=0.0049, dice=0.0824, grad_norm=0.786751
[01:24:52.591] Epoch 14, Iter 6220: loss=0.0313, ce=0.0047, dice=0.0491, grad_norm=0.144229
[01:24:56.214] Epoch 14, Iter 6230: loss=0.0436, ce=0.0051, dice=0.0693, grad_norm=0.279186
[01:24:59.869] Epoch 14, Iter 6240: loss=0.0427, ce=0.0058, dice=0.0674, grad_norm=0.267231
[01:25:03.532] Epoch 14, Iter 6250: loss=0.0326, ce=0.0026, dice=0.0525, grad_norm=0.182952
[01:25:07.172] Epoch 14, Iter 6260: loss=0.0283, ce=0.0030, dice=0.0451, grad_norm=0.170531
[01:25:10.806] Epoch 14, Iter 6270: loss=0.0214, ce=0.0014, dice=0.0348, grad_norm=0.124732
[01:25:14.464] Epoch 14, Iter 6280: loss=0.0227, ce=0.0056, dice=0.0342, grad_norm=0.081031
[01:25:18.114] Epoch 14, Iter 6290: loss=0.0159, ce=0.0032, dice=0.0243, grad_norm=0.047918
[01:25:21.753] Epoch 14, Iter 6300: loss=0.0236, ce=0.0063, dice=0.0351, grad_norm=0.103005
[01:25:25.394] Epoch 14, Iter 6310: loss=0.0271, ce=0.0079, dice=0.0398, grad_norm=0.071887
[01:25:29.009] Epoch 14, Iter 6320: loss=0.0371, ce=0.0032, dice=0.0597, grad_norm=0.269202
[01:25:32.648] Epoch 14, Iter 6330: loss=0.2097, ce=0.0027, dice=0.3477, grad_norm=0.031358
[01:25:36.283] Epoch 14, Iter 6340: loss=0.0732, ce=0.0028, dice=0.1201, grad_norm=0.495349
[01:25:39.925] Epoch 14, Iter 6350: loss=0.0246, ce=0.0056, dice=0.0372, grad_norm=0.121760
[01:25:43.550] Epoch 14, Iter 6360: loss=0.0326, ce=0.0045, dice=0.0514, grad_norm=0.155031
[01:25:47.206] Epoch 14, Iter 6370: loss=0.0501, ce=0.0048, dice=0.0802, grad_norm=0.146708
[01:25:50.819] Epoch 14, Iter 6380: loss=0.0473, ce=0.0030, dice=0.0768, grad_norm=0.317967
[01:25:54.462] Epoch 14, Iter 6390: loss=0.0231, ce=0.0045, dice=0.0355, grad_norm=0.074461
[01:25:58.110] Epoch 14, Iter 6400: loss=0.0282, ce=0.0029, dice=0.0450, grad_norm=0.241066
[01:26:01.750] Epoch 14, Iter 6410: loss=0.0598, ce=0.0048, dice=0.0964, grad_norm=0.115475
[01:26:05.378] Epoch 14, Iter 6420: loss=0.0518, ce=0.0025, dice=0.0847, grad_norm=0.461984
[01:26:09.012] Epoch 14, Iter 6430: loss=0.0317, ce=0.0033, dice=0.0506, grad_norm=0.105861
[01:26:12.606] Epoch 14, Iter 6440: loss=0.0255, ce=0.0029, dice=0.0406, grad_norm=0.163774
[01:26:16.226] Epoch 14, Iter 6450: loss=0.2059, ce=0.0035, dice=0.3409, grad_norm=0.012090
[01:26:19.831] Epoch 14, Iter 6460: loss=0.0493, ce=0.0014, dice=0.0812, grad_norm=1.132888
[01:26:23.425] Epoch 14, Iter 6470: loss=0.0759, ce=0.0067, dice=0.1220, grad_norm=0.347643
[01:26:27.041] Epoch 14, Iter 6480: loss=0.0396, ce=0.0056, dice=0.0623, grad_norm=0.171326
[01:26:30.639] Epoch 14, Iter 6490: loss=0.0133, ce=0.0037, dice=0.0198, grad_norm=0.079966
[01:26:33.034] Epoch 14: Avg Loss=0.0603, CE=0.0048, Dice=0.0974
[01:26:45.783] Epoch 15, Iter 6500: loss=0.2076, ce=0.0027, dice=0.3442, grad_norm=0.016937
[01:26:49.393] Epoch 15, Iter 6510: loss=0.0211, ce=0.0061, dice=0.0311, grad_norm=0.087879
[01:26:53.010] Epoch 15, Iter 6520: loss=0.0176, ce=0.0020, dice=0.0279, grad_norm=0.081100
[01:26:56.639] Epoch 15, Iter 6530: loss=0.0205, ce=0.0065, dice=0.0298, grad_norm=0.055177
[01:27:00.273] Epoch 15, Iter 6540: loss=0.0218, ce=0.0020, dice=0.0350, grad_norm=0.172707
[01:27:03.905] Epoch 15, Iter 6550: loss=0.0487, ce=0.0050, dice=0.0778, grad_norm=0.259827
[01:27:07.550] Epoch 15, Iter 6560: loss=0.0442, ce=0.0036, dice=0.0713, grad_norm=0.913336
[01:27:11.164] Epoch 15, Iter 6570: loss=0.0328, ce=0.0053, dice=0.0512, grad_norm=0.120879
[01:27:14.778] Epoch 15, Iter 6580: loss=0.0532, ce=0.0062, dice=0.0845, grad_norm=1.021357
[01:27:18.403] Epoch 15, Iter 6590: loss=0.0179, ce=0.0038, dice=0.0273, grad_norm=0.045970
[01:27:22.000] Epoch 15, Iter 6600: loss=0.2122, ce=0.0056, dice=0.3499, grad_norm=0.127088
[01:27:25.632] Epoch 15, Iter 6610: loss=0.0241, ce=0.0039, dice=0.0375, grad_norm=0.080181
[01:27:29.247] Epoch 15, Iter 6620: loss=0.0241, ce=0.0044, dice=0.0373, grad_norm=0.111145
[01:27:32.853] Epoch 15, Iter 6630: loss=0.0581, ce=0.0056, dice=0.0931, grad_norm=0.701032
[01:27:36.461] Epoch 15, Iter 6640: loss=0.1097, ce=0.0054, dice=0.1792, grad_norm=0.418038
[01:27:40.083] Epoch 15, Iter 6650: loss=0.0240, ce=0.0058, dice=0.0362, grad_norm=0.075106
[01:27:43.712] Epoch 15, Iter 6660: loss=0.0350, ce=0.0075, dice=0.0534, grad_norm=0.310895
[01:27:47.335] Epoch 15, Iter 6670: loss=0.0440, ce=0.0025, dice=0.0717, grad_norm=0.415839
[01:27:50.979] Epoch 15, Iter 6680: loss=0.0350, ce=0.0057, dice=0.0545, grad_norm=0.173868
[01:27:54.624] Epoch 15, Iter 6690: loss=0.0510, ce=0.0047, dice=0.0819, grad_norm=0.186420
[01:27:58.261] Epoch 15, Iter 6700: loss=0.0272, ce=0.0074, dice=0.0404, grad_norm=0.118952
[01:28:01.890] Epoch 15, Iter 6710: loss=0.0210, ce=0.0040, dice=0.0324, grad_norm=0.109417
[01:28:05.537] Epoch 15, Iter 6720: loss=0.0448, ce=0.0013, dice=0.0739, grad_norm=0.363280
[01:28:09.173] Epoch 15, Iter 6730: loss=0.0638, ce=0.0051, dice=0.1029, grad_norm=0.197509
[01:28:12.805] Epoch 15, Iter 6740: loss=0.1990, ce=0.0031, dice=0.3296, grad_norm=0.347593
[01:28:16.442] Epoch 15, Iter 6750: loss=0.0587, ce=0.0042, dice=0.0949, grad_norm=0.290983
[01:28:20.068] Epoch 15, Iter 6760: loss=0.0281, ce=0.0058, dice=0.0430, grad_norm=0.138583
[01:28:23.737] Epoch 15, Iter 6770: loss=0.0346, ce=0.0062, dice=0.0535, grad_norm=0.163873
[01:28:27.360] Epoch 15, Iter 6780: loss=0.2086, ce=0.0025, dice=0.3459, grad_norm=0.047830
[01:28:30.995] Epoch 15, Iter 6790: loss=0.0308, ce=0.0071, dice=0.0466, grad_norm=0.350697
[01:28:34.627] Epoch 15, Iter 6800: loss=0.0314, ce=0.0026, dice=0.0506, grad_norm=0.182056
[01:28:38.281] Epoch 15, Iter 6810: loss=0.0398, ce=0.0034, dice=0.0641, grad_norm=0.156515
[01:28:41.910] Epoch 15, Iter 6820: loss=0.0404, ce=0.0059, dice=0.0635, grad_norm=0.179113
[01:28:45.554] Epoch 15, Iter 6830: loss=0.0173, ce=0.0036, dice=0.0265, grad_norm=0.100270
[01:28:49.182] Epoch 15, Iter 6840: loss=0.2117, ce=0.0062, dice=0.3487, grad_norm=0.050887
[01:28:52.819] Epoch 15, Iter 6850: loss=0.0597, ce=0.0038, dice=0.0970, grad_norm=0.308000
[01:28:56.427] Epoch 15, Iter 6860: loss=0.0197, ce=0.0021, dice=0.0314, grad_norm=0.123282
[01:29:00.069] Epoch 15, Iter 6870: loss=0.0307, ce=0.0052, dice=0.0478, grad_norm=0.165630
[01:29:03.678] Epoch 15, Iter 6880: loss=0.0218, ce=0.0072, dice=0.0316, grad_norm=0.054703
[01:29:07.314] Epoch 15, Iter 6890: loss=0.0563, ce=0.0082, dice=0.0883, grad_norm=1.215924
[01:29:10.910] Epoch 15, Iter 6900: loss=0.0613, ce=0.0042, dice=0.0994, grad_norm=0.364771
[01:29:14.532] Epoch 15, Iter 6910: loss=0.0445, ce=0.0033, dice=0.0720, grad_norm=0.107919
[01:29:18.137] Epoch 15, Iter 6920: loss=0.0466, ce=0.0084, dice=0.0721, grad_norm=0.212509
[01:29:21.634] Epoch 15: Avg Loss=0.0589, CE=0.0047, Dice=0.0950
[01:29:21.636] 
[EPOCH 17] Calculating RGN weights for surgical fine-tuning...
[01:29:34.643] RGN: Max weight before normalization: 0.001450
[01:29:34.668] 
================================================================================
[01:29:34.668] SURGICAL FINE-TUNING WITH TPGM - RGN METHOD
[01:29:34.668] ================================================================================
[01:29:34.668] Layer Name                                         Weight       Learning Rate  
[01:29:34.668] --------------------------------------------------------------------------------
[01:29:34.668] cswin_unet.stage1.0.attns.1.get_v.bias             1.000000     0.00050000      [ACTIVE]
[01:29:34.668] cswin_unet.stage1.0.attns.0.get_v.bias             0.620210     0.00031010      [ACTIVE]
[01:29:34.669] cswin_unet.output.weight                           0.467846     0.00023392      [ACTIVE]
[01:29:34.669] cswin_unet.stage_up1.0.attns.1.get_v.bias          0.449229     0.00022461      [ACTIVE]
[01:29:34.669] cswin_unet.concat_linear2.weight                   0.443891     0.00022195      [ACTIVE]
[01:29:34.669] cswin_unet.concat_linear2.bias                     0.403025     0.00020151      [ACTIVE]
[01:29:34.669] cswin_unet.upsample2.out.weight                    0.400269     0.00020013      [ACTIVE]
[01:29:34.669] cswin_unet.upsample1.out.bias                      0.398760     0.00019938      [ACTIVE]
[01:29:34.669] cswin_unet.concat_linear3.weight                   0.395128     0.00019756      [ACTIVE]
[01:29:34.669] cswin_unet.upsample1.out.weight                    0.393902     0.00019695      [ACTIVE]
[01:29:34.669] cswin_unet.stage1_conv_embed.0.weight              0.378235     0.00018912      [ACTIVE]
[01:29:34.669] cswin_unet.upsample2.down.weight                   0.342839     0.00017142      [ACTIVE]
[01:29:34.669] cswin_unet.upsample3.out.weight                    0.330668     0.00016533      [ACTIVE]
[01:29:34.669] cswin_unet.stage1.0.proj.bias                      0.322095     0.00016105      [ACTIVE]
[01:29:34.669] cswin_unet.upsample2.encoder.weight                0.304898     0.00015245      [ACTIVE]
[01:29:34.669] cswin_unet.stage_up1.0.attns.0.get_v.bias          0.302023     0.00015101      [ACTIVE]
[01:29:34.669] cswin_unet.stage1.0.proj.weight                    0.290643     0.00014532      [ACTIVE]
[01:29:34.669] cswin_unet.upsample1.down.weight                   0.249415     0.00012471      [ACTIVE]
[01:29:34.670] cswin_unet.concat_linear3.bias                     0.242712     0.00012136      [ACTIVE]
[01:29:34.670] cswin_unet.stage1.0.mlp.fc1.weight                 0.234272     0.00011714      [ACTIVE]
[01:29:34.670] cswin_unet.stage1.0.mlp.fc2.weight                 0.223975     0.00011199      [ACTIVE]
[01:29:34.670] cswin_unet.stage1.0.mlp.fc2.bias                   0.222660     0.00011133      [ACTIVE]
[01:29:34.670] cswin_unet.stage2.1.attns.1.get_v.bias             0.220389     0.00011019      [ACTIVE]
[01:29:34.670] cswin_unet.upsample2.down.bias                     0.212204     0.00010610      [ACTIVE]
[01:29:34.670] cswin_unet.stage2.1.attns.0.get_v.bias             0.209364     0.00010468      [ACTIVE]
[01:29:34.670] cswin_unet.stage2.0.proj.bias                      0.208905     0.00010445      [ACTIVE]
[01:29:34.670] cswin_unet.upsample2.encoder.bias                  0.193934     0.00009697      [ACTIVE]
[01:29:34.670] cswin_unet.upsample1.down.bias                     0.190516     0.00009526      [ACTIVE]
[01:29:34.670] cswin_unet.stage1_conv_embed.2.bias                0.187492     0.00009375      [ACTIVE]
[01:29:34.670] cswin_unet.upsample2.out.bias                      0.176274     0.00008814      [ACTIVE]
[01:29:34.670] cswin_unet.stage1.0.qkv.weight                     0.164661     0.00008233      [ACTIVE]
[01:29:34.670] cswin_unet.stage_up1.0.mlp.fc2.weight              0.161922     0.00008096      [ACTIVE]
[01:29:34.670] cswin_unet.stage_up1.0.mlp.fc1.weight              0.156425     0.00007821      [ACTIVE]
[01:29:34.670] cswin_unet.stage_up2.1.attns.1.get_v.bias          0.154384     0.00007719      [ACTIVE]
[01:29:34.670] cswin_unet.stage2.0.attns.1.get_v.bias             0.151564     0.00007578      [ACTIVE]
[01:29:34.670] cswin_unet.stage_up1.0.mlp.fc2.bias                0.148907     0.00007445      [ACTIVE]
[01:29:34.670] cswin_unet.stage_up2.1.attns.0.get_v.bias          0.142134     0.00007107      [ACTIVE]
[01:29:34.670] cswin_unet.stage_up1.0.qkv.weight                  0.139377     0.00006969      [ACTIVE]
[01:29:34.670] cswin_unet.stage2.0.attns.0.get_v.bias             0.136436     0.00006822      [ACTIVE]
[01:29:34.670] cswin_unet.stage1.0.attns.1.get_v.weight           0.134512     0.00006726      [ACTIVE]
[01:29:34.670] cswin_unet.upsample3.encoder.weight                0.134348     0.00006717      [ACTIVE]
[01:29:34.670] cswin_unet.stage_up1.0.proj.weight                 0.131513     0.00006576      [ACTIVE]
[01:29:34.670] cswin_unet.merge1.conv.weight                      0.124272     0.00006214      [ACTIVE]
[01:29:34.671] cswin_unet.stage2.1.proj.bias                      0.122042     0.00006102      [ACTIVE]
[01:29:34.671] cswin_unet.stage_up1.0.proj.bias                   0.119132     0.00005957      [ACTIVE]
[01:29:34.671] cswin_unet.stage1.0.attns.0.get_v.weight           0.105522     0.00005276      [ACTIVE]
[01:29:34.671] cswin_unet.stage1.0.norm1.weight                   0.100000     0.00005000      [ACTIVE]
[01:29:34.671] cswin_unet.stage1.0.norm1.bias                     0.100000     0.00005000      [ACTIVE]
[01:29:34.671] cswin_unet.stage1.0.norm2.weight                   0.100000     0.00005000      [ACTIVE]
[01:29:34.671] cswin_unet.stage1.0.norm2.bias                     0.100000     0.00005000      [ACTIVE]
[01:29:34.671] cswin_unet.merge1.norm.weight                      0.100000     0.00005000      [ACTIVE]
[01:29:34.671] cswin_unet.merge1.norm.bias                        0.100000     0.00005000      [ACTIVE]
[01:29:34.671] cswin_unet.stage2.0.norm1.weight                   0.100000     0.00005000      [ACTIVE]
[01:29:34.671] cswin_unet.stage2.0.norm1.bias                     0.100000     0.00005000      [ACTIVE]
[01:29:34.671] cswin_unet.stage2.0.norm2.weight                   0.100000     0.00005000      [ACTIVE]
[01:29:34.671] cswin_unet.stage2.0.norm2.bias                     0.100000     0.00005000      [ACTIVE]
[01:29:34.671] cswin_unet.stage2.1.norm1.weight                   0.100000     0.00005000      [ACTIVE]
[01:29:34.671] cswin_unet.stage2.1.norm1.bias                     0.100000     0.00005000      [ACTIVE]
[01:29:34.671] cswin_unet.stage2.1.norm2.weight                   0.100000     0.00005000      [ACTIVE]
[01:29:34.671] cswin_unet.stage2.1.norm2.bias                     0.100000     0.00005000      [ACTIVE]
[01:29:34.672] cswin_unet.merge2.norm.weight                      0.100000     0.00005000      [ACTIVE]
[01:29:34.672] cswin_unet.merge2.norm.bias                        0.100000     0.00005000      [ACTIVE]
[01:29:34.672] cswin_unet.stage3.0.norm1.weight                   0.100000     0.00005000      [ACTIVE]
[01:29:34.672] cswin_unet.stage3.0.norm1.bias                     0.100000     0.00005000      [ACTIVE]
[01:29:34.672] cswin_unet.stage3.0.norm2.weight                   0.100000     0.00005000      [ACTIVE]
[01:29:34.672] cswin_unet.stage3.0.norm2.bias                     0.100000     0.00005000      [ACTIVE]
[01:29:34.672] cswin_unet.stage3.1.norm1.weight                   0.100000     0.00005000      [ACTIVE]
[01:29:34.672] cswin_unet.stage3.1.norm1.bias                     0.100000     0.00005000      [ACTIVE]
[01:29:34.672] cswin_unet.stage3.1.norm2.weight                   0.100000     0.00005000      [ACTIVE]
[01:29:34.672] cswin_unet.stage3.1.norm2.bias                     0.100000     0.00005000      [ACTIVE]
[01:29:34.672] cswin_unet.stage3.2.norm1.weight                   0.100000     0.00005000      [ACTIVE]
[01:29:34.672] cswin_unet.stage3.2.norm1.bias                     0.100000     0.00005000      [ACTIVE]
[01:29:34.672] cswin_unet.stage3.2.norm2.weight                   0.100000     0.00005000      [ACTIVE]
[01:29:34.672] cswin_unet.stage3.2.norm2.bias                     0.100000     0.00005000      [ACTIVE]
[01:29:34.672] cswin_unet.stage3.3.norm1.weight                   0.100000     0.00005000      [ACTIVE]
[01:29:34.672] cswin_unet.stage3.3.norm1.bias                     0.100000     0.00005000      [ACTIVE]
[01:29:34.672] cswin_unet.stage3.3.norm2.weight                   0.100000     0.00005000      [ACTIVE]
[01:29:34.672] cswin_unet.stage3.3.norm2.bias                     0.100000     0.00005000      [ACTIVE]
[01:29:34.672] cswin_unet.stage3.4.norm1.weight                   0.100000     0.00005000      [ACTIVE]
[01:29:34.672] cswin_unet.stage3.4.norm1.bias                     0.100000     0.00005000      [ACTIVE]
[01:29:34.672] cswin_unet.stage3.4.norm2.weight                   0.100000     0.00005000      [ACTIVE]
[01:29:34.672] cswin_unet.stage3.4.norm2.bias                     0.100000     0.00005000      [ACTIVE]
[01:29:34.672] cswin_unet.stage3.5.norm1.weight                   0.100000     0.00005000      [ACTIVE]
[01:29:34.672] cswin_unet.stage3.5.norm1.bias                     0.100000     0.00005000      [ACTIVE]
[01:29:34.672] cswin_unet.stage3.5.norm2.weight                   0.100000     0.00005000      [ACTIVE]
[01:29:34.672] cswin_unet.stage3.5.norm2.bias                     0.100000     0.00005000      [ACTIVE]
[01:29:34.672] cswin_unet.stage3.6.norm1.weight                   0.100000     0.00005000      [ACTIVE]
[01:29:34.672] cswin_unet.stage3.6.norm1.bias                     0.100000     0.00005000      [ACTIVE]
[01:29:34.672] cswin_unet.stage3.6.norm2.weight                   0.100000     0.00005000      [ACTIVE]
[01:29:34.672] cswin_unet.stage3.6.norm2.bias                     0.100000     0.00005000      [ACTIVE]
[01:29:34.672] cswin_unet.stage3.7.norm1.weight                   0.100000     0.00005000      [ACTIVE]
[01:29:34.672] cswin_unet.stage3.7.norm1.bias                     0.100000     0.00005000      [ACTIVE]
[01:29:34.672] cswin_unet.stage3.7.norm2.weight                   0.100000     0.00005000      [ACTIVE]
[01:29:34.672] cswin_unet.stage3.7.norm2.bias                     0.100000     0.00005000      [ACTIVE]
[01:29:34.672] cswin_unet.stage3.8.norm1.weight                   0.100000     0.00005000      [ACTIVE]
[01:29:34.672] cswin_unet.stage3.8.norm1.bias                     0.100000     0.00005000      [ACTIVE]
[01:29:34.672] cswin_unet.stage3.8.norm2.weight                   0.100000     0.00005000      [ACTIVE]
[01:29:34.674] cswin_unet.stage3.8.norm2.bias                     0.100000     0.00005000      [ACTIVE]
[01:29:34.674] cswin_unet.merge3.norm.weight                      0.100000     0.00005000      [ACTIVE]
[01:29:34.674] cswin_unet.merge3.norm.bias                        0.100000     0.00005000      [ACTIVE]
[01:29:34.674] cswin_unet.stage4.0.norm1.weight                   0.100000     0.00005000      [ACTIVE]
[01:29:34.674] cswin_unet.stage4.0.norm1.bias                     0.100000     0.00005000      [ACTIVE]
[01:29:34.674] cswin_unet.stage4.0.norm2.weight                   0.100000     0.00005000      [ACTIVE]
[01:29:34.674] cswin_unet.stage4.0.norm2.bias                     0.100000     0.00005000      [ACTIVE]
[01:29:34.674] cswin_unet.norm.weight                             0.100000     0.00005000      [ACTIVE]
[01:29:34.674] cswin_unet.norm.bias                               0.100000     0.00005000      [ACTIVE]
[01:29:34.674] cswin_unet.stage_up4.0.norm1.weight                0.100000     0.00005000      [ACTIVE]
[01:29:34.674] cswin_unet.stage_up4.0.norm1.bias                  0.100000     0.00005000      [ACTIVE]
[01:29:34.674] cswin_unet.stage_up4.0.norm2.weight                0.100000     0.00005000      [ACTIVE]
[01:29:34.674] cswin_unet.stage_up4.0.norm2.bias                  0.100000     0.00005000      [ACTIVE]
[01:29:34.674] cswin_unet.stage_up3.0.norm1.weight                0.100000     0.00005000      [ACTIVE]
[01:29:34.674] cswin_unet.stage_up3.0.norm1.bias                  0.100000     0.00005000      [ACTIVE]
[01:29:34.674] cswin_unet.stage_up3.0.norm2.weight                0.100000     0.00005000      [ACTIVE]
[01:29:34.674] cswin_unet.stage_up3.0.norm2.bias                  0.100000     0.00005000      [ACTIVE]
[01:29:34.674] cswin_unet.stage_up3.1.norm1.weight                0.100000     0.00005000      [ACTIVE]
[01:29:34.674] cswin_unet.stage_up3.1.norm1.bias                  0.100000     0.00005000      [ACTIVE]
[01:29:34.674] cswin_unet.stage_up3.1.norm2.weight                0.100000     0.00005000      [ACTIVE]
[01:29:34.674] cswin_unet.stage_up3.1.norm2.bias                  0.100000     0.00005000      [ACTIVE]
[01:29:34.674] cswin_unet.stage_up3.2.norm1.weight                0.100000     0.00005000      [ACTIVE]
[01:29:34.675] cswin_unet.stage_up3.2.norm1.bias                  0.100000     0.00005000      [ACTIVE]
[01:29:34.675] cswin_unet.stage_up3.2.norm2.weight                0.100000     0.00005000      [ACTIVE]
[01:29:34.675] cswin_unet.stage_up3.2.norm2.bias                  0.100000     0.00005000      [ACTIVE]
[01:29:34.675] cswin_unet.stage_up3.3.norm1.weight                0.100000     0.00005000      [ACTIVE]
[01:29:34.675] cswin_unet.stage_up3.3.norm1.bias                  0.100000     0.00005000      [ACTIVE]
[01:29:34.675] cswin_unet.stage_up3.3.norm2.weight                0.100000     0.00005000      [ACTIVE]
[01:29:34.675] cswin_unet.stage_up3.3.norm2.bias                  0.100000     0.00005000      [ACTIVE]
[01:29:34.675] cswin_unet.stage_up3.4.norm1.weight                0.100000     0.00005000      [ACTIVE]
[01:29:34.675] cswin_unet.stage_up3.4.norm1.bias                  0.100000     0.00005000      [ACTIVE]
[01:29:34.675] cswin_unet.stage_up3.4.norm2.weight                0.100000     0.00005000      [ACTIVE]
[01:29:34.675] cswin_unet.stage_up3.4.norm2.bias                  0.100000     0.00005000      [ACTIVE]
[01:29:34.675] cswin_unet.stage_up3.5.norm1.weight                0.100000     0.00005000      [ACTIVE]
[01:29:34.675] cswin_unet.stage_up3.5.norm1.bias                  0.100000     0.00005000      [ACTIVE]
[01:29:34.675] cswin_unet.stage_up3.5.norm2.weight                0.100000     0.00005000      [ACTIVE]
[01:29:34.675] cswin_unet.stage_up3.5.norm2.bias                  0.100000     0.00005000      [ACTIVE]
[01:29:34.675] cswin_unet.stage_up3.6.norm1.weight                0.100000     0.00005000      [ACTIVE]
[01:29:34.676] cswin_unet.stage_up3.6.norm1.bias                  0.100000     0.00005000      [ACTIVE]
[01:29:34.676] cswin_unet.stage_up3.6.norm2.weight                0.100000     0.00005000      [ACTIVE]
[01:29:34.676] cswin_unet.stage_up3.6.norm2.bias                  0.100000     0.00005000      [ACTIVE]
[01:29:34.676] cswin_unet.stage_up3.7.norm1.weight                0.100000     0.00005000      [ACTIVE]
[01:29:34.676] cswin_unet.stage_up3.7.norm1.bias                  0.100000     0.00005000      [ACTIVE]
[01:29:34.676] cswin_unet.stage_up3.7.norm2.weight                0.100000     0.00005000      [ACTIVE]
[01:29:34.676] cswin_unet.stage_up3.7.norm2.bias                  0.100000     0.00005000      [ACTIVE]
[01:29:34.676] cswin_unet.stage_up3.8.norm1.weight                0.100000     0.00005000      [ACTIVE]
[01:29:34.676] cswin_unet.stage_up3.8.norm1.bias                  0.100000     0.00005000      [ACTIVE]
[01:29:34.677] cswin_unet.stage_up3.8.norm2.weight                0.100000     0.00005000      [ACTIVE]
[01:29:34.677] cswin_unet.stage_up3.8.norm2.bias                  0.100000     0.00005000      [ACTIVE]
[01:29:34.677] cswin_unet.stage_up2.0.norm1.weight                0.100000     0.00005000      [ACTIVE]
[01:29:34.677] cswin_unet.stage_up2.0.norm1.bias                  0.100000     0.00005000      [ACTIVE]
[01:29:34.677] cswin_unet.stage_up2.0.norm2.weight                0.100000     0.00005000      [ACTIVE]
[01:29:34.677] cswin_unet.stage_up2.0.norm2.bias                  0.100000     0.00005000      [ACTIVE]
[01:29:34.677] cswin_unet.stage_up2.1.norm1.weight                0.100000     0.00005000      [ACTIVE]
[01:29:34.677] cswin_unet.stage_up2.1.norm1.bias                  0.100000     0.00005000      [ACTIVE]
[01:29:34.677] cswin_unet.stage_up2.1.norm2.weight                0.100000     0.00005000      [ACTIVE]
[01:29:34.677] cswin_unet.stage_up2.1.norm2.bias                  0.100000     0.00005000      [ACTIVE]
[01:29:34.677] cswin_unet.stage_up1.0.norm1.weight                0.100000     0.00005000      [ACTIVE]
[01:29:34.677] cswin_unet.stage_up1.0.norm1.bias                  0.100000     0.00005000      [ACTIVE]
[01:29:34.677] cswin_unet.stage_up1.0.norm2.weight                0.100000     0.00005000      [ACTIVE]
[01:29:34.677] cswin_unet.stage_up1.0.norm2.bias                  0.100000     0.00005000      [ACTIVE]
[01:29:34.677] cswin_unet.norm_up.weight                          0.100000     0.00005000      [ACTIVE]
[01:29:34.678] cswin_unet.norm_up.bias                            0.100000     0.00005000      [ACTIVE]
[01:29:34.678] cswin_unet.stage2.0.attns.1.get_v.weight           0.087004     0.00004350      [ACTIVE]
[01:29:34.678] cswin_unet.upsample1.encoder.bias                  0.086173     0.00004309      [ACTIVE]
[01:29:34.678] cswin_unet.upsample3.down.weight                   0.085397     0.00004270      [ACTIVE]
[01:29:34.678] cswin_unet.stage_up2.0.attns.1.get_v.bias          0.084518     0.00004226      [ACTIVE]
[01:29:34.678] cswin_unet.stage2.1.proj.weight                    0.081945     0.00004097      [ACTIVE]
[01:29:34.678] cswin_unet.concat_linear4.weight                   0.081721     0.00004086      [ACTIVE]
[01:29:34.678] cswin_unet.stage_up2.0.attns.0.get_v.bias          0.077356     0.00003868      [ACTIVE]
[01:29:34.678] cswin_unet.stage_up2.0.proj.bias                   0.076104     0.00003805      [ACTIVE]
[01:29:34.678] cswin_unet.stage2.1.attns.1.get_v.weight           0.071596     0.00003580      [ACTIVE]
[01:29:34.678] cswin_unet.stage2.0.proj.weight                    0.070861     0.00003543      [ACTIVE]
[01:29:34.678] cswin_unet.stage2.0.mlp.fc1.weight                 0.069829     0.00003491      [ACTIVE]
[01:29:34.678] cswin_unet.stage_up2.0.attns.0.get_v.weight        0.066469     0.00003323      [ACTIVE]
[01:29:34.678] cswin_unet.stage_up1.0.attns.0.get_v.weight        0.065867     0.00003293      [ACTIVE]
[01:29:34.679] cswin_unet.stage_up1.0.attns.1.get_v.weight        0.064854     0.00003243      [ACTIVE]
[01:29:34.679] cswin_unet.stage2.0.attns.0.get_v.weight           0.064031     0.00003202      [ACTIVE]
[01:29:34.679] cswin_unet.stage2.1.attns.0.get_v.weight           0.063803     0.00003190      [ACTIVE]
[01:29:34.679] cswin_unet.stage2.1.mlp.fc1.weight                 0.063474     0.00003174      [ACTIVE]
[01:29:34.679] cswin_unet.stage1_conv_embed.2.weight              0.063189     0.00003159      [ACTIVE]
[01:29:34.679] cswin_unet.stage_up2.0.attns.1.get_v.weight        0.063076     0.00003154      [ACTIVE]
[01:29:34.679] cswin_unet.stage2.0.mlp.fc2.bias                   0.062979     0.00003149      [ACTIVE]
[01:29:34.679] cswin_unet.stage2.1.qkv.weight                     0.061371     0.00003069      [ACTIVE]
[01:29:34.679] cswin_unet.stage2.0.mlp.fc2.weight                 0.060339     0.00003017      [ACTIVE]
[01:29:34.679] cswin_unet.stage_up2.1.proj.bias                   0.055895     0.00002795      [ACTIVE]
[01:29:34.679] cswin_unet.stage_up2.1.proj.weight                 0.054489     0.00002724      [ACTIVE]
[01:29:34.679] cswin_unet.stage1.0.qkv.bias                       0.051142     0.00002557      [ACTIVE]
[01:29:34.680] cswin_unet.stage_up2.0.proj.weight                 0.050425     0.00002521      [ACTIVE]
[01:29:34.680] cswin_unet.upsample1.encoder.weight                0.046787     0.00002339      [LOW_LR]
[01:29:34.680] cswin_unet.upsample3.out.bias                      0.046215     0.00002311      [LOW_LR]
[01:29:34.680] cswin_unet.stage_up2.1.qkv.weight                  0.045445     0.00002272      [LOW_LR]
[01:29:34.680] cswin_unet.stage_up2.1.attns.1.get_v.weight        0.043465     0.00002173      [LOW_LR]
[01:29:34.680] cswin_unet.stage_up2.1.attns.0.get_v.weight        0.042224     0.00002111      [LOW_LR]
[01:29:34.680] cswin_unet.stage_up2.0.qkv.weight                  0.039199     0.00001960      [LOW_LR]
[01:29:34.680] cswin_unet.stage_up2.0.mlp.fc1.weight              0.037647     0.00001882      [LOW_LR]
[01:29:34.680] cswin_unet.stage2.1.mlp.fc2.bias                   0.035809     0.00001790      [LOW_LR]
[01:29:34.680] cswin_unet.stage2.1.mlp.fc2.weight                 0.035317     0.00001766      [LOW_LR]
[01:29:34.680] cswin_unet.stage_up2.0.mlp.fc2.weight              0.035107     0.00001755      [LOW_LR]
[01:29:34.680] cswin_unet.stage2.0.qkv.weight                     0.034492     0.00001725      [LOW_LR]
[01:29:34.680] cswin_unet.stage_up1.0.qkv.bias                    0.033869     0.00001693      [LOW_LR]
[01:29:34.680] cswin_unet.concat_linear4.bias                     0.032854     0.00001643      [LOW_LR]
[01:29:34.680] cswin_unet.stage_up2.1.mlp.fc1.weight              0.030614     0.00001531      [LOW_LR]
[01:29:34.681] cswin_unet.stage_up2.1.mlp.fc2.bias                0.027609     0.00001380      [LOW_LR]
[01:29:34.681] cswin_unet.upsample3.encoder.bias                  0.025145     0.00001257      [LOW_LR]
[01:29:34.681] cswin_unet.stage_up2.0.mlp.fc2.bias                0.024389     0.00001219      [LOW_LR]
[01:29:34.681] cswin_unet.stage1.0.mlp.fc1.bias                   0.023902     0.00001195      [LOW_LR]
[01:29:34.681] cswin_unet.upsample3.down.bias                     0.023508     0.00001175      [LOW_LR]
[01:29:34.681] cswin_unet.stage_up2.1.mlp.fc2.weight              0.022358     0.00001118      [LOW_LR]
[01:29:34.681] cswin_unet.stage3.1.attns.1.get_v.weight           0.018867     0.00000943      [LOW_LR]
[01:29:34.681] cswin_unet.stage2.1.qkv.bias                       0.017434     0.00000872      [LOW_LR]
[01:29:34.681] cswin_unet.stage3.3.attns.1.get_v.weight           0.016115     0.00000806      [LOW_LR]
[01:29:34.681] cswin_unet.merge2.conv.weight                      0.015712     0.00000786      [LOW_LR]
[01:29:34.681] cswin_unet.stage3.1.attns.0.get_v.weight           0.015614     0.00000781      [LOW_LR]
[01:29:34.681] cswin_unet.stage3.0.attns.1.get_v.weight           0.015541     0.00000777      [LOW_LR]
[01:29:34.681] cswin_unet.stage2.0.qkv.bias                       0.015059     0.00000753      [LOW_LR]
[01:29:34.681] cswin_unet.stage3.0.attns.0.get_v.weight           0.014831     0.00000742      [LOW_LR]
[01:29:34.681] cswin_unet.stage_up1.0.mlp.fc1.bias                0.014371     0.00000719      [LOW_LR]
[01:29:34.681] cswin_unet.stage3.2.attns.0.get_v.weight           0.014209     0.00000710      [LOW_LR]
[01:29:34.681] cswin_unet.stage_up3.8.attns.1.get_v.bias          0.013085     0.00000654      [LOW_LR]
[01:29:34.681] cswin_unet.stage2.0.mlp.fc1.bias                   0.012457     0.00000623      [LOW_LR]
[01:29:34.681] cswin_unet.stage3.2.attns.1.get_v.weight           0.012408     0.00000620      [LOW_LR]
[01:29:34.681] cswin_unet.stage3.8.attns.0.get_v.weight           0.012366     0.00000618      [LOW_LR]
[01:29:34.681] cswin_unet.upsample4.out.weight                    0.012119     0.00000606      [LOW_LR]
[01:29:34.682] cswin_unet.stage_up4.0.attns.0.get_v.bias          0.011989     0.00000599      [LOW_LR]
[01:29:34.682] cswin_unet.stage3.6.attns.1.get_v.weight           0.011657     0.00000583      [LOW_LR]
[01:29:34.682] cswin_unet.stage3.3.attns.0.get_v.weight           0.011456     0.00000573      [LOW_LR]
[01:29:34.682] cswin_unet.stage3.4.attns.0.get_v.weight           0.011441     0.00000572      [LOW_LR]
[01:29:34.682] cswin_unet.stage3.4.attns.1.get_v.weight           0.010892     0.00000545      [LOW_LR]
[01:29:34.682] cswin_unet.stage3.5.attns.1.get_v.weight           0.010881     0.00000544      [LOW_LR]
[01:29:34.682] cswin_unet.upsample4.out.bias                      0.010819     0.00000541      [LOW_LR]
[01:29:34.682] cswin_unet.stage_up2.0.qkv.bias                    0.010771     0.00000539      [LOW_LR]
[01:29:34.682] cswin_unet.stage_up3.8.attns.0.get_v.bias          0.010464     0.00000523      [LOW_LR]
[01:29:34.682] cswin_unet.stage3.8.attns.0.get_v.bias             0.010400     0.00000520      [LOW_LR]
[01:29:34.682] cswin_unet.stage3.5.attns.0.get_v.weight           0.010034     0.00000502      [LOW_LR]
[01:29:34.682] cswin_unet.stage3.7.attns.0.get_v.weight           0.009769     0.00000488      [LOW_LR]
[01:29:34.683] cswin_unet.stage_up2.1.qkv.bias                    0.009761     0.00000488      [LOW_LR]
[01:29:34.683] cswin_unet.merge1.conv.bias                        0.009650     0.00000482      [LOW_LR]
[01:29:34.683] cswin_unet.stage_up3.1.attns.1.get_v.weight        0.009525     0.00000476      [LOW_LR]
[01:29:34.683] cswin_unet.stage_up3.1.attns.0.get_v.weight        0.009311     0.00000466      [LOW_LR]
[01:29:34.683] cswin_unet.stage3.0.attns.0.get_v.bias             0.008944     0.00000447      [LOW_LR]
[01:29:34.683] cswin_unet.stage_up3.4.attns.0.get_v.weight        0.008880     0.00000444      [LOW_LR]
[01:29:34.683] cswin_unet.stage3.1.proj.weight                    0.008827     0.00000441      [LOW_LR]
[01:29:34.683] cswin_unet.stage3.6.attns.0.get_v.weight           0.008635     0.00000432      [LOW_LR]
[01:29:34.683] cswin_unet.stage3.0.proj.weight                    0.008540     0.00000427      [LOW_LR]
[01:29:34.683] cswin_unet.stage_up3.4.attns.1.get_v.weight        0.008383     0.00000419      [LOW_LR]
[01:29:34.683] cswin_unet.stage_up3.3.attns.1.get_v.weight        0.008219     0.00000411      [LOW_LR]
[01:29:34.683] cswin_unet.stage3.3.proj.weight                    0.008210     0.00000410      [LOW_LR]
[01:29:34.683] cswin_unet.stage_up3.0.attns.0.get_v.weight        0.008208     0.00000410      [LOW_LR]
[01:29:34.683] cswin_unet.stage3.8.attns.1.get_v.weight           0.008089     0.00000404      [LOW_LR]
[01:29:34.683] cswin_unet.stage_up3.2.attns.1.get_v.weight        0.008030     0.00000401      [LOW_LR]
[01:29:34.683] cswin_unet.stage3.0.attns.1.get_v.bias             0.007978     0.00000399      [LOW_LR]
[01:29:34.683] cswin_unet.stage2.1.mlp.fc1.bias                   0.007923     0.00000396      [LOW_LR]
[01:29:34.683] cswin_unet.stage_up3.3.attns.0.get_v.weight        0.007689     0.00000384      [LOW_LR]
[01:29:34.683] cswin_unet.stage_up3.5.attns.1.get_v.weight        0.007655     0.00000383      [LOW_LR]
[01:29:34.683] cswin_unet.stage3.7.attns.1.get_v.weight           0.007566     0.00000378      [LOW_LR]
[01:29:34.683] cswin_unet.stage3.1.attns.0.get_v.bias             0.007520     0.00000376      [LOW_LR]
[01:29:34.683] cswin_unet.stage_up3.8.attns.0.get_v.weight        0.007464     0.00000373      [LOW_LR]
[01:29:34.683] cswin_unet.stage_up3.7.attns.0.get_v.bias          0.007436     0.00000372      [LOW_LR]
[01:29:34.683] cswin_unet.stage3.4.proj.weight                    0.007387     0.00000369      [LOW_LR]
[01:29:34.683] cswin_unet.stage_up3.5.attns.0.get_v.weight        0.007157     0.00000358      [LOW_LR]
[01:29:34.683] cswin_unet.stage_up3.6.attns.1.get_v.weight        0.007131     0.00000357      [LOW_LR]
[01:29:34.683] cswin_unet.stage_up3.2.attns.0.get_v.weight        0.007050     0.00000352      [LOW_LR]
[01:29:34.683] cswin_unet.stage3.3.qkv.weight                     0.007017     0.00000351      [LOW_LR]
[01:29:34.683] cswin_unet.stage3.2.proj.weight                    0.007004     0.00000350      [LOW_LR]
[01:29:34.683] cswin_unet.stage3.8.attns.1.get_v.bias             0.006969     0.00000348      [LOW_LR]
[01:29:34.683] cswin_unet.stage_up3.7.attns.0.get_v.weight        0.006778     0.00000339      [LOW_LR]
[01:29:34.683] cswin_unet.stage_up3.5.attns.0.get_v.bias          0.006769     0.00000338      [LOW_LR]
[01:29:34.683] cswin_unet.stage3.7.attns.0.get_v.bias             0.006762     0.00000338      [LOW_LR]
[01:29:34.684] cswin_unet.stage_up3.8.attns.1.get_v.weight        0.006744     0.00000337      [LOW_LR]
[01:29:34.684] cswin_unet.stage_up3.6.attns.0.get_v.weight        0.006733     0.00000337      [LOW_LR]
[01:29:34.684] cswin_unet.stage_up3.6.attns.0.get_v.bias          0.006690     0.00000334      [LOW_LR]
[01:29:34.684] cswin_unet.stage3.4.qkv.weight                     0.006488     0.00000324      [LOW_LR]
[01:29:34.684] cswin_unet.stage3.5.proj.weight                    0.006471     0.00000324      [LOW_LR]
[01:29:34.684] cswin_unet.stage3.1.attns.1.get_v.bias             0.006464     0.00000323      [LOW_LR]
[01:29:34.684] cswin_unet.stage_up3.8.mlp.fc2.bias                0.006351     0.00000318      [LOW_LR]
[01:29:34.684] cswin_unet.stage3.6.proj.weight                    0.006277     0.00000314      [LOW_LR]
[01:29:34.684] cswin_unet.stage3.8.proj.weight                    0.006264     0.00000313      [LOW_LR]
[01:29:34.684] cswin_unet.stage3.3.attns.1.get_v.bias             0.006259     0.00000313      [LOW_LR]
[01:29:34.684] cswin_unet.stage3.8.qkv.weight                     0.006250     0.00000313      [LOW_LR]
[01:29:34.684] cswin_unet.stage_up3.7.proj.bias                   0.006223     0.00000311      [LOW_LR]
[01:29:34.684] cswin_unet.stage_up3.8.proj.bias                   0.006185     0.00000309      [LOW_LR]
[01:29:34.684] cswin_unet.stage_up3.0.attns.1.get_v.weight        0.006150     0.00000308      [LOW_LR]
[01:29:34.684] cswin_unet.stage3.5.attns.0.get_v.bias             0.006094     0.00000305      [LOW_LR]
[01:29:34.684] cswin_unet.stage3.2.attns.0.get_v.bias             0.005997     0.00000300      [LOW_LR]
[01:29:34.684] cswin_unet.stage_up3.6.proj.bias                   0.005957     0.00000298      [LOW_LR]
[01:29:34.684] cswin_unet.stage3.1.proj.bias                      0.005944     0.00000297      [LOW_LR]
[01:29:34.685] cswin_unet.stage3.2.proj.bias                      0.005932     0.00000297      [LOW_LR]
[01:29:34.685] cswin_unet.stage_up3.3.proj.weight                 0.005910     0.00000296      [LOW_LR]
[01:29:34.685] cswin_unet.stage_up3.8.proj.weight                 0.005839     0.00000292      [LOW_LR]
[01:29:34.685] cswin_unet.stage3.7.proj.weight                    0.005839     0.00000292      [LOW_LR]
[01:29:34.685] cswin_unet.stage_up3.6.proj.weight                 0.005688     0.00000284      [LOW_LR]
[01:29:34.685] cswin_unet.stage3.6.attns.1.get_v.bias             0.005678     0.00000284      [LOW_LR]
[01:29:34.685] cswin_unet.stage_up3.1.attns.0.get_v.bias          0.005576     0.00000279      [LOW_LR]
[01:29:34.685] cswin_unet.stage_up3.4.proj.bias                   0.005568     0.00000278      [LOW_LR]
[01:29:34.685] cswin_unet.stage3.0.proj.bias                      0.005504     0.00000275      [LOW_LR]
[01:29:34.685] cswin_unet.stage3.2.mlp.fc2.bias                   0.005495     0.00000275      [LOW_LR]
[01:29:34.685] cswin_unet.stage3.0.qkv.weight                     0.005437     0.00000272      [LOW_LR]
[01:29:34.685] cswin_unet.stage3.1.qkv.weight                     0.005428     0.00000271      [LOW_LR]
[01:29:34.685] cswin_unet.stage3.3.proj.bias                      0.005353     0.00000268      [LOW_LR]
[01:29:34.685] cswin_unet.stage_up3.1.proj.weight                 0.005339     0.00000267      [LOW_LR]
[01:29:34.685] cswin_unet.stage_up3.6.attns.1.get_v.bias          0.005337     0.00000267      [LOW_LR]
[01:29:34.685] cswin_unet.stage_up3.7.mlp.fc2.bias                0.005323     0.00000266      [LOW_LR]
[01:29:34.686] cswin_unet.stage3.4.proj.bias                      0.005298     0.00000265      [LOW_LR]
[01:29:34.686] cswin_unet.stage_up3.5.proj.bias                   0.005232     0.00000262      [LOW_LR]
[01:29:34.686] cswin_unet.stage_up3.4.proj.weight                 0.005229     0.00000261      [LOW_LR]
[01:29:34.686] cswin_unet.stage_up3.5.mlp.fc2.bias                0.005151     0.00000258      [LOW_LR]
[01:29:34.686] cswin_unet.stage_up3.7.attns.1.get_v.weight        0.005119     0.00000256      [LOW_LR]
[01:29:34.686] cswin_unet.stage3.6.qkv.weight                     0.005106     0.00000255      [LOW_LR]
[01:29:34.686] cswin_unet.stage3.3.attns.0.get_v.bias             0.005082     0.00000254      [LOW_LR]
[01:29:34.686] cswin_unet.stage_up3.5.proj.weight                 0.005037     0.00000252      [LOW_LR]
[01:29:34.686] cswin_unet.stage_up3.6.mlp.fc2.bias                0.005034     0.00000252      [LOW_LR]
[01:29:34.686] cswin_unet.stage3.0.mlp.fc2.weight                 0.004930     0.00000247      [LOW_LR]
[01:29:34.686] cswin_unet.stage3.7.proj.bias                      0.004870     0.00000243      [LOW_LR]
[01:29:34.686] cswin_unet.stage_up3.7.proj.weight                 0.004818     0.00000241      [LOW_LR]
[01:29:34.686] cswin_unet.stage3.6.proj.bias                      0.004766     0.00000238      [LOW_LR]
[01:29:34.686] cswin_unet.stage_up3.0.attns.0.get_v.bias          0.004765     0.00000238      [LOW_LR]
[01:29:34.686] cswin_unet.stage3.5.qkv.weight                     0.004751     0.00000238      [LOW_LR]
[01:29:34.686] cswin_unet.stage_up3.4.mlp.fc2.bias                0.004731     0.00000237      [LOW_LR]
[01:29:34.686] cswin_unet.stage3.4.attns.1.get_v.bias             0.004694     0.00000235      [LOW_LR]
[01:29:34.686] cswin_unet.stage_up3.2.proj.bias                   0.004632     0.00000232      [LOW_LR]
[01:29:34.686] cswin_unet.stage3.3.mlp.fc2.bias                   0.004618     0.00000231      [LOW_LR]
[01:29:34.686] cswin_unet.stage3.2.qkv.weight                     0.004590     0.00000230      [LOW_LR]
[01:29:34.686] cswin_unet.stage3.6.attns.0.get_v.bias             0.004577     0.00000229      [LOW_LR]
[01:29:34.686] cswin_unet.stage_up3.3.proj.bias                   0.004573     0.00000229      [LOW_LR]
[01:29:34.686] cswin_unet.stage3.5.proj.bias                      0.004538     0.00000227      [LOW_LR]
[01:29:34.686] cswin_unet.stage_up2.0.mlp.fc1.bias                0.004462     0.00000223      [LOW_LR]
[01:29:34.686] cswin_unet.stage_up3.7.attns.1.get_v.bias          0.004443     0.00000222      [LOW_LR]
[01:29:34.686] cswin_unet.stage3.7.qkv.weight                     0.004419     0.00000221      [LOW_LR]
[01:29:34.686] cswin_unet.stage_up3.2.mlp.fc2.bias                0.004414     0.00000221      [LOW_LR]
[01:29:34.686] cswin_unet.stage3.8.proj.bias                      0.004380     0.00000219      [LOW_LR]
[01:29:34.686] cswin_unet.stage_up3.2.proj.weight                 0.004345     0.00000217      [LOW_LR]
[01:29:34.686] cswin_unet.stage_up3.1.proj.bias                   0.004320     0.00000216      [LOW_LR]
[01:29:34.686] cswin_unet.stage_up3.8.qkv.weight                  0.004319     0.00000216      [LOW_LR]
[01:29:34.686] cswin_unet.stage3.7.attns.1.get_v.bias             0.004270     0.00000214      [LOW_LR]
[01:29:34.686] cswin_unet.stage_up3.3.mlp.fc2.bias                0.004261     0.00000213      [LOW_LR]
[01:29:34.686] cswin_unet.stage3.5.mlp.fc2.bias                   0.004251     0.00000213      [LOW_LR]
[01:29:34.686] cswin_unet.stage3.8.mlp.fc2.bias                   0.004236     0.00000212      [LOW_LR]
[01:29:34.686] cswin_unet.stage3.4.attns.0.get_v.bias             0.004222     0.00000211      [LOW_LR]
[01:29:34.687] cswin_unet.stage3.2.attns.1.get_v.bias             0.004191     0.00000210      [LOW_LR]
[01:29:34.687] cswin_unet.stage3.4.mlp.fc2.bias                   0.004183     0.00000209      [LOW_LR]
[01:29:34.687] cswin_unet.stage3.0.mlp.fc1.weight                 0.004143     0.00000207      [LOW_LR]
[01:29:34.687] cswin_unet.stage1_conv_embed.0.bias                0.004093     0.00000205      [LOW_LR]
[01:29:34.687] cswin_unet.stage_up3.3.attns.1.get_v.bias          0.004084     0.00000204      [LOW_LR]
[01:29:34.687] cswin_unet.stage_up3.5.attns.1.get_v.bias          0.004054     0.00000203      [LOW_LR]
[01:29:34.687] cswin_unet.stage3.1.mlp.fc2.bias                   0.004029     0.00000201      [LOW_LR]
[01:29:34.687] cswin_unet.stage_up3.4.attns.0.get_v.bias          0.003948     0.00000197      [LOW_LR]
[01:29:34.687] cswin_unet.stage_up3.3.attns.0.get_v.bias          0.003941     0.00000197      [LOW_LR]
[01:29:34.687] cswin_unet.stage3.7.mlp.fc2.bias                   0.003874     0.00000194      [LOW_LR]
[01:29:34.687] cswin_unet.stage3.6.mlp.fc2.bias                   0.003764     0.00000188      [LOW_LR]
[01:29:34.687] cswin_unet.stage_up3.4.attns.1.get_v.bias          0.003658     0.00000183      [LOW_LR]
[01:29:34.687] cswin_unet.stage_up2.1.mlp.fc1.bias                0.003562     0.00000178      [LOW_LR]
[01:29:34.687] cswin_unet.stage_up3.0.proj.weight                 0.003532     0.00000177      [LOW_LR]
[01:29:34.687] cswin_unet.stage_up3.3.qkv.weight                  0.003483     0.00000174      [LOW_LR]
[01:29:34.687] cswin_unet.stage4.0.attns.0.get_v.bias             0.003476     0.00000174      [LOW_LR]
[01:29:34.687] cswin_unet.stage_up3.6.qkv.weight                  0.003474     0.00000174      [LOW_LR]
[01:29:34.687] cswin_unet.stage_up3.2.attns.0.get_v.bias          0.003445     0.00000172      [LOW_LR]
[01:29:34.687] cswin_unet.stage3.5.attns.1.get_v.bias             0.003364     0.00000168      [LOW_LR]
[01:29:34.687] cswin_unet.stage_up3.0.attns.1.get_v.bias          0.003331     0.00000167      [LOW_LR]
[01:29:34.687] cswin_unet.stage_up3.1.attns.1.get_v.bias          0.003243     0.00000162      [LOW_LR]
[01:29:34.687] cswin_unet.stage_up3.1.mlp.fc2.bias                0.003122     0.00000156      [LOW_LR]
[01:29:34.687] cswin_unet.stage_up3.8.mlp.fc1.weight              0.003090     0.00000155      [LOW_LR]
[01:29:34.688] cswin_unet.stage_up3.7.qkv.weight                  0.003055     0.00000153      [LOW_LR]
[01:29:34.688] cswin_unet.stage3.0.mlp.fc2.bias                   0.003048     0.00000152      [LOW_LR]
[01:29:34.688] cswin_unet.stage_up3.2.attns.1.get_v.bias          0.003020     0.00000151      [LOW_LR]
[01:29:34.688] cswin_unet.stage_up3.5.qkv.weight                  0.003019     0.00000151      [LOW_LR]
[01:29:34.688] cswin_unet.stage_up3.4.qkv.weight                  0.002986     0.00000149      [LOW_LR]
[01:29:34.688] cswin_unet.stage3.1.mlp.fc2.weight                 0.002919     0.00000146      [LOW_LR]
[01:29:34.688] cswin_unet.stage_up3.0.proj.bias                   0.002907     0.00000145      [LOW_LR]
[01:29:34.688] cswin_unet.stage_up3.1.qkv.weight                  0.002779     0.00000139      [LOW_LR]
[01:29:34.688] cswin_unet.stage_up3.8.mlp.fc2.weight              0.002546     0.00000127      [LOW_LR]
[01:29:34.688] cswin_unet.stage3.1.mlp.fc1.weight                 0.002494     0.00000125      [LOW_LR]
[01:29:34.688] cswin_unet.stage3.2.mlp.fc2.weight                 0.002438     0.00000122      [LOW_LR]
[01:29:34.688] cswin_unet.stage3.3.mlp.fc2.weight                 0.002421     0.00000121      [LOW_LR]
[01:29:34.688] cswin_unet.stage_up3.0.mlp.fc2.weight              0.002390     0.00000120      [LOW_LR]
[01:29:34.688] cswin_unet.stage3.3.mlp.fc1.weight                 0.002298     0.00000115      [LOW_LR]
[01:29:34.688] cswin_unet.stage_up3.6.mlp.fc2.weight              0.002295     0.00000115      [LOW_LR]
[01:29:34.688] cswin_unet.stage_up3.6.mlp.fc1.weight              0.002220     0.00000111      [LOW_LR]
[01:29:34.688] cswin_unet.stage3.2.mlp.fc1.weight                 0.002199     0.00000110      [LOW_LR]
[01:29:34.688] cswin_unet.stage_up3.7.mlp.fc1.weight              0.002189     0.00000109      [LOW_LR]
[01:29:34.688] cswin_unet.stage_up3.2.qkv.weight                  0.002187     0.00000109      [LOW_LR]
[01:29:34.688] cswin_unet.stage3.6.mlp.fc1.weight                 0.002170     0.00000109      [LOW_LR]
[01:29:34.688] cswin_unet.stage3.4.mlp.fc1.weight                 0.002149     0.00000107      [LOW_LR]
[01:29:34.688] cswin_unet.stage_up3.7.mlp.fc2.weight              0.002078     0.00000104      [LOW_LR]
[01:29:34.688] cswin_unet.stage_up3.0.mlp.fc2.bias                0.002041     0.00000102      [LOW_LR]
[01:29:34.689] cswin_unet.stage3.4.mlp.fc2.weight                 0.002039     0.00000102      [LOW_LR]
[01:29:34.689] cswin_unet.stage3.7.mlp.fc1.weight                 0.002004     0.00000100      [LOW_LR]
[01:29:34.689] cswin_unet.stage_up3.1.mlp.fc2.weight              0.001986     0.00000099      [LOW_LR]
[01:29:34.689] cswin_unet.stage3.6.mlp.fc2.weight                 0.001960     0.00000098      [LOW_LR]
[01:29:34.689] cswin_unet.stage_up3.4.mlp.fc2.weight              0.001942     0.00000097      [LOW_LR]
[01:29:34.689] cswin_unet.stage3.8.mlp.fc1.weight                 0.001856     0.00000093      [LOW_LR]
[01:29:34.689] cswin_unet.stage_up3.2.mlp.fc2.weight              0.001772     0.00000089      [LOW_LR]
[01:29:34.689] cswin_unet.stage3.5.mlp.fc2.weight                 0.001762     0.00000088      [LOW_LR]
[01:29:34.689] cswin_unet.stage3.5.mlp.fc1.weight                 0.001745     0.00000087      [LOW_LR]
[01:29:34.689] cswin_unet.stage_up3.3.mlp.fc2.weight              0.001736     0.00000087      [LOW_LR]
[01:29:34.689] cswin_unet.stage3.0.qkv.bias                       0.001691     0.00000085      [LOW_LR]
[01:29:34.689] cswin_unet.stage3.7.mlp.fc2.weight                 0.001665     0.00000083      [LOW_LR]
[01:29:34.689] cswin_unet.stage_up3.5.mlp.fc2.weight              0.001610     0.00000080      [LOW_LR]
[01:29:34.689] cswin_unet.stage3.8.mlp.fc2.weight                 0.001585     0.00000079      [LOW_LR]
[01:29:34.689] cswin_unet.stage_up3.4.mlp.fc1.weight              0.001572     0.00000079      [LOW_LR]
[01:29:34.689] cswin_unet.stage_up3.0.qkv.weight                  0.001545     0.00000077      [LOW_LR]
[01:29:34.689] cswin_unet.stage3.1.qkv.bias                       0.001530     0.00000076      [LOW_LR]
[01:29:34.690] cswin_unet.stage_up3.8.qkv.bias                    0.001524     0.00000076      [LOW_LR]
[01:29:34.690] cswin_unet.stage3.8.qkv.bias                       0.001496     0.00000075      [LOW_LR]
[01:29:34.690] cswin_unet.stage_up4.0.attns.0.get_v.weight        0.001471     0.00000074      [LOW_LR]
[01:29:34.690] cswin_unet.stage_up3.5.mlp.fc1.weight              0.001410     0.00000071      [LOW_LR]
[01:29:34.690] cswin_unet.stage3.3.qkv.bias                       0.001384     0.00000069      [LOW_LR]
[01:29:34.690] cswin_unet.stage_up3.0.mlp.fc1.weight              0.001364     0.00000068      [LOW_LR]
[01:29:34.690] cswin_unet.stage3.4.qkv.bias                       0.001241     0.00000062      [LOW_LR]
[01:29:34.690] cswin_unet.stage3.2.qkv.bias                       0.001211     0.00000061      [LOW_LR]
[01:29:34.690] cswin_unet.stage4.0.attns.0.get_v.weight           0.001200     0.00000060      [LOW_LR]
[01:29:34.690] cswin_unet.stage_up3.3.mlp.fc1.weight              0.001184     0.00000059      [LOW_LR]
[01:29:34.690] cswin_unet.stage_up3.1.mlp.fc1.weight              0.001151     0.00000058      [LOW_LR]
[01:29:34.690] cswin_unet.stage3.7.qkv.bias                       0.001126     0.00000056      [LOW_LR]
[01:29:34.690] cswin_unet.stage_up3.2.mlp.fc1.weight              0.001111     0.00000056      [LOW_LR]
[01:29:34.690] cswin_unet.stage_up3.1.qkv.bias                    0.001049     0.00000052      [LOW_LR]
[01:29:34.690] cswin_unet.stage_up3.6.qkv.bias                    0.001041     0.00000052      [LOW_LR]
[01:29:34.690] cswin_unet.stage3.6.qkv.bias                       0.000998     0.00000050      [LOW_LR]
[01:29:34.690] cswin_unet.stage_up3.7.qkv.bias                    0.000934     0.00000047      [LOW_LR]
[01:29:34.690] cswin_unet.stage3.5.qkv.bias                       0.000919     0.00000046      [LOW_LR]
[01:29:34.690] cswin_unet.stage_up3.3.qkv.bias                    0.000836     0.00000042      [LOW_LR]
[01:29:34.690] cswin_unet.stage_up3.5.qkv.bias                    0.000827     0.00000041      [LOW_LR]
[01:29:34.690] cswin_unet.stage_up4.0.proj.bias                   0.000764     0.00000038      [LOW_LR]
[01:29:34.690] cswin_unet.merge2.conv.bias                        0.000758     0.00000038      [LOW_LR]
[01:29:34.691] cswin_unet.stage_up3.0.qkv.bias                    0.000748     0.00000037      [LOW_LR]
[01:29:34.691] cswin_unet.stage_up3.2.qkv.bias                    0.000743     0.00000037      [LOW_LR]
[01:29:34.691] cswin_unet.stage3.0.mlp.fc1.bias                   0.000734     0.00000037      [LOW_LR]
[01:29:34.691] cswin_unet.stage_up3.4.qkv.bias                    0.000687     0.00000034      [LOW_LR]
[01:29:34.691] cswin_unet.stage_up4.0.proj.weight                 0.000602     0.00000030      [LOW_LR]
[01:29:34.691] cswin_unet.stage_up4.0.mlp.fc1.weight              0.000496     0.00000025      [LOW_LR]
[01:29:34.691] cswin_unet.stage4.0.proj.weight                    0.000463     0.00000023      [LOW_LR]
[01:29:34.691] cswin_unet.stage_up3.8.mlp.fc1.bias                0.000408     0.00000020      [LOW_LR]
[01:29:34.691] cswin_unet.stage_up4.0.mlp.fc2.weight              0.000390     0.00000020      [LOW_LR]
[01:29:34.691] cswin_unet.stage_up4.0.mlp.fc2.bias                0.000373     0.00000019      [LOW_LR]
[01:29:34.691] cswin_unet.stage3.1.mlp.fc1.bias                   0.000301     0.00000015      [LOW_LR]
[01:29:34.691] cswin_unet.stage_up4.0.qkv.weight                  0.000288     0.00000014      [LOW_LR]
[01:29:34.691] cswin_unet.stage_up3.6.mlp.fc1.bias                0.000283     0.00000014      [LOW_LR]
[01:29:34.691] cswin_unet.stage_up3.7.mlp.fc1.bias                0.000282     0.00000014      [LOW_LR]
[01:29:34.691] cswin_unet.stage4.0.mlp.fc1.weight                 0.000274     0.00000014      [LOW_LR]
[01:29:34.691] cswin_unet.stage4.0.mlp.fc2.weight                 0.000274     0.00000014      [LOW_LR]
[01:29:34.691] cswin_unet.stage3.3.mlp.fc1.bias                   0.000269     0.00000013      [LOW_LR]
[01:29:34.691] cswin_unet.stage_up4.0.qkv.bias                    0.000262     0.00000013      [LOW_LR]
[01:29:34.691] cswin_unet.merge3.conv.weight                      0.000261     0.00000013      [LOW_LR]
[01:29:34.691] cswin_unet.stage3.4.mlp.fc1.bias                   0.000260     0.00000013      [LOW_LR]
[01:29:34.691] cswin_unet.stage3.6.mlp.fc1.bias                   0.000256     0.00000013      [LOW_LR]
[01:29:34.691] cswin_unet.stage3.2.mlp.fc1.bias                   0.000255     0.00000013      [LOW_LR]
[01:29:34.692] cswin_unet.stage3.7.mlp.fc1.bias                   0.000244     0.00000012      [LOW_LR]
[01:29:34.692] cswin_unet.stage3.8.mlp.fc1.bias                   0.000236     0.00000012      [LOW_LR]
[01:29:34.692] cswin_unet.stage3.5.mlp.fc1.bias                   0.000213     0.00000011      [LOW_LR]
[01:29:34.692] cswin_unet.stage_up3.0.mlp.fc1.bias                0.000191     0.00000010      [LOW_LR]
[01:29:34.692] cswin_unet.stage_up3.4.mlp.fc1.bias                0.000187     0.00000009      [LOW_LR]
[01:29:34.692] cswin_unet.stage4.0.qkv.weight                     0.000180     0.00000009      [LOW_LR]
[01:29:34.692] cswin_unet.stage4.0.proj.bias                      0.000179     0.00000009      [LOW_LR]
[01:29:34.692] cswin_unet.stage_up3.5.mlp.fc1.bias                0.000176     0.00000009      [LOW_LR]
[01:29:34.692] cswin_unet.stage_up3.3.mlp.fc1.bias                0.000146     0.00000007      [LOW_LR]
[01:29:34.693] cswin_unet.stage_up3.1.mlp.fc1.bias                0.000125     0.00000006      [LOW_LR]
[01:29:34.693] cswin_unet.stage_up3.2.mlp.fc1.bias                0.000118     0.00000006      [LOW_LR]
[01:29:34.693] cswin_unet.stage4.0.qkv.bias                       0.000096     0.00000005      [LOW_LR]
[01:29:34.693] cswin_unet.stage4.0.mlp.fc2.bias                   0.000084     0.00000004      [LOW_LR]
[01:29:34.693] cswin_unet.upsample4.encoder.weight                0.000067     0.00000003      [LOW_LR]
[01:29:34.693] cswin_unet.stage_up4.0.mlp.fc1.bias                0.000065     0.00000003      [LOW_LR]
[01:29:34.693] cswin_unet.stage4.0.mlp.fc1.bias                   0.000039     0.00000002      [LOW_LR]
[01:29:34.693] cswin_unet.upsample4.encoder.bias                  0.000019     0.00000001      [LOW_LR]
[01:29:34.693] cswin_unet.upsample4.down.weight                   0.000013     0.00000001      [LOW_LR]
[01:29:34.693] cswin_unet.upsample4.down.bias                     0.000012     0.00000001      [LOW_LR]
[01:29:34.693] cswin_unet.merge3.conv.bias                        0.000004     0.00000000      [LOW_LR]
[01:29:34.693] --------------------------------------------------------------------------------
[01:29:34.693] Total layers: 463, High LR layers: 186, Low LR layers: 277
[01:29:34.694] ================================================================================

[01:29:46.247] Epoch 16, Iter 6930: loss=0.0297, ce=0.0068, dice=0.0449, grad_norm=0.094161
[01:29:49.917] Epoch 16, Iter 6940: loss=0.0273, ce=0.0016, dice=0.0444, grad_norm=0.129246
[01:29:53.501] Epoch 16, Iter 6950: loss=0.0239, ce=0.0031, dice=0.0377, grad_norm=0.184506
[01:29:57.098] Epoch 16, Iter 6960: loss=0.0458, ce=0.0065, dice=0.0720, grad_norm=0.283914
[01:30:00.690] Epoch 16, Iter 6970: loss=0.0279, ce=0.0097, dice=0.0401, grad_norm=0.051240
[01:30:04.270] Epoch 16, Iter 6980: loss=0.0180, ce=0.0063, dice=0.0258, grad_norm=0.116811
[01:30:07.858] Epoch 16, Iter 6990: loss=0.0342, ce=0.0039, dice=0.0543, grad_norm=0.152034
[01:30:11.441] Epoch 16, Iter 7000: loss=0.0292, ce=0.0053, dice=0.0451, grad_norm=0.093383
[01:30:15.006] Epoch 16, Iter 7010: loss=0.0262, ce=0.0062, dice=0.0395, grad_norm=0.042380
[01:30:18.591] Epoch 16, Iter 7020: loss=0.0209, ce=0.0034, dice=0.0325, grad_norm=0.049569
[01:30:22.211] Epoch 16, Iter 7030: loss=0.0974, ce=0.0039, dice=0.1597, grad_norm=1.182778
[01:30:25.856] Epoch 16, Iter 7040: loss=0.0431, ce=0.0033, dice=0.0696, grad_norm=0.297075
[01:30:29.463] Epoch 16, Iter 7050: loss=0.0725, ce=0.0060, dice=0.1167, grad_norm=0.216566
[01:30:33.068] Epoch 16, Iter 7060: loss=0.0247, ce=0.0015, dice=0.0401, grad_norm=0.127483
[01:30:36.692] Epoch 16, Iter 7070: loss=0.0424, ce=0.0023, dice=0.0691, grad_norm=0.112788
[01:30:40.298] Epoch 16, Iter 7080: loss=0.2048, ce=0.0025, dice=0.3396, grad_norm=0.101580
[01:30:43.899] Epoch 16, Iter 7090: loss=0.2024, ce=0.0025, dice=0.3357, grad_norm=0.261108
[01:30:47.504] Epoch 16, Iter 7100: loss=0.0343, ce=0.0031, dice=0.0552, grad_norm=0.217909
[01:30:51.106] Epoch 16, Iter 7110: loss=0.0298, ce=0.0078, dice=0.0445, grad_norm=0.057629
[01:30:54.721] Epoch 16, Iter 7120: loss=0.0404, ce=0.0044, dice=0.0644, grad_norm=0.109445
[01:30:58.335] Epoch 16, Iter 7130: loss=0.0353, ce=0.0031, dice=0.0567, grad_norm=0.202799
[01:31:01.935] Epoch 16, Iter 7140: loss=0.0470, ce=0.0040, dice=0.0756, grad_norm=0.294803
[01:31:05.554] Epoch 16, Iter 7150: loss=0.0403, ce=0.0026, dice=0.0655, grad_norm=0.251250
[01:31:09.158] Epoch 16, Iter 7160: loss=0.0253, ce=0.0042, dice=0.0393, grad_norm=0.228451
[01:31:12.781] Epoch 16, Iter 7170: loss=0.0228, ce=0.0055, dice=0.0343, grad_norm=0.039720
[01:31:16.389] Epoch 16, Iter 7180: loss=0.0282, ce=0.0020, dice=0.0457, grad_norm=0.087167
[01:31:20.008] Epoch 16, Iter 7190: loss=0.2074, ce=0.0038, dice=0.3432, grad_norm=0.021540
[01:31:23.607] Epoch 16, Iter 7200: loss=0.0371, ce=0.0066, dice=0.0574, grad_norm=0.265973
[01:31:27.226] Epoch 16, Iter 7210: loss=0.0321, ce=0.0019, dice=0.0522, grad_norm=0.103213
[01:31:30.854] Epoch 16, Iter 7220: loss=0.0231, ce=0.0091, dice=0.0324, grad_norm=0.041821
[01:31:34.475] Epoch 16, Iter 7230: loss=0.0490, ce=0.0040, dice=0.0791, grad_norm=0.251862
[01:31:38.072] Epoch 16, Iter 7240: loss=0.0270, ce=0.0058, dice=0.0412, grad_norm=0.074521
[01:31:41.687] Epoch 16, Iter 7250: loss=0.0489, ce=0.0029, dice=0.0796, grad_norm=0.283569
[01:31:45.281] Epoch 16, Iter 7260: loss=0.0578, ce=0.0078, dice=0.0911, grad_norm=0.319748
[01:31:48.895] Epoch 16, Iter 7270: loss=0.0406, ce=0.0041, dice=0.0649, grad_norm=0.208146
[01:31:52.519] Epoch 16, Iter 7280: loss=0.0250, ce=0.0044, dice=0.0387, grad_norm=0.113333
[01:31:56.155] Epoch 16, Iter 7290: loss=0.0334, ce=0.0031, dice=0.0536, grad_norm=0.226162
[01:31:59.777] Epoch 16, Iter 7300: loss=0.0244, ce=0.0076, dice=0.0355, grad_norm=0.093344
[01:32:03.419] Epoch 16, Iter 7310: loss=0.0184, ce=0.0035, dice=0.0283, grad_norm=0.060888
[01:32:07.016] Epoch 16, Iter 7320: loss=0.0311, ce=0.0026, dice=0.0502, grad_norm=0.269506
[01:32:10.635] Epoch 16, Iter 7330: loss=0.2106, ce=0.0038, dice=0.3485, grad_norm=0.078429
[01:32:14.232] Epoch 16, Iter 7340: loss=0.0244, ce=0.0044, dice=0.0377, grad_norm=0.149874
[01:32:17.844] Epoch 16, Iter 7350: loss=0.0254, ce=0.0072, dice=0.0376, grad_norm=0.077802
[01:32:21.471] Epoch 16, Iter 7360: loss=0.2035, ce=0.0010, dice=0.3385, grad_norm=0.010607
[01:32:22.445] Epoch 16: Avg Loss=0.0577, CE=0.0045, Dice=0.0932
[01:39:19.975] Epoch 17, Iter 7370: loss=0.0467, ce=0.0044, dice=0.0749, grad_norm=0.111575
[01:39:23.566] Epoch 17, Iter 7380: loss=0.0216, ce=0.0045, dice=0.0330, grad_norm=0.117755
[01:39:27.163] Epoch 17, Iter 7390: loss=0.0780, ce=0.0038, dice=0.1274, grad_norm=6.600185
[01:39:30.733] Epoch 17, Iter 7400: loss=0.0273, ce=0.0033, dice=0.0433, grad_norm=0.215854
[01:39:34.329] Epoch 17, Iter 7410: loss=0.0631, ce=0.0025, dice=0.1035, grad_norm=2.025722
[01:39:37.920] Epoch 17, Iter 7420: loss=0.0238, ce=0.0058, dice=0.0357, grad_norm=0.130673
[01:39:41.511] Epoch 17, Iter 7430: loss=0.0988, ce=0.0053, dice=0.1612, grad_norm=0.707541
[01:39:45.092] Epoch 17, Iter 7440: loss=0.2115, ce=0.0006, dice=0.3522, grad_norm=0.240887
[01:39:48.696] Epoch 17, Iter 7450: loss=0.0189, ce=0.0031, dice=0.0294, grad_norm=0.150890
[01:39:52.275] Epoch 17, Iter 7460: loss=0.2100, ce=0.0067, dice=0.3456, grad_norm=0.043228
[01:39:55.860] Epoch 17, Iter 7470: loss=0.0764, ce=0.0055, dice=0.1237, grad_norm=0.235600
[01:39:59.470] Epoch 17, Iter 7480: loss=0.0498, ce=0.0043, dice=0.0801, grad_norm=0.086683
[01:40:03.067] Epoch 17, Iter 7490: loss=0.0346, ce=0.0121, dice=0.0496, grad_norm=0.246699
[01:40:06.654] Epoch 17, Iter 7500: loss=0.0481, ce=0.0073, dice=0.0753, grad_norm=0.152369
[01:40:10.255] Epoch 17, Iter 7510: loss=0.0263, ce=0.0076, dice=0.0387, grad_norm=0.073365
[01:40:13.872] Epoch 17, Iter 7520: loss=0.0180, ce=0.0051, dice=0.0266, grad_norm=0.053335
[01:40:17.478] Epoch 17, Iter 7530: loss=0.0143, ce=0.0047, dice=0.0207, grad_norm=0.054670
[01:40:21.072] Epoch 17, Iter 7540: loss=0.0381, ce=0.0043, dice=0.0606, grad_norm=0.103599
[01:40:24.690] Epoch 17, Iter 7550: loss=0.0189, ce=0.0044, dice=0.0286, grad_norm=0.076373
[01:40:28.291] Epoch 17, Iter 7560: loss=0.2073, ce=0.0026, dice=0.3437, grad_norm=0.024013
[01:40:31.905] Epoch 17, Iter 7570: loss=0.0321, ce=0.0053, dice=0.0499, grad_norm=0.089234
[01:40:35.483] Epoch 17, Iter 7580: loss=0.0297, ce=0.0062, dice=0.0454, grad_norm=0.119345
[01:40:39.089] Epoch 17, Iter 7590: loss=0.0198, ce=0.0026, dice=0.0313, grad_norm=0.179167
[01:40:42.694] Epoch 17, Iter 7600: loss=0.0296, ce=0.0063, dice=0.0452, grad_norm=0.132415
[01:40:46.300] Epoch 17, Iter 7610: loss=0.0258, ce=0.0052, dice=0.0395, grad_norm=0.398619
[01:40:49.890] Epoch 17, Iter 7620: loss=0.0286, ce=0.0062, dice=0.0435, grad_norm=0.124986
[01:40:53.503] Epoch 17, Iter 7630: loss=0.0154, ce=0.0046, dice=0.0226, grad_norm=0.053655
[01:40:57.111] Epoch 17, Iter 7640: loss=0.0281, ce=0.0033, dice=0.0446, grad_norm=0.224335
[01:41:00.726] Epoch 17, Iter 7650: loss=0.0229, ce=0.0067, dice=0.0336, grad_norm=0.167543
[01:41:04.324] Epoch 17, Iter 7660: loss=0.0515, ce=0.0049, dice=0.0825, grad_norm=0.370603
[01:41:07.937] Epoch 17, Iter 7670: loss=0.0317, ce=0.0060, dice=0.0488, grad_norm=0.112002
[01:41:11.544] Epoch 17, Iter 7680: loss=0.0431, ce=0.0052, dice=0.0684, grad_norm=0.141481
[01:41:15.149] Epoch 17, Iter 7690: loss=0.0431, ce=0.0088, dice=0.0659, grad_norm=0.119601
[01:41:18.738] Epoch 17, Iter 7700: loss=0.0452, ce=0.0040, dice=0.0727, grad_norm=0.346453
[01:41:22.339] Epoch 17, Iter 7710: loss=0.0377, ce=0.0038, dice=0.0603, grad_norm=0.145586
[01:41:25.934] Epoch 17, Iter 7720: loss=0.0335, ce=0.0050, dice=0.0525, grad_norm=0.112025
[01:41:29.552] Epoch 17, Iter 7730: loss=0.0527, ce=0.0091, dice=0.0818, grad_norm=0.080474
[01:41:33.154] Epoch 17, Iter 7740: loss=0.0177, ce=0.0021, dice=0.0281, grad_norm=0.048318
[01:41:36.764] Epoch 17, Iter 7750: loss=0.0462, ce=0.0039, dice=0.0745, grad_norm=0.164724
[01:41:40.360] Epoch 17, Iter 7760: loss=0.0289, ce=0.0037, dice=0.0457, grad_norm=0.111782
[01:41:43.978] Epoch 17, Iter 7770: loss=0.0658, ce=0.0037, dice=0.1072, grad_norm=0.262461
[01:41:47.578] Epoch 17, Iter 7780: loss=0.0421, ce=0.0037, dice=0.0677, grad_norm=0.140151
[01:41:51.189] Epoch 17, Iter 7790: loss=0.0200, ce=0.0070, dice=0.0287, grad_norm=0.065539
[01:41:53.249] Epoch 17: Avg Loss=0.0630, CE=0.0047, Dice=0.1019
[01:42:06.465] Epoch 18, Iter 7800: loss=0.0600, ce=0.0054, dice=0.0964, grad_norm=0.293099
[01:42:10.058] Epoch 18, Iter 7810: loss=0.0557, ce=0.0022, dice=0.0913, grad_norm=0.420035
[01:42:13.650] Epoch 18, Iter 7820: loss=0.2006, ce=0.0019, dice=0.3331, grad_norm=0.238130
[01:42:17.263] Epoch 18, Iter 7830: loss=0.2042, ce=0.0012, dice=0.3395, grad_norm=0.017319
[01:42:20.851] Epoch 18, Iter 7840: loss=0.1119, ce=0.0062, dice=0.1824, grad_norm=1.161717
[01:42:24.438] Epoch 18, Iter 7850: loss=0.0162, ce=0.0020, dice=0.0256, grad_norm=0.074223
[01:42:28.025] Epoch 18, Iter 7860: loss=0.0728, ce=0.0033, dice=0.1191, grad_norm=0.876438
[01:42:31.630] Epoch 18, Iter 7870: loss=0.0377, ce=0.0080, dice=0.0574, grad_norm=0.207184
[01:42:35.239] Epoch 18, Iter 7880: loss=0.0459, ce=0.0065, dice=0.0722, grad_norm=0.203125
[01:42:38.854] Epoch 18, Iter 7890: loss=0.0182, ce=0.0034, dice=0.0281, grad_norm=0.087267
[01:42:42.441] Epoch 18, Iter 7900: loss=0.0289, ce=0.0026, dice=0.0465, grad_norm=0.138042
[01:42:46.050] Epoch 18, Iter 7910: loss=0.0352, ce=0.0044, dice=0.0557, grad_norm=0.113960
[01:42:49.645] Epoch 18, Iter 7920: loss=0.0329, ce=0.0029, dice=0.0530, grad_norm=0.121931
[01:42:53.254] Epoch 18, Iter 7930: loss=0.0371, ce=0.0026, dice=0.0601, grad_norm=0.322180
[01:42:56.845] Epoch 18, Iter 7940: loss=0.2056, ce=0.0017, dice=0.3415, grad_norm=0.016946
[01:43:00.446] Epoch 18, Iter 7950: loss=0.1098, ce=0.0056, dice=0.1793, grad_norm=0.864792
[01:43:04.053] Epoch 18, Iter 7960: loss=0.0298, ce=0.0050, dice=0.0464, grad_norm=0.131851
[01:43:07.679] Epoch 18, Iter 7970: loss=0.0358, ce=0.0039, dice=0.0571, grad_norm=0.139797
[01:43:11.267] Epoch 18, Iter 7980: loss=0.0359, ce=0.0018, dice=0.0586, grad_norm=0.127676
[01:43:14.906] Epoch 18, Iter 7990: loss=0.2060, ce=0.0019, dice=0.3420, grad_norm=0.025960
[01:43:18.516] Epoch 18, Iter 8000: loss=0.0319, ce=0.0027, dice=0.0513, grad_norm=0.125891
[01:43:22.125] Epoch 18, Iter 8010: loss=0.0254, ce=0.0044, dice=0.0394, grad_norm=0.072518
[01:43:25.723] Epoch 18, Iter 8020: loss=0.0547, ce=0.0027, dice=0.0893, grad_norm=0.329517
[01:43:29.326] Epoch 18, Iter 8030: loss=0.2076, ce=0.0060, dice=0.3419, grad_norm=0.104683
[01:43:32.922] Epoch 18, Iter 8040: loss=0.2060, ce=0.0024, dice=0.3417, grad_norm=0.035470
[01:43:36.528] Epoch 18, Iter 8050: loss=0.0406, ce=0.0033, dice=0.0654, grad_norm=0.121999
[01:43:40.138] Epoch 18, Iter 8060: loss=0.0239, ce=0.0021, dice=0.0385, grad_norm=0.087004
[01:43:43.767] Epoch 18, Iter 8070: loss=0.0381, ce=0.0025, dice=0.0618, grad_norm=0.597638
[01:43:47.371] Epoch 18, Iter 8080: loss=0.0574, ce=0.0067, dice=0.0912, grad_norm=1.485554
[01:43:50.994] Epoch 18, Iter 8090: loss=0.0372, ce=0.0046, dice=0.0590, grad_norm=0.332952
[01:43:54.591] Epoch 18, Iter 8100: loss=0.0305, ce=0.0043, dice=0.0479, grad_norm=0.085482
[01:43:58.198] Epoch 18, Iter 8110: loss=0.0288, ce=0.0025, dice=0.0463, grad_norm=0.176433
[01:44:01.792] Epoch 18, Iter 8120: loss=0.1146, ce=0.0067, dice=0.1865, grad_norm=0.485620
[01:44:05.445] Epoch 18, Iter 8130: loss=0.0453, ce=0.0020, dice=0.0741, grad_norm=1.541780
[01:44:09.064] Epoch 18, Iter 8140: loss=0.0335, ce=0.0040, dice=0.0532, grad_norm=0.341460
[01:44:12.699] Epoch 18, Iter 8150: loss=0.0246, ce=0.0070, dice=0.0363, grad_norm=0.045917
[01:44:16.298] Epoch 18, Iter 8160: loss=0.0375, ce=0.0044, dice=0.0596, grad_norm=0.212998
[01:44:19.903] Epoch 18, Iter 8170: loss=0.0495, ce=0.0066, dice=0.0780, grad_norm=0.178608
[01:44:23.532] Epoch 18, Iter 8180: loss=0.0190, ce=0.0039, dice=0.0291, grad_norm=0.071741
[01:44:27.150] Epoch 18, Iter 8190: loss=0.0279, ce=0.0047, dice=0.0433, grad_norm=0.106542
[01:44:30.839] Epoch 18, Iter 8200: loss=0.0464, ce=0.0058, dice=0.0735, grad_norm=0.262765
[01:44:34.457] Epoch 18, Iter 8210: loss=0.2081, ce=0.0022, dice=0.3453, grad_norm=0.067083
[01:44:38.065] Epoch 18, Iter 8220: loss=0.0287, ce=0.0065, dice=0.0435, grad_norm=0.063089
[01:44:41.202] Epoch 18: Avg Loss=0.0607, CE=0.0046, Dice=0.0981
[01:44:53.131] Epoch 19, Iter 8230: loss=0.0263, ce=0.0050, dice=0.0405, grad_norm=0.074051
[01:44:56.742] Epoch 19, Iter 8240: loss=0.0145, ce=0.0049, dice=0.0209, grad_norm=0.056361
[01:45:00.355] Epoch 19, Iter 8250: loss=0.2054, ce=0.0016, dice=0.3413, grad_norm=0.036439
[01:45:03.940] Epoch 19, Iter 8260: loss=0.2098, ce=0.0025, dice=0.3479, grad_norm=0.085359
[01:45:07.544] Epoch 19, Iter 8270: loss=0.0240, ce=0.0037, dice=0.0375, grad_norm=0.096379
[01:45:11.136] Epoch 19, Iter 8280: loss=0.2080, ce=0.0034, dice=0.3443, grad_norm=0.020774
[01:45:14.779] Epoch 19, Iter 8290: loss=0.0250, ce=0.0051, dice=0.0384, grad_norm=0.059835
[01:45:18.376] Epoch 19, Iter 8300: loss=0.0326, ce=0.0035, dice=0.0519, grad_norm=0.183873
[01:45:21.993] Epoch 19, Iter 8310: loss=0.0258, ce=0.0073, dice=0.0381, grad_norm=0.075384
[01:45:25.592] Epoch 19, Iter 8320: loss=0.0320, ce=0.0082, dice=0.0478, grad_norm=0.072719
[01:45:29.212] Epoch 19, Iter 8330: loss=0.0293, ce=0.0058, dice=0.0450, grad_norm=0.103864
[01:45:32.823] Epoch 19, Iter 8340: loss=0.0186, ce=0.0069, dice=0.0265, grad_norm=0.059227
[01:45:36.454] Epoch 19, Iter 8350: loss=0.0548, ce=0.0045, dice=0.0883, grad_norm=1.202946
[01:45:40.060] Epoch 19, Iter 8360: loss=0.0343, ce=0.0031, dice=0.0551, grad_norm=0.149972
[01:45:43.678] Epoch 19, Iter 8370: loss=0.0334, ce=0.0104, dice=0.0488, grad_norm=0.841234
[01:45:47.276] Epoch 19, Iter 8380: loss=0.0368, ce=0.0057, dice=0.0576, grad_norm=0.162727
[01:45:50.890] Epoch 19, Iter 8390: loss=0.0220, ce=0.0044, dice=0.0337, grad_norm=0.124785
[01:45:54.487] Epoch 19, Iter 8400: loss=0.0365, ce=0.0055, dice=0.0571, grad_norm=0.243355
[01:45:58.097] Epoch 19, Iter 8410: loss=0.2089, ce=0.0050, dice=0.3448, grad_norm=0.035300
[01:46:01.716] Epoch 19, Iter 8420: loss=0.0211, ce=0.0032, dice=0.0330, grad_norm=0.046528
[01:46:05.334] Epoch 19, Iter 8430: loss=0.0375, ce=0.0034, dice=0.0602, grad_norm=0.264946
[01:46:08.956] Epoch 19, Iter 8440: loss=0.0108, ce=0.0038, dice=0.0155, grad_norm=0.050463
[01:46:12.569] Epoch 19, Iter 8450: loss=0.0952, ce=0.0029, dice=0.1566, grad_norm=0.778539
[01:46:16.166] Epoch 19, Iter 8460: loss=0.0284, ce=0.0021, dice=0.0460, grad_norm=0.142270
[01:46:19.793] Epoch 19, Iter 8470: loss=0.0209, ce=0.0045, dice=0.0318, grad_norm=0.035657
[01:46:23.395] Epoch 19, Iter 8480: loss=0.0152, ce=0.0029, dice=0.0233, grad_norm=0.086748
[01:46:27.007] Epoch 19, Iter 8490: loss=0.0407, ce=0.0041, dice=0.0652, grad_norm=0.128333
[01:46:30.602] Epoch 19, Iter 8500: loss=0.0235, ce=0.0068, dice=0.0345, grad_norm=0.084037
[01:46:34.219] Epoch 19, Iter 8510: loss=0.0259, ce=0.0086, dice=0.0375, grad_norm=0.065891
[01:46:37.820] Epoch 19, Iter 8520: loss=0.0338, ce=0.0017, dice=0.0553, grad_norm=0.180574
[01:46:41.419] Epoch 19, Iter 8530: loss=0.0679, ce=0.0034, dice=0.1108, grad_norm=0.478207
[01:46:45.011] Epoch 19, Iter 8540: loss=0.0196, ce=0.0049, dice=0.0294, grad_norm=0.094920
[01:46:48.623] Epoch 19, Iter 8550: loss=0.0264, ce=0.0039, dice=0.0413, grad_norm=0.115286
[01:46:52.247] Epoch 19, Iter 8560: loss=0.0927, ce=0.0035, dice=0.1522, grad_norm=0.175047
[01:46:55.882] Epoch 19, Iter 8570: loss=0.0175, ce=0.0053, dice=0.0257, grad_norm=0.058864
[01:46:59.483] Epoch 19, Iter 8580: loss=0.0378, ce=0.0038, dice=0.0604, grad_norm=0.284482
[01:47:03.091] Epoch 19, Iter 8590: loss=0.0361, ce=0.0037, dice=0.0576, grad_norm=0.309133
[01:47:06.713] Epoch 19, Iter 8600: loss=0.2066, ce=0.0024, dice=0.3427, grad_norm=0.048529
[01:47:10.358] Epoch 19, Iter 8610: loss=0.0215, ce=0.0041, dice=0.0330, grad_norm=0.101723
[01:47:13.957] Epoch 19, Iter 8620: loss=0.0241, ce=0.0030, dice=0.0382, grad_norm=0.071490
[01:47:17.560] Epoch 19, Iter 8630: loss=0.0181, ce=0.0037, dice=0.0276, grad_norm=0.057600
[01:47:21.156] Epoch 19, Iter 8640: loss=0.0499, ce=0.0028, dice=0.0813, grad_norm=0.177350
[01:47:24.782] Epoch 19, Iter 8650: loss=0.2089, ce=0.0035, dice=0.3459, grad_norm=0.039442
[01:47:28.347] Epoch 19, Iter 8660: loss=0.0347, ce=0.0077, dice=0.0526, grad_norm=0.148109
[01:47:28.991] Epoch 19: Avg Loss=0.0553, CE=0.0045, Dice=0.0891
[01:54:32.059] save model to ./finetune_tpgm_surgical_lits17\finetuned_epoch_19.pth
[01:54:32.060] 
[EPOCH 21] Calculating RGN weights for surgical fine-tuning...
[01:54:44.999] RGN: Max weight before normalization: 0.001561
[01:54:45.024] 
================================================================================
[01:54:45.024] SURGICAL FINE-TUNING WITH TPGM - RGN METHOD
[01:54:45.024] ================================================================================
[01:54:45.024] Layer Name                                         Weight       Learning Rate  
[01:54:45.024] --------------------------------------------------------------------------------
[01:54:45.025] cswin_unet.stage1.0.attns.1.get_v.bias             1.000000     0.00050000      [ACTIVE]
[01:54:45.025] cswin_unet.stage1.0.attns.0.get_v.bias             0.669449     0.00033472      [ACTIVE]
[01:54:45.025] cswin_unet.upsample2.out.weight                    0.420241     0.00021012      [ACTIVE]
[01:54:45.025] cswin_unet.concat_linear3.weight                   0.413281     0.00020664      [ACTIVE]
[01:54:45.025] cswin_unet.upsample3.out.weight                    0.406094     0.00020305      [ACTIVE]
[01:54:45.025] cswin_unet.concat_linear2.weight                   0.393067     0.00019653      [ACTIVE]
[01:54:45.025] cswin_unet.stage_up1.0.attns.1.get_v.bias          0.388083     0.00019404      [ACTIVE]
[01:54:45.025] cswin_unet.concat_linear2.bias                     0.366048     0.00018302      [ACTIVE]
[01:54:45.025] cswin_unet.stage2.1.attns.1.get_v.bias             0.356060     0.00017803      [ACTIVE]
[01:54:45.025] cswin_unet.output.weight                           0.350038     0.00017502      [ACTIVE]
[01:54:45.025] cswin_unet.stage2.1.attns.0.get_v.bias             0.347726     0.00017386      [ACTIVE]
[01:54:45.025] cswin_unet.concat_linear3.bias                     0.345713     0.00017286      [ACTIVE]
[01:54:45.025] cswin_unet.upsample2.down.weight                   0.330669     0.00016533      [ACTIVE]
[01:54:45.025] cswin_unet.stage1_conv_embed.0.weight              0.322072     0.00016104      [ACTIVE]
[01:54:45.025] cswin_unet.upsample1.out.weight                    0.318964     0.00015948      [ACTIVE]
[01:54:45.025] cswin_unet.stage1.0.proj.weight                    0.310492     0.00015525      [ACTIVE]
[01:54:45.026] cswin_unet.upsample3.encoder.weight                0.310318     0.00015516      [ACTIVE]
[01:54:45.026] cswin_unet.stage1.0.proj.bias                      0.308316     0.00015416      [ACTIVE]
[01:54:45.026] cswin_unet.upsample1.out.bias                      0.307785     0.00015389      [ACTIVE]
[01:54:45.026] cswin_unet.stage2.0.proj.bias                      0.302745     0.00015137      [ACTIVE]
[01:54:45.026] cswin_unet.stage_up1.0.attns.0.get_v.bias          0.296218     0.00014811      [ACTIVE]
[01:54:45.026] cswin_unet.upsample2.encoder.weight                0.271447     0.00013572      [ACTIVE]
[01:54:45.026] cswin_unet.stage1.0.mlp.fc2.weight                 0.245451     0.00012273      [ACTIVE]
[01:54:45.026] cswin_unet.stage1.0.mlp.fc2.bias                   0.240206     0.00012010      [ACTIVE]
[01:54:45.026] cswin_unet.stage_up2.1.attns.1.get_v.bias          0.233466     0.00011673      [ACTIVE]
[01:54:45.026] cswin_unet.upsample2.encoder.bias                  0.229432     0.00011472      [ACTIVE]
[01:54:45.026] cswin_unet.stage2.0.attns.1.get_v.bias             0.228214     0.00011411      [ACTIVE]
[01:54:45.026] cswin_unet.stage1.0.mlp.fc1.weight                 0.224426     0.00011221      [ACTIVE]
[01:54:45.026] cswin_unet.upsample2.out.bias                      0.220330     0.00011017      [ACTIVE]
[01:54:45.026] cswin_unet.stage2.0.attns.0.get_v.bias             0.219098     0.00010955      [ACTIVE]
[01:54:45.026] cswin_unet.stage_up2.1.attns.0.get_v.bias          0.208832     0.00010442      [ACTIVE]
[01:54:45.026] cswin_unet.stage2.1.proj.bias                      0.187612     0.00009381      [ACTIVE]
[01:54:45.027] cswin_unet.stage1.0.qkv.weight                     0.184196     0.00009210      [ACTIVE]
[01:54:45.027] cswin_unet.upsample3.down.weight                   0.165366     0.00008268      [ACTIVE]
[01:54:45.027] cswin_unet.upsample2.down.bias                     0.163309     0.00008165      [ACTIVE]
[01:54:45.027] cswin_unet.stage1_conv_embed.2.bias                0.156064     0.00007803      [ACTIVE]
[01:54:45.027] cswin_unet.merge1.conv.weight                      0.151050     0.00007552      [ACTIVE]
[01:54:45.027] cswin_unet.stage_up1.0.proj.weight                 0.143661     0.00007183      [ACTIVE]
[01:54:45.027] cswin_unet.stage_up1.0.qkv.weight                  0.141153     0.00007058      [ACTIVE]
[01:54:45.027] cswin_unet.stage_up1.0.mlp.fc2.weight              0.140608     0.00007030      [ACTIVE]
[01:54:45.027] cswin_unet.stage_up2.0.attns.1.get_v.bias          0.139418     0.00006971      [ACTIVE]
[01:54:45.027] cswin_unet.stage_up1.0.mlp.fc1.weight              0.134936     0.00006747      [ACTIVE]
[01:54:45.027] cswin_unet.concat_linear4.weight                   0.133814     0.00006691      [ACTIVE]
[01:54:45.027] cswin_unet.upsample1.down.weight                   0.133586     0.00006679      [ACTIVE]
[01:54:45.027] cswin_unet.stage1.0.attns.0.get_v.weight           0.128566     0.00006428      [ACTIVE]
[01:54:45.027] cswin_unet.stage1.0.attns.1.get_v.weight           0.127798     0.00006390      [ACTIVE]
[01:54:45.027] cswin_unet.stage_up2.0.attns.0.get_v.bias          0.123699     0.00006185      [ACTIVE]
[01:54:45.027] cswin_unet.stage_up1.0.mlp.fc2.bias                0.117470     0.00005873      [ACTIVE]
[01:54:45.028] cswin_unet.stage2.1.proj.weight                    0.107743     0.00005387      [ACTIVE]
[01:54:45.028] cswin_unet.stage_up1.0.proj.bias                   0.106661     0.00005333      [ACTIVE]
[01:54:45.028] cswin_unet.stage_up2.0.proj.bias                   0.105949     0.00005297      [ACTIVE]
[01:54:45.028] cswin_unet.stage2.0.proj.weight                    0.100276     0.00005014      [ACTIVE]
[01:54:45.028] cswin_unet.stage1.0.norm1.weight                   0.100000     0.00005000      [ACTIVE]
[01:54:45.028] cswin_unet.stage1.0.norm1.bias                     0.100000     0.00005000      [ACTIVE]
[01:54:45.028] cswin_unet.stage1.0.norm2.weight                   0.100000     0.00005000      [ACTIVE]
[01:54:45.028] cswin_unet.stage1.0.norm2.bias                     0.100000     0.00005000      [ACTIVE]
[01:54:45.028] cswin_unet.merge1.norm.weight                      0.100000     0.00005000      [ACTIVE]
[01:54:45.028] cswin_unet.merge1.norm.bias                        0.100000     0.00005000      [ACTIVE]
[01:54:45.028] cswin_unet.stage2.0.norm1.weight                   0.100000     0.00005000      [ACTIVE]
[01:54:45.028] cswin_unet.stage2.0.norm1.bias                     0.100000     0.00005000      [ACTIVE]
[01:54:45.028] cswin_unet.stage2.0.norm2.weight                   0.100000     0.00005000      [ACTIVE]
[01:54:45.028] cswin_unet.stage2.0.norm2.bias                     0.100000     0.00005000      [ACTIVE]
[01:54:45.028] cswin_unet.stage2.1.norm1.weight                   0.100000     0.00005000      [ACTIVE]
[01:54:45.028] cswin_unet.stage2.1.norm1.bias                     0.100000     0.00005000      [ACTIVE]
[01:54:45.028] cswin_unet.stage2.1.norm2.weight                   0.100000     0.00005000      [ACTIVE]
[01:54:45.028] cswin_unet.stage2.1.norm2.bias                     0.100000     0.00005000      [ACTIVE]
[01:54:45.028] cswin_unet.merge2.norm.weight                      0.100000     0.00005000      [ACTIVE]
[01:54:45.029] cswin_unet.merge2.norm.bias                        0.100000     0.00005000      [ACTIVE]
[01:54:45.029] cswin_unet.stage3.0.norm1.weight                   0.100000     0.00005000      [ACTIVE]
[01:54:45.029] cswin_unet.stage3.0.norm1.bias                     0.100000     0.00005000      [ACTIVE]
[01:54:45.029] cswin_unet.stage3.0.norm2.weight                   0.100000     0.00005000      [ACTIVE]
[01:54:45.029] cswin_unet.stage3.0.norm2.bias                     0.100000     0.00005000      [ACTIVE]
[01:54:45.029] cswin_unet.stage3.1.norm1.weight                   0.100000     0.00005000      [ACTIVE]
[01:54:45.029] cswin_unet.stage3.1.norm1.bias                     0.100000     0.00005000      [ACTIVE]
[01:54:45.029] cswin_unet.stage3.1.norm2.weight                   0.100000     0.00005000      [ACTIVE]
[01:54:45.029] cswin_unet.stage3.1.norm2.bias                     0.100000     0.00005000      [ACTIVE]
[01:54:45.029] cswin_unet.stage3.2.norm1.weight                   0.100000     0.00005000      [ACTIVE]
[01:54:45.029] cswin_unet.stage3.2.norm1.bias                     0.100000     0.00005000      [ACTIVE]
[01:54:45.029] cswin_unet.stage3.2.norm2.weight                   0.100000     0.00005000      [ACTIVE]
[01:54:45.029] cswin_unet.stage3.2.norm2.bias                     0.100000     0.00005000      [ACTIVE]
[01:54:45.029] cswin_unet.stage3.3.norm1.weight                   0.100000     0.00005000      [ACTIVE]
[01:54:45.029] cswin_unet.stage3.3.norm1.bias                     0.100000     0.00005000      [ACTIVE]
[01:54:45.029] cswin_unet.stage3.3.norm2.weight                   0.100000     0.00005000      [ACTIVE]
[01:54:45.029] cswin_unet.stage3.3.norm2.bias                     0.100000     0.00005000      [ACTIVE]
[01:54:45.029] cswin_unet.stage3.4.norm1.weight                   0.100000     0.00005000      [ACTIVE]
[01:54:45.029] cswin_unet.stage3.4.norm1.bias                     0.100000     0.00005000      [ACTIVE]
[01:54:45.029] cswin_unet.stage3.4.norm2.weight                   0.100000     0.00005000      [ACTIVE]
[01:54:45.029] cswin_unet.stage3.4.norm2.bias                     0.100000     0.00005000      [ACTIVE]
[01:54:45.029] cswin_unet.stage3.5.norm1.weight                   0.100000     0.00005000      [ACTIVE]
[01:54:45.029] cswin_unet.stage3.5.norm1.bias                     0.100000     0.00005000      [ACTIVE]
[01:54:45.029] cswin_unet.stage3.5.norm2.weight                   0.100000     0.00005000      [ACTIVE]
[01:54:45.030] cswin_unet.stage3.5.norm2.bias                     0.100000     0.00005000      [ACTIVE]
[01:54:45.030] cswin_unet.stage3.6.norm1.weight                   0.100000     0.00005000      [ACTIVE]
[01:54:45.030] cswin_unet.stage3.6.norm1.bias                     0.100000     0.00005000      [ACTIVE]
[01:54:45.030] cswin_unet.stage3.6.norm2.weight                   0.100000     0.00005000      [ACTIVE]
[01:54:45.030] cswin_unet.stage3.6.norm2.bias                     0.100000     0.00005000      [ACTIVE]
[01:54:45.030] cswin_unet.stage3.7.norm1.weight                   0.100000     0.00005000      [ACTIVE]
[01:54:45.030] cswin_unet.stage3.7.norm1.bias                     0.100000     0.00005000      [ACTIVE]
[01:54:45.030] cswin_unet.stage3.7.norm2.weight                   0.100000     0.00005000      [ACTIVE]
[01:54:45.030] cswin_unet.stage3.7.norm2.bias                     0.100000     0.00005000      [ACTIVE]
[01:54:45.030] cswin_unet.stage3.8.norm1.weight                   0.100000     0.00005000      [ACTIVE]
[01:54:45.030] cswin_unet.stage3.8.norm1.bias                     0.100000     0.00005000      [ACTIVE]
[01:54:45.030] cswin_unet.stage3.8.norm2.weight                   0.100000     0.00005000      [ACTIVE]
[01:54:45.030] cswin_unet.stage3.8.norm2.bias                     0.100000     0.00005000      [ACTIVE]
[01:54:45.030] cswin_unet.merge3.norm.weight                      0.100000     0.00005000      [ACTIVE]
[01:54:45.030] cswin_unet.merge3.norm.bias                        0.100000     0.00005000      [ACTIVE]
[01:54:45.030] cswin_unet.stage4.0.norm1.weight                   0.100000     0.00005000      [ACTIVE]
[01:54:45.030] cswin_unet.stage4.0.norm1.bias                     0.100000     0.00005000      [ACTIVE]
[01:54:45.030] cswin_unet.stage4.0.norm2.weight                   0.100000     0.00005000      [ACTIVE]
[01:54:45.030] cswin_unet.stage4.0.norm2.bias                     0.100000     0.00005000      [ACTIVE]
[01:54:45.030] cswin_unet.norm.weight                             0.100000     0.00005000      [ACTIVE]
[01:54:45.030] cswin_unet.norm.bias                               0.100000     0.00005000      [ACTIVE]
[01:54:45.030] cswin_unet.stage_up4.0.norm1.weight                0.100000     0.00005000      [ACTIVE]
[01:54:45.030] cswin_unet.stage_up4.0.norm1.bias                  0.100000     0.00005000      [ACTIVE]
[01:54:45.030] cswin_unet.stage_up4.0.norm2.weight                0.100000     0.00005000      [ACTIVE]
[01:54:45.031] cswin_unet.stage_up4.0.norm2.bias                  0.100000     0.00005000      [ACTIVE]
[01:54:45.031] cswin_unet.stage_up3.0.norm1.weight                0.100000     0.00005000      [ACTIVE]
[01:54:45.031] cswin_unet.stage_up3.0.norm1.bias                  0.100000     0.00005000      [ACTIVE]
[01:54:45.031] cswin_unet.stage_up3.0.norm2.weight                0.100000     0.00005000      [ACTIVE]
[01:54:45.031] cswin_unet.stage_up3.0.norm2.bias                  0.100000     0.00005000      [ACTIVE]
[01:54:45.031] cswin_unet.stage_up3.1.norm1.weight                0.100000     0.00005000      [ACTIVE]
[01:54:45.031] cswin_unet.stage_up3.1.norm1.bias                  0.100000     0.00005000      [ACTIVE]
[01:54:45.031] cswin_unet.stage_up3.1.norm2.weight                0.100000     0.00005000      [ACTIVE]
[01:54:45.031] cswin_unet.stage_up3.1.norm2.bias                  0.100000     0.00005000      [ACTIVE]
[01:54:45.031] cswin_unet.stage_up3.2.norm1.weight                0.100000     0.00005000      [ACTIVE]
[01:54:45.031] cswin_unet.stage_up3.2.norm1.bias                  0.100000     0.00005000      [ACTIVE]
[01:54:45.031] cswin_unet.stage_up3.2.norm2.weight                0.100000     0.00005000      [ACTIVE]
[01:54:45.031] cswin_unet.stage_up3.2.norm2.bias                  0.100000     0.00005000      [ACTIVE]
[01:54:45.031] cswin_unet.stage_up3.3.norm1.weight                0.100000     0.00005000      [ACTIVE]
[01:54:45.031] cswin_unet.stage_up3.3.norm1.bias                  0.100000     0.00005000      [ACTIVE]
[01:54:45.031] cswin_unet.stage_up3.3.norm2.weight                0.100000     0.00005000      [ACTIVE]
[01:54:45.031] cswin_unet.stage_up3.3.norm2.bias                  0.100000     0.00005000      [ACTIVE]
[01:54:45.031] cswin_unet.stage_up3.4.norm1.weight                0.100000     0.00005000      [ACTIVE]
[01:54:45.031] cswin_unet.stage_up3.4.norm1.bias                  0.100000     0.00005000      [ACTIVE]
[01:54:45.031] cswin_unet.stage_up3.4.norm2.weight                0.100000     0.00005000      [ACTIVE]
[01:54:45.031] cswin_unet.stage_up3.4.norm2.bias                  0.100000     0.00005000      [ACTIVE]
[01:54:45.031] cswin_unet.stage_up3.5.norm1.weight                0.100000     0.00005000      [ACTIVE]
[01:54:45.031] cswin_unet.stage_up3.5.norm1.bias                  0.100000     0.00005000      [ACTIVE]
[01:54:45.031] cswin_unet.stage_up3.5.norm2.weight                0.100000     0.00005000      [ACTIVE]
[01:54:45.031] cswin_unet.stage_up3.5.norm2.bias                  0.100000     0.00005000      [ACTIVE]
[01:54:45.031] cswin_unet.stage_up3.6.norm1.weight                0.100000     0.00005000      [ACTIVE]
[01:54:45.032] cswin_unet.stage_up3.6.norm1.bias                  0.100000     0.00005000      [ACTIVE]
[01:54:45.032] cswin_unet.stage_up3.6.norm2.weight                0.100000     0.00005000      [ACTIVE]
[01:54:45.032] cswin_unet.stage_up3.6.norm2.bias                  0.100000     0.00005000      [ACTIVE]
[01:54:45.032] cswin_unet.stage_up3.7.norm1.weight                0.100000     0.00005000      [ACTIVE]
[01:54:45.032] cswin_unet.stage_up3.7.norm1.bias                  0.100000     0.00005000      [ACTIVE]
[01:54:45.032] cswin_unet.stage_up3.7.norm2.weight                0.100000     0.00005000      [ACTIVE]
[01:54:45.032] cswin_unet.stage_up3.7.norm2.bias                  0.100000     0.00005000      [ACTIVE]
[01:54:45.032] cswin_unet.stage_up3.8.norm1.weight                0.100000     0.00005000      [ACTIVE]
[01:54:45.032] cswin_unet.stage_up3.8.norm1.bias                  0.100000     0.00005000      [ACTIVE]
[01:54:45.033] cswin_unet.stage_up3.8.norm2.weight                0.100000     0.00005000      [ACTIVE]
[01:54:45.033] cswin_unet.stage_up3.8.norm2.bias                  0.100000     0.00005000      [ACTIVE]
[01:54:45.033] cswin_unet.stage_up2.0.norm1.weight                0.100000     0.00005000      [ACTIVE]
[01:54:45.033] cswin_unet.stage_up2.0.norm1.bias                  0.100000     0.00005000      [ACTIVE]
[01:54:45.033] cswin_unet.stage_up2.0.norm2.weight                0.100000     0.00005000      [ACTIVE]
[01:54:45.033] cswin_unet.stage_up2.0.norm2.bias                  0.100000     0.00005000      [ACTIVE]
[01:54:45.033] cswin_unet.stage_up2.1.norm1.weight                0.100000     0.00005000      [ACTIVE]
[01:54:45.033] cswin_unet.stage_up2.1.norm1.bias                  0.100000     0.00005000      [ACTIVE]
[01:54:45.033] cswin_unet.stage_up2.1.norm2.weight                0.100000     0.00005000      [ACTIVE]
[01:54:45.033] cswin_unet.stage_up2.1.norm2.bias                  0.100000     0.00005000      [ACTIVE]
[01:54:45.033] cswin_unet.stage_up1.0.norm1.weight                0.100000     0.00005000      [ACTIVE]
[01:54:45.033] cswin_unet.stage_up1.0.norm1.bias                  0.100000     0.00005000      [ACTIVE]
[01:54:45.033] cswin_unet.stage_up1.0.norm2.weight                0.100000     0.00005000      [ACTIVE]
[01:54:45.033] cswin_unet.stage_up1.0.norm2.bias                  0.100000     0.00005000      [ACTIVE]
[01:54:45.033] cswin_unet.norm_up.weight                          0.100000     0.00005000      [ACTIVE]
[01:54:45.033] cswin_unet.norm_up.bias                            0.100000     0.00005000      [ACTIVE]
[01:54:45.033] cswin_unet.stage2.0.mlp.fc1.weight                 0.091007     0.00004550      [ACTIVE]
[01:54:45.033] cswin_unet.stage2.0.attns.1.get_v.weight           0.090131     0.00004507      [ACTIVE]
[01:54:45.034] cswin_unet.stage2.0.mlp.fc2.bias                   0.088862     0.00004443      [ACTIVE]
[01:54:45.034] cswin_unet.stage_up2.0.attns.1.get_v.weight        0.084573     0.00004229      [ACTIVE]
[01:54:45.034] cswin_unet.stage_up2.0.attns.0.get_v.weight        0.084474     0.00004224      [ACTIVE]
[01:54:45.034] cswin_unet.stage2.0.attns.0.get_v.weight           0.083050     0.00004153      [ACTIVE]
[01:54:45.034] cswin_unet.stage2.1.qkv.weight                     0.082445     0.00004122      [ACTIVE]
[01:54:45.034] cswin_unet.stage2.1.attns.1.get_v.weight           0.082422     0.00004121      [ACTIVE]
[01:54:45.034] cswin_unet.upsample1.down.bias                     0.081550     0.00004078      [ACTIVE]
[01:54:45.034] cswin_unet.stage2.0.mlp.fc2.weight                 0.078822     0.00003941      [ACTIVE]
[01:54:45.034] cswin_unet.stage2.1.attns.0.get_v.weight           0.077148     0.00003857      [ACTIVE]
[01:54:45.034] cswin_unet.stage2.1.mlp.fc1.weight                 0.074880     0.00003744      [ACTIVE]
[01:54:45.034] cswin_unet.stage_up2.1.proj.bias                   0.069447     0.00003472      [ACTIVE]
[01:54:45.034] cswin_unet.stage1_conv_embed.2.weight              0.068472     0.00003424      [ACTIVE]
[01:54:45.034] cswin_unet.stage_up1.0.attns.1.get_v.weight        0.065665     0.00003283      [ACTIVE]
[01:54:45.034] cswin_unet.upsample3.out.bias                      0.063955     0.00003198      [ACTIVE]
[01:54:45.034] cswin_unet.stage_up2.1.attns.1.get_v.weight        0.062630     0.00003132      [ACTIVE]
[01:54:45.034] cswin_unet.concat_linear4.bias                     0.060812     0.00003041      [ACTIVE]
[01:54:45.034] cswin_unet.stage_up2.0.proj.weight                 0.058845     0.00002942      [ACTIVE]
[01:54:45.034] cswin_unet.stage2.1.mlp.fc2.bias                   0.058584     0.00002929      [ACTIVE]
[01:54:45.034] cswin_unet.stage_up2.1.qkv.weight                  0.057927     0.00002896      [ACTIVE]
[01:54:45.034] cswin_unet.stage1.0.qkv.bias                       0.055775     0.00002789      [ACTIVE]
[01:54:45.034] cswin_unet.upsample3.down.bias                     0.055460     0.00002773      [ACTIVE]
[01:54:45.034] cswin_unet.stage_up2.1.proj.weight                 0.054807     0.00002740      [ACTIVE]
[01:54:45.034] cswin_unet.stage_up2.1.attns.0.get_v.weight        0.054281     0.00002714      [ACTIVE]
[01:54:45.034] cswin_unet.stage_up1.0.attns.0.get_v.weight        0.051599     0.00002580      [ACTIVE]
[01:54:45.035] cswin_unet.upsample1.encoder.bias                  0.049696     0.00002485      [LOW_LR]
[01:54:45.035] cswin_unet.stage2.0.qkv.weight                     0.047426     0.00002371      [LOW_LR]
[01:54:45.035] cswin_unet.stage_up2.0.qkv.weight                  0.044259     0.00002213      [LOW_LR]
[01:54:45.035] cswin_unet.stage_up2.0.mlp.fc1.weight              0.044036     0.00002202      [LOW_LR]
[01:54:45.035] cswin_unet.stage2.1.mlp.fc2.weight                 0.043066     0.00002153      [LOW_LR]
[01:54:45.035] cswin_unet.stage_up2.0.mlp.fc2.weight              0.042611     0.00002131      [LOW_LR]
[01:54:45.035] cswin_unet.upsample3.encoder.bias                  0.039686     0.00001984      [LOW_LR]
[01:54:45.035] cswin_unet.upsample1.encoder.weight                0.034472     0.00001724      [LOW_LR]
[01:54:45.035] cswin_unet.stage_up2.1.mlp.fc2.bias                0.033357     0.00001668      [LOW_LR]
[01:54:45.035] cswin_unet.stage_up3.8.attns.1.get_v.bias          0.032005     0.00001600      [LOW_LR]
[01:54:45.035] cswin_unet.stage_up2.1.mlp.fc1.weight              0.031956     0.00001598      [LOW_LR]
[01:54:45.035] cswin_unet.stage_up2.0.mlp.fc2.bias                0.030825     0.00001541      [LOW_LR]
[01:54:45.035] cswin_unet.stage_up1.0.qkv.bias                    0.030695     0.00001535      [LOW_LR]
[01:54:45.035] cswin_unet.stage2.1.qkv.bias                       0.028478     0.00001424      [LOW_LR]
[01:54:45.035] cswin_unet.stage_up3.8.attns.0.get_v.bias          0.027044     0.00001352      [LOW_LR]
[01:54:45.036] cswin_unet.stage_up2.1.mlp.fc2.weight              0.025704     0.00001285      [LOW_LR]
[01:54:45.036] cswin_unet.stage3.1.attns.1.get_v.weight           0.025305     0.00001265      [LOW_LR]
[01:54:45.036] cswin_unet.stage1.0.mlp.fc1.bias                   0.023203     0.00001160      [LOW_LR]
[01:54:45.036] cswin_unet.stage2.0.qkv.bias                       0.023034     0.00001152      [LOW_LR]
[01:54:45.036] cswin_unet.merge2.conv.weight                      0.022304     0.00001115      [LOW_LR]
[01:54:45.036] cswin_unet.stage3.0.attns.0.get_v.weight           0.022169     0.00001108      [LOW_LR]
[01:54:45.036] cswin_unet.stage3.3.attns.1.get_v.weight           0.021392     0.00001070      [LOW_LR]
[01:54:45.036] cswin_unet.stage3.6.attns.1.get_v.weight           0.021252     0.00001063      [LOW_LR]
[01:54:45.036] cswin_unet.stage3.0.attns.1.get_v.weight           0.021129     0.00001056      [LOW_LR]
[01:54:45.036] cswin_unet.stage3.2.attns.0.get_v.weight           0.020754     0.00001038      [LOW_LR]
[01:54:45.036] cswin_unet.stage_up4.0.attns.0.get_v.bias          0.020692     0.00001035      [LOW_LR]
[01:54:45.036] cswin_unet.upsample4.out.bias                      0.020387     0.00001019      [LOW_LR]
[01:54:45.036] cswin_unet.stage3.2.attns.1.get_v.weight           0.019654     0.00000983      [LOW_LR]
[01:54:45.036] cswin_unet.upsample4.out.weight                    0.019583     0.00000979      [LOW_LR]
[01:54:45.036] cswin_unet.stage_up3.7.attns.0.get_v.bias          0.019281     0.00000964      [LOW_LR]
[01:54:45.036] cswin_unet.stage3.1.attns.0.get_v.weight           0.019178     0.00000959      [LOW_LR]
[01:54:45.037] cswin_unet.stage3.8.attns.0.get_v.bias             0.019073     0.00000954      [LOW_LR]
[01:54:45.037] cswin_unet.stage3.8.attns.0.get_v.weight           0.017496     0.00000875      [LOW_LR]
[01:54:45.037] cswin_unet.stage3.4.attns.0.get_v.weight           0.017099     0.00000855      [LOW_LR]
[01:54:45.037] cswin_unet.stage3.3.attns.0.get_v.weight           0.017004     0.00000850      [LOW_LR]
[01:54:45.037] cswin_unet.stage3.4.attns.1.get_v.weight           0.016661     0.00000833      [LOW_LR]
[01:54:45.037] cswin_unet.stage3.7.attns.0.get_v.weight           0.016149     0.00000807      [LOW_LR]
[01:54:45.037] cswin_unet.stage3.8.attns.1.get_v.bias             0.015701     0.00000785      [LOW_LR]
[01:54:45.037] cswin_unet.stage3.7.attns.1.get_v.weight           0.015654     0.00000783      [LOW_LR]
[01:54:45.037] cswin_unet.stage3.8.attns.1.get_v.weight           0.015577     0.00000779      [LOW_LR]
[01:54:45.037] cswin_unet.stage_up3.1.attns.0.get_v.weight        0.015053     0.00000753      [LOW_LR]
[01:54:45.037] cswin_unet.stage2.0.mlp.fc1.bias                   0.015032     0.00000752      [LOW_LR]
[01:54:45.037] cswin_unet.stage_up2.0.qkv.bias                    0.014909     0.00000745      [LOW_LR]
[01:54:45.037] cswin_unet.stage_up3.4.attns.1.get_v.weight        0.014860     0.00000743      [LOW_LR]
[01:54:45.037] cswin_unet.stage3.5.attns.0.get_v.weight           0.014753     0.00000738      [LOW_LR]
[01:54:45.037] cswin_unet.stage3.5.attns.1.get_v.weight           0.014459     0.00000723      [LOW_LR]
[01:54:45.038] cswin_unet.stage_up2.1.qkv.bias                    0.014356     0.00000718      [LOW_LR]
[01:54:45.038] cswin_unet.stage3.3.proj.weight                    0.014056     0.00000703      [LOW_LR]
[01:54:45.038] cswin_unet.stage_up3.8.mlp.fc2.bias                0.013986     0.00000699      [LOW_LR]
[01:54:45.038] cswin_unet.stage3.0.attns.1.get_v.bias             0.013986     0.00000699      [LOW_LR]
[01:54:45.038] cswin_unet.stage3.7.attns.0.get_v.bias             0.013925     0.00000696      [LOW_LR]
[01:54:45.038] cswin_unet.stage_up3.3.attns.1.get_v.weight        0.013918     0.00000696      [LOW_LR]
[01:54:45.038] cswin_unet.stage3.0.attns.0.get_v.bias             0.013910     0.00000696      [LOW_LR]
[01:54:45.038] cswin_unet.stage_up3.5.attns.0.get_v.bias          0.013809     0.00000690      [LOW_LR]
[01:54:45.038] cswin_unet.stage3.6.attns.1.get_v.bias             0.013728     0.00000686      [LOW_LR]
[01:54:45.038] cswin_unet.stage_up3.1.attns.1.get_v.weight        0.013632     0.00000682      [LOW_LR]
[01:54:45.038] cswin_unet.stage3.1.attns.0.get_v.bias             0.013457     0.00000673      [LOW_LR]
[01:54:45.038] cswin_unet.stage_up3.8.proj.bias                   0.013414     0.00000671      [LOW_LR]
[01:54:45.038] cswin_unet.stage_up3.6.attns.0.get_v.bias          0.013398     0.00000670      [LOW_LR]
[01:54:45.038] cswin_unet.stage_up3.4.attns.0.get_v.weight        0.013328     0.00000666      [LOW_LR]
[01:54:45.038] cswin_unet.stage_up3.5.attns.1.get_v.weight        0.012965     0.00000648      [LOW_LR]
[01:54:45.038] cswin_unet.merge1.conv.bias                        0.012962     0.00000648      [LOW_LR]
[01:54:45.038] cswin_unet.stage3.0.proj.weight                    0.012730     0.00000637      [LOW_LR]
[01:54:45.039] cswin_unet.stage_up3.2.attns.0.get_v.weight        0.012729     0.00000636      [LOW_LR]
[01:54:45.039] cswin_unet.stage_up3.6.attns.1.get_v.bias          0.012638     0.00000632      [LOW_LR]
[01:54:45.039] cswin_unet.stage_up3.7.proj.bias                   0.012522     0.00000626      [LOW_LR]
[01:54:45.039] cswin_unet.stage_up3.6.attns.1.get_v.weight        0.012325     0.00000616      [LOW_LR]
[01:54:45.039] cswin_unet.stage_up1.0.mlp.fc1.bias                0.012324     0.00000616      [LOW_LR]
[01:54:45.039] cswin_unet.stage3.5.attns.0.get_v.bias             0.011993     0.00000600      [LOW_LR]
[01:54:45.039] cswin_unet.stage3.6.attns.0.get_v.weight           0.011814     0.00000591      [LOW_LR]
[01:54:45.039] cswin_unet.stage3.1.proj.weight                    0.011704     0.00000585      [LOW_LR]
[01:54:45.039] cswin_unet.stage_up3.6.proj.bias                   0.011661     0.00000583      [LOW_LR]
[01:54:45.039] cswin_unet.stage_up3.2.attns.1.get_v.weight        0.011592     0.00000580      [LOW_LR]
[01:54:45.039] cswin_unet.stage_up3.8.attns.1.get_v.weight        0.011379     0.00000569      [LOW_LR]
[01:54:45.039] cswin_unet.stage_up3.8.attns.0.get_v.weight        0.011301     0.00000565      [LOW_LR]
[01:54:45.039] cswin_unet.stage3.8.proj.weight                    0.011187     0.00000559      [LOW_LR]
[01:54:45.039] cswin_unet.stage3.7.proj.weight                    0.011051     0.00000553      [LOW_LR]
[01:54:45.039] cswin_unet.stage_up3.3.attns.0.get_v.weight        0.011043     0.00000552      [LOW_LR]
[01:54:45.039] cswin_unet.stage_up3.7.mlp.fc2.bias                0.010911     0.00000546      [LOW_LR]
[01:54:45.039] cswin_unet.stage_up3.4.proj.bias                   0.010889     0.00000544      [LOW_LR]
[01:54:45.040] cswin_unet.stage3.4.proj.weight                    0.010715     0.00000536      [LOW_LR]
[01:54:45.040] cswin_unet.stage3.2.proj.weight                    0.010705     0.00000535      [LOW_LR]
[01:54:45.040] cswin_unet.stage_up3.0.attns.0.get_v.weight        0.010591     0.00000530      [LOW_LR]
[01:54:45.040] cswin_unet.stage_up3.7.attns.0.get_v.weight        0.010548     0.00000527      [LOW_LR]
[01:54:45.040] cswin_unet.stage3.1.attns.1.get_v.bias             0.010453     0.00000523      [LOW_LR]
[01:54:45.040] cswin_unet.stage_up3.1.attns.0.get_v.bias          0.010284     0.00000514      [LOW_LR]
[01:54:45.040] cswin_unet.stage2.1.mlp.fc1.bias                   0.010257     0.00000513      [LOW_LR]
[01:54:45.040] cswin_unet.stage3.6.proj.weight                    0.010170     0.00000508      [LOW_LR]
[01:54:45.040] cswin_unet.stage_up3.5.proj.bias                   0.010167     0.00000508      [LOW_LR]
[01:54:45.040] cswin_unet.stage_up3.5.mlp.fc2.bias                0.010048     0.00000502      [LOW_LR]
[01:54:45.040] cswin_unet.stage3.3.qkv.weight                     0.009984     0.00000499      [LOW_LR]
[01:54:45.040] cswin_unet.stage3.7.attns.1.get_v.bias             0.009955     0.00000498      [LOW_LR]
[01:54:45.040] cswin_unet.stage_up3.5.attns.0.get_v.weight        0.009882     0.00000494      [LOW_LR]
[01:54:45.040] cswin_unet.stage3.8.qkv.weight                     0.009872     0.00000494      [LOW_LR]
[01:54:45.040] cswin_unet.stage_up3.6.mlp.fc2.bias                0.009811     0.00000491      [LOW_LR]
[01:54:45.040] cswin_unet.stage3.2.attns.0.get_v.bias             0.009700     0.00000485      [LOW_LR]
[01:54:45.040] cswin_unet.stage_up3.0.attns.1.get_v.weight        0.009692     0.00000485      [LOW_LR]
[01:54:45.041] cswin_unet.stage3.7.proj.bias                      0.009685     0.00000484      [LOW_LR]
[01:54:45.041] cswin_unet.stage_up3.6.attns.0.get_v.weight        0.009661     0.00000483      [LOW_LR]
[01:54:45.041] cswin_unet.stage3.5.proj.weight                    0.009586     0.00000479      [LOW_LR]
[01:54:45.041] cswin_unet.stage3.1.proj.bias                      0.009505     0.00000475      [LOW_LR]
[01:54:45.041] cswin_unet.stage_up3.8.proj.weight                 0.009432     0.00000472      [LOW_LR]
[01:54:45.041] cswin_unet.stage_up3.4.mlp.fc2.bias                0.009312     0.00000466      [LOW_LR]
[01:54:45.041] cswin_unet.stage3.2.proj.bias                      0.009292     0.00000465      [LOW_LR]
[01:54:45.041] cswin_unet.stage_up3.3.proj.weight                 0.009243     0.00000462      [LOW_LR]
[01:54:45.041] cswin_unet.stage3.6.proj.bias                      0.009208     0.00000460      [LOW_LR]
[01:54:45.041] cswin_unet.stage3.4.qkv.weight                     0.009181     0.00000459      [LOW_LR]
[01:54:45.041] cswin_unet.stage_up3.3.attns.1.get_v.bias          0.009055     0.00000453      [LOW_LR]
[01:54:45.041] cswin_unet.stage3.8.proj.bias                      0.008988     0.00000449      [LOW_LR]
[01:54:45.041] cswin_unet.stage_up3.7.attns.1.get_v.bias          0.008949     0.00000447      [LOW_LR]
[01:54:45.041] cswin_unet.stage_up3.4.proj.weight                 0.008925     0.00000446      [LOW_LR]
[01:54:45.041] cswin_unet.stage_up3.2.proj.bias                   0.008905     0.00000445      [LOW_LR]
[01:54:45.041] cswin_unet.stage3.6.attns.0.get_v.bias             0.008897     0.00000445      [LOW_LR]
[01:54:45.041] cswin_unet.stage_up3.6.proj.weight                 0.008894     0.00000445      [LOW_LR]
[01:54:45.041] cswin_unet.stage3.3.attns.1.get_v.bias             0.008890     0.00000445      [LOW_LR]
[01:54:45.041] cswin_unet.stage3.4.proj.bias                      0.008802     0.00000440      [LOW_LR]
[01:54:45.041] cswin_unet.stage_up3.3.proj.bias                   0.008773     0.00000439      [LOW_LR]
[01:54:45.041] cswin_unet.stage3.8.mlp.fc2.bias                   0.008678     0.00000434      [LOW_LR]
[01:54:45.041] cswin_unet.stage_up3.1.proj.weight                 0.008676     0.00000434      [LOW_LR]
[01:54:45.041] cswin_unet.stage_up3.2.mlp.fc2.bias                0.008527     0.00000426      [LOW_LR]
[01:54:45.041] cswin_unet.stage3.2.mlp.fc2.bias                   0.008505     0.00000425      [LOW_LR]
[01:54:45.041] cswin_unet.stage_up3.8.qkv.weight                  0.008505     0.00000425      [LOW_LR]
[01:54:45.041] cswin_unet.stage_up3.5.proj.weight                 0.008498     0.00000425      [LOW_LR]
[01:54:45.041] cswin_unet.stage_up3.7.attns.1.get_v.weight        0.008490     0.00000425      [LOW_LR]
[01:54:45.041] cswin_unet.stage3.0.proj.bias                      0.008479     0.00000424      [LOW_LR]
[01:54:45.041] cswin_unet.stage3.3.proj.bias                      0.008375     0.00000419      [LOW_LR]
[01:54:45.041] cswin_unet.stage_up3.4.attns.0.get_v.bias          0.008336     0.00000417      [LOW_LR]
[01:54:45.041] cswin_unet.stage_up3.7.proj.weight                 0.008270     0.00000414      [LOW_LR]
[01:54:45.041] cswin_unet.stage_up3.5.attns.1.get_v.bias          0.008176     0.00000409      [LOW_LR]
[01:54:45.041] cswin_unet.stage_up3.1.proj.bias                   0.008171     0.00000409      [LOW_LR]
[01:54:45.041] cswin_unet.stage_up3.3.mlp.fc2.bias                0.008147     0.00000407      [LOW_LR]
[01:54:45.041] cswin_unet.stage3.5.proj.bias                      0.008013     0.00000401      [LOW_LR]
[01:54:45.041] cswin_unet.stage_up3.0.attns.0.get_v.bias          0.007978     0.00000399      [LOW_LR]
[01:54:45.042] cswin_unet.stage_up3.4.attns.1.get_v.bias          0.007936     0.00000397      [LOW_LR]
[01:54:45.042] cswin_unet.stage3.7.mlp.fc2.bias                   0.007865     0.00000393      [LOW_LR]
[01:54:45.042] cswin_unet.stage3.4.attns.1.get_v.bias             0.007669     0.00000383      [LOW_LR]
[01:54:45.042] cswin_unet.stage3.3.attns.0.get_v.bias             0.007588     0.00000379      [LOW_LR]
[01:54:45.042] cswin_unet.stage3.5.mlp.fc2.bias                   0.007572     0.00000379      [LOW_LR]
[01:54:45.042] cswin_unet.stage3.4.attns.0.get_v.bias             0.007534     0.00000377      [LOW_LR]
[01:54:45.042] cswin_unet.stage3.0.qkv.weight                     0.007470     0.00000374      [LOW_LR]
[01:54:45.042] cswin_unet.stage3.6.qkv.weight                     0.007461     0.00000373      [LOW_LR]
[01:54:45.042] cswin_unet.stage_up3.3.attns.0.get_v.bias          0.007459     0.00000373      [LOW_LR]
[01:54:45.042] cswin_unet.stage3.5.qkv.weight                     0.007399     0.00000370      [LOW_LR]
[01:54:45.042] cswin_unet.stage_up3.2.proj.weight                 0.007312     0.00000366      [LOW_LR]
[01:54:45.042] cswin_unet.stage3.6.mlp.fc2.bias                   0.007292     0.00000365      [LOW_LR]
[01:54:45.042] cswin_unet.stage3.2.attns.1.get_v.bias             0.007267     0.00000363      [LOW_LR]
[01:54:45.042] cswin_unet.stage3.3.mlp.fc2.bias                   0.007223     0.00000361      [LOW_LR]
[01:54:45.042] cswin_unet.stage3.4.mlp.fc2.bias                   0.007181     0.00000359      [LOW_LR]
[01:54:45.042] cswin_unet.stage3.1.qkv.weight                     0.006992     0.00000350      [LOW_LR]
[01:54:45.042] cswin_unet.stage3.2.qkv.weight                     0.006816     0.00000341      [LOW_LR]
[01:54:45.043] cswin_unet.stage_up3.2.attns.0.get_v.bias          0.006622     0.00000331      [LOW_LR]
[01:54:45.043] cswin_unet.stage3.0.mlp.fc2.weight                 0.006529     0.00000326      [LOW_LR]
[01:54:45.043] cswin_unet.stage3.7.qkv.weight                     0.006418     0.00000321      [LOW_LR]
[01:54:45.043] cswin_unet.stage3.1.mlp.fc2.bias                   0.006289     0.00000314      [LOW_LR]
[01:54:45.043] cswin_unet.stage_up3.1.attns.1.get_v.bias          0.006086     0.00000304      [LOW_LR]
[01:54:45.043] cswin_unet.stage3.5.attns.1.get_v.bias             0.006080     0.00000304      [LOW_LR]
[01:54:45.043] cswin_unet.stage_up2.0.mlp.fc1.bias                0.005986     0.00000299      [LOW_LR]
[01:54:45.043] cswin_unet.stage_up3.1.mlp.fc2.bias                0.005951     0.00000298      [LOW_LR]
[01:54:45.043] cswin_unet.stage_up3.6.qkv.weight                  0.005948     0.00000297      [LOW_LR]
[01:54:45.043] cswin_unet.stage_up3.2.attns.1.get_v.bias          0.005864     0.00000293      [LOW_LR]
[01:54:45.043] cswin_unet.stage_up3.0.proj.weight                 0.005706     0.00000285      [LOW_LR]
[01:54:45.043] cswin_unet.stage_up3.5.qkv.weight                  0.005676     0.00000284      [LOW_LR]
[01:54:45.043] cswin_unet.stage_up3.3.qkv.weight                  0.005651     0.00000283      [LOW_LR]
[01:54:45.043] cswin_unet.stage_up3.7.qkv.weight                  0.005624     0.00000281      [LOW_LR]
[01:54:45.043] cswin_unet.stage_up3.0.attns.1.get_v.bias          0.005610     0.00000281      [LOW_LR]
[01:54:45.043] cswin_unet.stage_up3.4.qkv.weight                  0.005558     0.00000278      [LOW_LR]
[01:54:45.043] cswin_unet.stage3.0.mlp.fc1.weight                 0.005472     0.00000274      [LOW_LR]
[01:54:45.043] cswin_unet.stage_up3.0.proj.bias                   0.005354     0.00000268      [LOW_LR]
[01:54:45.043] cswin_unet.stage1_conv_embed.0.bias                0.005088     0.00000254      [LOW_LR]
[01:54:45.043] cswin_unet.stage3.0.mlp.fc2.bias                   0.004594     0.00000230      [LOW_LR]
[01:54:45.044] cswin_unet.stage_up3.8.mlp.fc1.weight              0.004502     0.00000225      [LOW_LR]
[01:54:45.044] cswin_unet.stage_up3.1.qkv.weight                  0.004466     0.00000223      [LOW_LR]
[01:54:45.044] cswin_unet.stage_up2.1.mlp.fc1.bias                0.004106     0.00000205      [LOW_LR]
[01:54:45.044] cswin_unet.stage3.1.mlp.fc2.weight                 0.004025     0.00000201      [LOW_LR]
[01:54:45.044] cswin_unet.stage4.0.attns.0.get_v.bias             0.003954     0.00000198      [LOW_LR]
[01:54:45.044] cswin_unet.stage_up3.0.mlp.fc2.weight              0.003953     0.00000198      [LOW_LR]
[01:54:45.044] cswin_unet.stage_up3.8.mlp.fc2.weight              0.003917     0.00000196      [LOW_LR]
[01:54:45.044] cswin_unet.stage_up3.8.qkv.bias                    0.003878     0.00000194      [LOW_LR]
[01:54:45.044] cswin_unet.stage_up3.0.mlp.fc2.bias                0.003798     0.00000190      [LOW_LR]
[01:54:45.044] cswin_unet.stage3.3.mlp.fc2.weight                 0.003751     0.00000188      [LOW_LR]
[01:54:45.044] cswin_unet.stage_up3.6.mlp.fc1.weight              0.003736     0.00000187      [LOW_LR]
[01:54:45.044] cswin_unet.stage3.1.mlp.fc1.weight                 0.003654     0.00000183      [LOW_LR]
[01:54:45.044] cswin_unet.stage_up3.6.mlp.fc2.weight              0.003629     0.00000181      [LOW_LR]
[01:54:45.044] cswin_unet.stage3.6.mlp.fc1.weight                 0.003591     0.00000180      [LOW_LR]
[01:54:45.044] cswin_unet.stage3.2.mlp.fc2.weight                 0.003582     0.00000179      [LOW_LR]
[01:54:45.044] cswin_unet.stage_up3.2.qkv.weight                  0.003451     0.00000173      [LOW_LR]
[01:54:45.044] cswin_unet.stage3.6.mlp.fc2.weight                 0.003408     0.00000170      [LOW_LR]
[01:54:45.044] cswin_unet.stage_up3.7.mlp.fc2.weight              0.003408     0.00000170      [LOW_LR]
[01:54:45.044] cswin_unet.stage_up3.7.mlp.fc1.weight              0.003392     0.00000170      [LOW_LR]
[01:54:45.044] cswin_unet.stage3.7.mlp.fc1.weight                 0.003368     0.00000168      [LOW_LR]
[01:54:45.044] cswin_unet.stage3.4.mlp.fc1.weight                 0.003344     0.00000167      [LOW_LR]
[01:54:45.044] cswin_unet.stage3.3.mlp.fc1.weight                 0.003321     0.00000166      [LOW_LR]
[01:54:45.044] cswin_unet.stage3.4.mlp.fc2.weight                 0.003295     0.00000165      [LOW_LR]
[01:54:45.044] cswin_unet.stage3.7.mlp.fc2.weight                 0.003278     0.00000164      [LOW_LR]
[01:54:45.044] cswin_unet.stage3.2.mlp.fc1.weight                 0.003166     0.00000158      [LOW_LR]
[01:54:45.045] cswin_unet.stage_up3.1.mlp.fc2.weight              0.003151     0.00000158      [LOW_LR]
[01:54:45.045] cswin_unet.stage3.8.mlp.fc1.weight                 0.003131     0.00000157      [LOW_LR]
[01:54:45.045] cswin_unet.stage_up3.2.mlp.fc2.weight              0.003049     0.00000152      [LOW_LR]
[01:54:45.045] cswin_unet.stage3.5.mlp.fc2.weight                 0.003024     0.00000151      [LOW_LR]
[01:54:45.045] cswin_unet.stage_up3.4.mlp.fc2.weight              0.003008     0.00000150      [LOW_LR]
[01:54:45.045] cswin_unet.stage3.5.mlp.fc1.weight                 0.002885     0.00000144      [LOW_LR]
[01:54:45.045] cswin_unet.stage_up3.3.mlp.fc2.weight              0.002828     0.00000141      [LOW_LR]
[01:54:45.045] cswin_unet.stage3.8.qkv.bias                       0.002716     0.00000136      [LOW_LR]
[01:54:45.045] cswin_unet.stage3.8.mlp.fc2.weight                 0.002714     0.00000136      [LOW_LR]
[01:54:45.045] cswin_unet.stage_up3.5.mlp.fc2.weight              0.002631     0.00000132      [LOW_LR]
[01:54:45.045] cswin_unet.stage3.0.qkv.bias                       0.002628     0.00000131      [LOW_LR]
[01:54:45.045] cswin_unet.stage_up3.4.mlp.fc1.weight              0.002612     0.00000131      [LOW_LR]
[01:54:45.045] cswin_unet.stage_up3.0.qkv.weight                  0.002555     0.00000128      [LOW_LR]
[01:54:45.045] cswin_unet.stage_up4.0.attns.0.get_v.weight        0.002352     0.00000118      [LOW_LR]
[01:54:45.045] cswin_unet.stage_up3.5.mlp.fc1.weight              0.002340     0.00000117      [LOW_LR]
[01:54:45.045] cswin_unet.stage_up3.0.mlp.fc1.weight              0.002336     0.00000117      [LOW_LR]
[01:54:45.045] cswin_unet.stage3.1.qkv.bias                       0.002292     0.00000115      [LOW_LR]
[01:54:45.045] cswin_unet.stage_up3.6.qkv.bias                    0.002167     0.00000108      [LOW_LR]
[01:54:45.045] cswin_unet.stage_up3.7.qkv.bias                    0.001996     0.00000100      [LOW_LR]
[01:54:45.045] cswin_unet.stage_up3.1.mlp.fc1.weight              0.001965     0.00000098      [LOW_LR]
[01:54:45.046] cswin_unet.stage3.2.qkv.bias                       0.001964     0.00000098      [LOW_LR]
[01:54:45.046] cswin_unet.stage3.3.qkv.bias                       0.001961     0.00000098      [LOW_LR]
[01:54:45.046] cswin_unet.stage_up3.2.mlp.fc1.weight              0.001943     0.00000097      [LOW_LR]
[01:54:45.046] cswin_unet.stage3.7.qkv.bias                       0.001909     0.00000095      [LOW_LR]
[01:54:45.046] cswin_unet.stage_up3.3.mlp.fc1.weight              0.001864     0.00000093      [LOW_LR]
[01:54:45.046] cswin_unet.stage3.6.qkv.bias                       0.001847     0.00000092      [LOW_LR]
[01:54:45.046] cswin_unet.stage4.0.attns.0.get_v.weight           0.001831     0.00000092      [LOW_LR]
[01:54:45.046] cswin_unet.stage3.4.qkv.bias                       0.001733     0.00000087      [LOW_LR]
[01:54:45.046] cswin_unet.stage_up3.5.qkv.bias                    0.001719     0.00000086      [LOW_LR]
[01:54:45.046] cswin_unet.stage3.5.qkv.bias                       0.001666     0.00000083      [LOW_LR]
[01:54:45.046] cswin_unet.stage_up3.1.qkv.bias                    0.001623     0.00000081      [LOW_LR]
[01:54:45.046] cswin_unet.stage_up3.4.qkv.bias                    0.001600     0.00000080      [LOW_LR]
[01:54:45.046] cswin_unet.stage_up3.3.qkv.bias                    0.001557     0.00000078      [LOW_LR]
[01:54:45.046] cswin_unet.stage_up3.2.qkv.bias                    0.001365     0.00000068      [LOW_LR]
[01:54:45.046] cswin_unet.stage_up3.0.qkv.bias                    0.001332     0.00000067      [LOW_LR]
[01:54:45.046] cswin_unet.stage_up4.0.proj.bias                   0.001306     0.00000065      [LOW_LR]
[01:54:45.046] cswin_unet.merge2.conv.bias                        0.001133     0.00000057      [LOW_LR]
[01:54:45.046] cswin_unet.stage3.0.mlp.fc1.bias                   0.000943     0.00000047      [LOW_LR]
[01:54:45.046] cswin_unet.stage_up4.0.proj.weight                 0.000879     0.00000044      [LOW_LR]
[01:54:45.046] cswin_unet.stage4.0.proj.weight                    0.000744     0.00000037      [LOW_LR]
[01:54:45.046] cswin_unet.stage_up4.0.mlp.fc2.weight              0.000681     0.00000034      [LOW_LR]
[01:54:45.046] cswin_unet.stage_up3.8.mlp.fc1.bias                0.000660     0.00000033      [LOW_LR]
[01:54:45.047] cswin_unet.stage_up4.0.mlp.fc1.weight              0.000634     0.00000032      [LOW_LR]
[01:54:45.047] cswin_unet.stage_up4.0.mlp.fc2.bias                0.000633     0.00000032      [LOW_LR]
[01:54:45.047] cswin_unet.stage_up3.6.mlp.fc1.bias                0.000527     0.00000026      [LOW_LR]
[01:54:45.047] cswin_unet.stage_up3.7.mlp.fc1.bias                0.000477     0.00000024      [LOW_LR]
[01:54:45.047] cswin_unet.stage3.1.mlp.fc1.bias                   0.000446     0.00000022      [LOW_LR]
[01:54:45.047] cswin_unet.stage3.6.mlp.fc1.bias                   0.000430     0.00000021      [LOW_LR]
[01:54:45.047] cswin_unet.stage3.7.mlp.fc1.bias                   0.000421     0.00000021      [LOW_LR]
[01:54:45.047] cswin_unet.stage3.3.mlp.fc1.bias                   0.000408     0.00000020      [LOW_LR]
[01:54:45.047] cswin_unet.stage3.8.mlp.fc1.bias                   0.000406     0.00000020      [LOW_LR]
[01:54:45.047] cswin_unet.stage4.0.mlp.fc2.weight                 0.000395     0.00000020      [LOW_LR]
[01:54:45.047] cswin_unet.stage3.4.mlp.fc1.bias                   0.000388     0.00000019      [LOW_LR]
[01:54:45.047] cswin_unet.stage4.0.mlp.fc1.weight                 0.000369     0.00000018      [LOW_LR]
[01:54:45.047] cswin_unet.stage3.2.mlp.fc1.bias                   0.000364     0.00000018      [LOW_LR]
[01:54:45.047] cswin_unet.stage3.5.mlp.fc1.bias                   0.000363     0.00000018      [LOW_LR]
[01:54:45.048] cswin_unet.stage_up4.0.qkv.weight                  0.000348     0.00000017      [LOW_LR]
[01:54:45.048] cswin_unet.stage_up3.4.mlp.fc1.bias                0.000346     0.00000017      [LOW_LR]
[01:54:45.048] cswin_unet.stage_up3.0.mlp.fc1.bias                0.000340     0.00000017      [LOW_LR]
[01:54:45.048] cswin_unet.merge3.conv.weight                      0.000317     0.00000016      [LOW_LR]
[01:54:45.048] cswin_unet.stage_up3.5.mlp.fc1.bias                0.000310     0.00000015      [LOW_LR]
[01:54:45.048] cswin_unet.stage_up4.0.qkv.bias                    0.000302     0.00000015      [LOW_LR]
[01:54:45.048] cswin_unet.stage_up3.3.mlp.fc1.bias                0.000235     0.00000012      [LOW_LR]
[01:54:45.048] cswin_unet.stage4.0.proj.bias                      0.000229     0.00000011      [LOW_LR]
[01:54:45.048] cswin_unet.stage_up3.1.mlp.fc1.bias                0.000227     0.00000011      [LOW_LR]
[01:54:45.048] cswin_unet.stage_up3.2.mlp.fc1.bias                0.000226     0.00000011      [LOW_LR]
[01:54:45.048] cswin_unet.stage4.0.qkv.weight                     0.000216     0.00000011      [LOW_LR]
[01:54:45.048] cswin_unet.stage4.0.mlp.fc2.bias                   0.000109     0.00000005      [LOW_LR]
[01:54:45.048] cswin_unet.stage4.0.qkv.bias                       0.000082     0.00000004      [LOW_LR]
[01:54:45.048] cswin_unet.stage_up4.0.mlp.fc1.bias                0.000079     0.00000004      [LOW_LR]
[01:54:45.048] cswin_unet.upsample4.encoder.weight                0.000068     0.00000003      [LOW_LR]
[01:54:45.048] cswin_unet.stage4.0.mlp.fc1.bias                   0.000049     0.00000002      [LOW_LR]
[01:54:45.048] cswin_unet.upsample4.encoder.bias                  0.000020     0.00000001      [LOW_LR]
[01:54:45.048] cswin_unet.upsample4.down.weight                   0.000014     0.00000001      [LOW_LR]
[01:54:45.048] cswin_unet.upsample4.down.bias                     0.000013     0.00000001      [LOW_LR]
[01:54:45.048] cswin_unet.merge3.conv.bias                        0.000005     0.00000000      [LOW_LR]
[01:54:45.048] --------------------------------------------------------------------------------
[01:54:45.048] Total layers: 463, High LR layers: 192, Low LR layers: 271
[01:54:45.049] ================================================================================

[01:54:59.669] Epoch 20, Iter 8670: loss=0.0225, ce=0.0072, dice=0.0327, grad_norm=0.165549
[01:55:03.235] Epoch 20, Iter 8680: loss=0.0273, ce=0.0030, dice=0.0435, grad_norm=0.085722
[01:55:06.842] Epoch 20, Iter 8690: loss=0.0296, ce=0.0038, dice=0.0468, grad_norm=0.343444
[01:55:10.445] Epoch 20, Iter 8700: loss=0.0408, ce=0.0042, dice=0.0653, grad_norm=0.198569
[01:55:14.048] Epoch 20, Iter 8710: loss=0.2064, ce=0.0023, dice=0.3426, grad_norm=0.014339
[01:55:17.636] Epoch 20, Iter 8720: loss=0.0430, ce=0.0045, dice=0.0686, grad_norm=0.184721
[01:55:21.248] Epoch 20, Iter 8730: loss=0.2047, ce=0.0023, dice=0.3396, grad_norm=0.015905
[01:55:24.828] Epoch 20, Iter 8740: loss=0.0281, ce=0.0084, dice=0.0412, grad_norm=0.100766
[01:55:28.410] Epoch 20, Iter 8750: loss=0.0387, ce=0.0027, dice=0.0627, grad_norm=0.186627
[01:55:32.045] Epoch 20, Iter 8760: loss=0.0563, ce=0.0039, dice=0.0912, grad_norm=0.438195
[01:55:35.629] Epoch 20, Iter 8770: loss=0.0467, ce=0.0038, dice=0.0753, grad_norm=0.384229
[01:55:39.223] Epoch 20, Iter 8780: loss=0.0267, ce=0.0073, dice=0.0396, grad_norm=0.172750
[01:55:42.831] Epoch 20, Iter 8790: loss=0.0267, ce=0.0073, dice=0.0396, grad_norm=0.059511
[01:55:46.421] Epoch 20, Iter 8800: loss=0.0221, ce=0.0062, dice=0.0326, grad_norm=0.072007
[01:55:50.012] Epoch 20, Iter 8810: loss=0.0338, ce=0.0020, dice=0.0550, grad_norm=0.109117
[01:55:53.605] Epoch 20, Iter 8820: loss=0.0220, ce=0.0044, dice=0.0338, grad_norm=0.079855
[01:55:57.218] Epoch 20, Iter 8830: loss=0.2095, ce=0.0054, dice=0.3456, grad_norm=0.032670
[01:56:00.804] Epoch 20, Iter 8840: loss=0.0211, ce=0.0025, dice=0.0335, grad_norm=0.083797
[01:56:04.394] Epoch 20, Iter 8850: loss=0.0320, ce=0.0052, dice=0.0499, grad_norm=0.104023
[01:56:07.960] Epoch 20, Iter 8860: loss=0.0423, ce=0.0048, dice=0.0672, grad_norm=0.060770
[01:56:11.575] Epoch 20, Iter 8870: loss=0.0185, ce=0.0061, dice=0.0268, grad_norm=0.066271
[01:56:15.151] Epoch 20, Iter 8880: loss=0.0221, ce=0.0022, dice=0.0353, grad_norm=0.118657
[01:56:18.746] Epoch 20, Iter 8890: loss=0.0663, ce=0.0043, dice=0.1076, grad_norm=0.282012
[01:56:22.350] Epoch 20, Iter 8900: loss=0.0164, ce=0.0061, dice=0.0233, grad_norm=0.044226
[01:56:25.941] Epoch 20, Iter 8910: loss=0.0250, ce=0.0034, dice=0.0394, grad_norm=0.110993
[01:56:29.522] Epoch 20, Iter 8920: loss=0.0155, ce=0.0024, dice=0.0241, grad_norm=0.087816
[01:56:33.137] Epoch 20, Iter 8930: loss=0.0312, ce=0.0046, dice=0.0489, grad_norm=0.111121
[01:56:36.717] Epoch 20, Iter 8940: loss=0.0705, ce=0.0030, dice=0.1156, grad_norm=0.396249
[01:56:40.304] Epoch 20, Iter 8950: loss=0.0324, ce=0.0053, dice=0.0505, grad_norm=0.430514
[01:56:43.880] Epoch 20, Iter 8960: loss=0.0177, ce=0.0022, dice=0.0280, grad_norm=0.103365
[01:56:47.478] Epoch 20, Iter 8970: loss=0.0341, ce=0.0053, dice=0.0533, grad_norm=0.218073
[01:56:51.059] Epoch 20, Iter 8980: loss=0.0433, ce=0.0064, dice=0.0679, grad_norm=0.413279
[01:56:54.652] Epoch 20, Iter 8990: loss=0.0384, ce=0.0023, dice=0.0625, grad_norm=1.030125
[01:56:58.237] Epoch 20, Iter 9000: loss=0.0206, ce=0.0057, dice=0.0306, grad_norm=0.072441
[01:57:01.823] Epoch 20, Iter 9010: loss=0.0229, ce=0.0051, dice=0.0348, grad_norm=0.077058
[01:57:05.412] Epoch 20, Iter 9020: loss=0.2080, ce=0.0048, dice=0.3434, grad_norm=0.022546
[01:57:09.025] Epoch 20, Iter 9030: loss=0.0238, ce=0.0061, dice=0.0355, grad_norm=0.125863
[01:57:12.599] Epoch 20, Iter 9040: loss=0.0128, ce=0.0036, dice=0.0190, grad_norm=0.038034
[01:57:16.203] Epoch 20, Iter 9050: loss=0.0191, ce=0.0064, dice=0.0276, grad_norm=0.070322
[01:57:19.777] Epoch 20, Iter 9060: loss=0.0249, ce=0.0051, dice=0.0380, grad_norm=0.062325
[01:57:23.375] Epoch 20, Iter 9070: loss=0.2068, ce=0.0032, dice=0.3425, grad_norm=0.018473
[01:57:26.964] Epoch 20, Iter 9080: loss=0.0411, ce=0.0045, dice=0.0654, grad_norm=0.292864
[01:57:30.568] Epoch 20, Iter 9090: loss=0.0302, ce=0.0031, dice=0.0483, grad_norm=0.090230
[01:57:32.269] Epoch 20: Avg Loss=0.0544, CE=0.0044, Dice=0.0878
[01:57:45.729] Epoch 21, Iter 9100: loss=0.0163, ce=0.0030, dice=0.0252, grad_norm=0.117797
[01:57:49.344] Epoch 21, Iter 9110: loss=0.0276, ce=0.0048, dice=0.0429, grad_norm=0.099089
[01:57:52.963] Epoch 21, Iter 9120: loss=0.0346, ce=0.0045, dice=0.0546, grad_norm=0.245290
[01:57:56.611] Epoch 21, Iter 9130: loss=0.0782, ce=0.0053, dice=0.1267, grad_norm=0.564997
[01:58:00.212] Epoch 21, Iter 9140: loss=0.0361, ce=0.0039, dice=0.0576, grad_norm=0.093260
[01:58:03.837] Epoch 21, Iter 9150: loss=0.0842, ce=0.0059, dice=0.1364, grad_norm=0.244681
[01:58:07.441] Epoch 21, Iter 9160: loss=0.0376, ce=0.0029, dice=0.0608, grad_norm=1.101213
[01:58:11.070] Epoch 21, Iter 9170: loss=0.0481, ce=0.0068, dice=0.0756, grad_norm=0.144120
[01:58:14.726] Epoch 21, Iter 9180: loss=0.0354, ce=0.0074, dice=0.0541, grad_norm=0.130841
[01:58:18.329] Epoch 21, Iter 9190: loss=0.0320, ce=0.0043, dice=0.0505, grad_norm=0.281644
[01:58:21.934] Epoch 21, Iter 9200: loss=0.0191, ce=0.0041, dice=0.0292, grad_norm=0.089120
[01:58:25.538] Epoch 21, Iter 9210: loss=0.0294, ce=0.0012, dice=0.0482, grad_norm=0.115964
[01:58:29.179] Epoch 21, Iter 9220: loss=0.0275, ce=0.0051, dice=0.0425, grad_norm=0.133480
[01:58:32.803] Epoch 21, Iter 9230: loss=0.0778, ce=0.0062, dice=0.1256, grad_norm=0.427039
[01:58:36.409] Epoch 21, Iter 9240: loss=0.0281, ce=0.0099, dice=0.0402, grad_norm=0.088532
[01:58:40.022] Epoch 21, Iter 9250: loss=0.2067, ce=0.0029, dice=0.3426, grad_norm=0.031545
[01:58:43.631] Epoch 21, Iter 9260: loss=0.0285, ce=0.0063, dice=0.0433, grad_norm=0.083126
[01:58:47.245] Epoch 21, Iter 9270: loss=0.0330, ce=0.0057, dice=0.0512, grad_norm=0.242465
[01:58:50.872] Epoch 21, Iter 9280: loss=0.0239, ce=0.0053, dice=0.0363, grad_norm=0.068318
[01:58:54.484] Epoch 21, Iter 9290: loss=0.0205, ce=0.0064, dice=0.0299, grad_norm=0.106114
[01:58:58.100] Epoch 21, Iter 9300: loss=0.0228, ce=0.0038, dice=0.0354, grad_norm=0.047855
[01:59:01.711] Epoch 21, Iter 9310: loss=0.0205, ce=0.0057, dice=0.0304, grad_norm=0.155110
[01:59:05.323] Epoch 21, Iter 9320: loss=0.0462, ce=0.0027, dice=0.0751, grad_norm=0.358576
[01:59:08.954] Epoch 21, Iter 9330: loss=0.2080, ce=0.0050, dice=0.3434, grad_norm=0.047518
[01:59:12.577] Epoch 21, Iter 9340: loss=0.0299, ce=0.0041, dice=0.0471, grad_norm=0.139365
[01:59:16.193] Epoch 21, Iter 9350: loss=0.0236, ce=0.0061, dice=0.0354, grad_norm=0.085792
[01:59:19.833] Epoch 21, Iter 9360: loss=0.0434, ce=0.0061, dice=0.0682, grad_norm=0.256507
[01:59:23.452] Epoch 21, Iter 9370: loss=0.0228, ce=0.0074, dice=0.0332, grad_norm=0.098185
[01:59:27.061] Epoch 21, Iter 9380: loss=0.0238, ce=0.0009, dice=0.0392, grad_norm=0.184660
[01:59:30.671] Epoch 21, Iter 9390: loss=0.0263, ce=0.0035, dice=0.0415, grad_norm=0.094065
[01:59:34.283] Epoch 21, Iter 9400: loss=0.0263, ce=0.0071, dice=0.0391, grad_norm=0.092250
[01:59:37.922] Epoch 21, Iter 9410: loss=0.0229, ce=0.0036, dice=0.0357, grad_norm=0.142069
[01:59:41.542] Epoch 21, Iter 9420: loss=0.0240, ce=0.0029, dice=0.0380, grad_norm=0.198437
[01:59:45.186] Epoch 21, Iter 9430: loss=0.0474, ce=0.0096, dice=0.0727, grad_norm=0.406355
[01:59:48.794] Epoch 21, Iter 9440: loss=0.0229, ce=0.0022, dice=0.0367, grad_norm=0.129368
[01:59:52.404] Epoch 21, Iter 9450: loss=0.0435, ce=0.0065, dice=0.0682, grad_norm=0.186179
[01:59:56.020] Epoch 21, Iter 9460: loss=0.0195, ce=0.0056, dice=0.0288, grad_norm=0.097704
[01:59:59.638] Epoch 21, Iter 9470: loss=0.2048, ce=0.0018, dice=0.3401, grad_norm=0.046563
[02:00:03.232] Epoch 21, Iter 9480: loss=0.1926, ce=0.0030, dice=0.3190, grad_norm=0.372785
[02:00:06.858] Epoch 21, Iter 9490: loss=0.1678, ce=0.0036, dice=0.2773, grad_norm=1.334192
[02:00:10.481] Epoch 21, Iter 9500: loss=0.0385, ce=0.0022, dice=0.0626, grad_norm=0.468198
[02:00:14.098] Epoch 21, Iter 9510: loss=0.0410, ce=0.0068, dice=0.0638, grad_norm=0.128682
[02:00:17.701] Epoch 21, Iter 9520: loss=0.0314, ce=0.0026, dice=0.0507, grad_norm=0.101585
[02:00:20.463] Epoch 21: Avg Loss=0.0586, CE=0.0044, Dice=0.0947
[02:00:32.814] Epoch 22, Iter 9530: loss=0.0318, ce=0.0032, dice=0.0509, grad_norm=0.127983
[02:00:36.415] Epoch 22, Iter 9540: loss=0.0250, ce=0.0062, dice=0.0376, grad_norm=0.098454
[02:00:40.013] Epoch 22, Iter 9550: loss=0.0459, ce=0.0037, dice=0.0741, grad_norm=0.204860
[02:00:43.605] Epoch 22, Iter 9560: loss=0.0463, ce=0.0044, dice=0.0742, grad_norm=0.238361
[02:00:47.213] Epoch 22, Iter 9570: loss=0.0186, ce=0.0029, dice=0.0291, grad_norm=0.082480
[02:00:50.803] Epoch 22, Iter 9580: loss=0.0263, ce=0.0068, dice=0.0394, grad_norm=0.150867
[02:00:54.411] Epoch 22, Iter 9590: loss=0.2057, ce=0.0029, dice=0.3408, grad_norm=0.024614
[02:00:58.010] Epoch 22, Iter 9600: loss=0.0444, ce=0.0048, dice=0.0708, grad_norm=0.188495
[02:01:01.621] Epoch 22, Iter 9610: loss=0.2104, ce=0.0007, dice=0.3503, grad_norm=0.133518
[02:01:05.215] Epoch 22, Iter 9620: loss=0.0617, ce=0.0018, dice=0.1016, grad_norm=0.406731
[02:01:08.856] Epoch 22, Iter 9630: loss=0.0162, ce=0.0023, dice=0.0255, grad_norm=0.054120
[02:01:12.446] Epoch 22, Iter 9640: loss=0.0175, ce=0.0053, dice=0.0256, grad_norm=0.102852
[02:01:16.073] Epoch 22, Iter 9650: loss=0.0519, ce=0.0042, dice=0.0837, grad_norm=0.377987
[02:01:19.682] Epoch 22, Iter 9660: loss=0.2052, ce=0.0018, dice=0.3409, grad_norm=0.018099
[02:01:23.312] Epoch 22, Iter 9670: loss=0.0467, ce=0.0041, dice=0.0751, grad_norm=0.121841
[02:01:26.910] Epoch 22, Iter 9680: loss=0.0328, ce=0.0066, dice=0.0503, grad_norm=0.153290
[02:01:30.526] Epoch 22, Iter 9690: loss=0.0659, ce=0.0053, dice=0.1062, grad_norm=0.625304
[02:01:34.129] Epoch 22, Iter 9700: loss=0.0274, ce=0.0049, dice=0.0425, grad_norm=0.098391
[02:01:37.742] Epoch 22, Iter 9710: loss=0.0315, ce=0.0031, dice=0.0505, grad_norm=0.075179
[02:01:41.385] Epoch 22, Iter 9720: loss=0.0180, ce=0.0037, dice=0.0275, grad_norm=0.051168
[02:01:45.005] Epoch 22, Iter 9730: loss=0.0343, ce=0.0047, dice=0.0540, grad_norm=0.432275
[02:01:48.624] Epoch 22, Iter 9740: loss=0.0440, ce=0.0028, dice=0.0714, grad_norm=0.402728
[02:01:52.335] Epoch 22, Iter 9750: loss=0.0425, ce=0.0058, dice=0.0669, grad_norm=0.600005
[02:01:55.938] Epoch 22, Iter 9760: loss=0.0536, ce=0.0050, dice=0.0859, grad_norm=0.147358
[02:01:59.548] Epoch 22, Iter 9770: loss=0.2073, ce=0.0030, dice=0.3436, grad_norm=0.034965
[02:02:03.171] Epoch 22, Iter 9780: loss=0.2102, ce=0.0057, dice=0.3465, grad_norm=0.029504
[02:02:06.784] Epoch 22, Iter 9790: loss=0.0273, ce=0.0057, dice=0.0417, grad_norm=0.106998
[02:02:10.414] Epoch 22, Iter 9800: loss=0.2070, ce=0.0039, dice=0.3425, grad_norm=0.016973
[02:02:14.023] Epoch 22, Iter 9810: loss=0.0199, ce=0.0039, dice=0.0305, grad_norm=0.064375
[02:02:17.624] Epoch 22, Iter 9820: loss=0.2126, ce=0.0075, dice=0.3493, grad_norm=0.044435
[02:02:21.227] Epoch 22, Iter 9830: loss=0.0388, ce=0.0022, dice=0.0631, grad_norm=0.322407
[02:02:24.836] Epoch 22, Iter 9840: loss=0.0275, ce=0.0023, dice=0.0444, grad_norm=0.231631
[02:02:28.445] Epoch 22, Iter 9850: loss=0.0267, ce=0.0061, dice=0.0404, grad_norm=0.111234
[02:02:32.042] Epoch 22, Iter 9860: loss=0.0419, ce=0.0060, dice=0.0659, grad_norm=0.204062
[02:02:35.669] Epoch 22, Iter 9870: loss=0.0330, ce=0.0020, dice=0.0537, grad_norm=0.243970
[02:02:39.284] Epoch 22, Iter 9880: loss=0.0181, ce=0.0039, dice=0.0277, grad_norm=0.051635
[02:02:42.903] Epoch 22, Iter 9890: loss=0.0329, ce=0.0045, dice=0.0518, grad_norm=0.541039
[02:02:46.510] Epoch 22, Iter 9900: loss=0.0275, ce=0.0084, dice=0.0402, grad_norm=0.068912
[02:02:50.127] Epoch 22, Iter 9910: loss=0.0433, ce=0.0047, dice=0.0690, grad_norm=0.291049
[02:02:53.739] Epoch 22, Iter 9920: loss=0.0255, ce=0.0017, dice=0.0413, grad_norm=0.110203
[02:02:57.340] Epoch 22, Iter 9930: loss=0.0484, ce=0.0023, dice=0.0791, grad_norm=1.038512
[02:03:00.969] Epoch 22, Iter 9940: loss=0.2032, ce=0.0031, dice=0.3366, grad_norm=0.109125
[02:03:04.596] Epoch 22, Iter 9950: loss=0.0429, ce=0.0061, dice=0.0674, grad_norm=0.137598
[02:03:08.455] Epoch 22: Avg Loss=0.0572, CE=0.0044, Dice=0.0924
[02:10:01.746] Epoch 23, Iter 9960: loss=0.0294, ce=0.0043, dice=0.0462, grad_norm=0.108756
[02:10:05.297] Epoch 23, Iter 9970: loss=0.0431, ce=0.0027, dice=0.0701, grad_norm=0.196352
[02:10:08.839] Epoch 23, Iter 9980: loss=0.0314, ce=0.0064, dice=0.0482, grad_norm=0.070504
[02:10:12.403] Epoch 23, Iter 9990: loss=0.2086, ce=0.0038, dice=0.3452, grad_norm=0.026675
[02:10:15.956] Epoch 23, Iter 10000: loss=0.0440, ce=0.0028, dice=0.0716, grad_norm=0.178483
[02:10:19.524] Epoch 23, Iter 10010: loss=0.0317, ce=0.0074, dice=0.0479, grad_norm=0.103519
[02:10:23.094] Epoch 23, Iter 10020: loss=0.2035, ce=0.0029, dice=0.3373, grad_norm=0.101369
[02:10:26.655] Epoch 23, Iter 10030: loss=0.2111, ce=0.0022, dice=0.3503, grad_norm=0.048205
[02:10:30.201] Epoch 23, Iter 10040: loss=0.0330, ce=0.0054, dice=0.0514, grad_norm=0.193403
[02:10:33.759] Epoch 23, Iter 10050: loss=0.0395, ce=0.0026, dice=0.0642, grad_norm=0.181296
[02:10:37.314] Epoch 23, Iter 10060: loss=0.0190, ce=0.0053, dice=0.0281, grad_norm=0.061888
[02:10:40.871] Epoch 23, Iter 10070: loss=0.0445, ce=0.0028, dice=0.0723, grad_norm=0.154286
[02:10:44.430] Epoch 23, Iter 10080: loss=0.0218, ce=0.0083, dice=0.0308, grad_norm=0.052232
[02:10:47.990] Epoch 23, Iter 10090: loss=0.0221, ce=0.0027, dice=0.0351, grad_norm=0.197714
[02:10:51.577] Epoch 23, Iter 10100: loss=0.0671, ce=0.0047, dice=0.1086, grad_norm=0.502798
[02:10:55.147] Epoch 23, Iter 10110: loss=0.0240, ce=0.0019, dice=0.0388, grad_norm=0.069380
[02:10:58.732] Epoch 23, Iter 10120: loss=0.2066, ce=0.0021, dice=0.3430, grad_norm=0.022941
[02:11:02.342] Epoch 23, Iter 10130: loss=0.0332, ce=0.0035, dice=0.0530, grad_norm=0.174972
[02:11:05.907] Epoch 23, Iter 10140: loss=0.0238, ce=0.0055, dice=0.0361, grad_norm=0.255728
[02:11:09.469] Epoch 23, Iter 10150: loss=0.0274, ce=0.0046, dice=0.0426, grad_norm=0.069432
[02:11:13.043] Epoch 23, Iter 10160: loss=0.0204, ce=0.0042, dice=0.0312, grad_norm=0.130145
[02:11:16.646] Epoch 23, Iter 10170: loss=0.0260, ce=0.0067, dice=0.0389, grad_norm=0.071099
[02:11:20.195] Epoch 23, Iter 10180: loss=0.0192, ce=0.0066, dice=0.0275, grad_norm=0.054498
[02:11:23.756] Epoch 23, Iter 10190: loss=0.0235, ce=0.0050, dice=0.0359, grad_norm=0.060505
[02:11:27.294] Epoch 23, Iter 10200: loss=0.0256, ce=0.0043, dice=0.0398, grad_norm=0.111468
[02:11:30.848] Epoch 23, Iter 10210: loss=0.0532, ce=0.0021, dice=0.0873, grad_norm=0.278006
[02:11:34.393] Epoch 23, Iter 10220: loss=0.0239, ce=0.0083, dice=0.0343, grad_norm=0.095284
[02:11:37.937] Epoch 23, Iter 10230: loss=0.0216, ce=0.0052, dice=0.0325, grad_norm=0.067571
[02:11:41.482] Epoch 23, Iter 10240: loss=0.2074, ce=0.0024, dice=0.3440, grad_norm=0.031762
[02:11:45.048] Epoch 23, Iter 10250: loss=0.0177, ce=0.0021, dice=0.0281, grad_norm=0.113618
[02:11:48.587] Epoch 23, Iter 10260: loss=0.0482, ce=0.0059, dice=0.0764, grad_norm=0.275229
[02:11:52.139] Epoch 23, Iter 10270: loss=0.0157, ce=0.0042, dice=0.0234, grad_norm=0.047401
[02:11:55.685] Epoch 23, Iter 10280: loss=0.0854, ce=0.0046, dice=0.1392, grad_norm=1.629100
[02:11:59.241] Epoch 23, Iter 10290: loss=0.0291, ce=0.0020, dice=0.0472, grad_norm=0.222046
[02:12:02.784] Epoch 23, Iter 10300: loss=0.0861, ce=0.0042, dice=0.1408, grad_norm=0.572591
[02:12:06.358] Epoch 23, Iter 10310: loss=0.0354, ce=0.0083, dice=0.0535, grad_norm=0.344877
[02:12:09.900] Epoch 23, Iter 10320: loss=0.0473, ce=0.0042, dice=0.0761, grad_norm=0.389544
[02:12:13.453] Epoch 23, Iter 10330: loss=0.0463, ce=0.0045, dice=0.0742, grad_norm=0.444216
[02:12:16.989] Epoch 23, Iter 10340: loss=0.0326, ce=0.0035, dice=0.0520, grad_norm=0.455751
[02:12:20.543] Epoch 23, Iter 10350: loss=0.0181, ce=0.0034, dice=0.0279, grad_norm=0.062340
[02:12:24.087] Epoch 23, Iter 10360: loss=0.0369, ce=0.0016, dice=0.0603, grad_norm=0.152452
[02:12:27.667] Epoch 23, Iter 10370: loss=0.0446, ce=0.0071, dice=0.0696, grad_norm=0.189730
[02:12:31.211] Epoch 23, Iter 10380: loss=0.0253, ce=0.0028, dice=0.0403, grad_norm=0.091578
[02:12:34.761] Epoch 23, Iter 10390: loss=0.0325, ce=0.0060, dice=0.0501, grad_norm=0.096528
[02:12:36.021] Epoch 23: Avg Loss=0.0561, CE=0.0044, Dice=0.0906
[02:12:36.023] 
[EPOCH 25] Calculating RGN weights for surgical fine-tuning...
[02:12:48.201] RGN: Max weight before normalization: 0.001458
[02:12:48.225] 
================================================================================
[02:12:48.225] SURGICAL FINE-TUNING WITH TPGM - RGN METHOD
[02:12:48.226] ================================================================================
[02:12:48.226] Layer Name                                         Weight       Learning Rate  
[02:12:48.226] --------------------------------------------------------------------------------
[02:12:48.226] cswin_unet.stage1.0.attns.1.get_v.bias             1.000000     0.00050000      [ACTIVE]
[02:12:48.226] cswin_unet.stage1.0.attns.0.get_v.bias             0.695344     0.00034767      [ACTIVE]
[02:12:48.226] cswin_unet.upsample3.encoder.weight                0.522032     0.00026102      [ACTIVE]
[02:12:48.226] cswin_unet.stage1_conv_embed.0.weight              0.394348     0.00019717      [ACTIVE]
[02:12:48.226] cswin_unet.concat_linear2.weight                   0.343429     0.00017171      [ACTIVE]
[02:12:48.226] cswin_unet.upsample2.out.weight                    0.337774     0.00016889      [ACTIVE]
[02:12:48.226] cswin_unet.concat_linear3.bias                     0.326008     0.00016300      [ACTIVE]
[02:12:48.226] cswin_unet.concat_linear3.weight                   0.323427     0.00016171      [ACTIVE]
[02:12:48.226] cswin_unet.upsample2.down.weight                   0.314662     0.00015733      [ACTIVE]
[02:12:48.226] cswin_unet.stage1.0.proj.bias                      0.306956     0.00015348      [ACTIVE]
[02:12:48.226] cswin_unet.upsample2.encoder.weight                0.290878     0.00014544      [ACTIVE]
[02:12:48.226] cswin_unet.stage1.0.proj.weight                    0.290213     0.00014511      [ACTIVE]
[02:12:48.226] cswin_unet.upsample3.down.weight                   0.288197     0.00014410      [ACTIVE]
[02:12:48.226] cswin_unet.upsample3.out.weight                    0.284298     0.00014215      [ACTIVE]
[02:12:48.227] cswin_unet.stage2.0.proj.bias                      0.269814     0.00013491      [ACTIVE]
[02:12:48.227] cswin_unet.concat_linear2.bias                     0.255887     0.00012794      [ACTIVE]
[02:12:48.227] cswin_unet.stage_up1.0.attns.1.get_v.bias          0.254852     0.00012743      [ACTIVE]
[02:12:48.227] cswin_unet.output.weight                           0.251688     0.00012584      [ACTIVE]
[02:12:48.227] cswin_unet.stage1.0.mlp.fc2.weight                 0.240462     0.00012023      [ACTIVE]
[02:12:48.227] cswin_unet.stage1.0.mlp.fc1.weight                 0.237472     0.00011874      [ACTIVE]
[02:12:48.227] cswin_unet.upsample2.encoder.bias                  0.230869     0.00011543      [ACTIVE]
[02:12:48.227] cswin_unet.upsample1.out.weight                    0.224630     0.00011231      [ACTIVE]
[02:12:48.227] cswin_unet.stage2.1.attns.1.get_v.bias             0.219060     0.00010953      [ACTIVE]
[02:12:48.227] cswin_unet.stage2.1.attns.0.get_v.bias             0.218268     0.00010913      [ACTIVE]
[02:12:48.227] cswin_unet.stage1.0.mlp.fc2.bias                   0.211710     0.00010585      [ACTIVE]
[02:12:48.227] cswin_unet.stage2.0.attns.1.get_v.bias             0.202664     0.00010133      [ACTIVE]
[02:12:48.227] cswin_unet.stage1.0.qkv.weight                     0.195010     0.00009751      [ACTIVE]
[02:12:48.227] cswin_unet.stage_up1.0.attns.0.get_v.bias          0.192696     0.00009635      [ACTIVE]
[02:12:48.228] cswin_unet.concat_linear4.weight                   0.179842     0.00008992      [ACTIVE]
[02:12:48.228] cswin_unet.stage2.0.attns.0.get_v.bias             0.170650     0.00008532      [ACTIVE]
[02:12:48.228] cswin_unet.upsample2.out.bias                      0.167878     0.00008394      [ACTIVE]
[02:12:48.228] cswin_unet.upsample2.down.bias                     0.165710     0.00008286      [ACTIVE]
[02:12:48.228] cswin_unet.upsample1.down.weight                   0.153997     0.00007700      [ACTIVE]
[02:12:48.228] cswin_unet.upsample1.out.bias                      0.150509     0.00007525      [ACTIVE]
[02:12:48.228] cswin_unet.stage1.0.attns.1.get_v.weight           0.150215     0.00007511      [ACTIVE]
[02:12:48.228] cswin_unet.stage2.1.proj.bias                      0.148531     0.00007427      [ACTIVE]
[02:12:48.228] cswin_unet.stage1_conv_embed.2.bias                0.147646     0.00007382      [ACTIVE]
[02:12:48.228] cswin_unet.merge1.conv.weight                      0.146290     0.00007315      [ACTIVE]
[02:12:48.228] cswin_unet.stage1.0.attns.0.get_v.weight           0.145277     0.00007264      [ACTIVE]
[02:12:48.228] cswin_unet.stage_up1.0.proj.weight                 0.133868     0.00006693      [ACTIVE]
[02:12:48.228] cswin_unet.stage_up1.0.qkv.weight                  0.131767     0.00006588      [ACTIVE]
[02:12:48.228] cswin_unet.stage_up1.0.mlp.fc1.weight              0.126282     0.00006314      [ACTIVE]
[02:12:48.228] cswin_unet.stage_up2.1.attns.1.get_v.bias          0.118533     0.00005927      [ACTIVE]
[02:12:48.228] cswin_unet.stage_up2.1.attns.0.get_v.bias          0.114566     0.00005728      [ACTIVE]
[02:12:48.228] cswin_unet.stage_up1.0.mlp.fc2.weight              0.113671     0.00005684      [ACTIVE]
[02:12:48.228] cswin_unet.upsample1.down.bias                     0.111695     0.00005585      [ACTIVE]
[02:12:48.228] cswin_unet.stage2.1.proj.weight                    0.105896     0.00005295      [ACTIVE]
[02:12:48.228] cswin_unet.stage1.0.norm1.weight                   0.100000     0.00005000      [ACTIVE]
[02:12:48.228] cswin_unet.stage1.0.norm1.bias                     0.100000     0.00005000      [ACTIVE]
[02:12:48.228] cswin_unet.stage1.0.norm2.weight                   0.100000     0.00005000      [ACTIVE]
[02:12:48.228] cswin_unet.stage1.0.norm2.bias                     0.100000     0.00005000      [ACTIVE]
[02:12:48.228] cswin_unet.merge1.norm.weight                      0.100000     0.00005000      [ACTIVE]
[02:12:48.229] cswin_unet.merge1.norm.bias                        0.100000     0.00005000      [ACTIVE]
[02:12:48.229] cswin_unet.stage2.0.norm1.weight                   0.100000     0.00005000      [ACTIVE]
[02:12:48.229] cswin_unet.stage2.0.norm1.bias                     0.100000     0.00005000      [ACTIVE]
[02:12:48.229] cswin_unet.stage2.0.norm2.weight                   0.100000     0.00005000      [ACTIVE]
[02:12:48.229] cswin_unet.stage2.0.norm2.bias                     0.100000     0.00005000      [ACTIVE]
[02:12:48.229] cswin_unet.stage2.1.norm1.weight                   0.100000     0.00005000      [ACTIVE]
[02:12:48.229] cswin_unet.stage2.1.norm1.bias                     0.100000     0.00005000      [ACTIVE]
[02:12:48.229] cswin_unet.stage2.1.norm2.weight                   0.100000     0.00005000      [ACTIVE]
[02:12:48.229] cswin_unet.stage2.1.norm2.bias                     0.100000     0.00005000      [ACTIVE]
[02:12:48.229] cswin_unet.merge2.norm.weight                      0.100000     0.00005000      [ACTIVE]
[02:12:48.229] cswin_unet.merge2.norm.bias                        0.100000     0.00005000      [ACTIVE]
[02:12:48.229] cswin_unet.stage3.0.norm1.weight                   0.100000     0.00005000      [ACTIVE]
[02:12:48.229] cswin_unet.stage3.0.norm1.bias                     0.100000     0.00005000      [ACTIVE]
[02:12:48.229] cswin_unet.stage3.0.norm2.weight                   0.100000     0.00005000      [ACTIVE]
[02:12:48.229] cswin_unet.stage3.0.norm2.bias                     0.100000     0.00005000      [ACTIVE]
[02:12:48.229] cswin_unet.stage3.1.norm1.weight                   0.100000     0.00005000      [ACTIVE]
[02:12:48.229] cswin_unet.stage3.1.norm1.bias                     0.100000     0.00005000      [ACTIVE]
[02:12:48.229] cswin_unet.stage3.1.norm2.weight                   0.100000     0.00005000      [ACTIVE]
[02:12:48.229] cswin_unet.stage3.1.norm2.bias                     0.100000     0.00005000      [ACTIVE]
[02:12:48.229] cswin_unet.stage3.2.norm1.weight                   0.100000     0.00005000      [ACTIVE]
[02:12:48.229] cswin_unet.stage3.2.norm1.bias                     0.100000     0.00005000      [ACTIVE]
[02:12:48.229] cswin_unet.stage3.2.norm2.weight                   0.100000     0.00005000      [ACTIVE]
[02:12:48.229] cswin_unet.stage3.2.norm2.bias                     0.100000     0.00005000      [ACTIVE]
[02:12:48.229] cswin_unet.stage3.3.norm1.weight                   0.100000     0.00005000      [ACTIVE]
[02:12:48.229] cswin_unet.stage3.3.norm1.bias                     0.100000     0.00005000      [ACTIVE]
[02:12:48.229] cswin_unet.stage3.3.norm2.weight                   0.100000     0.00005000      [ACTIVE]
[02:12:48.229] cswin_unet.stage3.3.norm2.bias                     0.100000     0.00005000      [ACTIVE]
[02:12:48.229] cswin_unet.stage3.4.norm1.weight                   0.100000     0.00005000      [ACTIVE]
[02:12:48.229] cswin_unet.stage3.4.norm1.bias                     0.100000     0.00005000      [ACTIVE]
[02:12:48.229] cswin_unet.stage3.4.norm2.weight                   0.100000     0.00005000      [ACTIVE]
[02:12:48.229] cswin_unet.stage3.4.norm2.bias                     0.100000     0.00005000      [ACTIVE]
[02:12:48.229] cswin_unet.stage3.5.norm1.weight                   0.100000     0.00005000      [ACTIVE]
[02:12:48.229] cswin_unet.stage3.5.norm1.bias                     0.100000     0.00005000      [ACTIVE]
[02:12:48.229] cswin_unet.stage3.5.norm2.weight                   0.100000     0.00005000      [ACTIVE]
[02:12:48.229] cswin_unet.stage3.5.norm2.bias                     0.100000     0.00005000      [ACTIVE]
[02:12:48.229] cswin_unet.stage3.6.norm1.weight                   0.100000     0.00005000      [ACTIVE]
[02:12:48.229] cswin_unet.stage3.6.norm1.bias                     0.100000     0.00005000      [ACTIVE]
[02:12:48.230] cswin_unet.stage3.6.norm2.weight                   0.100000     0.00005000      [ACTIVE]
[02:12:48.230] cswin_unet.stage3.6.norm2.bias                     0.100000     0.00005000      [ACTIVE]
[02:12:48.230] cswin_unet.stage3.7.norm1.weight                   0.100000     0.00005000      [ACTIVE]
[02:12:48.230] cswin_unet.stage3.7.norm1.bias                     0.100000     0.00005000      [ACTIVE]
[02:12:48.230] cswin_unet.stage3.7.norm2.weight                   0.100000     0.00005000      [ACTIVE]
[02:12:48.230] cswin_unet.stage3.7.norm2.bias                     0.100000     0.00005000      [ACTIVE]
[02:12:48.230] cswin_unet.stage3.8.norm1.weight                   0.100000     0.00005000      [ACTIVE]
[02:12:48.230] cswin_unet.stage3.8.norm1.bias                     0.100000     0.00005000      [ACTIVE]
[02:12:48.230] cswin_unet.stage3.8.norm2.weight                   0.100000     0.00005000      [ACTIVE]
[02:12:48.230] cswin_unet.stage3.8.norm2.bias                     0.100000     0.00005000      [ACTIVE]
[02:12:48.230] cswin_unet.merge3.norm.weight                      0.100000     0.00005000      [ACTIVE]
[02:12:48.230] cswin_unet.merge3.norm.bias                        0.100000     0.00005000      [ACTIVE]
[02:12:48.230] cswin_unet.stage4.0.norm1.weight                   0.100000     0.00005000      [ACTIVE]
[02:12:48.230] cswin_unet.stage4.0.norm1.bias                     0.100000     0.00005000      [ACTIVE]
[02:12:48.230] cswin_unet.stage4.0.norm2.weight                   0.100000     0.00005000      [ACTIVE]
[02:12:48.230] cswin_unet.stage4.0.norm2.bias                     0.100000     0.00005000      [ACTIVE]
[02:12:48.230] cswin_unet.norm.weight                             0.100000     0.00005000      [ACTIVE]
[02:12:48.230] cswin_unet.norm.bias                               0.100000     0.00005000      [ACTIVE]
[02:12:48.230] cswin_unet.stage_up4.0.norm1.weight                0.100000     0.00005000      [ACTIVE]
[02:12:48.230] cswin_unet.stage_up4.0.norm1.bias                  0.100000     0.00005000      [ACTIVE]
[02:12:48.230] cswin_unet.stage_up4.0.norm2.weight                0.100000     0.00005000      [ACTIVE]
[02:12:48.230] cswin_unet.stage_up4.0.norm2.bias                  0.100000     0.00005000      [ACTIVE]
[02:12:48.230] cswin_unet.stage_up3.0.norm1.weight                0.100000     0.00005000      [ACTIVE]
[02:12:48.230] cswin_unet.stage_up3.0.norm1.bias                  0.100000     0.00005000      [ACTIVE]
[02:12:48.230] cswin_unet.stage_up3.0.norm2.weight                0.100000     0.00005000      [ACTIVE]
[02:12:48.231] cswin_unet.stage_up3.0.norm2.bias                  0.100000     0.00005000      [ACTIVE]
[02:12:48.231] cswin_unet.stage_up3.1.norm1.weight                0.100000     0.00005000      [ACTIVE]
[02:12:48.231] cswin_unet.stage_up3.1.norm1.bias                  0.100000     0.00005000      [ACTIVE]
[02:12:48.231] cswin_unet.stage_up3.1.norm2.weight                0.100000     0.00005000      [ACTIVE]
[02:12:48.231] cswin_unet.stage_up3.1.norm2.bias                  0.100000     0.00005000      [ACTIVE]
[02:12:48.231] cswin_unet.stage_up3.2.norm1.weight                0.100000     0.00005000      [ACTIVE]
[02:12:48.231] cswin_unet.stage_up3.2.norm1.bias                  0.100000     0.00005000      [ACTIVE]
[02:12:48.231] cswin_unet.stage_up3.2.norm2.weight                0.100000     0.00005000      [ACTIVE]
[02:12:48.231] cswin_unet.stage_up3.2.norm2.bias                  0.100000     0.00005000      [ACTIVE]
[02:12:48.231] cswin_unet.stage_up3.3.norm1.weight                0.100000     0.00005000      [ACTIVE]
[02:12:48.231] cswin_unet.stage_up3.3.norm1.bias                  0.100000     0.00005000      [ACTIVE]
[02:12:48.231] cswin_unet.stage_up3.3.norm2.weight                0.100000     0.00005000      [ACTIVE]
[02:12:48.231] cswin_unet.stage_up3.3.norm2.bias                  0.100000     0.00005000      [ACTIVE]
[02:12:48.231] cswin_unet.stage_up3.4.norm1.weight                0.100000     0.00005000      [ACTIVE]
[02:12:48.231] cswin_unet.stage_up3.4.norm1.bias                  0.100000     0.00005000      [ACTIVE]
[02:12:48.231] cswin_unet.stage_up3.4.norm2.weight                0.100000     0.00005000      [ACTIVE]
[02:12:48.231] cswin_unet.stage_up3.4.norm2.bias                  0.100000     0.00005000      [ACTIVE]
[02:12:48.231] cswin_unet.stage_up3.5.norm1.weight                0.100000     0.00005000      [ACTIVE]
[02:12:48.231] cswin_unet.stage_up3.5.norm1.bias                  0.100000     0.00005000      [ACTIVE]
[02:12:48.231] cswin_unet.stage_up3.5.norm2.weight                0.100000     0.00005000      [ACTIVE]
[02:12:48.232] cswin_unet.stage_up3.5.norm2.bias                  0.100000     0.00005000      [ACTIVE]
[02:12:48.232] cswin_unet.stage_up3.6.norm1.weight                0.100000     0.00005000      [ACTIVE]
[02:12:48.232] cswin_unet.stage_up3.6.norm1.bias                  0.100000     0.00005000      [ACTIVE]
[02:12:48.232] cswin_unet.stage_up3.6.norm2.weight                0.100000     0.00005000      [ACTIVE]
[02:12:48.232] cswin_unet.stage_up3.6.norm2.bias                  0.100000     0.00005000      [ACTIVE]
[02:12:48.232] cswin_unet.stage_up3.7.norm1.weight                0.100000     0.00005000      [ACTIVE]
[02:12:48.232] cswin_unet.stage_up3.7.norm1.bias                  0.100000     0.00005000      [ACTIVE]
[02:12:48.232] cswin_unet.stage_up3.7.norm2.weight                0.100000     0.00005000      [ACTIVE]
[02:12:48.232] cswin_unet.stage_up3.7.norm2.bias                  0.100000     0.00005000      [ACTIVE]
[02:12:48.232] cswin_unet.stage_up3.8.norm1.weight                0.100000     0.00005000      [ACTIVE]
[02:12:48.232] cswin_unet.stage_up3.8.norm1.bias                  0.100000     0.00005000      [ACTIVE]
[02:12:48.232] cswin_unet.stage_up3.8.norm2.weight                0.100000     0.00005000      [ACTIVE]
[02:12:48.232] cswin_unet.stage_up3.8.norm2.bias                  0.100000     0.00005000      [ACTIVE]
[02:12:48.232] cswin_unet.stage_up2.0.norm1.weight                0.100000     0.00005000      [ACTIVE]
[02:12:48.232] cswin_unet.stage_up2.0.norm1.bias                  0.100000     0.00005000      [ACTIVE]
[02:12:48.232] cswin_unet.stage_up2.0.norm2.weight                0.100000     0.00005000      [ACTIVE]
[02:12:48.232] cswin_unet.stage_up2.0.norm2.bias                  0.100000     0.00005000      [ACTIVE]
[02:12:48.232] cswin_unet.stage_up2.1.norm1.weight                0.100000     0.00005000      [ACTIVE]
[02:12:48.232] cswin_unet.stage_up2.1.norm1.bias                  0.100000     0.00005000      [ACTIVE]
[02:12:48.232] cswin_unet.stage_up2.1.norm2.weight                0.100000     0.00005000      [ACTIVE]
[02:12:48.232] cswin_unet.stage_up2.1.norm2.bias                  0.100000     0.00005000      [ACTIVE]
[02:12:48.232] cswin_unet.stage_up1.0.norm1.weight                0.100000     0.00005000      [ACTIVE]
[02:12:48.232] cswin_unet.stage_up1.0.norm1.bias                  0.100000     0.00005000      [ACTIVE]
[02:12:48.232] cswin_unet.stage_up1.0.norm2.weight                0.100000     0.00005000      [ACTIVE]
[02:12:48.232] cswin_unet.stage_up1.0.norm2.bias                  0.100000     0.00005000      [ACTIVE]
[02:12:48.232] cswin_unet.norm_up.weight                          0.100000     0.00005000      [ACTIVE]
[02:12:48.232] cswin_unet.norm_up.bias                            0.100000     0.00005000      [ACTIVE]
[02:12:48.232] cswin_unet.stage2.0.proj.weight                    0.090791     0.00004540      [ACTIVE]
[02:12:48.232] cswin_unet.upsample3.down.bias                     0.090031     0.00004502      [ACTIVE]
[02:12:48.232] cswin_unet.stage2.0.attns.1.get_v.weight           0.087749     0.00004387      [ACTIVE]
[02:12:48.232] cswin_unet.stage_up2.0.proj.bias                   0.087308     0.00004365      [ACTIVE]
[02:12:48.232] cswin_unet.concat_linear4.bias                     0.085130     0.00004257      [ACTIVE]
[02:12:48.232] cswin_unet.upsample3.encoder.bias                  0.084580     0.00004229      [ACTIVE]
[02:12:48.232] cswin_unet.stage2.0.mlp.fc1.weight                 0.083540     0.00004177      [ACTIVE]
[02:12:48.232] cswin_unet.stage2.0.attns.0.get_v.weight           0.081607     0.00004080      [ACTIVE]
[02:12:48.232] cswin_unet.stage_up2.0.attns.0.get_v.bias          0.078133     0.00003907      [ACTIVE]
[02:12:48.232] cswin_unet.stage_up2.0.attns.1.get_v.bias          0.077419     0.00003871      [ACTIVE]
[02:12:48.232] cswin_unet.upsample1.encoder.bias                  0.075301     0.00003765      [ACTIVE]
[02:12:48.234] cswin_unet.stage2.1.mlp.fc1.weight                 0.073541     0.00003677      [ACTIVE]
[02:12:48.234] cswin_unet.stage_up1.0.proj.bias                   0.073372     0.00003669      [ACTIVE]
[02:12:48.234] cswin_unet.stage2.0.mlp.fc2.weight                 0.072229     0.00003611      [ACTIVE]
[02:12:48.234] cswin_unet.stage2.1.qkv.weight                     0.071598     0.00003580      [ACTIVE]
[02:12:48.234] cswin_unet.stage2.1.attns.1.get_v.weight           0.071340     0.00003567      [ACTIVE]
[02:12:48.234] cswin_unet.stage2.1.attns.0.get_v.weight           0.069726     0.00003486      [ACTIVE]
[02:12:48.234] cswin_unet.stage2.0.mlp.fc2.bias                   0.069058     0.00003453      [ACTIVE]
[02:12:48.234] cswin_unet.stage_up2.0.attns.1.get_v.weight        0.063125     0.00003156      [ACTIVE]
[02:12:48.234] cswin_unet.upsample3.out.bias                      0.061629     0.00003081      [ACTIVE]
[02:12:48.234] cswin_unet.stage1_conv_embed.2.weight              0.060292     0.00003015      [ACTIVE]
[02:12:48.234] cswin_unet.stage_up1.0.mlp.fc2.bias                0.059944     0.00002997      [ACTIVE]
[02:12:48.234] cswin_unet.stage_up2.0.attns.0.get_v.weight        0.058436     0.00002922      [ACTIVE]
[02:12:48.234] cswin_unet.stage2.1.mlp.fc2.bias                   0.056394     0.00002820      [ACTIVE]
[02:12:48.234] cswin_unet.stage1.0.qkv.bias                       0.054918     0.00002746      [ACTIVE]
[02:12:48.234] cswin_unet.stage_up2.1.proj.bias                   0.053372     0.00002669      [ACTIVE]
[02:12:48.234] cswin_unet.stage_up1.0.attns.1.get_v.weight        0.052145     0.00002607      [ACTIVE]
[02:12:48.234] cswin_unet.stage_up2.0.proj.weight                 0.051453     0.00002573      [ACTIVE]
[02:12:48.234] cswin_unet.stage_up1.0.attns.0.get_v.weight        0.048052     0.00002403      [LOW_LR]
[02:12:48.234] cswin_unet.stage_up2.1.attns.1.get_v.weight        0.047761     0.00002388      [LOW_LR]
[02:12:48.234] cswin_unet.stage_up2.1.proj.weight                 0.047282     0.00002364      [LOW_LR]
[02:12:48.234] cswin_unet.stage2.0.qkv.weight                     0.045378     0.00002269      [LOW_LR]
[02:12:48.234] cswin_unet.stage2.1.mlp.fc2.weight                 0.043647     0.00002182      [LOW_LR]
[02:12:48.234] cswin_unet.stage_up2.0.mlp.fc1.weight              0.042382     0.00002119      [LOW_LR]
[02:12:48.234] cswin_unet.upsample1.encoder.weight                0.040880     0.00002044      [LOW_LR]
[02:12:48.234] cswin_unet.stage_up2.1.qkv.weight                  0.040631     0.00002032      [LOW_LR]
[02:12:48.234] cswin_unet.stage_up3.8.attns.1.get_v.bias          0.040239     0.00002012      [LOW_LR]
[02:12:48.235] cswin_unet.stage_up2.1.attns.0.get_v.weight        0.039694     0.00001985      [LOW_LR]
[02:12:48.235] cswin_unet.stage_up2.0.mlp.fc2.weight              0.037691     0.00001885      [LOW_LR]
[02:12:48.235] cswin_unet.stage_up2.0.qkv.weight                  0.033762     0.00001688      [LOW_LR]
[02:12:48.235] cswin_unet.stage3.1.attns.1.get_v.weight           0.032164     0.00001608      [LOW_LR]
[02:12:48.235] cswin_unet.stage_up3.8.attns.0.get_v.bias          0.031740     0.00001587      [LOW_LR]
[02:12:48.235] cswin_unet.stage_up2.1.mlp.fc1.weight              0.030236     0.00001512      [LOW_LR]
[02:12:48.235] cswin_unet.stage3.0.attns.0.get_v.weight           0.029529     0.00001476      [LOW_LR]
[02:12:48.235] cswin_unet.merge2.conv.weight                      0.028580     0.00001429      [LOW_LR]
[02:12:48.235] cswin_unet.stage3.3.attns.1.get_v.weight           0.028178     0.00001409      [LOW_LR]
[02:12:48.235] cswin_unet.stage3.2.attns.0.get_v.weight           0.027445     0.00001372      [LOW_LR]
[02:12:48.235] cswin_unet.stage3.0.attns.1.get_v.weight           0.027047     0.00001352      [LOW_LR]
[02:12:48.235] cswin_unet.stage_up2.1.mlp.fc2.bias                0.026508     0.00001325      [LOW_LR]
[02:12:48.235] cswin_unet.stage_up3.7.attns.0.get_v.bias          0.026328     0.00001316      [LOW_LR]
[02:12:48.235] cswin_unet.stage3.8.attns.0.get_v.bias             0.025847     0.00001292      [LOW_LR]
[02:12:48.236] cswin_unet.upsample4.out.bias                      0.025808     0.00001290      [LOW_LR]
[02:12:48.236] cswin_unet.stage3.6.attns.1.get_v.weight           0.025759     0.00001288      [LOW_LR]
[02:12:48.236] cswin_unet.stage3.2.attns.1.get_v.weight           0.025322     0.00001266      [LOW_LR]
[02:12:48.236] cswin_unet.upsample4.out.weight                    0.024942     0.00001247      [LOW_LR]
[02:12:48.236] cswin_unet.stage3.4.attns.1.get_v.weight           0.024855     0.00001243      [LOW_LR]
[02:12:48.236] cswin_unet.stage_up2.0.mlp.fc2.bias                0.024738     0.00001237      [LOW_LR]
[02:12:48.236] cswin_unet.stage_up4.0.attns.0.get_v.bias          0.024690     0.00001234      [LOW_LR]
[02:12:48.236] cswin_unet.stage3.4.attns.0.get_v.weight           0.024564     0.00001228      [LOW_LR]
[02:12:48.236] cswin_unet.stage_up1.0.qkv.bias                    0.024553     0.00001228      [LOW_LR]
[02:12:48.236] cswin_unet.stage3.8.attns.0.get_v.weight           0.024352     0.00001218      [LOW_LR]
[02:12:48.236] cswin_unet.stage3.5.attns.0.get_v.weight           0.024348     0.00001217      [LOW_LR]
[02:12:48.236] cswin_unet.stage3.1.attns.0.get_v.weight           0.024181     0.00001209      [LOW_LR]
[02:12:48.236] cswin_unet.stage3.3.attns.0.get_v.weight           0.023119     0.00001156      [LOW_LR]
[02:12:48.236] cswin_unet.stage_up3.1.attns.0.get_v.weight        0.022811     0.00001141      [LOW_LR]
[02:12:48.236] cswin_unet.stage1.0.mlp.fc1.bias                   0.022616     0.00001131      [LOW_LR]
[02:12:48.236] cswin_unet.stage_up3.4.attns.0.get_v.weight        0.022238     0.00001112      [LOW_LR]
[02:12:48.236] cswin_unet.stage_up2.1.mlp.fc2.weight              0.021756     0.00001088      [LOW_LR]
[02:12:48.236] cswin_unet.stage3.7.attns.0.get_v.weight           0.020750     0.00001038      [LOW_LR]
[02:12:48.236] cswin_unet.stage_up3.3.attns.0.get_v.weight        0.020519     0.00001026      [LOW_LR]
[02:12:48.236] cswin_unet.stage_up3.5.attns.0.get_v.bias          0.020461     0.00001023      [LOW_LR]
[02:12:48.236] cswin_unet.stage_up3.2.attns.0.get_v.weight        0.020026     0.00001001      [LOW_LR]
[02:12:48.236] cswin_unet.stage3.5.attns.1.get_v.weight           0.020003     0.00001000      [LOW_LR]
[02:12:48.237] cswin_unet.stage2.0.qkv.bias                       0.019985     0.00000999      [LOW_LR]
[02:12:48.237] cswin_unet.stage3.6.attns.0.get_v.weight           0.019964     0.00000998      [LOW_LR]
[02:12:48.237] cswin_unet.stage3.8.attns.1.get_v.bias             0.019942     0.00000997      [LOW_LR]
[02:12:48.237] cswin_unet.stage3.3.proj.weight                    0.019858     0.00000993      [LOW_LR]
[02:12:48.237] cswin_unet.stage2.1.qkv.bias                       0.019631     0.00000982      [LOW_LR]
[02:12:48.237] cswin_unet.stage_up3.6.attns.0.get_v.bias          0.018868     0.00000943      [LOW_LR]
[02:12:48.237] cswin_unet.stage_up3.8.mlp.fc2.bias                0.018504     0.00000925      [LOW_LR]
[02:12:48.237] cswin_unet.stage3.1.attns.0.get_v.bias             0.018390     0.00000919      [LOW_LR]
[02:12:48.237] cswin_unet.stage3.0.proj.weight                    0.018301     0.00000915      [LOW_LR]
[02:12:48.237] cswin_unet.stage_up3.8.proj.bias                   0.018197     0.00000910      [LOW_LR]
[02:12:48.237] cswin_unet.stage_up3.3.attns.1.get_v.weight        0.018145     0.00000907      [LOW_LR]
[02:12:48.237] cswin_unet.stage3.5.attns.0.get_v.bias             0.017761     0.00000888      [LOW_LR]
[02:12:48.237] cswin_unet.stage_up3.7.proj.bias                   0.017540     0.00000877      [LOW_LR]
[02:12:48.237] cswin_unet.stage3.4.proj.weight                    0.017421     0.00000871      [LOW_LR]
[02:12:48.237] cswin_unet.stage_up3.0.attns.0.get_v.weight        0.017321     0.00000866      [LOW_LR]
[02:12:48.237] cswin_unet.stage_up3.1.attns.1.get_v.weight        0.017204     0.00000860      [LOW_LR]
[02:12:48.237] cswin_unet.stage3.7.attns.0.get_v.bias             0.017108     0.00000855      [LOW_LR]
[02:12:48.237] cswin_unet.stage3.6.attns.1.get_v.bias             0.017082     0.00000854      [LOW_LR]
[02:12:48.237] cswin_unet.stage3.1.proj.weight                    0.016803     0.00000840      [LOW_LR]
[02:12:48.237] cswin_unet.stage_up3.6.proj.bias                   0.016746     0.00000837      [LOW_LR]
[02:12:48.237] cswin_unet.stage3.0.attns.1.get_v.bias             0.016550     0.00000827      [LOW_LR]
[02:12:48.237] cswin_unet.stage3.0.attns.0.get_v.bias             0.016361     0.00000818      [LOW_LR]
[02:12:48.237] cswin_unet.stage3.8.attns.1.get_v.weight           0.015870     0.00000794      [LOW_LR]
[02:12:48.237] cswin_unet.stage3.7.attns.1.get_v.weight           0.015751     0.00000788      [LOW_LR]
[02:12:48.238] cswin_unet.stage3.1.attns.1.get_v.bias             0.015638     0.00000782      [LOW_LR]
[02:12:48.238] cswin_unet.stage_up3.8.attns.0.get_v.weight        0.015613     0.00000781      [LOW_LR]
[02:12:48.238] cswin_unet.stage_up3.4.proj.bias                   0.015462     0.00000773      [LOW_LR]
[02:12:48.238] cswin_unet.stage3.5.proj.weight                    0.015407     0.00000770      [LOW_LR]
[02:12:48.238] cswin_unet.stage_up3.6.attns.0.get_v.weight        0.015380     0.00000769      [LOW_LR]
[02:12:48.238] cswin_unet.stage3.2.proj.weight                    0.015278     0.00000764      [LOW_LR]
[02:12:48.238] cswin_unet.stage_up3.4.attns.1.get_v.weight        0.015271     0.00000764      [LOW_LR]
[02:12:48.238] cswin_unet.stage_up3.2.attns.1.get_v.weight        0.015107     0.00000755      [LOW_LR]
[02:12:48.238] cswin_unet.stage3.6.proj.weight                    0.015071     0.00000754      [LOW_LR]
[02:12:48.238] cswin_unet.stage_up3.8.attns.1.get_v.weight        0.015052     0.00000753      [LOW_LR]
[02:12:48.238] cswin_unet.stage_up3.7.mlp.fc2.bias                0.015051     0.00000753      [LOW_LR]
[02:12:48.238] cswin_unet.stage_up3.0.attns.1.get_v.weight        0.014569     0.00000728      [LOW_LR]
[02:12:48.238] cswin_unet.stage_up3.5.proj.bias                   0.014556     0.00000728      [LOW_LR]
[02:12:48.238] cswin_unet.stage_up3.5.attns.1.get_v.weight        0.014537     0.00000727      [LOW_LR]
[02:12:48.238] cswin_unet.stage3.6.attns.0.get_v.bias             0.014491     0.00000725      [LOW_LR]
[02:12:48.238] cswin_unet.stage_up3.5.mlp.fc2.bias                0.014475     0.00000724      [LOW_LR]
[02:12:48.238] cswin_unet.stage_up3.1.attns.0.get_v.bias          0.014442     0.00000722      [LOW_LR]
[02:12:48.239] cswin_unet.stage_up3.6.attns.1.get_v.bias          0.014351     0.00000718      [LOW_LR]
[02:12:48.239] cswin_unet.stage3.8.proj.weight                    0.014325     0.00000716      [LOW_LR]
[02:12:48.239] cswin_unet.stage3.4.qkv.weight                     0.014249     0.00000712      [LOW_LR]
[02:12:48.239] cswin_unet.stage_up3.4.attns.0.get_v.bias          0.014061     0.00000703      [LOW_LR]
[02:12:48.239] cswin_unet.stage3.3.attns.1.get_v.bias             0.014012     0.00000701      [LOW_LR]
[02:12:48.239] cswin_unet.stage_up3.6.mlp.fc2.bias                0.013929     0.00000696      [LOW_LR]
[02:12:48.239] cswin_unet.stage_up3.7.attns.0.get_v.weight        0.013926     0.00000696      [LOW_LR]
[02:12:48.239] cswin_unet.stage_up3.3.proj.weight                 0.013836     0.00000692      [LOW_LR]
[02:12:48.239] cswin_unet.stage_up3.8.proj.weight                 0.013554     0.00000678      [LOW_LR]
[02:12:48.239] cswin_unet.stage_up3.5.attns.0.get_v.weight        0.013478     0.00000674      [LOW_LR]
[02:12:48.239] cswin_unet.stage_up3.4.mlp.fc2.bias                0.013241     0.00000662      [LOW_LR]
[02:12:48.239] cswin_unet.stage3.8.qkv.weight                     0.012872     0.00000644      [LOW_LR]
[02:12:48.239] cswin_unet.stage3.7.proj.weight                    0.012787     0.00000639      [LOW_LR]
[02:12:48.239] cswin_unet.stage3.2.proj.bias                      0.012760     0.00000638      [LOW_LR]
[02:12:48.239] cswin_unet.stage3.6.qkv.weight                     0.012731     0.00000637      [LOW_LR]
[02:12:48.239] cswin_unet.stage_up3.6.attns.1.get_v.weight        0.012656     0.00000633      [LOW_LR]
[02:12:48.239] cswin_unet.stage3.4.proj.bias                      0.012647     0.00000632      [LOW_LR]
[02:12:48.239] cswin_unet.stage3.1.proj.bias                      0.012636     0.00000632      [LOW_LR]
[02:12:48.239] cswin_unet.stage2.0.mlp.fc1.bias                   0.012634     0.00000632      [LOW_LR]
[02:12:48.239] cswin_unet.stage3.3.qkv.weight                     0.012604     0.00000630      [LOW_LR]
[02:12:48.239] cswin_unet.stage3.4.attns.1.get_v.bias             0.012587     0.00000629      [LOW_LR]
[02:12:48.239] cswin_unet.stage_up3.3.attns.0.get_v.bias          0.012502     0.00000625      [LOW_LR]
[02:12:48.239] cswin_unet.stage_up3.3.proj.bias                   0.012393     0.00000620      [LOW_LR]
[02:12:48.239] cswin_unet.stage3.7.proj.bias                      0.012338     0.00000617      [LOW_LR]
[02:12:48.239] cswin_unet.stage_up3.2.proj.bias                   0.012333     0.00000617      [LOW_LR]
[02:12:48.239] cswin_unet.stage3.6.proj.bias                      0.012296     0.00000615      [LOW_LR]
[02:12:48.239] cswin_unet.stage_up3.7.attns.1.get_v.bias          0.012219     0.00000611      [LOW_LR]
[02:12:48.239] cswin_unet.stage_up3.4.proj.weight                 0.012206     0.00000610      [LOW_LR]
[02:12:48.239] cswin_unet.stage3.2.attns.0.get_v.bias             0.012142     0.00000607      [LOW_LR]
[02:12:48.239] cswin_unet.stage3.7.attns.1.get_v.bias             0.012112     0.00000606      [LOW_LR]
[02:12:48.239] cswin_unet.stage3.8.proj.bias                      0.012110     0.00000605      [LOW_LR]
[02:12:48.239] cswin_unet.stage_up3.1.proj.weight                 0.012094     0.00000605      [LOW_LR]
[02:12:48.239] cswin_unet.merge1.conv.bias                        0.011854     0.00000593      [LOW_LR]
[02:12:48.239] cswin_unet.stage_up3.2.mlp.fc2.bias                0.011823     0.00000591      [LOW_LR]
[02:12:48.239] cswin_unet.stage3.3.proj.bias                      0.011813     0.00000591      [LOW_LR]
[02:12:48.239] cswin_unet.stage_up3.7.proj.weight                 0.011669     0.00000583      [LOW_LR]
[02:12:48.240] cswin_unet.stage_up3.5.proj.weight                 0.011606     0.00000580      [LOW_LR]
[02:12:48.240] cswin_unet.stage3.2.mlp.fc2.bias                   0.011599     0.00000580      [LOW_LR]
[02:12:48.240] cswin_unet.stage3.8.mlp.fc2.bias                   0.011575     0.00000579      [LOW_LR]
[02:12:48.240] cswin_unet.stage_up3.3.mlp.fc2.bias                0.011514     0.00000576      [LOW_LR]
[02:12:48.240] cswin_unet.stage3.5.proj.bias                      0.011466     0.00000573      [LOW_LR]
[02:12:48.240] cswin_unet.stage_up3.1.proj.bias                   0.011417     0.00000571      [LOW_LR]
[02:12:48.240] cswin_unet.stage_up3.6.proj.weight                 0.011283     0.00000564      [LOW_LR]
[02:12:48.240] cswin_unet.stage_up3.7.attns.1.get_v.weight        0.011220     0.00000561      [LOW_LR]
[02:12:48.240] cswin_unet.stage_up3.3.attns.1.get_v.bias          0.011202     0.00000560      [LOW_LR]
[02:12:48.240] cswin_unet.stage3.0.qkv.weight                     0.011082     0.00000554      [LOW_LR]
[02:12:48.240] cswin_unet.stage_up3.0.attns.0.get_v.bias          0.011036     0.00000552      [LOW_LR]
[02:12:48.240] cswin_unet.stage3.2.attns.1.get_v.bias             0.011004     0.00000550      [LOW_LR]
[02:12:48.240] cswin_unet.stage3.0.proj.bias                      0.010847     0.00000542      [LOW_LR]
[02:12:48.240] cswin_unet.stage3.5.mlp.fc2.bias                   0.010663     0.00000533      [LOW_LR]
[02:12:48.240] cswin_unet.stage_up3.8.qkv.weight                  0.010541     0.00000527      [LOW_LR]
[02:12:48.240] cswin_unet.stage_up3.5.attns.1.get_v.bias          0.010421     0.00000521      [LOW_LR]
[02:12:48.240] cswin_unet.stage3.1.qkv.weight                     0.010412     0.00000521      [LOW_LR]
[02:12:48.240] cswin_unet.stage3.4.attns.0.get_v.bias             0.010247     0.00000512      [LOW_LR]
[02:12:48.240] cswin_unet.stage_up1.0.mlp.fc1.bias                0.010211     0.00000511      [LOW_LR]
[02:12:48.240] cswin_unet.stage3.4.mlp.fc2.bias                   0.010193     0.00000510      [LOW_LR]
[02:12:48.240] cswin_unet.stage3.3.mlp.fc2.bias                   0.010178     0.00000509      [LOW_LR]
[02:12:48.240] cswin_unet.stage_up2.0.qkv.bias                    0.010050     0.00000502      [LOW_LR]
[02:12:48.240] cswin_unet.stage3.5.qkv.weight                     0.009834     0.00000492      [LOW_LR]
[02:12:48.241] cswin_unet.stage3.3.attns.0.get_v.bias             0.009808     0.00000490      [LOW_LR]
[02:12:48.241] cswin_unet.stage_up3.4.attns.1.get_v.bias          0.009788     0.00000489      [LOW_LR]
[02:12:48.241] cswin_unet.stage3.7.mlp.fc2.bias                   0.009771     0.00000489      [LOW_LR]
[02:12:48.241] cswin_unet.stage2.1.mlp.fc1.bias                   0.009663     0.00000483      [LOW_LR]
[02:12:48.241] cswin_unet.stage3.6.mlp.fc2.bias                   0.009498     0.00000475      [LOW_LR]
[02:12:48.241] cswin_unet.stage_up3.2.proj.weight                 0.009438     0.00000472      [LOW_LR]
[02:12:48.241] cswin_unet.stage_up3.2.attns.0.get_v.bias          0.009366     0.00000468      [LOW_LR]
[02:12:48.241] cswin_unet.stage3.2.qkv.weight                     0.009329     0.00000466      [LOW_LR]
[02:12:48.241] cswin_unet.stage_up2.1.qkv.bias                    0.008996     0.00000450      [LOW_LR]
[02:12:48.241] cswin_unet.stage3.7.qkv.weight                     0.008898     0.00000445      [LOW_LR]
[02:12:48.241] cswin_unet.stage_up3.0.attns.1.get_v.bias          0.008757     0.00000438      [LOW_LR]
[02:12:48.241] cswin_unet.stage3.0.mlp.fc2.weight                 0.008581     0.00000429      [LOW_LR]
[02:12:48.241] cswin_unet.stage_up3.0.proj.weight                 0.008501     0.00000425      [LOW_LR]
[02:12:48.241] cswin_unet.stage3.1.mlp.fc2.bias                   0.008443     0.00000422      [LOW_LR]
[02:12:48.241] cswin_unet.stage3.5.attns.1.get_v.bias             0.008419     0.00000421      [LOW_LR]
[02:12:48.241] cswin_unet.stage_up3.1.mlp.fc2.bias                0.008269     0.00000413      [LOW_LR]
[02:12:48.241] cswin_unet.stage_up3.3.qkv.weight                  0.008218     0.00000411      [LOW_LR]
[02:12:48.241] cswin_unet.stage_up3.6.qkv.weight                  0.007887     0.00000394      [LOW_LR]
[02:12:48.241] cswin_unet.stage_up3.7.qkv.weight                  0.007744     0.00000387      [LOW_LR]
[02:12:48.241] cswin_unet.stage_up3.5.qkv.weight                  0.007517     0.00000376      [LOW_LR]
[02:12:48.241] cswin_unet.stage_up3.0.proj.bias                   0.007408     0.00000370      [LOW_LR]
[02:12:48.241] cswin_unet.stage_up3.4.qkv.weight                  0.007364     0.00000368      [LOW_LR]
[02:12:48.241] cswin_unet.stage_up3.1.attns.1.get_v.bias          0.007354     0.00000368      [LOW_LR]
[02:12:48.241] cswin_unet.stage_up3.2.attns.1.get_v.bias          0.007183     0.00000359      [LOW_LR]
[02:12:48.241] cswin_unet.stage3.0.mlp.fc1.weight                 0.007077     0.00000354      [LOW_LR]
[02:12:48.242] cswin_unet.stage_up3.2.qkv.weight                  0.006766     0.00000338      [LOW_LR]
[02:12:48.242] cswin_unet.stage_up3.8.mlp.fc1.weight              0.006113     0.00000306      [LOW_LR]
[02:12:48.242] cswin_unet.stage3.0.mlp.fc2.bias                   0.006038     0.00000302      [LOW_LR]
[02:12:48.242] cswin_unet.stage_up3.1.qkv.weight                  0.005596     0.00000280      [LOW_LR]
[02:12:48.242] cswin_unet.stage_up3.0.mlp.fc2.weight              0.005322     0.00000266      [LOW_LR]
[02:12:48.242] cswin_unet.stage3.1.mlp.fc2.weight                 0.005254     0.00000263      [LOW_LR]
[02:12:48.242] cswin_unet.stage_up3.0.mlp.fc2.bias                0.005247     0.00000262      [LOW_LR]
[02:12:48.242] cswin_unet.stage_up2.0.mlp.fc1.bias                0.005107     0.00000255      [LOW_LR]
[02:12:48.242] cswin_unet.stage3.3.mlp.fc2.weight                 0.005018     0.00000251      [LOW_LR]
[02:12:48.242] cswin_unet.stage3.6.mlp.fc1.weight                 0.004948     0.00000247      [LOW_LR]
[02:12:48.242] cswin_unet.stage_up3.8.mlp.fc2.weight              0.004777     0.00000239      [LOW_LR]
[02:12:48.242] cswin_unet.stage_up3.6.mlp.fc1.weight              0.004750     0.00000237      [LOW_LR]
[02:12:48.242] cswin_unet.stage3.6.mlp.fc2.weight                 0.004644     0.00000232      [LOW_LR]
[02:12:48.242] cswin_unet.stage3.1.mlp.fc1.weight                 0.004634     0.00000232      [LOW_LR]
[02:12:48.242] cswin_unet.stage3.4.mlp.fc2.weight                 0.004622     0.00000231      [LOW_LR]
[02:12:48.242] cswin_unet.stage3.2.mlp.fc2.weight                 0.004599     0.00000230      [LOW_LR]
[02:12:48.242] cswin_unet.stage_up3.8.qkv.bias                    0.004523     0.00000226      [LOW_LR]
[02:12:48.242] cswin_unet.stage3.7.mlp.fc1.weight                 0.004516     0.00000226      [LOW_LR]
[02:12:48.242] cswin_unet.stage_up3.6.mlp.fc2.weight              0.004458     0.00000223      [LOW_LR]
[02:12:48.242] cswin_unet.stage3.7.mlp.fc2.weight                 0.004349     0.00000217      [LOW_LR]
[02:12:48.242] cswin_unet.stage3.3.mlp.fc1.weight                 0.004336     0.00000217      [LOW_LR]
[02:12:48.242] cswin_unet.stage3.4.mlp.fc1.weight                 0.004311     0.00000216      [LOW_LR]
[02:12:48.242] cswin_unet.stage_up3.1.mlp.fc2.weight              0.004256     0.00000213      [LOW_LR]
[02:12:48.242] cswin_unet.stage3.5.mlp.fc2.weight                 0.004230     0.00000212      [LOW_LR]
[02:12:48.242] cswin_unet.stage_up3.7.mlp.fc2.weight              0.004120     0.00000206      [LOW_LR]
[02:12:48.243] cswin_unet.stage3.2.mlp.fc1.weight                 0.004101     0.00000205      [LOW_LR]
[02:12:48.243] cswin_unet.stage3.8.mlp.fc1.weight                 0.003963     0.00000198      [LOW_LR]
[02:12:48.243] cswin_unet.stage3.5.mlp.fc1.weight                 0.003905     0.00000195      [LOW_LR]
[02:12:48.243] cswin_unet.stage_up3.7.mlp.fc1.weight              0.003862     0.00000193      [LOW_LR]
[02:12:48.243] cswin_unet.stage_up3.2.mlp.fc2.weight              0.003842     0.00000192      [LOW_LR]
[02:12:48.243] cswin_unet.stage_up3.4.mlp.fc2.weight              0.003841     0.00000192      [LOW_LR]
[02:12:48.243] cswin_unet.stage_up3.3.mlp.fc2.weight              0.003722     0.00000186      [LOW_LR]
[02:12:48.243] cswin_unet.stage3.8.mlp.fc2.weight                 0.003659     0.00000183      [LOW_LR]
[02:12:48.243] cswin_unet.stage_up3.0.qkv.weight                  0.003622     0.00000181      [LOW_LR]
[02:12:48.243] cswin_unet.stage3.0.qkv.bias                       0.003598     0.00000180      [LOW_LR]
[02:12:48.243] cswin_unet.stage_up3.5.mlp.fc2.weight              0.003539     0.00000177      [LOW_LR]
[02:12:48.243] cswin_unet.stage_up2.1.mlp.fc1.bias                0.003497     0.00000175      [LOW_LR]
[02:12:48.243] cswin_unet.stage3.6.qkv.bias                       0.003410     0.00000171      [LOW_LR]
[02:12:48.243] cswin_unet.stage3.1.qkv.bias                       0.003405     0.00000170      [LOW_LR]
[02:12:48.243] cswin_unet.stage3.8.qkv.bias                       0.003382     0.00000169      [LOW_LR]
[02:12:48.243] cswin_unet.stage1_conv_embed.0.bias                0.003376     0.00000169      [LOW_LR]
[02:12:48.244] cswin_unet.stage4.0.attns.0.get_v.bias             0.003141     0.00000157      [LOW_LR]
[02:12:48.244] cswin_unet.stage_up3.4.mlp.fc1.weight              0.003076     0.00000154      [LOW_LR]
[02:12:48.244] cswin_unet.stage_up4.0.attns.0.get_v.weight        0.002970     0.00000149      [LOW_LR]
[02:12:48.244] cswin_unet.stage_up3.7.qkv.bias                    0.002924     0.00000146      [LOW_LR]
[02:12:48.244] cswin_unet.stage_up3.6.qkv.bias                    0.002873     0.00000144      [LOW_LR]
[02:12:48.244] cswin_unet.stage_up3.0.mlp.fc1.weight              0.002870     0.00000144      [LOW_LR]
[02:12:48.244] cswin_unet.stage_up3.5.mlp.fc1.weight              0.002778     0.00000139      [LOW_LR]
[02:12:48.244] cswin_unet.stage3.4.qkv.bias                       0.002751     0.00000138      [LOW_LR]
[02:12:48.244] cswin_unet.stage3.2.qkv.bias                       0.002726     0.00000136      [LOW_LR]
[02:12:48.244] cswin_unet.stage_up3.3.mlp.fc1.weight              0.002533     0.00000127      [LOW_LR]
[02:12:48.244] cswin_unet.stage_up3.5.qkv.bias                    0.002510     0.00000126      [LOW_LR]
[02:12:48.244] cswin_unet.stage3.7.qkv.bias                       0.002453     0.00000123      [LOW_LR]
[02:12:48.244] cswin_unet.stage_up3.2.qkv.bias                    0.002433     0.00000122      [LOW_LR]
[02:12:48.244] cswin_unet.stage3.3.qkv.bias                       0.002400     0.00000120      [LOW_LR]
[02:12:48.244] cswin_unet.stage_up3.1.mlp.fc1.weight              0.002380     0.00000119      [LOW_LR]
[02:12:48.244] cswin_unet.stage_up3.3.qkv.bias                    0.002245     0.00000112      [LOW_LR]
[02:12:48.244] cswin_unet.stage_up3.4.qkv.bias                    0.002208     0.00000110      [LOW_LR]
[02:12:48.244] cswin_unet.stage_up3.2.mlp.fc1.weight              0.002205     0.00000110      [LOW_LR]
[02:12:48.244] cswin_unet.stage_up3.1.qkv.bias                    0.002186     0.00000109      [LOW_LR]
[02:12:48.244] cswin_unet.stage3.5.qkv.bias                       0.002175     0.00000109      [LOW_LR]
[02:12:48.244] cswin_unet.stage_up3.0.qkv.bias                    0.001961     0.00000098      [LOW_LR]
[02:12:48.244] cswin_unet.stage4.0.attns.0.get_v.weight           0.001651     0.00000083      [LOW_LR]
[02:12:48.244] cswin_unet.stage_up4.0.proj.bias                   0.001527     0.00000076      [LOW_LR]
[02:12:48.244] cswin_unet.merge2.conv.bias                        0.001460     0.00000073      [LOW_LR]
[02:12:48.245] cswin_unet.stage3.0.mlp.fc1.bias                   0.001218     0.00000061      [LOW_LR]
[02:12:48.245] cswin_unet.stage_up4.0.proj.weight                 0.001029     0.00000051      [LOW_LR]
[02:12:48.245] cswin_unet.stage_up4.0.mlp.fc1.weight              0.000915     0.00000046      [LOW_LR]
[02:12:48.245] cswin_unet.stage_up3.8.mlp.fc1.bias                0.000856     0.00000043      [LOW_LR]
[02:12:48.245] cswin_unet.stage_up4.0.mlp.fc2.bias                0.000784     0.00000039      [LOW_LR]
[02:12:48.245] cswin_unet.stage4.0.proj.weight                    0.000773     0.00000039      [LOW_LR]
[02:12:48.245] cswin_unet.stage_up4.0.mlp.fc2.weight              0.000762     0.00000038      [LOW_LR]
[02:12:48.245] cswin_unet.stage_up3.6.mlp.fc1.bias                0.000641     0.00000032      [LOW_LR]
[02:12:48.245] cswin_unet.stage3.6.mlp.fc1.bias                   0.000605     0.00000030      [LOW_LR]
[02:12:48.245] cswin_unet.stage3.1.mlp.fc1.bias                   0.000581     0.00000029      [LOW_LR]
[02:12:48.245] cswin_unet.stage3.7.mlp.fc1.bias                   0.000541     0.00000027      [LOW_LR]
[02:12:48.245] cswin_unet.stage3.3.mlp.fc1.bias                   0.000536     0.00000027      [LOW_LR]
[02:12:48.245] cswin_unet.stage3.8.mlp.fc1.bias                   0.000522     0.00000026      [LOW_LR]
[02:12:48.245] cswin_unet.stage3.4.mlp.fc1.bias                   0.000500     0.00000025      [LOW_LR]
[02:12:48.245] cswin_unet.stage_up3.7.mlp.fc1.bias                0.000497     0.00000025      [LOW_LR]
[02:12:48.245] cswin_unet.stage3.5.mlp.fc1.bias                   0.000492     0.00000025      [LOW_LR]
[02:12:48.245] cswin_unet.stage3.2.mlp.fc1.bias                   0.000485     0.00000024      [LOW_LR]
[02:12:48.245] cswin_unet.stage_up3.0.mlp.fc1.bias                0.000452     0.00000023      [LOW_LR]
[02:12:48.245] cswin_unet.stage4.0.mlp.fc2.weight                 0.000433     0.00000022      [LOW_LR]
[02:12:48.245] cswin_unet.stage_up4.0.qkv.weight                  0.000414     0.00000021      [LOW_LR]
[02:12:48.245] cswin_unet.stage_up3.4.mlp.fc1.bias                0.000396     0.00000020      [LOW_LR]
[02:12:48.245] cswin_unet.stage_up4.0.qkv.bias                    0.000362     0.00000018      [LOW_LR]
[02:12:48.245] cswin_unet.stage4.0.mlp.fc1.weight                 0.000361     0.00000018      [LOW_LR]
[02:12:48.245] cswin_unet.stage_up3.5.mlp.fc1.bias                0.000359     0.00000018      [LOW_LR]
[02:12:48.245] cswin_unet.stage_up3.3.mlp.fc1.bias                0.000345     0.00000017      [LOW_LR]
[02:12:48.245] cswin_unet.merge3.conv.weight                      0.000274     0.00000014      [LOW_LR]
[02:12:48.245] cswin_unet.stage_up3.1.mlp.fc1.bias                0.000272     0.00000014      [LOW_LR]
[02:12:48.245] cswin_unet.stage_up3.2.mlp.fc1.bias                0.000253     0.00000013      [LOW_LR]
[02:12:48.245] cswin_unet.stage4.0.proj.bias                      0.000227     0.00000011      [LOW_LR]
[02:12:48.245] cswin_unet.stage4.0.qkv.weight                     0.000211     0.00000011      [LOW_LR]
[02:12:48.245] cswin_unet.stage_up4.0.mlp.fc1.bias                0.000120     0.00000006      [LOW_LR]
[02:12:48.245] cswin_unet.stage4.0.mlp.fc2.bias                   0.000116     0.00000006      [LOW_LR]
[02:12:48.245] cswin_unet.stage4.0.qkv.bias                       0.000105     0.00000005      [LOW_LR]
[02:12:48.245] cswin_unet.stage4.0.mlp.fc1.bias                   0.000047     0.00000002      [LOW_LR]
[02:12:48.245] cswin_unet.upsample4.encoder.weight                0.000009     0.00000000      [LOW_LR]
[02:12:48.245] cswin_unet.merge3.conv.bias                        0.000006     0.00000000      [LOW_LR]
[02:12:48.245] cswin_unet.upsample4.encoder.bias                  0.000002     0.00000000      [LOW_LR]
[02:12:48.245] cswin_unet.upsample4.down.weight                   0.000002     0.00000000      [LOW_LR]
[02:12:48.245] cswin_unet.upsample4.down.bias                     0.000002     0.00000000      [LOW_LR]
[02:12:48.247] --------------------------------------------------------------------------------
[02:12:48.247] Total layers: 463, High LR layers: 189, Low LR layers: 274
[02:12:48.247] ================================================================================

[02:13:01.183] Epoch 24, Iter 10400: loss=0.0601, ce=0.0054, dice=0.0966, grad_norm=0.318265
[02:13:04.720] Epoch 24, Iter 10410: loss=0.2061, ce=0.0032, dice=0.3414, grad_norm=0.022265
[02:13:08.258] Epoch 24, Iter 10420: loss=0.0243, ce=0.0025, dice=0.0389, grad_norm=0.113183
[02:13:11.813] Epoch 24, Iter 10430: loss=0.0903, ce=0.0028, dice=0.1487, grad_norm=0.439039
[02:13:15.342] Epoch 24, Iter 10440: loss=0.0208, ce=0.0062, dice=0.0306, grad_norm=0.056948
[02:13:18.886] Epoch 24, Iter 10450: loss=0.2099, ce=0.0042, dice=0.3470, grad_norm=0.025390
[02:13:22.418] Epoch 24, Iter 10460: loss=0.0226, ce=0.0074, dice=0.0327, grad_norm=0.055702
[02:13:25.968] Epoch 24, Iter 10470: loss=0.0346, ce=0.0030, dice=0.0556, grad_norm=0.087314
[02:13:29.504] Epoch 24, Iter 10480: loss=0.0143, ce=0.0014, dice=0.0230, grad_norm=0.077940
[02:13:33.049] Epoch 24, Iter 10490: loss=0.1026, ce=0.0011, dice=0.1703, grad_norm=0.295452
[02:13:36.582] Epoch 24, Iter 10500: loss=0.0279, ce=0.0030, dice=0.0444, grad_norm=0.201557
[02:13:40.138] Epoch 24, Iter 10510: loss=0.0199, ce=0.0052, dice=0.0296, grad_norm=0.053395
[02:13:43.687] Epoch 24, Iter 10520: loss=0.0318, ce=0.0023, dice=0.0515, grad_norm=0.098280
[02:13:47.241] Epoch 24, Iter 10530: loss=0.0489, ce=0.0038, dice=0.0789, grad_norm=0.224382
[02:13:50.779] Epoch 24, Iter 10540: loss=0.0183, ce=0.0044, dice=0.0275, grad_norm=0.042979
[02:13:54.339] Epoch 24, Iter 10550: loss=0.0210, ce=0.0025, dice=0.0333, grad_norm=0.070080
[02:13:57.875] Epoch 24, Iter 10560: loss=0.0233, ce=0.0040, dice=0.0361, grad_norm=0.096033
[02:14:01.423] Epoch 24, Iter 10570: loss=0.0236, ce=0.0084, dice=0.0337, grad_norm=0.055177
[02:14:04.952] Epoch 24, Iter 10580: loss=0.0422, ce=0.0035, dice=0.0681, grad_norm=0.209449
[02:14:08.506] Epoch 24, Iter 10590: loss=0.0247, ce=0.0031, dice=0.0392, grad_norm=0.140112
[02:14:12.048] Epoch 24, Iter 10600: loss=0.0206, ce=0.0067, dice=0.0298, grad_norm=0.046999
[02:14:15.594] Epoch 24, Iter 10610: loss=0.0448, ce=0.0042, dice=0.0719, grad_norm=0.360816
[02:14:19.146] Epoch 24, Iter 10620: loss=0.0630, ce=0.0023, dice=0.1035, grad_norm=0.214234
[02:14:22.703] Epoch 24, Iter 10630: loss=0.0226, ce=0.0049, dice=0.0343, grad_norm=0.096820
[02:14:26.261] Epoch 24, Iter 10640: loss=0.0230, ce=0.0062, dice=0.0342, grad_norm=0.047149
[02:14:29.858] Epoch 24, Iter 10650: loss=0.0194, ce=0.0042, dice=0.0295, grad_norm=0.065345
[02:14:33.414] Epoch 24, Iter 10660: loss=0.0250, ce=0.0042, dice=0.0389, grad_norm=0.078049
[02:14:36.961] Epoch 24, Iter 10670: loss=0.1920, ce=0.0037, dice=0.3175, grad_norm=0.654561
[02:14:40.499] Epoch 24, Iter 10680: loss=0.0224, ce=0.0060, dice=0.0332, grad_norm=0.056939
[02:14:44.049] Epoch 24, Iter 10690: loss=0.0626, ce=0.0057, dice=0.1005, grad_norm=0.415518
[02:14:47.584] Epoch 24, Iter 10700: loss=0.0411, ce=0.0025, dice=0.0668, grad_norm=0.135724
[02:14:51.125] Epoch 24, Iter 10710: loss=0.0285, ce=0.0054, dice=0.0439, grad_norm=0.166425
[02:14:54.668] Epoch 24, Iter 10720: loss=0.0574, ce=0.0039, dice=0.0930, grad_norm=0.293505
[02:14:58.206] Epoch 24, Iter 10730: loss=0.1285, ce=0.0024, dice=0.2126, grad_norm=1.033730
[02:15:01.763] Epoch 24, Iter 10740: loss=0.0138, ce=0.0035, dice=0.0207, grad_norm=0.103299
[02:15:05.338] Epoch 24, Iter 10750: loss=0.1816, ce=0.0059, dice=0.2988, grad_norm=0.732070
[02:15:08.903] Epoch 24, Iter 10760: loss=0.0253, ce=0.0048, dice=0.0389, grad_norm=0.125451
[02:15:12.459] Epoch 24, Iter 10770: loss=0.0149, ce=0.0032, dice=0.0227, grad_norm=0.060358
[02:15:15.991] Epoch 24, Iter 10780: loss=0.0218, ce=0.0065, dice=0.0320, grad_norm=0.044287
[02:15:19.545] Epoch 24, Iter 10790: loss=0.1133, ce=0.0059, dice=0.1848, grad_norm=0.387304
[02:15:23.101] Epoch 24, Iter 10800: loss=0.0276, ce=0.0041, dice=0.0433, grad_norm=0.102415
[02:15:26.658] Epoch 24, Iter 10810: loss=0.2063, ce=0.0017, dice=0.3427, grad_norm=0.027047
[02:15:30.193] Epoch 24, Iter 10820: loss=0.0271, ce=0.0032, dice=0.0430, grad_norm=0.144395
[02:15:32.516] Epoch 24: Avg Loss=0.0524, CE=0.0042, Dice=0.0846
[02:15:32.595] save model to ./finetune_tpgm_surgical_lits17\finetuned_epoch_24.pth
[02:15:32.748] save final model to ./finetune_tpgm_surgical_lits17\finetuned_final.pth
