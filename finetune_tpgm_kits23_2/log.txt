[13:15:06.150] Namespace(root_path='./datasets/kits23/train_npz', dataset='kits23', list_dir='./lists/kits23', num_classes=4, output_dir='./finetune_tpgm_kits23_2', max_iterations=10000, max_epochs=50, batch_size=32, n_gpu=1, deterministic=1, base_lr=0.0005, img_size=224, seed=1234, cfg='configs/finetune.yaml', pretrained_path='./pretrain/epoch_149.pth', data_fraction=0.1, freeze_layers=0, proj_freq=10, max_iters=5, proj_lr=0.01, norm_mode='mars', pgm_data_fraction=0.05, opts=None, zip=False, cache_mode='part', resume=None, accumulation_steps=None, use_checkpoint=False, amp_opt_level='O1', tag=None, eval=False, throughput=False)
[13:15:06.159] Using 9522/95221 samples (10.0%) for finetuning
[13:15:30.121] Namespace(root_path='./datasets/kits23/train_npz', dataset='kits23', list_dir='./lists/kits23', num_classes=4, output_dir='./finetune_tpgm_kits23_2', max_iterations=10000, max_epochs=50, batch_size=32, n_gpu=1, deterministic=1, base_lr=0.0005, img_size=224, seed=1234, cfg='configs/finetune.yaml', pretrained_path='./pretrain/epoch_149.pth', data_fraction=0.1, freeze_layers=0, proj_freq=10, max_iters=5, proj_lr=0.01, norm_mode='mars', pgm_data_fraction=0.05, opts=None, zip=False, cache_mode='part', resume=None, accumulation_steps=None, use_checkpoint=False, amp_opt_level='O1', tag=None, eval=False, throughput=False)
[13:15:30.129] Using 9522/95221 samples (10.0%) for finetuning
[13:15:40.443] TPGM enabled with proj_freq=10, max_iters=5
[13:15:40.446] 298 iterations per epoch. 14900 max iterations 
[13:38:17.009] Namespace(root_path='./datasets/kits23/train_npz', dataset='kits23', list_dir='./lists/kits23', num_classes=4, output_dir='./finetune_tpgm_kits23_2', max_iterations=10000, max_epochs=50, batch_size=32, n_gpu=1, deterministic=1, base_lr=0.001, img_size=224, seed=1234, cfg='configs/finetune.yaml', pretrained_path='./pretrain/epoch_149.pth', data_fraction=0.1, freeze_layers=0, opts=None, zip=False, cache_mode='part', resume=None, accumulation_steps=None, use_checkpoint=False, amp_opt_level='O1', tag=None, eval=False, throughput=False, tpgm_norm_mode='mars', tpgm_lr=0.001, tpgm_iters=100, tpgm_exclude=[])
[13:38:17.036] Using 8569/95221 samples for finetuning
[13:38:17.036] Using 953/95221 samples for TPGM
[13:38:26.691] 268 iterations per epoch. 13400 max iterations 
[13:38:41.743] iteration 10 : loss : 0.463206, loss_ce: 0.055055
[13:38:46.122] iteration 20 : loss : 0.442464, loss_ce: 0.055041
[13:38:50.331] iteration 30 : loss : 0.440438, loss_ce: 0.054771
[13:38:54.468] iteration 40 : loss : 0.437666, loss_ce: 0.043234
[13:38:58.570] iteration 50 : loss : 0.427083, loss_ce: 0.048292
[13:39:02.773] iteration 60 : loss : 0.429667, loss_ce: 0.061614
[13:39:07.186] iteration 70 : loss : 0.423237, loss_ce: 0.048129
[13:39:11.521] iteration 80 : loss : 0.421468, loss_ce: 0.043336
[13:39:15.631] iteration 90 : loss : 0.425519, loss_ce: 0.049139
[13:39:19.690] iteration 100 : loss : 0.412090, loss_ce: 0.050992
[13:39:23.767] iteration 110 : loss : 0.404296, loss_ce: 0.064233
[13:39:27.831] iteration 120 : loss : 0.405619, loss_ce: 0.088311
[13:39:31.897] iteration 130 : loss : 0.416009, loss_ce: 0.029896
[13:39:35.961] iteration 140 : loss : 0.377517, loss_ce: 0.029499
[13:39:40.044] iteration 150 : loss : 0.377713, loss_ce: 0.033063
[13:39:44.396] iteration 160 : loss : 0.384387, loss_ce: 0.039624
[13:39:48.545] iteration 170 : loss : 0.365792, loss_ce: 0.040278
[13:39:52.669] iteration 180 : loss : 0.411955, loss_ce: 0.058484
[13:39:56.799] iteration 190 : loss : 0.346811, loss_ce: 0.046004
[13:40:00.907] iteration 200 : loss : 0.357780, loss_ce: 0.063065
[13:40:05.055] iteration 210 : loss : 0.345447, loss_ce: 0.021945
[13:40:09.152] iteration 220 : loss : 0.337625, loss_ce: 0.034440
[13:40:13.309] iteration 230 : loss : 0.353904, loss_ce: 0.045336
[13:40:17.442] iteration 240 : loss : 0.350367, loss_ce: 0.023277
[13:40:21.577] iteration 250 : loss : 0.322420, loss_ce: 0.021344
[13:40:25.786] iteration 260 : loss : 0.317590, loss_ce: 0.016215
[13:42:06.775] iteration 270 : loss : 0.463948, loss_ce: 0.040863
[13:42:10.855] iteration 280 : loss : 0.436847, loss_ce: 0.065831
[13:42:14.974] iteration 290 : loss : 0.414228, loss_ce: 0.030373
[13:42:19.079] iteration 300 : loss : 0.425983, loss_ce: 0.034590
[13:42:23.182] iteration 310 : loss : 0.374043, loss_ce: 0.030158
[13:42:27.312] iteration 320 : loss : 0.372944, loss_ce: 0.045149
[13:42:31.414] iteration 330 : loss : 0.282640, loss_ce: 0.027168
[13:42:35.535] iteration 340 : loss : 0.397836, loss_ce: 0.090040
[13:42:39.658] iteration 350 : loss : 0.358132, loss_ce: 0.021598
[13:42:43.761] iteration 360 : loss : 0.352672, loss_ce: 0.020752
[13:42:47.901] iteration 370 : loss : 0.348007, loss_ce: 0.034457
[13:42:51.995] iteration 380 : loss : 0.298720, loss_ce: 0.019720
[13:42:56.130] iteration 390 : loss : 0.350434, loss_ce: 0.019812
[13:43:00.243] iteration 400 : loss : 0.310270, loss_ce: 0.029677
[13:43:04.363] iteration 410 : loss : 0.343085, loss_ce: 0.024990
[13:43:08.491] iteration 420 : loss : 0.325884, loss_ce: 0.028576
[13:43:12.594] iteration 430 : loss : 0.285327, loss_ce: 0.025137
[13:43:16.767] iteration 440 : loss : 0.255981, loss_ce: 0.022572
[13:43:20.932] iteration 450 : loss : 0.290354, loss_ce: 0.030351
[13:43:25.034] iteration 460 : loss : 0.225568, loss_ce: 0.016955
[13:43:29.371] iteration 470 : loss : 0.282459, loss_ce: 0.043404
[13:43:33.501] iteration 480 : loss : 0.230360, loss_ce: 0.013050
[13:43:37.688] iteration 490 : loss : 0.340645, loss_ce: 0.013569
[13:43:41.814] iteration 500 : loss : 0.355403, loss_ce: 0.022695
[13:43:45.935] iteration 510 : loss : 0.220349, loss_ce: 0.014532
[13:43:50.065] iteration 520 : loss : 0.177655, loss_ce: 0.016151
[13:43:54.167] iteration 530 : loss : 0.214474, loss_ce: 0.015634
[13:45:33.335] iteration 540 : loss : 0.340711, loss_ce: 0.029229
[13:45:37.469] iteration 550 : loss : 0.460210, loss_ce: 0.058401
[13:45:41.556] iteration 560 : loss : 0.462640, loss_ce: 0.071754
[13:45:45.688] iteration 570 : loss : 0.455341, loss_ce: 0.063293
[13:45:49.793] iteration 580 : loss : 0.465088, loss_ce: 0.088134
[13:45:53.914] iteration 590 : loss : 0.440922, loss_ce: 0.037902
[13:45:58.046] iteration 600 : loss : 0.424771, loss_ce: 0.063634
[13:46:02.158] iteration 610 : loss : 0.407815, loss_ce: 0.041429
[13:46:06.292] iteration 620 : loss : 0.360232, loss_ce: 0.026844
[13:46:10.414] iteration 630 : loss : 0.412187, loss_ce: 0.039101
[13:46:14.538] iteration 640 : loss : 0.353017, loss_ce: 0.016134
[13:46:18.682] iteration 650 : loss : 0.341617, loss_ce: 0.039891
[13:46:22.783] iteration 660 : loss : 0.312788, loss_ce: 0.024144
[13:46:26.932] iteration 670 : loss : 0.359783, loss_ce: 0.036021
[13:46:31.041] iteration 680 : loss : 0.334705, loss_ce: 0.011790
[13:46:35.177] iteration 690 : loss : 0.261173, loss_ce: 0.028192
[13:46:39.304] iteration 700 : loss : 0.339317, loss_ce: 0.028531
[13:46:43.442] iteration 710 : loss : 0.264592, loss_ce: 0.025287
[13:46:47.658] iteration 720 : loss : 0.259516, loss_ce: 0.023250
[13:46:51.915] iteration 730 : loss : 0.342236, loss_ce: 0.015169
[13:46:56.049] iteration 740 : loss : 0.279972, loss_ce: 0.025594
[13:47:00.177] iteration 750 : loss : 0.249787, loss_ce: 0.035388
[13:47:04.290] iteration 760 : loss : 0.285249, loss_ce: 0.007910
[13:47:08.442] iteration 770 : loss : 0.337824, loss_ce: 0.023116
[13:47:12.540] iteration 780 : loss : 0.346900, loss_ce: 0.019107
[13:47:16.679] iteration 790 : loss : 0.251567, loss_ce: 0.027287
[13:47:20.796] iteration 800 : loss : 0.337723, loss_ce: 0.013329
[13:49:01.225] iteration 810 : loss : 0.462197, loss_ce: 0.125158
[13:49:05.636] iteration 820 : loss : 0.377883, loss_ce: 0.035540
[13:49:09.829] iteration 830 : loss : 0.313448, loss_ce: 0.015883
[13:49:13.929] iteration 840 : loss : 0.366431, loss_ce: 0.033820
[13:49:18.055] iteration 850 : loss : 0.302866, loss_ce: 0.015857
[13:49:22.155] iteration 860 : loss : 0.229140, loss_ce: 0.022510
[13:49:26.267] iteration 870 : loss : 0.322474, loss_ce: 0.018772
[13:49:30.410] iteration 880 : loss : 0.267012, loss_ce: 0.017957
[13:49:34.522] iteration 890 : loss : 0.314081, loss_ce: 0.009945
[13:49:38.659] iteration 900 : loss : 0.233898, loss_ce: 0.023069
[13:49:42.785] iteration 910 : loss : 0.339808, loss_ce: 0.014455
[13:49:46.914] iteration 920 : loss : 0.310400, loss_ce: 0.008373
[13:49:51.060] iteration 930 : loss : 0.334296, loss_ce: 0.015849
[13:49:55.187] iteration 940 : loss : 0.302032, loss_ce: 0.033619
[13:49:59.339] iteration 950 : loss : 0.296856, loss_ce: 0.019655
[13:50:03.443] iteration 960 : loss : 0.364362, loss_ce: 0.024441
[13:50:07.581] iteration 970 : loss : 0.264518, loss_ce: 0.026056
[13:50:11.711] iteration 980 : loss : 0.258502, loss_ce: 0.017118
[13:50:15.817] iteration 990 : loss : 0.280410, loss_ce: 0.015704
[13:50:19.951] iteration 1000 : loss : 0.233924, loss_ce: 0.023123
[13:50:24.096] iteration 1010 : loss : 0.161447, loss_ce: 0.018732
[13:50:28.271] iteration 1020 : loss : 0.245515, loss_ce: 0.022620
[13:50:32.420] iteration 1030 : loss : 0.137900, loss_ce: 0.013553
[13:50:36.530] iteration 1040 : loss : 0.314429, loss_ce: 0.010700
[13:50:40.672] iteration 1050 : loss : 0.336211, loss_ce: 0.032198
[13:50:44.763] iteration 1060 : loss : 0.274262, loss_ce: 0.023329
[13:50:48.893] iteration 1070 : loss : 0.227588, loss_ce: 0.022350
[13:52:37.423] iteration 1080 : loss : 0.479405, loss_ce: 0.228924
[13:52:41.554] iteration 1090 : loss : 0.331715, loss_ce: 0.012759
[13:52:45.640] iteration 1100 : loss : 0.216696, loss_ce: 0.024096
[13:52:49.751] iteration 1110 : loss : 0.249001, loss_ce: 0.013313
[13:52:53.860] iteration 1120 : loss : 0.251466, loss_ce: 0.020874
[13:52:57.982] iteration 1130 : loss : 0.309331, loss_ce: 0.019731
[13:53:02.198] iteration 1140 : loss : 0.311665, loss_ce: 0.016790
[13:53:06.310] iteration 1150 : loss : 0.255822, loss_ce: 0.015018
[13:53:10.447] iteration 1160 : loss : 0.276116, loss_ce: 0.033100
[13:53:14.579] iteration 1170 : loss : 0.294981, loss_ce: 0.026178
[13:53:18.706] iteration 1180 : loss : 0.322020, loss_ce: 0.017051
[13:53:23.022] iteration 1190 : loss : 0.366804, loss_ce: 0.024599
[13:53:27.410] iteration 1200 : loss : 0.307820, loss_ce: 0.009690
[13:53:31.829] iteration 1210 : loss : 0.179005, loss_ce: 0.014849
[13:53:36.300] iteration 1220 : loss : 0.275716, loss_ce: 0.019345
[13:53:40.636] iteration 1230 : loss : 0.312000, loss_ce: 0.015937
[13:53:44.706] iteration 1240 : loss : 0.233136, loss_ce: 0.016673
[13:53:48.830] iteration 1250 : loss : 0.267716, loss_ce: 0.023029
[13:53:52.940] iteration 1260 : loss : 0.295946, loss_ce: 0.024619
[13:53:57.014] iteration 1270 : loss : 0.279017, loss_ce: 0.032947
[13:54:01.066] iteration 1280 : loss : 0.247494, loss_ce: 0.024765
[13:54:05.128] iteration 1290 : loss : 0.239309, loss_ce: 0.017519
[13:54:09.195] iteration 1300 : loss : 0.307075, loss_ce: 0.038886
[13:54:13.251] iteration 1310 : loss : 0.321275, loss_ce: 0.016156
[13:54:17.298] iteration 1320 : loss : 0.230294, loss_ce: 0.019720
[13:54:21.376] iteration 1330 : loss : 0.307895, loss_ce: 0.009308
[13:54:25.325] iteration 1340 : loss : 0.181232, loss_ce: 0.010126
[13:56:03.603] iteration 1350 : loss : 0.320547, loss_ce: 0.050332
[13:56:07.694] iteration 1360 : loss : 0.277580, loss_ce: 0.017119
[13:56:11.818] iteration 1370 : loss : 0.186882, loss_ce: 0.020544
[13:56:15.974] iteration 1380 : loss : 0.328054, loss_ce: 0.024856
[13:56:20.080] iteration 1390 : loss : 0.317722, loss_ce: 0.015639
[13:56:24.205] iteration 1400 : loss : 0.264852, loss_ce: 0.009989
[13:56:28.317] iteration 1410 : loss : 0.322300, loss_ce: 0.029981
[13:56:32.508] iteration 1420 : loss : 0.203111, loss_ce: 0.014970
[13:56:36.767] iteration 1430 : loss : 0.248957, loss_ce: 0.011786
[13:56:40.819] iteration 1440 : loss : 0.265940, loss_ce: 0.031298
[13:56:44.879] iteration 1450 : loss : 0.250798, loss_ce: 0.024278
[13:56:48.927] iteration 1460 : loss : 0.267448, loss_ce: 0.011180
[13:56:52.985] iteration 1470 : loss : 0.279355, loss_ce: 0.047251
[13:56:57.059] iteration 1480 : loss : 0.230371, loss_ce: 0.021979
[13:57:01.124] iteration 1490 : loss : 0.323873, loss_ce: 0.025455
[13:57:05.195] iteration 1500 : loss : 0.248211, loss_ce: 0.016056
[13:57:09.312] iteration 1510 : loss : 0.192855, loss_ce: 0.011448
[13:57:13.488] iteration 1520 : loss : 0.232827, loss_ce: 0.018740
[13:57:17.565] iteration 1530 : loss : 0.298311, loss_ce: 0.029909
[13:57:21.628] iteration 1540 : loss : 0.293471, loss_ce: 0.017204
[13:57:25.693] iteration 1550 : loss : 0.300664, loss_ce: 0.013114
[13:57:29.892] iteration 1560 : loss : 0.283372, loss_ce: 0.030260
[13:57:34.051] iteration 1570 : loss : 0.197996, loss_ce: 0.006899
[13:57:38.146] iteration 1580 : loss : 0.290368, loss_ce: 0.014294
[13:57:42.281] iteration 1590 : loss : 0.243512, loss_ce: 0.012451
[13:57:46.419] iteration 1600 : loss : 0.194309, loss_ce: 0.017667
[13:59:25.258] iteration 1610 : loss : 0.286398, loss_ce: 0.048323
[13:59:29.374] iteration 1620 : loss : 0.292073, loss_ce: 0.023263
[13:59:33.502] iteration 1630 : loss : 0.356524, loss_ce: 0.046821
[13:59:37.622] iteration 1640 : loss : 0.377671, loss_ce: 0.047623
[13:59:41.964] iteration 1650 : loss : 0.404155, loss_ce: 0.056152
[13:59:46.494] iteration 1660 : loss : 0.399696, loss_ce: 0.095090
[13:59:50.926] iteration 1670 : loss : 0.277606, loss_ce: 0.024551
[13:59:55.328] iteration 1680 : loss : 0.263181, loss_ce: 0.010712
[13:59:59.628] iteration 1690 : loss : 0.294224, loss_ce: 0.016592
[14:00:03.870] iteration 1700 : loss : 0.252806, loss_ce: 0.019647
[14:00:08.022] iteration 1710 : loss : 0.302589, loss_ce: 0.022729
[14:00:12.151] iteration 1720 : loss : 0.273939, loss_ce: 0.031264
[14:00:16.419] iteration 1730 : loss : 0.256242, loss_ce: 0.032632
[14:00:20.865] iteration 1740 : loss : 0.295084, loss_ce: 0.017773
[14:00:25.297] iteration 1750 : loss : 0.225722, loss_ce: 0.027965
[14:00:29.756] iteration 1760 : loss : 0.365383, loss_ce: 0.037872
[14:00:34.215] iteration 1770 : loss : 0.266976, loss_ce: 0.029325
[14:00:38.659] iteration 1780 : loss : 0.207399, loss_ce: 0.007603
[14:00:43.092] iteration 1790 : loss : 0.308306, loss_ce: 0.020922
[14:00:47.515] iteration 1800 : loss : 0.268397, loss_ce: 0.029938
[14:00:51.897] iteration 1810 : loss : 0.361999, loss_ce: 0.040311
[14:00:56.064] iteration 1820 : loss : 0.378770, loss_ce: 0.017140
[14:01:00.175] iteration 1830 : loss : 0.270770, loss_ce: 0.023830
[14:01:04.284] iteration 1840 : loss : 0.203239, loss_ce: 0.005276
[14:01:08.509] iteration 1850 : loss : 0.378917, loss_ce: 0.018742
[14:01:12.781] iteration 1860 : loss : 0.278058, loss_ce: 0.036851
[14:01:17.022] iteration 1870 : loss : 0.304243, loss_ce: 0.020528
[14:03:07.017] iteration 1880 : loss : 0.320487, loss_ce: 0.038973
[14:03:11.192] iteration 1890 : loss : 0.305130, loss_ce: 0.030291
[14:03:15.349] iteration 1900 : loss : 0.288058, loss_ce: 0.016818
[14:03:19.591] iteration 1910 : loss : 0.286652, loss_ce: 0.010554
[14:03:23.844] iteration 1920 : loss : 0.298159, loss_ce: 0.073406
[14:03:28.003] iteration 1930 : loss : 0.327892, loss_ce: 0.012329
[14:03:32.185] iteration 1940 : loss : 0.299706, loss_ce: 0.041433
[14:03:36.353] iteration 1950 : loss : 0.317777, loss_ce: 0.030754
[14:03:40.521] iteration 1960 : loss : 0.286633, loss_ce: 0.014592
[14:03:44.708] iteration 1970 : loss : 0.253751, loss_ce: 0.018072
[14:03:48.938] iteration 1980 : loss : 0.322501, loss_ce: 0.019937
[14:03:53.139] iteration 1990 : loss : 0.291339, loss_ce: 0.015271
[14:03:57.297] iteration 2000 : loss : 0.283213, loss_ce: 0.021576
[14:04:01.486] iteration 2010 : loss : 0.315448, loss_ce: 0.019585
[14:04:05.658] iteration 2020 : loss : 0.285944, loss_ce: 0.012338
[14:04:09.827] iteration 2030 : loss : 0.266457, loss_ce: 0.020535
[14:04:14.017] iteration 2040 : loss : 0.273557, loss_ce: 0.017998
[14:04:18.179] iteration 2050 : loss : 0.312752, loss_ce: 0.014715
[14:04:22.365] iteration 2060 : loss : 0.188086, loss_ce: 0.016817
[14:04:26.550] iteration 2070 : loss : 0.284114, loss_ce: 0.016844
[14:04:30.714] iteration 2080 : loss : 0.244441, loss_ce: 0.017085
[14:04:34.905] iteration 2090 : loss : 0.210792, loss_ce: 0.015560
[14:04:39.152] iteration 2100 : loss : 0.221504, loss_ce: 0.015997
[14:04:43.348] iteration 2110 : loss : 0.264555, loss_ce: 0.015581
[14:04:47.496] iteration 2120 : loss : 0.326798, loss_ce: 0.015153
[14:04:51.670] iteration 2130 : loss : 0.190233, loss_ce: 0.040178
[14:04:55.834] iteration 2140 : loss : 0.225116, loss_ce: 0.013953
[14:06:35.338] iteration 2150 : loss : 0.294469, loss_ce: 0.022487
[14:06:39.581] iteration 2160 : loss : 0.399555, loss_ce: 0.081969
[14:06:44.061] iteration 2170 : loss : 0.344687, loss_ce: 0.021364
[14:06:48.428] iteration 2180 : loss : 0.353466, loss_ce: 0.029903
[14:06:52.597] iteration 2190 : loss : 0.246616, loss_ce: 0.026411
[14:06:56.702] iteration 2200 : loss : 0.294333, loss_ce: 0.019486
[14:07:01.152] iteration 2210 : loss : 0.307861, loss_ce: 0.028753
[14:07:05.281] iteration 2220 : loss : 0.281503, loss_ce: 0.026254
[14:07:09.406] iteration 2230 : loss : 0.363189, loss_ce: 0.044981
[14:07:13.537] iteration 2240 : loss : 0.369122, loss_ce: 0.027867
[14:07:17.642] iteration 2250 : loss : 0.234055, loss_ce: 0.009250
[14:07:21.817] iteration 2260 : loss : 0.219026, loss_ce: 0.018344
[14:07:25.941] iteration 2270 : loss : 0.279088, loss_ce: 0.032013
[14:07:30.061] iteration 2280 : loss : 0.339279, loss_ce: 0.028736
[14:07:34.194] iteration 2290 : loss : 0.215811, loss_ce: 0.011401
[14:07:38.293] iteration 2300 : loss : 0.207471, loss_ce: 0.016093
[14:07:42.443] iteration 2310 : loss : 0.305584, loss_ce: 0.009947
[14:07:46.551] iteration 2320 : loss : 0.224398, loss_ce: 0.010984
[14:07:50.682] iteration 2330 : loss : 0.297106, loss_ce: 0.025504
[14:07:54.802] iteration 2340 : loss : 0.268833, loss_ce: 0.012219
[14:07:58.915] iteration 2350 : loss : 0.202510, loss_ce: 0.017187
[14:08:03.058] iteration 2360 : loss : 0.123157, loss_ce: 0.010662
[14:08:07.167] iteration 2370 : loss : 0.270451, loss_ce: 0.009739
[14:08:11.289] iteration 2380 : loss : 0.272704, loss_ce: 0.009986
[14:08:15.415] iteration 2390 : loss : 0.213970, loss_ce: 0.011336
[14:08:19.522] iteration 2400 : loss : 0.235010, loss_ce: 0.019825
[14:08:23.662] iteration 2410 : loss : 0.198103, loss_ce: 0.015210
[14:10:02.537] iteration 2420 : loss : 0.296193, loss_ce: 0.026681
[14:10:06.664] iteration 2430 : loss : 0.473428, loss_ce: 0.061871
[14:10:10.758] iteration 2440 : loss : 0.460564, loss_ce: 0.063924
[14:10:14.896] iteration 2450 : loss : 0.426327, loss_ce: 0.040995
[14:10:18.987] iteration 2460 : loss : 0.394806, loss_ce: 0.033552
[14:10:23.123] iteration 2470 : loss : 0.328477, loss_ce: 0.013879
[14:10:27.239] iteration 2480 : loss : 0.349074, loss_ce: 0.023398
[14:10:31.354] iteration 2490 : loss : 0.294118, loss_ce: 0.021961
[14:10:35.490] iteration 2500 : loss : 0.292221, loss_ce: 0.030047
[14:10:39.597] iteration 2510 : loss : 0.328796, loss_ce: 0.014694
[14:10:43.726] iteration 2520 : loss : 0.275472, loss_ce: 0.017914
[14:10:47.853] iteration 2530 : loss : 0.308666, loss_ce: 0.009851
[14:10:51.965] iteration 2540 : loss : 0.318149, loss_ce: 0.014189
[14:10:56.113] iteration 2550 : loss : 0.381319, loss_ce: 0.058493
[14:11:00.213] iteration 2560 : loss : 0.189876, loss_ce: 0.019074
[14:11:04.362] iteration 2570 : loss : 0.254276, loss_ce: 0.013161
[14:11:08.475] iteration 2580 : loss : 0.199845, loss_ce: 0.018315
[14:11:12.598] iteration 2590 : loss : 0.167822, loss_ce: 0.010907
[14:11:16.729] iteration 2600 : loss : 0.257710, loss_ce: 0.018593
[14:11:20.839] iteration 2610 : loss : 0.315978, loss_ce: 0.025527
[14:11:24.971] iteration 2620 : loss : 0.217967, loss_ce: 0.017497
[14:11:29.089] iteration 2630 : loss : 0.228188, loss_ce: 0.008486
[14:11:33.263] iteration 2640 : loss : 0.310941, loss_ce: 0.022951
[14:11:37.485] iteration 2650 : loss : 0.248806, loss_ce: 0.008282
[14:11:41.600] iteration 2660 : loss : 0.313388, loss_ce: 0.013820
[14:11:45.745] iteration 2670 : loss : 0.223483, loss_ce: 0.014569
[14:11:49.754] iteration 2680 : loss : 0.312686, loss_ce: 0.008052
[14:13:24.821] save model to ./finetune_tpgm_kits23_2\finetuned_epoch_9.pth
[14:13:38.686] iteration 2690 : loss : 0.470241, loss_ce: 0.055579
[14:13:42.764] iteration 2700 : loss : 0.461293, loss_ce: 0.062162
[14:13:46.899] iteration 2710 : loss : 0.457263, loss_ce: 0.082277
[14:13:50.995] iteration 2720 : loss : 0.420136, loss_ce: 0.086261
[14:13:55.219] iteration 2730 : loss : 0.385012, loss_ce: 0.021097
[14:13:59.448] iteration 2740 : loss : 0.323135, loss_ce: 0.026415
[14:14:03.573] iteration 2750 : loss : 0.357286, loss_ce: 0.039642
[14:14:07.717] iteration 2760 : loss : 0.304877, loss_ce: 0.033988
[14:14:11.835] iteration 2770 : loss : 0.238376, loss_ce: 0.020451
[14:14:15.960] iteration 2780 : loss : 0.251344, loss_ce: 0.035347
[14:14:20.092] iteration 2790 : loss : 0.353918, loss_ce: 0.023770
[14:14:24.198] iteration 2800 : loss : 0.246005, loss_ce: 0.025650
[14:14:28.350] iteration 2810 : loss : 0.224368, loss_ce: 0.018506
[14:14:32.449] iteration 2820 : loss : 0.334329, loss_ce: 0.024499
[14:14:36.585] iteration 2830 : loss : 0.251548, loss_ce: 0.015702
[14:14:40.706] iteration 2840 : loss : 0.325084, loss_ce: 0.013831
[14:14:44.823] iteration 2850 : loss : 0.130327, loss_ce: 0.014648
[14:14:48.957] iteration 2860 : loss : 0.293411, loss_ce: 0.021142
[14:14:53.066] iteration 2870 : loss : 0.236004, loss_ce: 0.024575
[14:14:57.198] iteration 2880 : loss : 0.217297, loss_ce: 0.022031
[14:15:01.324] iteration 2890 : loss : 0.307486, loss_ce: 0.005879
[14:15:05.435] iteration 2900 : loss : 0.320069, loss_ce: 0.016264
[14:15:09.578] iteration 2910 : loss : 0.240035, loss_ce: 0.020289
[14:15:13.675] iteration 2920 : loss : 0.302972, loss_ce: 0.027980
[14:15:17.820] iteration 2930 : loss : 0.310735, loss_ce: 0.015262
[14:15:21.930] iteration 2940 : loss : 0.227670, loss_ce: 0.011862
[14:17:00.533] iteration 2950 : loss : 0.360540, loss_ce: 0.021831
[14:17:04.612] iteration 2960 : loss : 0.336291, loss_ce: 0.012766
[14:17:08.793] iteration 2970 : loss : 0.308620, loss_ce: 0.067509
[14:17:12.863] iteration 2980 : loss : 0.349441, loss_ce: 0.018054
[14:17:16.953] iteration 2990 : loss : 0.319084, loss_ce: 0.015314
[14:17:21.269] iteration 3000 : loss : 0.213262, loss_ce: 0.013711
[14:17:25.683] iteration 3010 : loss : 0.320090, loss_ce: 0.017093
[14:17:30.010] iteration 3020 : loss : 0.335794, loss_ce: 0.010624
[14:17:34.405] iteration 3030 : loss : 0.195247, loss_ce: 0.012333
[14:17:38.787] iteration 3040 : loss : 0.252890, loss_ce: 0.011670
[14:17:43.156] iteration 3050 : loss : 0.300693, loss_ce: 0.013169
[14:17:47.417] iteration 3060 : loss : 0.211732, loss_ce: 0.019042
[14:17:51.774] iteration 3070 : loss : 0.296004, loss_ce: 0.015183
[14:17:56.095] iteration 3080 : loss : 0.306102, loss_ce: 0.018996
[14:18:00.381] iteration 3090 : loss : 0.342270, loss_ce: 0.019433
[14:18:04.815] iteration 3100 : loss : 0.222747, loss_ce: 0.025197
[14:18:09.244] iteration 3110 : loss : 0.295421, loss_ce: 0.018191
[14:18:13.667] iteration 3120 : loss : 0.194150, loss_ce: 0.013494
[14:18:18.098] iteration 3130 : loss : 0.307270, loss_ce: 0.008669
[14:18:22.519] iteration 3140 : loss : 0.322049, loss_ce: 0.030357
[14:18:26.948] iteration 3150 : loss : 0.271194, loss_ce: 0.006845
[14:18:31.369] iteration 3160 : loss : 0.252161, loss_ce: 0.014858
[14:18:35.800] iteration 3170 : loss : 0.245317, loss_ce: 0.007279
[14:18:40.219] iteration 3180 : loss : 0.334817, loss_ce: 0.020363
[14:18:44.649] iteration 3190 : loss : 0.341208, loss_ce: 0.034584
[14:18:49.070] iteration 3200 : loss : 0.253632, loss_ce: 0.016226
[14:18:53.500] iteration 3210 : loss : 0.218232, loss_ce: 0.009653
[14:20:38.166] iteration 3220 : loss : 0.278943, loss_ce: 0.024653
[14:20:42.602] iteration 3230 : loss : 0.258012, loss_ce: 0.017808
[14:20:47.027] iteration 3240 : loss : 0.286447, loss_ce: 0.020961
[14:20:51.466] iteration 3250 : loss : 0.314428, loss_ce: 0.019770
[14:20:55.904] iteration 3260 : loss : 0.285766, loss_ce: 0.042685
[14:21:00.352] iteration 3270 : loss : 0.334078, loss_ce: 0.013835
[14:21:04.795] iteration 3280 : loss : 0.341857, loss_ce: 0.020622
[14:21:09.258] iteration 3290 : loss : 0.356452, loss_ce: 0.024244
[14:21:13.722] iteration 3300 : loss : 0.266996, loss_ce: 0.009106
[14:21:18.188] iteration 3310 : loss : 0.371416, loss_ce: 0.013198
[14:21:22.651] iteration 3320 : loss : 0.230775, loss_ce: 0.010449
[14:21:27.101] iteration 3330 : loss : 0.144338, loss_ce: 0.019046
[14:21:31.535] iteration 3340 : loss : 0.341195, loss_ce: 0.019358
[14:21:35.979] iteration 3350 : loss : 0.223416, loss_ce: 0.013030
[14:21:40.409] iteration 3360 : loss : 0.319405, loss_ce: 0.016201
[14:21:44.862] iteration 3370 : loss : 0.247279, loss_ce: 0.011183
[14:21:49.296] iteration 3380 : loss : 0.268145, loss_ce: 0.016388
[14:21:53.741] iteration 3390 : loss : 0.299552, loss_ce: 0.012047
[14:21:58.174] iteration 3400 : loss : 0.219482, loss_ce: 0.023268
[14:22:02.626] iteration 3410 : loss : 0.326543, loss_ce: 0.025935
[14:22:07.075] iteration 3420 : loss : 0.226102, loss_ce: 0.012689
[14:22:11.528] iteration 3430 : loss : 0.183980, loss_ce: 0.008114
[14:22:15.967] iteration 3440 : loss : 0.153681, loss_ce: 0.018542
[14:22:20.427] iteration 3450 : loss : 0.250468, loss_ce: 0.020593
[14:22:24.869] iteration 3460 : loss : 0.115680, loss_ce: 0.007705
[14:22:29.318] iteration 3470 : loss : 0.215093, loss_ce: 0.009901
[14:22:33.759] iteration 3480 : loss : 0.154295, loss_ce: 0.009829
[14:24:29.607] iteration 3490 : loss : 0.344644, loss_ce: 0.041155
[14:24:34.028] iteration 3500 : loss : 0.287130, loss_ce: 0.013404
[14:24:38.456] iteration 3510 : loss : 0.249234, loss_ce: 0.012329
[14:24:42.871] iteration 3520 : loss : 0.358727, loss_ce: 0.065702
[14:24:47.339] iteration 3530 : loss : 0.324690, loss_ce: 0.009582
[14:24:51.803] iteration 3540 : loss : 0.262541, loss_ce: 0.027830
[14:24:56.280] iteration 3550 : loss : 0.254036, loss_ce: 0.033857
[14:25:00.729] iteration 3560 : loss : 0.309306, loss_ce: 0.030193
[14:25:05.178] iteration 3570 : loss : 0.217694, loss_ce: 0.016642
[14:25:09.628] iteration 3580 : loss : 0.267089, loss_ce: 0.029797
[14:25:14.079] iteration 3590 : loss : 0.222734, loss_ce: 0.012181
[14:25:18.520] iteration 3600 : loss : 0.299199, loss_ce: 0.005640
[14:25:22.965] iteration 3610 : loss : 0.222099, loss_ce: 0.015004
[14:25:27.409] iteration 3620 : loss : 0.283443, loss_ce: 0.006001
[14:25:31.864] iteration 3630 : loss : 0.260798, loss_ce: 0.014591
[14:25:36.305] iteration 3640 : loss : 0.219308, loss_ce: 0.020735
[14:25:40.757] iteration 3650 : loss : 0.326763, loss_ce: 0.023809
[14:25:45.202] iteration 3660 : loss : 0.192544, loss_ce: 0.006975
[14:25:49.657] iteration 3670 : loss : 0.210483, loss_ce: 0.012747
[14:25:54.110] iteration 3680 : loss : 0.350174, loss_ce: 0.033155
[14:25:58.568] iteration 3690 : loss : 0.242095, loss_ce: 0.023291
[14:26:03.014] iteration 3700 : loss : 0.221955, loss_ce: 0.017518
[14:26:07.471] iteration 3710 : loss : 0.223627, loss_ce: 0.009132
[14:26:11.918] iteration 3720 : loss : 0.201014, loss_ce: 0.009366
[14:26:16.368] iteration 3730 : loss : 0.179626, loss_ce: 0.016481
[14:26:20.812] iteration 3740 : loss : 0.302814, loss_ce: 0.018804
[14:26:25.268] iteration 3750 : loss : 0.199316, loss_ce: 0.013310
[14:28:10.218] iteration 3760 : loss : 0.309859, loss_ce: 0.016860
[14:28:14.643] iteration 3770 : loss : 0.328620, loss_ce: 0.009456
[14:28:19.105] iteration 3780 : loss : 0.360106, loss_ce: 0.027698
[14:28:23.587] iteration 3790 : loss : 0.269376, loss_ce: 0.014236
[14:28:28.048] iteration 3800 : loss : 0.316937, loss_ce: 0.016679
[14:28:32.513] iteration 3810 : loss : 0.245399, loss_ce: 0.017943
[14:28:36.977] iteration 3820 : loss : 0.239329, loss_ce: 0.020806
[14:28:41.451] iteration 3830 : loss : 0.342627, loss_ce: 0.087973
[14:28:45.881] iteration 3840 : loss : 0.246067, loss_ce: 0.021368
[14:28:50.333] iteration 3850 : loss : 0.337294, loss_ce: 0.052488
[14:28:54.776] iteration 3860 : loss : 0.272414, loss_ce: 0.018375
[14:28:59.226] iteration 3870 : loss : 0.241726, loss_ce: 0.009614
[14:29:03.668] iteration 3880 : loss : 0.252773, loss_ce: 0.009593
[14:29:08.122] iteration 3890 : loss : 0.229714, loss_ce: 0.019188
[14:29:12.566] iteration 3900 : loss : 0.222595, loss_ce: 0.012956
[14:29:17.020] iteration 3910 : loss : 0.292254, loss_ce: 0.031270
[14:29:21.460] iteration 3920 : loss : 0.132485, loss_ce: 0.018016
[14:29:25.919] iteration 3930 : loss : 0.235210, loss_ce: 0.019443
[14:29:30.366] iteration 3940 : loss : 0.225972, loss_ce: 0.027428
[14:29:34.814] iteration 3950 : loss : 0.278987, loss_ce: 0.019138
[14:29:39.258] iteration 3960 : loss : 0.329388, loss_ce: 0.028943
[14:29:43.716] iteration 3970 : loss : 0.289939, loss_ce: 0.011623
[14:29:48.159] iteration 3980 : loss : 0.227781, loss_ce: 0.029386
[14:29:52.610] iteration 3990 : loss : 0.282500, loss_ce: 0.013773
[14:29:57.044] iteration 4000 : loss : 0.274910, loss_ce: 0.022528
[14:30:01.498] iteration 4010 : loss : 0.196465, loss_ce: 0.010338
[14:30:05.841] iteration 4020 : loss : 0.283899, loss_ce: 0.007609
[14:31:50.906] iteration 4030 : loss : 0.224776, loss_ce: 0.030159
[14:31:55.353] iteration 4040 : loss : 0.298369, loss_ce: 0.012814
[14:31:59.807] iteration 4050 : loss : 0.332972, loss_ce: 0.010313
[14:32:04.259] iteration 4060 : loss : 0.319295, loss_ce: 0.011380
[14:32:08.728] iteration 4070 : loss : 0.274092, loss_ce: 0.029869
[14:32:13.176] iteration 4080 : loss : 0.326160, loss_ce: 0.027779
[14:32:17.634] iteration 4090 : loss : 0.339085, loss_ce: 0.016021
[14:32:22.079] iteration 4100 : loss : 0.286958, loss_ce: 0.013395
[14:32:26.534] iteration 4110 : loss : 0.185962, loss_ce: 0.022757
[14:32:30.985] iteration 4120 : loss : 0.213747, loss_ce: 0.017968
[14:32:35.440] iteration 4130 : loss : 0.209380, loss_ce: 0.023399
[14:32:39.886] iteration 4140 : loss : 0.234712, loss_ce: 0.009472
[14:32:44.343] iteration 4150 : loss : 0.328322, loss_ce: 0.050431
[14:32:48.788] iteration 4160 : loss : 0.226808, loss_ce: 0.012918
[14:32:53.242] iteration 4170 : loss : 0.230144, loss_ce: 0.022711
[14:32:57.685] iteration 4180 : loss : 0.287335, loss_ce: 0.019687
[14:33:02.136] iteration 4190 : loss : 0.209200, loss_ce: 0.012468
[14:33:06.577] iteration 4200 : loss : 0.311047, loss_ce: 0.017163
[14:33:11.031] iteration 4210 : loss : 0.211801, loss_ce: 0.012078
[14:33:15.476] iteration 4220 : loss : 0.136626, loss_ce: 0.015483
[14:33:19.938] iteration 4230 : loss : 0.279470, loss_ce: 0.019185
[14:33:24.381] iteration 4240 : loss : 0.241426, loss_ce: 0.011700
[14:33:28.839] iteration 4250 : loss : 0.366834, loss_ce: 0.050296
[14:33:33.290] iteration 4260 : loss : 0.347145, loss_ce: 0.029963
[14:33:37.746] iteration 4270 : loss : 0.287452, loss_ce: 0.009245
[14:33:42.186] iteration 4280 : loss : 0.311242, loss_ce: 0.016200
[14:35:38.469] iteration 4290 : loss : 0.386479, loss_ce: 0.089427
[14:35:42.892] iteration 4300 : loss : 0.370941, loss_ce: 0.032189
[14:35:47.323] iteration 4310 : loss : 0.274902, loss_ce: 0.029037
[14:35:51.744] iteration 4320 : loss : 0.242785, loss_ce: 0.009891
[14:35:56.188] iteration 4330 : loss : 0.266212, loss_ce: 0.013368
[14:36:00.625] iteration 4340 : loss : 0.306957, loss_ce: 0.010335
[14:36:05.078] iteration 4350 : loss : 0.329399, loss_ce: 0.013605
[14:36:09.525] iteration 4360 : loss : 0.205056, loss_ce: 0.020704
[14:36:13.983] iteration 4370 : loss : 0.297252, loss_ce: 0.016586
[14:36:18.432] iteration 4380 : loss : 0.320258, loss_ce: 0.033678
[14:36:22.890] iteration 4390 : loss : 0.235299, loss_ce: 0.016431
[14:36:27.333] iteration 4400 : loss : 0.315577, loss_ce: 0.015358
[14:36:31.786] iteration 4410 : loss : 0.325646, loss_ce: 0.017792
[14:36:36.231] iteration 4420 : loss : 0.328069, loss_ce: 0.007359
[14:36:40.685] iteration 4430 : loss : 0.289076, loss_ce: 0.018513
[14:36:45.131] iteration 4440 : loss : 0.218652, loss_ce: 0.015896
[14:36:49.590] iteration 4450 : loss : 0.243196, loss_ce: 0.021214
[14:36:54.035] iteration 4460 : loss : 0.312259, loss_ce: 0.013387
[14:36:58.486] iteration 4470 : loss : 0.307750, loss_ce: 0.007513
[14:37:02.941] iteration 4480 : loss : 0.239025, loss_ce: 0.013421
[14:37:07.396] iteration 4490 : loss : 0.308791, loss_ce: 0.014669
[14:37:11.842] iteration 4500 : loss : 0.310548, loss_ce: 0.016162
[14:37:16.295] iteration 4510 : loss : 0.221317, loss_ce: 0.008303
[14:37:20.743] iteration 4520 : loss : 0.332089, loss_ce: 0.011525
[14:37:25.196] iteration 4530 : loss : 0.234516, loss_ce: 0.012644
[14:37:29.643] iteration 4540 : loss : 0.261286, loss_ce: 0.017991
[14:37:34.097] iteration 4550 : loss : 0.290329, loss_ce: 0.012310
[14:39:19.456] iteration 4560 : loss : 0.269870, loss_ce: 0.028300
[14:39:23.739] iteration 4570 : loss : 0.343667, loss_ce: 0.026127
[14:39:28.055] iteration 4580 : loss : 0.325559, loss_ce: 0.039119
[14:39:32.370] iteration 4590 : loss : 0.258636, loss_ce: 0.013380
[14:39:36.667] iteration 4600 : loss : 0.323496, loss_ce: 0.010146
[14:39:40.971] iteration 4610 : loss : 0.279743, loss_ce: 0.016532
[14:39:45.263] iteration 4620 : loss : 0.285323, loss_ce: 0.024859
[14:39:49.566] iteration 4630 : loss : 0.313537, loss_ce: 0.007150
[14:39:53.861] iteration 4640 : loss : 0.255572, loss_ce: 0.015808
[14:39:58.167] iteration 4650 : loss : 0.304042, loss_ce: 0.012465
[14:40:02.470] iteration 4660 : loss : 0.278742, loss_ce: 0.010940
[14:40:06.773] iteration 4670 : loss : 0.233327, loss_ce: 0.018275
[14:40:11.070] iteration 4680 : loss : 0.258738, loss_ce: 0.033602
[14:40:15.376] iteration 4690 : loss : 0.213281, loss_ce: 0.011091
[14:40:19.671] iteration 4700 : loss : 0.211991, loss_ce: 0.013228
[14:40:23.981] iteration 4710 : loss : 0.250549, loss_ce: 0.029794
[14:40:28.277] iteration 4720 : loss : 0.242960, loss_ce: 0.020650
[14:40:32.583] iteration 4730 : loss : 0.236393, loss_ce: 0.014639
[14:40:36.883] iteration 4740 : loss : 0.223979, loss_ce: 0.018680
[14:40:41.194] iteration 4750 : loss : 0.250748, loss_ce: 0.011809
[14:40:45.490] iteration 4760 : loss : 0.250869, loss_ce: 0.020539
[14:40:49.794] iteration 4770 : loss : 0.223707, loss_ce: 0.012110
[14:40:54.090] iteration 4780 : loss : 0.220504, loss_ce: 0.026678
[14:40:58.400] iteration 4790 : loss : 0.302975, loss_ce: 0.003857
[14:41:02.701] iteration 4800 : loss : 0.328120, loss_ce: 0.023434
[14:41:07.008] iteration 4810 : loss : 0.228705, loss_ce: 0.024075
[14:41:11.302] iteration 4820 : loss : 0.247809, loss_ce: 0.016178
[14:43:17.430] iteration 4830 : loss : 0.323266, loss_ce: 0.027643
[14:43:21.722] iteration 4840 : loss : 0.240105, loss_ce: 0.022110
[14:43:26.010] iteration 4850 : loss : 0.248025, loss_ce: 0.013037
[14:43:30.290] iteration 4860 : loss : 0.279713, loss_ce: 0.027863
[14:43:34.587] iteration 4870 : loss : 0.277650, loss_ce: 0.018515
[14:43:38.875] iteration 4880 : loss : 0.324243, loss_ce: 0.025234
[14:43:43.175] iteration 4890 : loss : 0.325915, loss_ce: 0.018755
[14:43:47.460] iteration 4900 : loss : 0.279258, loss_ce: 0.022531
[14:43:51.759] iteration 4910 : loss : 0.260725, loss_ce: 0.010858
[14:43:56.046] iteration 4920 : loss : 0.227871, loss_ce: 0.018377
[14:44:00.348] iteration 4930 : loss : 0.271751, loss_ce: 0.031306
[14:44:04.638] iteration 4940 : loss : 0.330379, loss_ce: 0.013529
[14:44:08.940] iteration 4950 : loss : 0.248251, loss_ce: 0.006213
[14:44:13.233] iteration 4960 : loss : 0.331490, loss_ce: 0.020526
[14:44:17.538] iteration 4970 : loss : 0.148753, loss_ce: 0.010370
[14:44:21.833] iteration 4980 : loss : 0.276052, loss_ce: 0.015551
[14:44:26.138] iteration 4990 : loss : 0.226280, loss_ce: 0.015144
[14:44:30.432] iteration 5000 : loss : 0.325402, loss_ce: 0.014274
[14:44:34.743] iteration 5010 : loss : 0.186874, loss_ce: 0.014084
[14:44:39.035] iteration 5020 : loss : 0.114455, loss_ce: 0.007303
[14:44:43.340] iteration 5030 : loss : 0.294401, loss_ce: 0.032641
[14:44:47.637] iteration 5040 : loss : 0.184470, loss_ce: 0.047445
[14:44:51.943] iteration 5050 : loss : 0.284170, loss_ce: 0.018685
[14:44:56.236] iteration 5060 : loss : 0.333872, loss_ce: 0.043840
[14:45:00.543] iteration 5070 : loss : 0.212301, loss_ce: 0.021039
[14:45:04.837] iteration 5080 : loss : 0.309255, loss_ce: 0.010780
[14:45:09.143] iteration 5090 : loss : 0.300163, loss_ce: 0.010409
[14:47:25.355] iteration 5100 : loss : 0.269801, loss_ce: 0.045178
[14:47:29.641] iteration 5110 : loss : 0.314326, loss_ce: 0.024650
[14:47:33.917] iteration 5120 : loss : 0.241358, loss_ce: 0.016492
[14:47:38.203] iteration 5130 : loss : 0.261007, loss_ce: 0.013340
[14:47:42.480] iteration 5140 : loss : 0.229747, loss_ce: 0.018955
[14:47:46.777] iteration 5150 : loss : 0.355249, loss_ce: 0.024608
[14:47:51.062] iteration 5160 : loss : 0.236658, loss_ce: 0.021991
[14:47:55.361] iteration 5170 : loss : 0.253379, loss_ce: 0.010272
[14:47:59.647] iteration 5180 : loss : 0.270565, loss_ce: 0.017771
[14:48:03.948] iteration 5190 : loss : 0.267387, loss_ce: 0.011428
[14:48:08.235] iteration 5200 : loss : 0.252593, loss_ce: 0.012240
[14:48:12.533] iteration 5210 : loss : 0.269606, loss_ce: 0.019891
[14:48:16.824] iteration 5220 : loss : 0.316025, loss_ce: 0.041088
[14:48:21.124] iteration 5230 : loss : 0.245083, loss_ce: 0.017987
[14:48:25.412] iteration 5240 : loss : 0.298655, loss_ce: 0.015927
[14:48:29.720] iteration 5250 : loss : 0.280793, loss_ce: 0.014692
[14:48:34.010] iteration 5260 : loss : 0.341291, loss_ce: 0.016915
[14:48:38.316] iteration 5270 : loss : 0.258583, loss_ce: 0.027247
[14:48:42.609] iteration 5280 : loss : 0.245005, loss_ce: 0.029476
[14:48:46.916] iteration 5290 : loss : 0.217680, loss_ce: 0.014778
[14:48:51.212] iteration 5300 : loss : 0.229027, loss_ce: 0.014403
[14:48:55.515] iteration 5310 : loss : 0.248572, loss_ce: 0.013734
[14:48:59.810] iteration 5320 : loss : 0.317692, loss_ce: 0.019954
[14:49:04.117] iteration 5330 : loss : 0.264524, loss_ce: 0.018259
[14:49:08.412] iteration 5340 : loss : 0.222988, loss_ce: 0.021303
[14:49:12.716] iteration 5350 : loss : 0.209523, loss_ce: 0.013435
[14:49:16.906] iteration 5360 : loss : 0.305204, loss_ce: 0.012015
[14:51:10.305] save model to ./finetune_tpgm_kits23_2\finetuned_epoch_19.pth
[14:51:25.018] iteration 5370 : loss : 0.257315, loss_ce: 0.030586
[14:51:29.339] iteration 5380 : loss : 0.373356, loss_ce: 0.074715
[14:51:33.669] iteration 5390 : loss : 0.341273, loss_ce: 0.018424
[14:51:37.987] iteration 5400 : loss : 0.227936, loss_ce: 0.020288
[14:51:42.321] iteration 5410 : loss : 0.219113, loss_ce: 0.021679
[14:51:46.645] iteration 5420 : loss : 0.275082, loss_ce: 0.014071
[14:51:50.983] iteration 5430 : loss : 0.267341, loss_ce: 0.015724
[14:51:55.311] iteration 5440 : loss : 0.285738, loss_ce: 0.027186
[14:51:59.655] iteration 5450 : loss : 0.277339, loss_ce: 0.027931
[14:52:03.986] iteration 5460 : loss : 0.258985, loss_ce: 0.017391
[14:52:08.328] iteration 5470 : loss : 0.218436, loss_ce: 0.018673
[14:52:12.659] iteration 5480 : loss : 0.331439, loss_ce: 0.027960
[14:52:17.004] iteration 5490 : loss : 0.216342, loss_ce: 0.010537
[14:52:21.338] iteration 5500 : loss : 0.322928, loss_ce: 0.005963
[14:52:25.685] iteration 5510 : loss : 0.296921, loss_ce: 0.024879
[14:52:30.021] iteration 5520 : loss : 0.274440, loss_ce: 0.022024
[14:52:34.365] iteration 5530 : loss : 0.293245, loss_ce: 0.022862
[14:52:38.697] iteration 5540 : loss : 0.328311, loss_ce: 0.011966
[14:52:43.043] iteration 5550 : loss : 0.337662, loss_ce: 0.009605
[14:52:47.377] iteration 5560 : loss : 0.203708, loss_ce: 0.008005
[14:52:51.725] iteration 5570 : loss : 0.196327, loss_ce: 0.008621
[14:52:56.062] iteration 5580 : loss : 0.251687, loss_ce: 0.012611
[14:53:00.410] iteration 5590 : loss : 0.233559, loss_ce: 0.008235
[14:53:04.750] iteration 5600 : loss : 0.329721, loss_ce: 0.005364
[14:53:09.093] iteration 5610 : loss : 0.260807, loss_ce: 0.017567
[14:53:13.428] iteration 5620 : loss : 0.247622, loss_ce: 0.007125
[14:55:20.860] iteration 5630 : loss : 0.333823, loss_ce: 0.056474
[14:55:25.435] iteration 5640 : loss : 0.300721, loss_ce: 0.020231
[14:55:29.760] iteration 5650 : loss : 0.244541, loss_ce: 0.009347
[14:55:34.079] iteration 5660 : loss : 0.318374, loss_ce: 0.014205
[14:55:38.408] iteration 5670 : loss : 0.356618, loss_ce: 0.053709
[14:55:42.729] iteration 5680 : loss : 0.304790, loss_ce: 0.029628
[14:55:47.062] iteration 5690 : loss : 0.212352, loss_ce: 0.013305
[14:55:51.384] iteration 5700 : loss : 0.244353, loss_ce: 0.017843
[14:55:55.720] iteration 5710 : loss : 0.314257, loss_ce: 0.015257
[14:56:00.052] iteration 5720 : loss : 0.273665, loss_ce: 0.014203
[14:56:04.400] iteration 5730 : loss : 0.310169, loss_ce: 0.022150
[14:56:08.731] iteration 5740 : loss : 0.325362, loss_ce: 0.013589
[14:56:13.070] iteration 5750 : loss : 0.259803, loss_ce: 0.006022
[14:56:17.404] iteration 5760 : loss : 0.210734, loss_ce: 0.008575
[14:56:21.746] iteration 5770 : loss : 0.258750, loss_ce: 0.011526
[14:56:26.082] iteration 5780 : loss : 0.289563, loss_ce: 0.023108
[14:56:30.424] iteration 5790 : loss : 0.316720, loss_ce: 0.033436
[14:56:34.762] iteration 5800 : loss : 0.277834, loss_ce: 0.024166
[14:56:39.107] iteration 5810 : loss : 0.293835, loss_ce: 0.041260
[14:56:43.441] iteration 5820 : loss : 0.212016, loss_ce: 0.014220
[14:56:47.787] iteration 5830 : loss : 0.357628, loss_ce: 0.028106
[14:56:52.122] iteration 5840 : loss : 0.342097, loss_ce: 0.007005
[14:56:56.462] iteration 5850 : loss : 0.347571, loss_ce: 0.018698
[14:57:00.802] iteration 5860 : loss : 0.258989, loss_ce: 0.005874
[14:57:05.148] iteration 5870 : loss : 0.255815, loss_ce: 0.020150
[14:57:09.477] iteration 5880 : loss : 0.142692, loss_ce: 0.010326
[14:57:13.821] iteration 5890 : loss : 0.348377, loss_ce: 0.023398
[14:59:32.111] iteration 5900 : loss : 0.204499, loss_ce: 0.016026
[14:59:36.552] iteration 5910 : loss : 0.332109, loss_ce: 0.011862
[14:59:40.865] iteration 5920 : loss : 0.325356, loss_ce: 0.019523
[14:59:45.191] iteration 5930 : loss : 0.317405, loss_ce: 0.016753
[14:59:49.509] iteration 5940 : loss : 0.225804, loss_ce: 0.020661
[14:59:53.837] iteration 5950 : loss : 0.254130, loss_ce: 0.027723
[14:59:58.153] iteration 5960 : loss : 0.306237, loss_ce: 0.012260
[15:00:02.491] iteration 5970 : loss : 0.238374, loss_ce: 0.012573
[15:00:06.818] iteration 5980 : loss : 0.220305, loss_ce: 0.018450
[15:00:11.153] iteration 5990 : loss : 0.241985, loss_ce: 0.016048
[15:00:15.484] iteration 6000 : loss : 0.247740, loss_ce: 0.009530
[15:00:19.822] iteration 6010 : loss : 0.168329, loss_ce: 0.015428
[15:00:24.152] iteration 6020 : loss : 0.290855, loss_ce: 0.007817
[15:00:28.494] iteration 6030 : loss : 0.210861, loss_ce: 0.031743
[15:00:32.825] iteration 6040 : loss : 0.251578, loss_ce: 0.011614
[15:00:37.170] iteration 6050 : loss : 0.261750, loss_ce: 0.020337
[15:00:41.500] iteration 6060 : loss : 0.326177, loss_ce: 0.014573
[15:00:45.844] iteration 6070 : loss : 0.217774, loss_ce: 0.009216
[15:00:50.177] iteration 6080 : loss : 0.268484, loss_ce: 0.014575
[15:00:54.518] iteration 6090 : loss : 0.300389, loss_ce: 0.024808
[15:00:58.852] iteration 6100 : loss : 0.206391, loss_ce: 0.018258
[15:01:03.199] iteration 6110 : loss : 0.167521, loss_ce: 0.023386
[15:01:07.534] iteration 6120 : loss : 0.199730, loss_ce: 0.008219
[15:01:11.885] iteration 6130 : loss : 0.232028, loss_ce: 0.023791
[15:01:16.218] iteration 6140 : loss : 0.174079, loss_ce: 0.016450
[15:01:20.560] iteration 6150 : loss : 0.193200, loss_ce: 0.009487
[15:01:24.896] iteration 6160 : loss : 0.175609, loss_ce: 0.009902
[15:03:32.367] iteration 6170 : loss : 0.309139, loss_ce: 0.048373
[15:03:36.683] iteration 6180 : loss : 0.321681, loss_ce: 0.025694
[15:03:41.001] iteration 6190 : loss : 0.233011, loss_ce: 0.009076
[15:03:45.305] iteration 6200 : loss : 0.328597, loss_ce: 0.016121
[15:03:49.628] iteration 6210 : loss : 0.314841, loss_ce: 0.025454
[15:03:53.940] iteration 6220 : loss : 0.281073, loss_ce: 0.026339
[15:03:58.262] iteration 6230 : loss : 0.273676, loss_ce: 0.011141
[15:04:02.571] iteration 6240 : loss : 0.217361, loss_ce: 0.021061
[15:04:06.898] iteration 6250 : loss : 0.181260, loss_ce: 0.014764
[15:04:11.214] iteration 6260 : loss : 0.347918, loss_ce: 0.039666
[15:04:15.549] iteration 6270 : loss : 0.273699, loss_ce: 0.013895
[15:04:19.868] iteration 6280 : loss : 0.163112, loss_ce: 0.015160
[15:04:24.202] iteration 6290 : loss : 0.212888, loss_ce: 0.004755
[15:04:28.523] iteration 6300 : loss : 0.295071, loss_ce: 0.011108
[15:04:32.856] iteration 6310 : loss : 0.198476, loss_ce: 0.017006
[15:04:37.178] iteration 6320 : loss : 0.235955, loss_ce: 0.012457
[15:04:41.512] iteration 6330 : loss : 0.282146, loss_ce: 0.007079
[15:04:45.837] iteration 6340 : loss : 0.311332, loss_ce: 0.023961
[15:04:50.175] iteration 6350 : loss : 0.300695, loss_ce: 0.015552
[15:04:54.496] iteration 6360 : loss : 0.216889, loss_ce: 0.009077
[15:04:58.834] iteration 6370 : loss : 0.210075, loss_ce: 0.013299
[15:05:03.162] iteration 6380 : loss : 0.234834, loss_ce: 0.030839
[15:05:07.501] iteration 6390 : loss : 0.249112, loss_ce: 0.019749
[15:05:11.824] iteration 6400 : loss : 0.214614, loss_ce: 0.007325
[15:05:16.159] iteration 6410 : loss : 0.249423, loss_ce: 0.017128
[15:05:20.485] iteration 6420 : loss : 0.206526, loss_ce: 0.009992
[15:05:24.818] iteration 6430 : loss : 0.251306, loss_ce: 0.013201
[15:07:34.086] iteration 6440 : loss : 0.329167, loss_ce: 0.011862
[15:07:38.399] iteration 6450 : loss : 0.391514, loss_ce: 0.060800
[15:07:42.708] iteration 6460 : loss : 0.268954, loss_ce: 0.020272
[15:07:47.026] iteration 6470 : loss : 0.342559, loss_ce: 0.021708
[15:07:51.340] iteration 6480 : loss : 0.243283, loss_ce: 0.032305
[15:07:55.662] iteration 6490 : loss : 0.271117, loss_ce: 0.016634
[15:07:59.975] iteration 6500 : loss : 0.266152, loss_ce: 0.024146
[15:08:04.301] iteration 6510 : loss : 0.247977, loss_ce: 0.022586
[15:08:08.613] iteration 6520 : loss : 0.309399, loss_ce: 0.013017
[15:08:12.937] iteration 6530 : loss : 0.247947, loss_ce: 0.019043
[15:08:17.253] iteration 6540 : loss : 0.236610, loss_ce: 0.018319
[15:08:21.582] iteration 6550 : loss : 0.309804, loss_ce: 0.014523
[15:08:25.900] iteration 6560 : loss : 0.238376, loss_ce: 0.007230
[15:08:30.229] iteration 6570 : loss : 0.275885, loss_ce: 0.012943
[15:08:34.541] iteration 6580 : loss : 0.233355, loss_ce: 0.008683
[15:08:38.872] iteration 6590 : loss : 0.209486, loss_ce: 0.011353
[15:08:43.195] iteration 6600 : loss : 0.376008, loss_ce: 0.025258
[15:08:47.528] iteration 6610 : loss : 0.209905, loss_ce: 0.012610
[15:08:51.848] iteration 6620 : loss : 0.285892, loss_ce: 0.019283
[15:08:56.180] iteration 6630 : loss : 0.317871, loss_ce: 0.010354
[15:09:00.502] iteration 6640 : loss : 0.332801, loss_ce: 0.025565
[15:09:04.838] iteration 6650 : loss : 0.328622, loss_ce: 0.012772
[15:09:09.160] iteration 6660 : loss : 0.131634, loss_ce: 0.021449
[15:09:13.495] iteration 6670 : loss : 0.290980, loss_ce: 0.013406
[15:09:17.817] iteration 6680 : loss : 0.344657, loss_ce: 0.007967
[15:09:22.150] iteration 6690 : loss : 0.192138, loss_ce: 0.019665
[15:09:26.371] iteration 6700 : loss : 0.278664, loss_ce: 0.007840
[15:11:45.627] iteration 6710 : loss : 0.315403, loss_ce: 0.037521
[15:11:49.938] iteration 6720 : loss : 0.299611, loss_ce: 0.025665
[15:11:54.264] iteration 6730 : loss : 0.297835, loss_ce: 0.021883
[15:11:58.579] iteration 6740 : loss : 0.274526, loss_ce: 0.028994
[15:12:02.912] iteration 6750 : loss : 0.292808, loss_ce: 0.015865
[15:12:07.224] iteration 6760 : loss : 0.207540, loss_ce: 0.013690
[15:12:11.557] iteration 6770 : loss : 0.295810, loss_ce: 0.030306
[15:12:15.878] iteration 6780 : loss : 0.349423, loss_ce: 0.130410
[15:12:20.209] iteration 6790 : loss : 0.262231, loss_ce: 0.022054
[15:12:24.536] iteration 6800 : loss : 0.274850, loss_ce: 0.011215
[15:12:28.874] iteration 6810 : loss : 0.309577, loss_ce: 0.011755
[15:12:33.203] iteration 6820 : loss : 0.344738, loss_ce: 0.017684
[15:12:37.547] iteration 6830 : loss : 0.205070, loss_ce: 0.009323
[15:12:41.875] iteration 6840 : loss : 0.229159, loss_ce: 0.020051
[15:12:46.212] iteration 6850 : loss : 0.242572, loss_ce: 0.012948
[15:12:50.546] iteration 6860 : loss : 0.222000, loss_ce: 0.009400
[15:12:54.891] iteration 6870 : loss : 0.178257, loss_ce: 0.003024
[15:12:59.222] iteration 6880 : loss : 0.238300, loss_ce: 0.013384
[15:13:03.567] iteration 6890 : loss : 0.200124, loss_ce: 0.005899
[15:13:07.897] iteration 6900 : loss : 0.276653, loss_ce: 0.010002
[15:13:12.236] iteration 6910 : loss : 0.343751, loss_ce: 0.052278
[15:13:16.571] iteration 6920 : loss : 0.249977, loss_ce: 0.013285
[15:13:20.915] iteration 6930 : loss : 0.196815, loss_ce: 0.008198
[15:13:25.248] iteration 6940 : loss : 0.340333, loss_ce: 0.046388
[15:13:29.594] iteration 6950 : loss : 0.135389, loss_ce: 0.013617
[15:13:33.925] iteration 6960 : loss : 0.257725, loss_ce: 0.008366
[15:15:42.111] iteration 6970 : loss : 0.328519, loss_ce: 0.024937
[15:15:46.664] iteration 6980 : loss : 0.296101, loss_ce: 0.037146
[15:15:50.987] iteration 6990 : loss : 0.347584, loss_ce: 0.024865
[15:15:55.301] iteration 7000 : loss : 0.298063, loss_ce: 0.026533
[15:15:59.635] iteration 7010 : loss : 0.306561, loss_ce: 0.011464
[15:16:03.958] iteration 7020 : loss : 0.296389, loss_ce: 0.027193
[15:16:08.291] iteration 7030 : loss : 0.286312, loss_ce: 0.020188
[15:16:12.612] iteration 7040 : loss : 0.214136, loss_ce: 0.031776
[15:16:16.944] iteration 7050 : loss : 0.122153, loss_ce: 0.008494
[15:16:21.269] iteration 7060 : loss : 0.318307, loss_ce: 0.014177
[15:16:25.610] iteration 7070 : loss : 0.347810, loss_ce: 0.007563
[15:16:29.939] iteration 7080 : loss : 0.237987, loss_ce: 0.010120
[15:16:34.277] iteration 7090 : loss : 0.293516, loss_ce: 0.025889
[15:16:38.607] iteration 7100 : loss : 0.233204, loss_ce: 0.026165
[15:16:42.950] iteration 7110 : loss : 0.313329, loss_ce: 0.008769
[15:16:47.281] iteration 7120 : loss : 0.190346, loss_ce: 0.005015
[15:16:51.626] iteration 7130 : loss : 0.241758, loss_ce: 0.025199
[15:16:55.961] iteration 7140 : loss : 0.284971, loss_ce: 0.004086
[15:17:00.298] iteration 7150 : loss : 0.247141, loss_ce: 0.014234
[15:17:04.630] iteration 7160 : loss : 0.295846, loss_ce: 0.012644
[15:17:08.973] iteration 7170 : loss : 0.215262, loss_ce: 0.013457
[15:17:13.306] iteration 7180 : loss : 0.227458, loss_ce: 0.015482
[15:17:17.647] iteration 7190 : loss : 0.330147, loss_ce: 0.047651
[15:17:21.982] iteration 7200 : loss : 0.214198, loss_ce: 0.005641
[15:17:26.325] iteration 7210 : loss : 0.225184, loss_ce: 0.015626
[15:17:30.658] iteration 7220 : loss : 0.246049, loss_ce: 0.010115
[15:17:35.005] iteration 7230 : loss : 0.221178, loss_ce: 0.014638
[15:19:38.608] iteration 7240 : loss : 0.270199, loss_ce: 0.015140
[15:19:42.807] iteration 7250 : loss : 0.333512, loss_ce: 0.023598
[15:19:46.862] iteration 7260 : loss : 0.210577, loss_ce: 0.019770
[15:19:50.946] iteration 7270 : loss : 0.258321, loss_ce: 0.018882
[15:19:55.026] iteration 7280 : loss : 0.286264, loss_ce: 0.022534
[15:19:59.143] iteration 7290 : loss : 0.284580, loss_ce: 0.017792
[15:20:03.212] iteration 7300 : loss : 0.279929, loss_ce: 0.019507
[15:20:07.280] iteration 7310 : loss : 0.325116, loss_ce: 0.011718
[15:20:11.378] iteration 7320 : loss : 0.240653, loss_ce: 0.012282
[15:20:15.510] iteration 7330 : loss : 0.310692, loss_ce: 0.014787
[15:20:19.599] iteration 7340 : loss : 0.090446, loss_ce: 0.008521
[15:20:23.707] iteration 7350 : loss : 0.224601, loss_ce: 0.014306
[15:20:27.760] iteration 7360 : loss : 0.177811, loss_ce: 0.019846
[15:20:31.836] iteration 7370 : loss : 0.263925, loss_ce: 0.014169
[15:20:35.918] iteration 7380 : loss : 0.219113, loss_ce: 0.014378
[15:20:40.013] iteration 7390 : loss : 0.171996, loss_ce: 0.006163
[15:20:44.077] iteration 7400 : loss : 0.241172, loss_ce: 0.010615
[15:20:48.152] iteration 7410 : loss : 0.240453, loss_ce: 0.030325
[15:20:52.206] iteration 7420 : loss : 0.299686, loss_ce: 0.020515
[15:20:56.270] iteration 7430 : loss : 0.208783, loss_ce: 0.012470
[15:21:00.321] iteration 7440 : loss : 0.159934, loss_ce: 0.021979
[15:21:04.389] iteration 7450 : loss : 0.237512, loss_ce: 0.006311
[15:21:08.457] iteration 7460 : loss : 0.181009, loss_ce: 0.009445
[15:21:12.519] iteration 7470 : loss : 0.230971, loss_ce: 0.009762
[15:21:16.581] iteration 7480 : loss : 0.303778, loss_ce: 0.024141
[15:21:20.707] iteration 7490 : loss : 0.265178, loss_ce: 0.008286
[15:21:24.808] iteration 7500 : loss : 0.265470, loss_ce: 0.018800
[15:23:34.272] iteration 7510 : loss : 0.286410, loss_ce: 0.094525
[15:23:38.362] iteration 7520 : loss : 0.252902, loss_ce: 0.014486
[15:23:42.491] iteration 7530 : loss : 0.333018, loss_ce: 0.017880
[15:23:46.602] iteration 7540 : loss : 0.281538, loss_ce: 0.022138
[15:23:50.692] iteration 7550 : loss : 0.323188, loss_ce: 0.031086
[15:23:54.782] iteration 7560 : loss : 0.322247, loss_ce: 0.012309
[15:23:58.870] iteration 7570 : loss : 0.236603, loss_ce: 0.017129
[15:24:02.947] iteration 7580 : loss : 0.240690, loss_ce: 0.028821
[15:24:07.047] iteration 7590 : loss : 0.214593, loss_ce: 0.009029
[15:24:11.109] iteration 7600 : loss : 0.290667, loss_ce: 0.016319
[15:24:15.173] iteration 7610 : loss : 0.291086, loss_ce: 0.009741
[15:24:19.221] iteration 7620 : loss : 0.305009, loss_ce: 0.005558
[15:24:23.273] iteration 7630 : loss : 0.317257, loss_ce: 0.030549
[15:24:27.318] iteration 7640 : loss : 0.289649, loss_ce: 0.014279
[15:24:31.379] iteration 7650 : loss : 0.225051, loss_ce: 0.010273
[15:24:35.426] iteration 7660 : loss : 0.260703, loss_ce: 0.031154
[15:24:39.483] iteration 7670 : loss : 0.245905, loss_ce: 0.009068
[15:24:43.529] iteration 7680 : loss : 0.274330, loss_ce: 0.010882
[15:24:47.600] iteration 7690 : loss : 0.212062, loss_ce: 0.005667
[15:24:51.678] iteration 7700 : loss : 0.232404, loss_ce: 0.019390
[15:24:55.813] iteration 7710 : loss : 0.168991, loss_ce: 0.013357
[15:24:59.962] iteration 7720 : loss : 0.305540, loss_ce: 0.007504
[15:25:04.041] iteration 7730 : loss : 0.105665, loss_ce: 0.012622
[15:25:08.092] iteration 7740 : loss : 0.323358, loss_ce: 0.026652
[15:25:12.150] iteration 7750 : loss : 0.310287, loss_ce: 0.020919
[15:25:16.200] iteration 7760 : loss : 0.254076, loss_ce: 0.009978
[15:25:20.258] iteration 7770 : loss : 0.236764, loss_ce: 0.018611
[15:27:03.643] iteration 7780 : loss : 0.246900, loss_ce: 0.026192
[15:27:08.071] iteration 7790 : loss : 0.240926, loss_ce: 0.017781
[15:27:12.487] iteration 7800 : loss : 0.230969, loss_ce: 0.015321
[15:27:16.918] iteration 7810 : loss : 0.267800, loss_ce: 0.020834
[15:27:21.334] iteration 7820 : loss : 0.250214, loss_ce: 0.017746
[15:27:25.755] iteration 7830 : loss : 0.311961, loss_ce: 0.021812
[15:27:30.119] iteration 7840 : loss : 0.238869, loss_ce: 0.015710
[15:27:34.536] iteration 7850 : loss : 0.268500, loss_ce: 0.017892
[15:27:39.127] iteration 7860 : loss : 0.339056, loss_ce: 0.017295
[15:27:43.651] iteration 7870 : loss : 0.237764, loss_ce: 0.011701
[15:27:48.189] iteration 7880 : loss : 0.220999, loss_ce: 0.013261
[15:27:52.655] iteration 7890 : loss : 0.181718, loss_ce: 0.016351
[15:27:57.218] iteration 7900 : loss : 0.273487, loss_ce: 0.013628
[15:28:01.855] iteration 7910 : loss : 0.258417, loss_ce: 0.026364
[15:28:06.460] iteration 7920 : loss : 0.128721, loss_ce: 0.011347
[15:28:10.930] iteration 7930 : loss : 0.284190, loss_ce: 0.015341
[15:28:15.358] iteration 7940 : loss : 0.250013, loss_ce: 0.011302
[15:28:19.792] iteration 7950 : loss : 0.232883, loss_ce: 0.011557
[15:28:24.220] iteration 7960 : loss : 0.207523, loss_ce: 0.018719
[15:28:28.661] iteration 7970 : loss : 0.238929, loss_ce: 0.028626
[15:28:33.087] iteration 7980 : loss : 0.246133, loss_ce: 0.023485
[15:28:37.525] iteration 7990 : loss : 0.205451, loss_ce: 0.012309
[15:28:41.945] iteration 8000 : loss : 0.235412, loss_ce: 0.019927
[15:28:46.382] iteration 8010 : loss : 0.293650, loss_ce: 0.030433
[15:28:50.824] iteration 8020 : loss : 0.167958, loss_ce: 0.014928
[15:28:55.014] iteration 8030 : loss : 0.202212, loss_ce: 0.010652
[15:28:59.045] iteration 8040 : loss : 0.216537, loss_ce: 0.007044
[15:30:24.379] save model to ./finetune_tpgm_kits23_2\finetuned_epoch_29.pth
[15:30:38.318] iteration 8050 : loss : 0.315012, loss_ce: 0.014045
[15:30:42.432] iteration 8060 : loss : 0.241456, loss_ce: 0.018276
[15:30:46.560] iteration 8070 : loss : 0.213631, loss_ce: 0.017195
[15:30:50.683] iteration 8080 : loss : 0.234748, loss_ce: 0.014729
[15:30:54.812] iteration 8090 : loss : 0.230379, loss_ce: 0.014505
[15:30:58.937] iteration 8100 : loss : 0.365570, loss_ce: 0.011591
[15:31:03.071] iteration 8110 : loss : 0.239188, loss_ce: 0.009705
[15:31:07.193] iteration 8120 : loss : 0.241680, loss_ce: 0.013403
[15:31:11.325] iteration 8130 : loss : 0.212089, loss_ce: 0.014095
[15:31:15.451] iteration 8140 : loss : 0.233687, loss_ce: 0.010879
[15:31:19.587] iteration 8150 : loss : 0.224257, loss_ce: 0.028308
[15:31:23.711] iteration 8160 : loss : 0.274112, loss_ce: 0.007701
[15:31:27.848] iteration 8170 : loss : 0.206284, loss_ce: 0.020139
[15:31:31.974] iteration 8180 : loss : 0.244976, loss_ce: 0.026622
[15:31:36.107] iteration 8190 : loss : 0.311284, loss_ce: 0.033311
[15:31:40.233] iteration 8200 : loss : 0.246613, loss_ce: 0.017419
[15:31:44.369] iteration 8210 : loss : 0.311469, loss_ce: 0.011264
[15:31:48.495] iteration 8220 : loss : 0.253615, loss_ce: 0.013552
[15:31:52.632] iteration 8230 : loss : 0.243277, loss_ce: 0.010901
[15:31:56.758] iteration 8240 : loss : 0.323284, loss_ce: 0.010012
[15:32:00.898] iteration 8250 : loss : 0.223864, loss_ce: 0.018781
[15:32:05.023] iteration 8260 : loss : 0.262395, loss_ce: 0.007913
[15:32:09.159] iteration 8270 : loss : 0.195454, loss_ce: 0.006531
[15:32:13.284] iteration 8280 : loss : 0.311956, loss_ce: 0.014690
[15:32:17.424] iteration 8290 : loss : 0.198534, loss_ce: 0.010398
[15:32:21.550] iteration 8300 : loss : 0.223027, loss_ce: 0.011474
[15:34:11.156] iteration 8310 : loss : 0.314058, loss_ce: 0.021032
[15:34:15.266] iteration 8320 : loss : 0.213415, loss_ce: 0.011634
[15:34:19.389] iteration 8330 : loss : 0.208929, loss_ce: 0.020257
[15:34:23.507] iteration 8340 : loss : 0.247298, loss_ce: 0.013993
[15:34:27.638] iteration 8350 : loss : 0.286398, loss_ce: 0.013241
[15:34:31.760] iteration 8360 : loss : 0.286531, loss_ce: 0.014287
[15:34:35.888] iteration 8370 : loss : 0.229861, loss_ce: 0.007272
[15:34:40.012] iteration 8380 : loss : 0.314451, loss_ce: 0.008416
[15:34:44.143] iteration 8390 : loss : 0.245209, loss_ce: 0.020140
[15:34:48.266] iteration 8400 : loss : 0.276887, loss_ce: 0.025749
[15:34:52.399] iteration 8410 : loss : 0.282507, loss_ce: 0.010767
[15:34:56.521] iteration 8420 : loss : 0.199764, loss_ce: 0.014229
[15:35:00.656] iteration 8430 : loss : 0.271079, loss_ce: 0.015835
[15:35:04.781] iteration 8440 : loss : 0.179261, loss_ce: 0.009905
[15:35:08.915] iteration 8450 : loss : 0.254937, loss_ce: 0.014772
[15:35:13.042] iteration 8460 : loss : 0.286967, loss_ce: 0.037243
[15:35:17.177] iteration 8470 : loss : 0.196336, loss_ce: 0.009410
[15:35:21.303] iteration 8480 : loss : 0.335841, loss_ce: 0.013648
[15:35:25.438] iteration 8490 : loss : 0.165293, loss_ce: 0.006387
[15:35:29.565] iteration 8500 : loss : 0.274048, loss_ce: 0.008070
[15:35:33.700] iteration 8510 : loss : 0.152641, loss_ce: 0.011029
[15:35:37.827] iteration 8520 : loss : 0.217221, loss_ce: 0.013775
[15:35:41.961] iteration 8530 : loss : 0.211731, loss_ce: 0.009751
[15:35:46.086] iteration 8540 : loss : 0.305501, loss_ce: 0.016808
[15:35:50.221] iteration 8550 : loss : 0.273112, loss_ce: 0.009175
[15:35:54.345] iteration 8560 : loss : 0.256042, loss_ce: 0.007475
[15:35:58.480] iteration 8570 : loss : 0.298449, loss_ce: 0.013276
[15:37:37.515] iteration 8580 : loss : 0.249273, loss_ce: 0.027828
[15:37:41.638] iteration 8590 : loss : 0.332488, loss_ce: 0.022202
[15:37:45.754] iteration 8600 : loss : 0.253608, loss_ce: 0.019900
[15:37:49.881] iteration 8610 : loss : 0.261614, loss_ce: 0.017512
[15:37:54.001] iteration 8620 : loss : 0.216320, loss_ce: 0.018173
[15:37:58.130] iteration 8630 : loss : 0.326622, loss_ce: 0.015574
[15:38:02.256] iteration 8640 : loss : 0.297474, loss_ce: 0.006494
[15:38:06.390] iteration 8650 : loss : 0.282494, loss_ce: 0.012103
[15:38:10.516] iteration 8660 : loss : 0.211588, loss_ce: 0.012089
[15:38:14.648] iteration 8670 : loss : 0.250489, loss_ce: 0.010664
[15:38:18.775] iteration 8680 : loss : 0.158520, loss_ce: 0.013423
[15:38:22.906] iteration 8690 : loss : 0.225282, loss_ce: 0.015619
[15:38:27.032] iteration 8700 : loss : 0.215927, loss_ce: 0.009249
[15:38:31.166] iteration 8710 : loss : 0.282028, loss_ce: 0.017491
[15:38:35.293] iteration 8720 : loss : 0.295741, loss_ce: 0.019571
[15:38:39.428] iteration 8730 : loss : 0.305380, loss_ce: 0.058984
[15:38:43.551] iteration 8740 : loss : 0.254421, loss_ce: 0.011578
[15:38:47.686] iteration 8750 : loss : 0.309690, loss_ce: 0.017556
[15:38:49.905] iteration 8760 : loss : 0.258953, loss_ce: 0.018078
[15:38:54.041] iteration 8770 : loss : 0.335338, loss_ce: 0.042603
[15:38:58.168] iteration 8780 : loss : 0.222659, loss_ce: 0.015697
[15:39:02.312] iteration 8790 : loss : 0.273458, loss_ce: 0.011013
[15:39:06.440] iteration 8800 : loss : 0.232933, loss_ce: 0.007890
[15:39:10.577] iteration 8810 : loss : 0.278215, loss_ce: 0.008832
[15:39:14.705] iteration 8820 : loss : 0.227933, loss_ce: 0.017567
[15:39:18.880] iteration 8830 : loss : 0.241804, loss_ce: 0.013730
[15:39:23.013] iteration 8840 : loss : 0.294230, loss_ce: 0.009760
[15:41:01.975] iteration 8850 : loss : 0.269856, loss_ce: 0.019888
[15:41:06.089] iteration 8860 : loss : 0.324316, loss_ce: 0.012771
[15:41:10.214] iteration 8870 : loss : 0.288034, loss_ce: 0.007857
[15:41:14.333] iteration 8880 : loss : 0.259202, loss_ce: 0.024776
[15:41:18.462] iteration 8890 : loss : 0.333484, loss_ce: 0.020084
[15:41:22.582] iteration 8900 : loss : 0.230008, loss_ce: 0.010549
[15:41:26.712] iteration 8910 : loss : 0.205202, loss_ce: 0.009850
[15:41:30.834] iteration 8920 : loss : 0.097468, loss_ce: 0.013382
[15:41:34.966] iteration 8930 : loss : 0.284809, loss_ce: 0.022531
[15:41:39.091] iteration 8940 : loss : 0.194596, loss_ce: 0.016028
[15:41:43.224] iteration 8950 : loss : 0.315220, loss_ce: 0.010233
[15:41:47.349] iteration 8960 : loss : 0.205329, loss_ce: 0.009369
[15:41:51.486] iteration 8970 : loss : 0.297554, loss_ce: 0.028973
[15:41:55.610] iteration 8980 : loss : 0.267036, loss_ce: 0.016393
[15:41:59.743] iteration 8990 : loss : 0.255889, loss_ce: 0.017481
[15:42:03.875] iteration 9000 : loss : 0.225771, loss_ce: 0.009161
[15:42:08.009] iteration 9010 : loss : 0.250497, loss_ce: 0.020034
[15:42:12.134] iteration 9020 : loss : 0.137962, loss_ce: 0.013941
[15:42:16.269] iteration 9030 : loss : 0.128819, loss_ce: 0.007873
[15:42:20.394] iteration 9040 : loss : 0.192104, loss_ce: 0.007849
[15:42:24.564] iteration 9050 : loss : 0.216372, loss_ce: 0.007477
[15:42:28.693] iteration 9060 : loss : 0.204210, loss_ce: 0.011824
[15:42:32.834] iteration 9070 : loss : 0.279145, loss_ce: 0.010779
[15:42:36.967] iteration 9080 : loss : 0.205771, loss_ce: 0.007854
[15:42:41.112] iteration 9090 : loss : 0.177918, loss_ce: 0.008155
[15:42:45.238] iteration 9100 : loss : 0.310449, loss_ce: 0.022452
[15:42:49.371] iteration 9110 : loss : 0.229030, loss_ce: 0.013320
[15:44:38.928] iteration 9120 : loss : 0.323805, loss_ce: 0.021745
[15:44:43.048] iteration 9130 : loss : 0.223082, loss_ce: 0.019982
[15:44:47.163] iteration 9140 : loss : 0.207970, loss_ce: 0.013412
[15:44:51.285] iteration 9150 : loss : 0.186762, loss_ce: 0.006525
[15:44:55.402] iteration 9160 : loss : 0.244247, loss_ce: 0.026716
[15:44:59.534] iteration 9170 : loss : 0.219584, loss_ce: 0.019950
[15:45:03.659] iteration 9180 : loss : 0.265148, loss_ce: 0.009722
[15:45:07.791] iteration 9190 : loss : 0.253586, loss_ce: 0.029301
[15:45:11.914] iteration 9200 : loss : 0.201204, loss_ce: 0.009940
[15:45:16.044] iteration 9210 : loss : 0.209845, loss_ce: 0.011484
[15:45:20.168] iteration 9220 : loss : 0.179897, loss_ce: 0.006210
[15:45:24.302] iteration 9230 : loss : 0.282768, loss_ce: 0.019348
[15:45:28.426] iteration 9240 : loss : 0.174660, loss_ce: 0.007870
[15:45:32.596] iteration 9250 : loss : 0.257916, loss_ce: 0.030850
[15:45:36.724] iteration 9260 : loss : 0.326536, loss_ce: 0.023860
[15:45:40.862] iteration 9270 : loss : 0.207549, loss_ce: 0.016938
[15:45:44.995] iteration 9280 : loss : 0.231408, loss_ce: 0.013327
[15:45:49.138] iteration 9290 : loss : 0.311636, loss_ce: 0.005932
[15:45:53.263] iteration 9300 : loss : 0.251367, loss_ce: 0.012238
[15:45:57.398] iteration 9310 : loss : 0.313585, loss_ce: 0.012873
[15:46:01.530] iteration 9320 : loss : 0.195572, loss_ce: 0.010362
[15:46:05.665] iteration 9330 : loss : 0.125633, loss_ce: 0.011647
[15:46:09.790] iteration 9340 : loss : 0.196696, loss_ce: 0.010385
[15:46:13.927] iteration 9350 : loss : 0.213315, loss_ce: 0.014526
[15:46:18.055] iteration 9360 : loss : 0.155475, loss_ce: 0.008852
[15:46:22.190] iteration 9370 : loss : 0.154316, loss_ce: 0.015329
[15:46:26.217] iteration 9380 : loss : 0.249656, loss_ce: 0.005314
[15:48:05.488] iteration 9390 : loss : 0.253444, loss_ce: 0.014167
[15:48:09.600] iteration 9400 : loss : 0.198457, loss_ce: 0.015190
[15:48:13.726] iteration 9410 : loss : 0.138837, loss_ce: 0.011872
[15:48:17.846] iteration 9420 : loss : 0.311746, loss_ce: 0.011467
[15:48:21.977] iteration 9430 : loss : 0.245471, loss_ce: 0.036249
[15:48:26.098] iteration 9440 : loss : 0.273562, loss_ce: 0.006053
[15:48:30.228] iteration 9450 : loss : 0.267921, loss_ce: 0.010347
[15:48:34.350] iteration 9460 : loss : 0.214164, loss_ce: 0.013853
[15:48:38.483] iteration 9470 : loss : 0.311685, loss_ce: 0.009587
[15:48:42.647] iteration 9480 : loss : 0.199516, loss_ce: 0.020735
[15:48:46.787] iteration 9490 : loss : 0.248799, loss_ce: 0.016749
[15:48:50.916] iteration 9500 : loss : 0.289850, loss_ce: 0.028700
[15:48:55.054] iteration 9510 : loss : 0.263419, loss_ce: 0.014161
[15:48:59.185] iteration 9520 : loss : 0.168386, loss_ce: 0.003560
[15:49:03.324] iteration 9530 : loss : 0.193196, loss_ce: 0.010524
[15:49:07.451] iteration 9540 : loss : 0.312014, loss_ce: 0.012048
[15:49:11.585] iteration 9550 : loss : 0.183955, loss_ce: 0.016864
[15:49:15.713] iteration 9560 : loss : 0.337570, loss_ce: 0.025990
[15:49:19.850] iteration 9570 : loss : 0.266398, loss_ce: 0.017535
[15:49:23.975] iteration 9580 : loss : 0.197356, loss_ce: 0.010708
[15:49:28.113] iteration 9590 : loss : 0.160298, loss_ce: 0.007666
[15:49:32.243] iteration 9600 : loss : 0.128211, loss_ce: 0.005223
[15:49:36.375] iteration 9610 : loss : 0.213013, loss_ce: 0.010862
[15:49:40.499] iteration 9620 : loss : 0.181136, loss_ce: 0.009646
[15:49:44.635] iteration 9630 : loss : 0.276076, loss_ce: 0.011449
[15:49:48.761] iteration 9640 : loss : 0.197365, loss_ce: 0.012347
[15:51:27.729] iteration 9650 : loss : 0.239147, loss_ce: 0.021470
[15:51:31.842] iteration 9660 : loss : 0.290771, loss_ce: 0.011544
[15:51:35.968] iteration 9670 : loss : 0.270326, loss_ce: 0.032556
[15:51:40.085] iteration 9680 : loss : 0.321559, loss_ce: 0.014269
[15:51:44.214] iteration 9690 : loss : 0.250606, loss_ce: 0.017075
[15:51:48.369] iteration 9700 : loss : 0.287407, loss_ce: 0.016792
[15:51:52.507] iteration 9710 : loss : 0.214154, loss_ce: 0.017751
[15:51:56.636] iteration 9720 : loss : 0.291643, loss_ce: 0.011406
[15:52:00.779] iteration 9730 : loss : 0.303340, loss_ce: 0.008078
[15:52:04.911] iteration 9740 : loss : 0.316449, loss_ce: 0.008032
[15:52:09.044] iteration 9750 : loss : 0.233506, loss_ce: 0.023260
[15:52:13.167] iteration 9760 : loss : 0.274276, loss_ce: 0.009761
[15:52:17.302] iteration 9770 : loss : 0.275250, loss_ce: 0.013288
[15:52:21.427] iteration 9780 : loss : 0.239945, loss_ce: 0.014220
[15:52:25.562] iteration 9790 : loss : 0.202183, loss_ce: 0.013343
[15:52:29.687] iteration 9800 : loss : 0.276023, loss_ce: 0.014666
[15:52:33.821] iteration 9810 : loss : 0.187682, loss_ce: 0.009626
[15:52:37.946] iteration 9820 : loss : 0.301076, loss_ce: 0.005349
[15:52:42.081] iteration 9830 : loss : 0.224820, loss_ce: 0.003085
[15:52:46.207] iteration 9840 : loss : 0.295927, loss_ce: 0.006081
[15:52:50.347] iteration 9850 : loss : 0.169877, loss_ce: 0.018527
[15:52:54.473] iteration 9860 : loss : 0.212715, loss_ce: 0.010461
[15:52:58.608] iteration 9870 : loss : 0.143697, loss_ce: 0.008250
[15:53:02.737] iteration 9880 : loss : 0.300288, loss_ce: 0.016103
[15:53:06.875] iteration 9890 : loss : 0.280983, loss_ce: 0.006161
[15:53:11.004] iteration 9900 : loss : 0.316982, loss_ce: 0.007809
[15:53:15.139] iteration 9910 : loss : 0.190695, loss_ce: 0.011251
[15:55:04.695] iteration 9920 : loss : 0.333632, loss_ce: 0.032155
[15:55:08.824] iteration 9930 : loss : 0.200645, loss_ce: 0.009305
[15:55:12.948] iteration 9940 : loss : 0.258446, loss_ce: 0.021741
[15:55:17.075] iteration 9950 : loss : 0.350947, loss_ce: 0.036551
[15:55:21.191] iteration 9960 : loss : 0.255847, loss_ce: 0.011766
[15:55:25.317] iteration 9970 : loss : 0.278036, loss_ce: 0.016317
[15:55:29.438] iteration 9980 : loss : 0.201884, loss_ce: 0.013732
[15:55:33.569] iteration 9990 : loss : 0.195566, loss_ce: 0.013669
[15:55:37.691] iteration 10000 : loss : 0.220105, loss_ce: 0.018670
[15:55:41.824] iteration 10010 : loss : 0.256368, loss_ce: 0.010048
[15:55:45.947] iteration 10020 : loss : 0.223368, loss_ce: 0.006815
[15:55:50.083] iteration 10030 : loss : 0.199253, loss_ce: 0.015114
[15:55:54.208] iteration 10040 : loss : 0.203207, loss_ce: 0.014369
[15:55:58.343] iteration 10050 : loss : 0.285602, loss_ce: 0.010344
[15:56:02.472] iteration 10060 : loss : 0.172202, loss_ce: 0.009742
[15:56:06.607] iteration 10070 : loss : 0.228354, loss_ce: 0.029051
[15:56:10.732] iteration 10080 : loss : 0.195831, loss_ce: 0.013855
[15:56:14.866] iteration 10090 : loss : 0.322072, loss_ce: 0.016841
[15:56:18.991] iteration 10100 : loss : 0.196510, loss_ce: 0.012867
[15:56:23.128] iteration 10110 : loss : 0.227707, loss_ce: 0.009838
[15:56:27.251] iteration 10120 : loss : 0.122691, loss_ce: 0.007085
[15:56:31.386] iteration 10130 : loss : 0.199089, loss_ce: 0.010665
[15:56:35.513] iteration 10140 : loss : 0.114211, loss_ce: 0.017998
[15:56:39.647] iteration 10150 : loss : 0.252603, loss_ce: 0.019696
[15:56:43.774] iteration 10160 : loss : 0.304950, loss_ce: 0.008339
[15:56:47.908] iteration 10170 : loss : 0.310332, loss_ce: 0.006984
[15:56:52.035] iteration 10180 : loss : 0.309497, loss_ce: 0.004306
[15:58:31.244] iteration 10190 : loss : 0.256575, loss_ce: 0.027861
[15:58:35.321] iteration 10200 : loss : 0.248027, loss_ce: 0.016872
[15:58:39.383] iteration 10210 : loss : 0.326228, loss_ce: 0.030385
[15:58:43.462] iteration 10220 : loss : 0.298683, loss_ce: 0.022298
[15:58:47.539] iteration 10230 : loss : 0.210443, loss_ce: 0.021176
[15:58:51.639] iteration 10240 : loss : 0.308012, loss_ce: 0.015845
[15:58:55.712] iteration 10250 : loss : 0.290412, loss_ce: 0.012981
[15:58:59.815] iteration 10260 : loss : 0.229038, loss_ce: 0.013346
[15:59:03.902] iteration 10270 : loss : 0.300833, loss_ce: 0.006909
[15:59:07.999] iteration 10280 : loss : 0.293964, loss_ce: 0.017709
[15:59:12.113] iteration 10290 : loss : 0.292525, loss_ce: 0.008674
[15:59:16.198] iteration 10300 : loss : 0.282325, loss_ce: 0.018940
[15:59:20.271] iteration 10310 : loss : 0.304516, loss_ce: 0.031369
[15:59:24.362] iteration 10320 : loss : 0.293424, loss_ce: 0.013355
[15:59:28.454] iteration 10330 : loss : 0.182859, loss_ce: 0.008517
[15:59:32.513] iteration 10340 : loss : 0.266358, loss_ce: 0.008346
[15:59:36.583] iteration 10350 : loss : 0.235203, loss_ce: 0.009276
[15:59:40.701] iteration 10360 : loss : 0.250932, loss_ce: 0.015069
[15:59:44.813] iteration 10370 : loss : 0.326791, loss_ce: 0.016491
[15:59:48.888] iteration 10380 : loss : 0.320139, loss_ce: 0.012943
[15:59:52.995] iteration 10390 : loss : 0.242541, loss_ce: 0.010573
[15:59:57.058] iteration 10400 : loss : 0.225216, loss_ce: 0.009707
[16:00:01.123] iteration 10410 : loss : 0.191893, loss_ce: 0.012129
[16:00:05.209] iteration 10420 : loss : 0.255860, loss_ce: 0.006149
[16:00:09.289] iteration 10430 : loss : 0.185211, loss_ce: 0.007073
[16:00:13.402] iteration 10440 : loss : 0.239677, loss_ce: 0.007817
[16:00:17.491] iteration 10450 : loss : 0.212816, loss_ce: 0.020054
[16:02:00.192] iteration 10460 : loss : 0.228287, loss_ce: 0.015414
[16:02:04.604] iteration 10470 : loss : 0.321860, loss_ce: 0.012076
[16:02:09.006] iteration 10480 : loss : 0.321042, loss_ce: 0.008477
[16:02:13.413] iteration 10490 : loss : 0.243836, loss_ce: 0.015448
[16:02:17.814] iteration 10500 : loss : 0.270019, loss_ce: 0.014500
[16:02:22.229] iteration 10510 : loss : 0.242326, loss_ce: 0.014637
[16:02:26.637] iteration 10520 : loss : 0.247259, loss_ce: 0.014751
[16:02:31.059] iteration 10530 : loss : 0.161026, loss_ce: 0.008442
[16:02:35.468] iteration 10540 : loss : 0.284813, loss_ce: 0.006887
[16:02:39.882] iteration 10550 : loss : 0.204902, loss_ce: 0.012800
[16:02:44.289] iteration 10560 : loss : 0.260746, loss_ce: 0.012326
[16:02:48.706] iteration 10570 : loss : 0.278816, loss_ce: 0.008476
[16:02:53.119] iteration 10580 : loss : 0.295679, loss_ce: 0.008456
[16:02:57.543] iteration 10590 : loss : 0.209556, loss_ce: 0.017922
[16:03:01.958] iteration 10600 : loss : 0.292241, loss_ce: 0.003554
[16:03:06.386] iteration 10610 : loss : 0.280683, loss_ce: 0.006311
[16:03:10.801] iteration 10620 : loss : 0.211685, loss_ce: 0.011386
[16:03:15.225] iteration 10630 : loss : 0.216087, loss_ce: 0.015233
[16:03:19.639] iteration 10640 : loss : 0.181349, loss_ce: 0.009771
[16:03:24.055] iteration 10650 : loss : 0.174201, loss_ce: 0.018492
[16:03:28.464] iteration 10660 : loss : 0.207800, loss_ce: 0.014376
[16:03:32.878] iteration 10670 : loss : 0.215515, loss_ce: 0.006893
[16:03:37.282] iteration 10680 : loss : 0.198487, loss_ce: 0.012529
[16:03:41.699] iteration 10690 : loss : 0.197848, loss_ce: 0.008820
[16:03:46.104] iteration 10700 : loss : 0.311215, loss_ce: 0.006987
[16:03:50.525] iteration 10710 : loss : 0.234895, loss_ce: 0.007359
[16:03:54.836] iteration 10720 : loss : 0.144773, loss_ce: 0.011240
[16:05:36.360] save model to ./finetune_tpgm_kits23_2\finetuned_epoch_39.pth
[16:05:50.496] iteration 10730 : loss : 0.283990, loss_ce: 0.022251
[16:05:54.558] iteration 10740 : loss : 0.341446, loss_ce: 0.038634
[16:05:58.782] iteration 10750 : loss : 0.238968, loss_ce: 0.011948
[16:06:02.902] iteration 10760 : loss : 0.320612, loss_ce: 0.023611
[16:06:06.965] iteration 10770 : loss : 0.315574, loss_ce: 0.014514
[16:06:11.045] iteration 10780 : loss : 0.222391, loss_ce: 0.016778
[16:06:15.125] iteration 10790 : loss : 0.244992, loss_ce: 0.014291
[16:06:19.218] iteration 10800 : loss : 0.199717, loss_ce: 0.014252
[16:06:23.296] iteration 10810 : loss : 0.319373, loss_ce: 0.009868
[16:06:27.357] iteration 10820 : loss : 0.238546, loss_ce: 0.030081
[16:06:31.452] iteration 10830 : loss : 0.202475, loss_ce: 0.011548
[16:06:35.534] iteration 10840 : loss : 0.323765, loss_ce: 0.010171
[16:06:39.596] iteration 10850 : loss : 0.230631, loss_ce: 0.009780
[16:06:43.649] iteration 10860 : loss : 0.281693, loss_ce: 0.009777
[16:06:47.711] iteration 10870 : loss : 0.245839, loss_ce: 0.021428
[16:06:51.772] iteration 10880 : loss : 0.200832, loss_ce: 0.016108
[16:06:55.835] iteration 10890 : loss : 0.205547, loss_ce: 0.008058
[16:06:59.889] iteration 10900 : loss : 0.229459, loss_ce: 0.009561
[16:07:03.954] iteration 10910 : loss : 0.214872, loss_ce: 0.011586
[16:07:08.008] iteration 10920 : loss : 0.226236, loss_ce: 0.008796
[16:07:12.071] iteration 10930 : loss : 0.233746, loss_ce: 0.013934
[16:07:16.132] iteration 10940 : loss : 0.272032, loss_ce: 0.005493
[16:07:20.205] iteration 10950 : loss : 0.218993, loss_ce: 0.005034
[16:07:24.289] iteration 10960 : loss : 0.166630, loss_ce: 0.015189
[16:07:28.376] iteration 10970 : loss : 0.253845, loss_ce: 0.009079
[16:07:32.428] iteration 10980 : loss : 0.165817, loss_ce: 0.004246
[16:09:10.432] iteration 10990 : loss : 0.337313, loss_ce: 0.029975
[16:09:14.484] iteration 11000 : loss : 0.253896, loss_ce: 0.016748
[16:09:18.571] iteration 11010 : loss : 0.317314, loss_ce: 0.055670
[16:09:22.617] iteration 11020 : loss : 0.317510, loss_ce: 0.011274
[16:09:26.703] iteration 11030 : loss : 0.292261, loss_ce: 0.022763
[16:09:30.785] iteration 11040 : loss : 0.306343, loss_ce: 0.015107
[16:09:34.848] iteration 11050 : loss : 0.208428, loss_ce: 0.009174
[16:09:38.902] iteration 11060 : loss : 0.194312, loss_ce: 0.019847
[16:09:42.987] iteration 11070 : loss : 0.214879, loss_ce: 0.019049
[16:09:47.057] iteration 11080 : loss : 0.122215, loss_ce: 0.013620
[16:09:51.132] iteration 11090 : loss : 0.225174, loss_ce: 0.019734
[16:09:55.186] iteration 11100 : loss : 0.259756, loss_ce: 0.015274
[16:09:59.255] iteration 11110 : loss : 0.219529, loss_ce: 0.013094
[16:10:03.314] iteration 11120 : loss : 0.215184, loss_ce: 0.008134
[16:10:07.396] iteration 11130 : loss : 0.239921, loss_ce: 0.009367
[16:10:11.453] iteration 11140 : loss : 0.203919, loss_ce: 0.012273
[16:10:15.525] iteration 11150 : loss : 0.274780, loss_ce: 0.006822
[16:10:19.607] iteration 11160 : loss : 0.212339, loss_ce: 0.013153
[16:10:23.681] iteration 11170 : loss : 0.230714, loss_ce: 0.007159
[16:10:27.753] iteration 11180 : loss : 0.214872, loss_ce: 0.016821
[16:10:31.858] iteration 11190 : loss : 0.233407, loss_ce: 0.015873
[16:10:35.923] iteration 11200 : loss : 0.212099, loss_ce: 0.012255
[16:10:40.038] iteration 11210 : loss : 0.198842, loss_ce: 0.009590
[16:10:44.105] iteration 11220 : loss : 0.194722, loss_ce: 0.014537
[16:10:48.181] iteration 11230 : loss : 0.207678, loss_ce: 0.012252
[16:10:52.236] iteration 11240 : loss : 0.284842, loss_ce: 0.007516
[16:10:56.333] iteration 11250 : loss : 0.251520, loss_ce: 0.015440
[16:12:34.185] iteration 11260 : loss : 0.330429, loss_ce: 0.034494
[16:12:38.456] iteration 11270 : loss : 0.310591, loss_ce: 0.012627
[16:12:42.606] iteration 11280 : loss : 0.336928, loss_ce: 0.012299
[16:12:46.675] iteration 11290 : loss : 0.339431, loss_ce: 0.018630
[16:12:50.720] iteration 11300 : loss : 0.237449, loss_ce: 0.014797
[16:12:54.777] iteration 11310 : loss : 0.199450, loss_ce: 0.012344
[16:12:58.826] iteration 11320 : loss : 0.215595, loss_ce: 0.016972
[16:13:02.899] iteration 11330 : loss : 0.290808, loss_ce: 0.008691
[16:13:06.985] iteration 11340 : loss : 0.257956, loss_ce: 0.014778
[16:13:11.044] iteration 11350 : loss : 0.263362, loss_ce: 0.013997
[16:13:15.110] iteration 11360 : loss : 0.214518, loss_ce: 0.019664
[16:13:19.450] iteration 11370 : loss : 0.163454, loss_ce: 0.017792
[16:13:23.931] iteration 11380 : loss : 0.306736, loss_ce: 0.012688
[16:13:28.361] iteration 11390 : loss : 0.291765, loss_ce: 0.009496
[16:13:32.753] iteration 11400 : loss : 0.207261, loss_ce: 0.008748
[16:13:37.146] iteration 11410 : loss : 0.207096, loss_ce: 0.009723
[16:13:41.568] iteration 11420 : loss : 0.266339, loss_ce: 0.011144
[16:13:45.983] iteration 11430 : loss : 0.184800, loss_ce: 0.013398
[16:13:50.385] iteration 11440 : loss : 0.172721, loss_ce: 0.007201
[16:13:54.826] iteration 11450 : loss : 0.186891, loss_ce: 0.011238
[16:13:59.252] iteration 11460 : loss : 0.219535, loss_ce: 0.013193
[16:14:03.716] iteration 11470 : loss : 0.226187, loss_ce: 0.013558
[16:14:08.084] iteration 11480 : loss : 0.299581, loss_ce: 0.006010
[16:14:12.428] iteration 11490 : loss : 0.234633, loss_ce: 0.006433
[16:14:16.764] iteration 11500 : loss : 0.245044, loss_ce: 0.009622
[16:14:21.215] iteration 11510 : loss : 0.094288, loss_ce: 0.011167
[16:14:25.390] iteration 11520 : loss : 0.285976, loss_ce: 0.006105
[16:16:19.068] iteration 11530 : loss : 0.324134, loss_ce: 0.029611
[16:16:23.427] iteration 11540 : loss : 0.248403, loss_ce: 0.026505
[16:16:27.800] iteration 11550 : loss : 0.271780, loss_ce: 0.012703
[16:16:32.148] iteration 11560 : loss : 0.228663, loss_ce: 0.024156
[16:16:36.506] iteration 11570 : loss : 0.195026, loss_ce: 0.014148
[16:16:40.904] iteration 11580 : loss : 0.310645, loss_ce: 0.012006
[16:16:45.296] iteration 11590 : loss : 0.310368, loss_ce: 0.011764
[16:16:49.660] iteration 11600 : loss : 0.201106, loss_ce: 0.016427
[16:16:54.038] iteration 11610 : loss : 0.186374, loss_ce: 0.015250
[16:16:58.416] iteration 11620 : loss : 0.215665, loss_ce: 0.017931
[16:17:02.953] iteration 11630 : loss : 0.182429, loss_ce: 0.008355
[16:17:07.325] iteration 11640 : loss : 0.190527, loss_ce: 0.013556
[16:17:11.752] iteration 11650 : loss : 0.193506, loss_ce: 0.013568
[16:17:16.319] iteration 11660 : loss : 0.232302, loss_ce: 0.008155
[16:17:20.738] iteration 11670 : loss : 0.230228, loss_ce: 0.010283
[16:17:25.111] iteration 11680 : loss : 0.200438, loss_ce: 0.011100
[16:17:29.479] iteration 11690 : loss : 0.252470, loss_ce: 0.014747
[16:17:33.850] iteration 11700 : loss : 0.312965, loss_ce: 0.009430
[16:17:38.238] iteration 11710 : loss : 0.164976, loss_ce: 0.012765
[16:17:42.537] iteration 11720 : loss : 0.224279, loss_ce: 0.009510
[16:17:46.593] iteration 11730 : loss : 0.253748, loss_ce: 0.008159
[16:17:50.647] iteration 11740 : loss : 0.184736, loss_ce: 0.007304
[16:17:54.749] iteration 11750 : loss : 0.225461, loss_ce: 0.012767
[16:17:58.863] iteration 11760 : loss : 0.238043, loss_ce: 0.010257
[16:18:02.926] iteration 11770 : loss : 0.231326, loss_ce: 0.018640
[16:18:06.981] iteration 11780 : loss : 0.209427, loss_ce: 0.010757
[16:18:11.318] iteration 11790 : loss : 0.301606, loss_ce: 0.012907
[16:19:55.863] iteration 11800 : loss : 0.346646, loss_ce: 0.025394
[16:20:00.270] iteration 11810 : loss : 0.215172, loss_ce: 0.018212
[16:20:04.672] iteration 11820 : loss : 0.230328, loss_ce: 0.019335
[16:20:09.080] iteration 11830 : loss : 0.282688, loss_ce: 0.024860
[16:20:13.481] iteration 11840 : loss : 0.221019, loss_ce: 0.020955
[16:20:17.894] iteration 11850 : loss : 0.315068, loss_ce: 0.009165
[16:20:22.325] iteration 11860 : loss : 0.254691, loss_ce: 0.032268
[16:20:26.755] iteration 11870 : loss : 0.163366, loss_ce: 0.016390
[16:20:31.173] iteration 11880 : loss : 0.265833, loss_ce: 0.023490
[16:20:35.684] iteration 11890 : loss : 0.228982, loss_ce: 0.007494
[16:20:40.139] iteration 11900 : loss : 0.217889, loss_ce: 0.013759
[16:20:44.618] iteration 11910 : loss : 0.237941, loss_ce: 0.007797
[16:20:49.090] iteration 11920 : loss : 0.229462, loss_ce: 0.011221
[16:20:53.575] iteration 11930 : loss : 0.202158, loss_ce: 0.006476
[16:20:58.038] iteration 11940 : loss : 0.251222, loss_ce: 0.013164
[16:21:02.512] iteration 11950 : loss : 0.183685, loss_ce: 0.014622
[16:21:06.971] iteration 11960 : loss : 0.199530, loss_ce: 0.010407
[16:21:11.462] iteration 11970 : loss : 0.166143, loss_ce: 0.009441
[16:21:15.922] iteration 11980 : loss : 0.255662, loss_ce: 0.010808
[16:21:20.396] iteration 11990 : loss : 0.220580, loss_ce: 0.008715
[16:21:24.862] iteration 12000 : loss : 0.212736, loss_ce: 0.012689
[16:21:29.345] iteration 12010 : loss : 0.168381, loss_ce: 0.012577
[16:21:33.827] iteration 12020 : loss : 0.202422, loss_ce: 0.010590
[16:21:38.306] iteration 12030 : loss : 0.146527, loss_ce: 0.008275
[16:21:42.772] iteration 12040 : loss : 0.189587, loss_ce: 0.009823
[16:21:47.252] iteration 12050 : loss : 0.205377, loss_ce: 0.012416
[16:21:51.670] iteration 12060 : loss : 0.274231, loss_ce: 0.021776
[16:23:34.326] iteration 12070 : loss : 0.303446, loss_ce: 0.030220
[16:23:38.719] iteration 12080 : loss : 0.311089, loss_ce: 0.020295
[16:23:43.105] iteration 12090 : loss : 0.305397, loss_ce: 0.024314
[16:23:47.473] iteration 12100 : loss : 0.336754, loss_ce: 0.030216
[16:23:51.854] iteration 12110 : loss : 0.251663, loss_ce: 0.018847
[16:23:56.229] iteration 12120 : loss : 0.311968, loss_ce: 0.014805
[16:24:00.616] iteration 12130 : loss : 0.196054, loss_ce: 0.013961
[16:24:05.030] iteration 12140 : loss : 0.303137, loss_ce: 0.025743
[16:24:09.404] iteration 12150 : loss : 0.256475, loss_ce: 0.021577
[16:24:13.818] iteration 12160 : loss : 0.268998, loss_ce: 0.022249
[16:24:18.242] iteration 12170 : loss : 0.289162, loss_ce: 0.009801
[16:24:22.706] iteration 12180 : loss : 0.218165, loss_ce: 0.015755
[16:24:27.181] iteration 12190 : loss : 0.172360, loss_ce: 0.013427
[16:24:31.602] iteration 12200 : loss : 0.187524, loss_ce: 0.014644
[16:24:36.032] iteration 12210 : loss : 0.203447, loss_ce: 0.012832
[16:24:40.420] iteration 12220 : loss : 0.191471, loss_ce: 0.015632
[16:24:44.791] iteration 12230 : loss : 0.296445, loss_ce: 0.008909
[16:24:49.158] iteration 12240 : loss : 0.206756, loss_ce: 0.011898
[16:24:53.511] iteration 12250 : loss : 0.264673, loss_ce: 0.020245
[16:24:57.854] iteration 12260 : loss : 0.215859, loss_ce: 0.010435
[16:25:02.204] iteration 12270 : loss : 0.199489, loss_ce: 0.017648
[16:25:06.543] iteration 12280 : loss : 0.246979, loss_ce: 0.009281
[16:25:10.891] iteration 12290 : loss : 0.316331, loss_ce: 0.017422
[16:25:15.241] iteration 12300 : loss : 0.196047, loss_ce: 0.014899
[16:25:19.625] iteration 12310 : loss : 0.197015, loss_ce: 0.011968
[16:25:23.973] iteration 12320 : loss : 0.210631, loss_ce: 0.011047
[16:27:16.352] iteration 12330 : loss : 0.402466, loss_ce: 0.046304
[16:27:20.712] iteration 12340 : loss : 0.369666, loss_ce: 0.030860
[16:27:25.185] iteration 12350 : loss : 0.255199, loss_ce: 0.030257
[16:27:29.610] iteration 12360 : loss : 0.221005, loss_ce: 0.026423
[16:27:34.066] iteration 12370 : loss : 0.248537, loss_ce: 0.026625
[16:27:38.545] iteration 12380 : loss : 0.291510, loss_ce: 0.027806
[16:27:43.214] iteration 12390 : loss : 0.293317, loss_ce: 0.021649
[16:27:47.866] iteration 12400 : loss : 0.222328, loss_ce: 0.027771
[16:27:52.484] iteration 12410 : loss : 0.309249, loss_ce: 0.012152
[16:27:57.132] iteration 12420 : loss : 0.327453, loss_ce: 0.017216
[16:28:01.835] iteration 12430 : loss : 0.230755, loss_ce: 0.017976
[16:28:06.503] iteration 12440 : loss : 0.254695, loss_ce: 0.020949
[16:28:11.103] iteration 12450 : loss : 0.195779, loss_ce: 0.020700
[16:28:15.593] iteration 12460 : loss : 0.209312, loss_ce: 0.017315
[16:28:20.058] iteration 12470 : loss : 0.199565, loss_ce: 0.017453
[16:28:24.476] iteration 12480 : loss : 0.326806, loss_ce: 0.019244
[16:28:28.960] iteration 12490 : loss : 0.180439, loss_ce: 0.011154
[16:28:33.487] iteration 12500 : loss : 0.237909, loss_ce: 0.018992
[16:28:37.910] iteration 12510 : loss : 0.218498, loss_ce: 0.018451
[16:28:42.376] iteration 12520 : loss : 0.196278, loss_ce: 0.017126
[16:28:47.019] iteration 12530 : loss : 0.206526, loss_ce: 0.014706
[16:28:51.536] iteration 12540 : loss : 0.207641, loss_ce: 0.014527
[16:28:56.029] iteration 12550 : loss : 0.290334, loss_ce: 0.015381
[16:29:00.605] iteration 12560 : loss : 0.241292, loss_ce: 0.012413
[16:29:05.228] iteration 12570 : loss : 0.298224, loss_ce: 0.008380
[16:29:09.723] iteration 12580 : loss : 0.312597, loss_ce: 0.010795
[16:29:14.255] iteration 12590 : loss : 0.246927, loss_ce: 0.023592
[16:30:59.326] iteration 12600 : loss : 0.389224, loss_ce: 0.043116
[16:31:03.680] iteration 12610 : loss : 0.377013, loss_ce: 0.047321
[16:31:08.037] iteration 12620 : loss : 0.320374, loss_ce: 0.038697
[16:31:12.392] iteration 12630 : loss : 0.258594, loss_ce: 0.028999
[16:31:16.749] iteration 12640 : loss : 0.244464, loss_ce: 0.026876
[16:31:21.131] iteration 12650 : loss : 0.310293, loss_ce: 0.022074
[16:31:25.516] iteration 12660 : loss : 0.334046, loss_ce: 0.026066
[16:31:29.906] iteration 12670 : loss : 0.240067, loss_ce: 0.027987
[16:31:34.263] iteration 12680 : loss : 0.231429, loss_ce: 0.024319
[16:31:38.630] iteration 12690 : loss : 0.260279, loss_ce: 0.022674
[16:31:43.015] iteration 12700 : loss : 0.207893, loss_ce: 0.020426
[16:31:47.379] iteration 12710 : loss : 0.207993, loss_ce: 0.018979
[16:31:51.759] iteration 12720 : loss : 0.291037, loss_ce: 0.027499
[16:31:56.302] iteration 12730 : loss : 0.210681, loss_ce: 0.014352
[16:32:00.753] iteration 12740 : loss : 0.238381, loss_ce: 0.020183
[16:32:05.252] iteration 12750 : loss : 0.281294, loss_ce: 0.015030
[16:32:09.831] iteration 12760 : loss : 0.234436, loss_ce: 0.024459
[16:32:14.408] iteration 12770 : loss : 0.195194, loss_ce: 0.018759
[16:32:18.951] iteration 12780 : loss : 0.297197, loss_ce: 0.014333
[16:32:23.379] iteration 12790 : loss : 0.336204, loss_ce: 0.014390
[16:32:27.782] iteration 12800 : loss : 0.220146, loss_ce: 0.021108
[16:32:32.158] iteration 12810 : loss : 0.212786, loss_ce: 0.016976
[16:32:36.519] iteration 12820 : loss : 0.262776, loss_ce: 0.017824
[16:32:40.938] iteration 12830 : loss : 0.220699, loss_ce: 0.015838
[16:32:45.318] iteration 12840 : loss : 0.268450, loss_ce: 0.016898
[16:32:49.746] iteration 12850 : loss : 0.235184, loss_ce: 0.021433
[16:32:54.129] iteration 12860 : loss : 0.327853, loss_ce: 0.010355
[16:34:37.432] iteration 12870 : loss : 0.430850, loss_ce: 0.043927
[16:34:41.775] iteration 12880 : loss : 0.409895, loss_ce: 0.049747
[16:34:46.114] iteration 12890 : loss : 0.374069, loss_ce: 0.049879
[16:34:50.437] iteration 12900 : loss : 0.338196, loss_ce: 0.038521
[16:34:54.796] iteration 12910 : loss : 0.380750, loss_ce: 0.035177
[16:34:59.184] iteration 12920 : loss : 0.346590, loss_ce: 0.037904
[16:35:03.550] iteration 12930 : loss : 0.348490, loss_ce: 0.035203
[16:35:07.925] iteration 12940 : loss : 0.297187, loss_ce: 0.041328
[16:35:12.240] iteration 12950 : loss : 0.270041, loss_ce: 0.028840
[16:35:16.425] iteration 12960 : loss : 0.338941, loss_ce: 0.024439
[16:35:20.823] iteration 12970 : loss : 0.225404, loss_ce: 0.024187
[16:35:25.197] iteration 12980 : loss : 0.306551, loss_ce: 0.032676
[16:35:29.599] iteration 12990 : loss : 0.342719, loss_ce: 0.026594
[16:35:33.739] iteration 13000 : loss : 0.280592, loss_ce: 0.030181
[16:35:37.868] iteration 13010 : loss : 0.222841, loss_ce: 0.022341
[16:35:41.980] iteration 13020 : loss : 0.287722, loss_ce: 0.033574
[16:35:46.093] iteration 13030 : loss : 0.304354, loss_ce: 0.027752
[16:35:50.222] iteration 13040 : loss : 0.225987, loss_ce: 0.019148
[16:35:54.321] iteration 13050 : loss : 0.222104, loss_ce: 0.018044
[16:35:58.447] iteration 13060 : loss : 0.333593, loss_ce: 0.019693
[16:36:02.618] iteration 13070 : loss : 0.261879, loss_ce: 0.026788
[16:36:06.770] iteration 13080 : loss : 0.215886, loss_ce: 0.019904
[16:36:10.922] iteration 13090 : loss : 0.222267, loss_ce: 0.022204
[16:36:15.132] iteration 13100 : loss : 0.311805, loss_ce: 0.023106
[16:36:19.324] iteration 13110 : loss : 0.338586, loss_ce: 0.032108
[16:36:23.491] iteration 13120 : loss : 0.203350, loss_ce: 0.015708
[16:36:27.677] iteration 13130 : loss : 0.310094, loss_ce: 0.032981
[16:38:16.916] iteration 13140 : loss : 0.440308, loss_ce: 0.067728
[16:38:20.989] iteration 13150 : loss : 0.436114, loss_ce: 0.074874
[16:38:25.031] iteration 13160 : loss : 0.422250, loss_ce: 0.055940
[16:38:29.147] iteration 13170 : loss : 0.380519, loss_ce: 0.052903
[16:38:33.223] iteration 13180 : loss : 0.351643, loss_ce: 0.053383
[16:38:37.349] iteration 13190 : loss : 0.407681, loss_ce: 0.057997
[16:38:41.457] iteration 13200 : loss : 0.386150, loss_ce: 0.058035
[16:38:45.543] iteration 13210 : loss : 0.384197, loss_ce: 0.049426
[16:38:49.608] iteration 13220 : loss : 0.374452, loss_ce: 0.057268
[16:38:53.687] iteration 13230 : loss : 0.371024, loss_ce: 0.051923
[16:38:57.771] iteration 13240 : loss : 0.418958, loss_ce: 0.045870
[16:39:01.840] iteration 13250 : loss : 0.389450, loss_ce: 0.058574
[16:39:05.913] iteration 13260 : loss : 0.363818, loss_ce: 0.052944
[16:39:10.000] iteration 13270 : loss : 0.383597, loss_ce: 0.056659
[16:39:14.073] iteration 13280 : loss : 0.402028, loss_ce: 0.054135
[16:39:18.157] iteration 13290 : loss : 0.352814, loss_ce: 0.048189
[16:39:22.270] iteration 13300 : loss : 0.295222, loss_ce: 0.039566
[16:39:26.367] iteration 13310 : loss : 0.359585, loss_ce: 0.037946
[16:39:30.448] iteration 13320 : loss : 0.337148, loss_ce: 0.044794
[16:39:34.565] iteration 13330 : loss : 0.375642, loss_ce: 0.054180
[16:39:38.665] iteration 13340 : loss : 0.390906, loss_ce: 0.045313
[16:39:42.726] iteration 13350 : loss : 0.333888, loss_ce: 0.039162
[16:39:46.777] iteration 13360 : loss : 0.374594, loss_ce: 0.039176
[16:39:50.835] iteration 13370 : loss : 0.356581, loss_ce: 0.037006
[16:39:54.883] iteration 13380 : loss : 0.297189, loss_ce: 0.038424
[16:39:58.941] iteration 13390 : loss : 0.302493, loss_ce: 0.033099
[16:40:02.900] iteration 13400 : loss : 0.283404, loss_ce: 0.038541
[16:41:27.538] save model to ./finetune_tpgm_kits23_2\finetuned_epoch_49.pth
[16:41:27.746] save final model to ./finetune_tpgm_kits23_2\finetuned_final.pth
